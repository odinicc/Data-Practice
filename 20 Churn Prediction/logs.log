2024-02-04 00:29:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 00:29:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 00:29:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 00:29:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 18:25:52,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 18:25:52,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 18:25:52,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 18:25:52,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 19:26:23,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 19:26:23,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 19:26:23,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 19:26:23,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 20:02:05,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 20:02:05,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 20:02:05,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 20:02:05,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 21:14:37,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 21:14:37,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 21:14:37,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 21:14:37,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:10:00,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:10:00,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:10:00,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:10:00,869:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:15:37,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:15:37,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:15:37,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:15:37,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:47:12,423:WARNING:C:\Users\user\AppData\Local\Temp\ipykernel_1752\700273268.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.
  df_train[df_train[df_train.columns].isnull().any(1)]

2024-02-04 22:47:29,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:47:29,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:47:29,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:47:29,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 22:47:41,017:INFO:PyCaret ClassificationExperiment
2024-02-04 22:47:41,017:INFO:Logging name: clf-default-name
2024-02-04 22:47:41,017:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 22:47:41,017:INFO:version 3.2.0
2024-02-04 22:47:41,017:INFO:Initializing setup()
2024-02-04 22:47:41,017:INFO:self.USI: 8812
2024-02-04 22:47:41,017:INFO:self._variable_keys: {'data', 'log_plots_param', 'pipeline', 'gpu_n_jobs_param', 'target_param', 'y_train', 'fold_generator', 'gpu_param', 'fold_shuffle_param', 'idx', 'html_param', 'fix_imbalance', 'is_multiclass', 'logging_param', 'y', 'X', 'X_train', '_available_plots', 'exp_id', 'USI', '_ml_usecase', 'seed', 'y_test', 'n_jobs_param', 'fold_groups_param', 'X_test', 'exp_name_log', 'memory'}
2024-02-04 22:47:41,017:INFO:Checking environment
2024-02-04 22:47:41,017:INFO:python_version: 3.10.9
2024-02-04 22:47:41,017:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 22:47:41,018:INFO:machine: AMD64
2024-02-04 22:47:41,018:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 22:47:41,018:INFO:Memory: svmem(total=16856182784, available=9569951744, percent=43.2, used=7286231040, free=9569951744)
2024-02-04 22:47:41,018:INFO:Physical Core: 4
2024-02-04 22:47:41,018:INFO:Logical Core: 8
2024-02-04 22:47:41,018:INFO:Checking libraries
2024-02-04 22:47:41,018:INFO:System:
2024-02-04 22:47:41,018:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 22:47:41,018:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 22:47:41,018:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 22:47:41,018:INFO:PyCaret required dependencies:
2024-02-04 22:47:41,106:INFO:                 pip: 22.3.1
2024-02-04 22:47:41,106:INFO:          setuptools: 65.6.3
2024-02-04 22:47:41,106:INFO:             pycaret: 3.2.0
2024-02-04 22:47:41,106:INFO:             IPython: 8.20.0
2024-02-04 22:47:41,107:INFO:          ipywidgets: 8.0.4
2024-02-04 22:47:41,107:INFO:                tqdm: 4.64.1
2024-02-04 22:47:41,107:INFO:               numpy: 1.25.2
2024-02-04 22:47:41,107:INFO:              pandas: 1.5.3
2024-02-04 22:47:41,107:INFO:              jinja2: 3.1.3
2024-02-04 22:47:41,107:INFO:               scipy: 1.10.1
2024-02-04 22:47:41,107:INFO:              joblib: 1.3.2
2024-02-04 22:47:41,107:INFO:             sklearn: 1.2.2
2024-02-04 22:47:41,107:INFO:                pyod: 1.1.2
2024-02-04 22:47:41,107:INFO:            imblearn: 0.12.0
2024-02-04 22:47:41,107:INFO:   category_encoders: 2.6.3
2024-02-04 22:47:41,107:INFO:            lightgbm: 4.3.0
2024-02-04 22:47:41,107:INFO:               numba: 0.59.0
2024-02-04 22:47:41,107:INFO:            requests: 2.31.0
2024-02-04 22:47:41,107:INFO:          matplotlib: 3.6.0
2024-02-04 22:47:41,107:INFO:          scikitplot: 0.3.7
2024-02-04 22:47:41,107:INFO:         yellowbrick: 1.5
2024-02-04 22:47:41,107:INFO:              plotly: 5.18.0
2024-02-04 22:47:41,107:INFO:    plotly-resampler: Not installed
2024-02-04 22:47:41,107:INFO:             kaleido: 0.2.1
2024-02-04 22:47:41,107:INFO:           schemdraw: 0.15
2024-02-04 22:47:41,107:INFO:         statsmodels: 0.14.1
2024-02-04 22:47:41,107:INFO:              sktime: 0.21.1
2024-02-04 22:47:41,108:INFO:               tbats: 1.1.3
2024-02-04 22:47:41,108:INFO:            pmdarima: 2.0.4
2024-02-04 22:47:41,108:INFO:              psutil: 5.9.0
2024-02-04 22:47:41,108:INFO:          markupsafe: 2.1.3
2024-02-04 22:47:41,108:INFO:             pickle5: Not installed
2024-02-04 22:47:41,108:INFO:         cloudpickle: 3.0.0
2024-02-04 22:47:41,108:INFO:         deprecation: 2.1.0
2024-02-04 22:47:41,108:INFO:              xxhash: 3.4.1
2024-02-04 22:47:41,108:INFO:           wurlitzer: Not installed
2024-02-04 22:47:41,108:INFO:PyCaret optional dependencies:
2024-02-04 22:47:41,120:INFO:                shap: 0.44.1
2024-02-04 22:47:41,120:INFO:           interpret: Not installed
2024-02-04 22:47:41,120:INFO:                umap: Not installed
2024-02-04 22:47:41,120:INFO:     ydata_profiling: Not installed
2024-02-04 22:47:41,120:INFO:  explainerdashboard: 0.4.5
2024-02-04 22:47:41,120:INFO:             autoviz: Not installed
2024-02-04 22:47:41,120:INFO:           fairlearn: Not installed
2024-02-04 22:47:41,120:INFO:          deepchecks: Not installed
2024-02-04 22:47:41,120:INFO:             xgboost: Not installed
2024-02-04 22:47:41,120:INFO:            catboost: 1.2.2
2024-02-04 22:47:41,120:INFO:              kmodes: Not installed
2024-02-04 22:47:41,120:INFO:             mlxtend: Not installed
2024-02-04 22:47:41,120:INFO:       statsforecast: Not installed
2024-02-04 22:47:41,120:INFO:        tune_sklearn: Not installed
2024-02-04 22:47:41,120:INFO:                 ray: Not installed
2024-02-04 22:47:41,120:INFO:            hyperopt: Not installed
2024-02-04 22:47:41,121:INFO:              optuna: Not installed
2024-02-04 22:47:41,121:INFO:               skopt: Not installed
2024-02-04 22:47:41,121:INFO:              mlflow: 2.10.0
2024-02-04 22:47:41,121:INFO:              gradio: Not installed
2024-02-04 22:47:41,121:INFO:             fastapi: Not installed
2024-02-04 22:47:41,121:INFO:             uvicorn: Not installed
2024-02-04 22:47:41,121:INFO:              m2cgen: Not installed
2024-02-04 22:47:41,121:INFO:           evidently: Not installed
2024-02-04 22:47:41,121:INFO:               fugue: Not installed
2024-02-04 22:47:41,121:INFO:           streamlit: Not installed
2024-02-04 22:47:41,121:INFO:             prophet: Not installed
2024-02-04 22:47:41,121:INFO:None
2024-02-04 22:47:41,121:INFO:Set up data.
2024-02-04 22:47:41,134:INFO:Set up folding strategy.
2024-02-04 22:47:41,134:INFO:Set up train/test split.
2024-02-04 22:47:41,145:INFO:Set up index.
2024-02-04 22:47:41,146:INFO:Assigning column types.
2024-02-04 22:47:41,151:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 22:47:41,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,199:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,234:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,331:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,332:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 22:47:41,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,453:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,497:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:47:41,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,524:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,524:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 22:47:41,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,592:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:41,666:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:41,668:INFO:Preparing preprocessing pipeline...
2024-02-04 22:47:41,669:INFO:Set up label encoding.
2024-02-04 22:47:41,669:INFO:Set up simple imputation.
2024-02-04 22:47:41,673:INFO:Set up encoding of ordinal features.
2024-02-04 22:47:41,678:INFO:Set up encoding of categorical features.
2024-02-04 22:47:41,828:INFO:Finished creating preprocessing pipeline.
2024-02-04 22:47:41,853:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'to...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-02-04 22:47:41,853:INFO:Creating final display dataframe.
2024-02-04 22:47:42,169:INFO:Setup _display_container:                     Description             Value
0                    Session id              2010
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 20)
5        Transformed data shape        (4250, 22)
6   Transformed train set shape        (2975, 22)
7    Transformed test set shape        (1275, 22)
8              Ordinal features                 2
9              Numeric features                15
10         Categorical features                 4
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              8812
2024-02-04 22:47:42,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:42,259:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:42,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:47:42,335:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:47:42,336:INFO:setup() successfully completed in 1.33s...............
2024-02-04 22:47:42,352:INFO:Initializing compare_models()
2024-02-04 22:47:42,352:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-04 22:47:42,352:INFO:Checking exceptions
2024-02-04 22:47:42,357:INFO:Preparing display monitor
2024-02-04 22:47:42,402:INFO:Initializing Logistic Regression
2024-02-04 22:47:42,403:INFO:Total runtime is 1.6617774963378907e-05 minutes
2024-02-04 22:47:42,408:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:42,408:INFO:Initializing create_model()
2024-02-04 22:47:42,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:42,409:INFO:Checking exceptions
2024-02-04 22:47:42,409:INFO:Importing libraries
2024-02-04 22:47:42,409:INFO:Copying training dataset
2024-02-04 22:47:42,419:INFO:Defining folds
2024-02-04 22:47:42,419:INFO:Declaring metric variables
2024-02-04 22:47:42,422:INFO:Importing untrained model
2024-02-04 22:47:42,426:INFO:Logistic Regression Imported successfully
2024-02-04 22:47:42,448:INFO:Starting cross validation
2024-02-04 22:47:42,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:48,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,745:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,763:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,790:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,795:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:48,870:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:48,975:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:49,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:49,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:47:49,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,392:INFO:Calculating mean and std
2024-02-04 22:47:49,393:INFO:Creating metrics dataframe
2024-02-04 22:47:49,396:INFO:Uploading results into container
2024-02-04 22:47:49,397:INFO:Uploading model into container now
2024-02-04 22:47:49,397:INFO:_master_model_container: 1
2024-02-04 22:47:49,397:INFO:_display_container: 2
2024-02-04 22:47:49,398:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2010, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:47:49,398:INFO:create_model() successfully completed......................................
2024-02-04 22:47:49,565:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:49,565:INFO:Creating metrics dataframe
2024-02-04 22:47:49,574:INFO:Initializing K Neighbors Classifier
2024-02-04 22:47:49,575:INFO:Total runtime is 0.11956245899200439 minutes
2024-02-04 22:47:49,578:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:49,578:INFO:Initializing create_model()
2024-02-04 22:47:49,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:49,578:INFO:Checking exceptions
2024-02-04 22:47:49,578:INFO:Importing libraries
2024-02-04 22:47:49,578:INFO:Copying training dataset
2024-02-04 22:47:49,585:INFO:Defining folds
2024-02-04 22:47:49,585:INFO:Declaring metric variables
2024-02-04 22:47:49,589:INFO:Importing untrained model
2024-02-04 22:47:49,592:INFO:K Neighbors Classifier Imported successfully
2024-02-04 22:47:49,599:INFO:Starting cross validation
2024-02-04 22:47:49,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:49,979:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:49,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,011:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,193:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,212:INFO:Calculating mean and std
2024-02-04 22:47:50,214:INFO:Creating metrics dataframe
2024-02-04 22:47:50,217:INFO:Uploading results into container
2024-02-04 22:47:50,218:INFO:Uploading model into container now
2024-02-04 22:47:50,218:INFO:_master_model_container: 2
2024-02-04 22:47:50,218:INFO:_display_container: 2
2024-02-04 22:47:50,219:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 22:47:50,219:INFO:create_model() successfully completed......................................
2024-02-04 22:47:50,384:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:50,384:INFO:Creating metrics dataframe
2024-02-04 22:47:50,395:INFO:Initializing Naive Bayes
2024-02-04 22:47:50,395:INFO:Total runtime is 0.133218514919281 minutes
2024-02-04 22:47:50,398:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:50,398:INFO:Initializing create_model()
2024-02-04 22:47:50,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:50,398:INFO:Checking exceptions
2024-02-04 22:47:50,398:INFO:Importing libraries
2024-02-04 22:47:50,399:INFO:Copying training dataset
2024-02-04 22:47:50,404:INFO:Defining folds
2024-02-04 22:47:50,404:INFO:Declaring metric variables
2024-02-04 22:47:50,408:INFO:Importing untrained model
2024-02-04 22:47:50,412:INFO:Naive Bayes Imported successfully
2024-02-04 22:47:50,418:INFO:Starting cross validation
2024-02-04 22:47:50,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:50,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,703:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,704:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,726:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,742:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,855:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,866:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:50,877:INFO:Calculating mean and std
2024-02-04 22:47:50,878:INFO:Creating metrics dataframe
2024-02-04 22:47:50,881:INFO:Uploading results into container
2024-02-04 22:47:50,882:INFO:Uploading model into container now
2024-02-04 22:47:50,882:INFO:_master_model_container: 3
2024-02-04 22:47:50,882:INFO:_display_container: 2
2024-02-04 22:47:50,882:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 22:47:50,882:INFO:create_model() successfully completed......................................
2024-02-04 22:47:51,062:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:51,062:INFO:Creating metrics dataframe
2024-02-04 22:47:51,072:INFO:Initializing Decision Tree Classifier
2024-02-04 22:47:51,072:INFO:Total runtime is 0.1445073127746582 minutes
2024-02-04 22:47:51,077:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:51,077:INFO:Initializing create_model()
2024-02-04 22:47:51,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:51,078:INFO:Checking exceptions
2024-02-04 22:47:51,078:INFO:Importing libraries
2024-02-04 22:47:51,078:INFO:Copying training dataset
2024-02-04 22:47:51,083:INFO:Defining folds
2024-02-04 22:47:51,083:INFO:Declaring metric variables
2024-02-04 22:47:51,086:INFO:Importing untrained model
2024-02-04 22:47:51,091:INFO:Decision Tree Classifier Imported successfully
2024-02-04 22:47:51,099:INFO:Starting cross validation
2024-02-04 22:47:51,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:51,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,439:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:51,649:INFO:Calculating mean and std
2024-02-04 22:47:51,651:INFO:Creating metrics dataframe
2024-02-04 22:47:51,654:INFO:Uploading results into container
2024-02-04 22:47:51,654:INFO:Uploading model into container now
2024-02-04 22:47:51,655:INFO:_master_model_container: 4
2024-02-04 22:47:51,655:INFO:_display_container: 2
2024-02-04 22:47:51,655:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2010, splitter='best')
2024-02-04 22:47:51,655:INFO:create_model() successfully completed......................................
2024-02-04 22:47:51,814:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:51,814:INFO:Creating metrics dataframe
2024-02-04 22:47:51,826:INFO:Initializing SVM - Linear Kernel
2024-02-04 22:47:51,826:INFO:Total runtime is 0.15706642866134643 minutes
2024-02-04 22:47:51,828:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:51,829:INFO:Initializing create_model()
2024-02-04 22:47:51,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:51,829:INFO:Checking exceptions
2024-02-04 22:47:51,829:INFO:Importing libraries
2024-02-04 22:47:51,829:INFO:Copying training dataset
2024-02-04 22:47:51,836:INFO:Defining folds
2024-02-04 22:47:51,836:INFO:Declaring metric variables
2024-02-04 22:47:51,840:INFO:Importing untrained model
2024-02-04 22:47:51,844:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 22:47:51,851:INFO:Starting cross validation
2024-02-04 22:47:51,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:52,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,170:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,171:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,178:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,188:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,202:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,202:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:47:52,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,224:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:47:52,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,391:INFO:Calculating mean and std
2024-02-04 22:47:52,393:INFO:Creating metrics dataframe
2024-02-04 22:47:52,397:INFO:Uploading results into container
2024-02-04 22:47:52,398:INFO:Uploading model into container now
2024-02-04 22:47:52,399:INFO:_master_model_container: 5
2024-02-04 22:47:52,399:INFO:_display_container: 2
2024-02-04 22:47:52,400:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2010, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 22:47:52,400:INFO:create_model() successfully completed......................................
2024-02-04 22:47:52,567:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:52,567:INFO:Creating metrics dataframe
2024-02-04 22:47:52,580:INFO:Initializing Ridge Classifier
2024-02-04 22:47:52,581:INFO:Total runtime is 0.16965440114339192 minutes
2024-02-04 22:47:52,584:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:52,584:INFO:Initializing create_model()
2024-02-04 22:47:52,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:52,585:INFO:Checking exceptions
2024-02-04 22:47:52,585:INFO:Importing libraries
2024-02-04 22:47:52,585:INFO:Copying training dataset
2024-02-04 22:47:52,590:INFO:Defining folds
2024-02-04 22:47:52,590:INFO:Declaring metric variables
2024-02-04 22:47:52,594:INFO:Importing untrained model
2024-02-04 22:47:52,599:INFO:Ridge Classifier Imported successfully
2024-02-04 22:47:52,605:INFO:Starting cross validation
2024-02-04 22:47:52,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:52,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,871:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,874:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,888:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,894:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:52,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,909:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:52,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:53,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:47:53,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,051:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:53,067:INFO:Calculating mean and std
2024-02-04 22:47:53,069:INFO:Creating metrics dataframe
2024-02-04 22:47:53,072:INFO:Uploading results into container
2024-02-04 22:47:53,073:INFO:Uploading model into container now
2024-02-04 22:47:53,073:INFO:_master_model_container: 6
2024-02-04 22:47:53,073:INFO:_display_container: 2
2024-02-04 22:47:53,074:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2010, solver='auto',
                tol=0.0001)
2024-02-04 22:47:53,074:INFO:create_model() successfully completed......................................
2024-02-04 22:47:53,243:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:53,243:INFO:Creating metrics dataframe
2024-02-04 22:47:53,254:INFO:Initializing Random Forest Classifier
2024-02-04 22:47:53,254:INFO:Total runtime is 0.18087802728017172 minutes
2024-02-04 22:47:53,258:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:53,258:INFO:Initializing create_model()
2024-02-04 22:47:53,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:53,258:INFO:Checking exceptions
2024-02-04 22:47:53,259:INFO:Importing libraries
2024-02-04 22:47:53,259:INFO:Copying training dataset
2024-02-04 22:47:53,264:INFO:Defining folds
2024-02-04 22:47:53,265:INFO:Declaring metric variables
2024-02-04 22:47:53,268:INFO:Importing untrained model
2024-02-04 22:47:53,272:INFO:Random Forest Classifier Imported successfully
2024-02-04 22:47:53,279:INFO:Starting cross validation
2024-02-04 22:47:53,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:54,834:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,834:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,843:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,849:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,883:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:54,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,483:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,502:INFO:Calculating mean and std
2024-02-04 22:47:55,503:INFO:Creating metrics dataframe
2024-02-04 22:47:55,507:INFO:Uploading results into container
2024-02-04 22:47:55,507:INFO:Uploading model into container now
2024-02-04 22:47:55,507:INFO:_master_model_container: 7
2024-02-04 22:47:55,508:INFO:_display_container: 2
2024-02-04 22:47:55,508:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:47:55,508:INFO:create_model() successfully completed......................................
2024-02-04 22:47:55,674:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:55,674:INFO:Creating metrics dataframe
2024-02-04 22:47:55,685:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 22:47:55,685:INFO:Total runtime is 0.22139288584391276 minutes
2024-02-04 22:47:55,690:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:55,690:INFO:Initializing create_model()
2024-02-04 22:47:55,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:55,691:INFO:Checking exceptions
2024-02-04 22:47:55,691:INFO:Importing libraries
2024-02-04 22:47:55,691:INFO:Copying training dataset
2024-02-04 22:47:55,697:INFO:Defining folds
2024-02-04 22:47:55,697:INFO:Declaring metric variables
2024-02-04 22:47:55,701:INFO:Importing untrained model
2024-02-04 22:47:55,704:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 22:47:55,711:INFO:Starting cross validation
2024-02-04 22:47:55,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:55,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,912:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,919:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,926:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,963:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,965:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:55,994:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:55,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,010:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,013:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,125:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:56,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:47:56,171:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,178:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,186:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:56,199:INFO:Calculating mean and std
2024-02-04 22:47:56,200:INFO:Creating metrics dataframe
2024-02-04 22:47:56,204:INFO:Uploading results into container
2024-02-04 22:47:56,205:INFO:Uploading model into container now
2024-02-04 22:47:56,205:INFO:_master_model_container: 8
2024-02-04 22:47:56,205:INFO:_display_container: 2
2024-02-04 22:47:56,206:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 22:47:56,206:INFO:create_model() successfully completed......................................
2024-02-04 22:47:56,375:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:56,375:INFO:Creating metrics dataframe
2024-02-04 22:47:56,386:INFO:Initializing Ada Boost Classifier
2024-02-04 22:47:56,386:INFO:Total runtime is 0.2330679972966512 minutes
2024-02-04 22:47:56,389:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:56,389:INFO:Initializing create_model()
2024-02-04 22:47:56,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:56,390:INFO:Checking exceptions
2024-02-04 22:47:56,390:INFO:Importing libraries
2024-02-04 22:47:56,390:INFO:Copying training dataset
2024-02-04 22:47:56,396:INFO:Defining folds
2024-02-04 22:47:56,396:INFO:Declaring metric variables
2024-02-04 22:47:56,400:INFO:Importing untrained model
2024-02-04 22:47:56,404:INFO:Ada Boost Classifier Imported successfully
2024-02-04 22:47:56,411:INFO:Starting cross validation
2024-02-04 22:47:56,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:57,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,151:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,180:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:57,601:INFO:Calculating mean and std
2024-02-04 22:47:57,602:INFO:Creating metrics dataframe
2024-02-04 22:47:57,606:INFO:Uploading results into container
2024-02-04 22:47:57,606:INFO:Uploading model into container now
2024-02-04 22:47:57,607:INFO:_master_model_container: 9
2024-02-04 22:47:57,607:INFO:_display_container: 2
2024-02-04 22:47:57,607:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2010)
2024-02-04 22:47:57,607:INFO:create_model() successfully completed......................................
2024-02-04 22:47:57,765:INFO:SubProcess create_model() end ==================================
2024-02-04 22:47:57,765:INFO:Creating metrics dataframe
2024-02-04 22:47:57,776:INFO:Initializing Gradient Boosting Classifier
2024-02-04 22:47:57,777:INFO:Total runtime is 0.2562533656756083 minutes
2024-02-04 22:47:57,780:INFO:SubProcess create_model() called ==================================
2024-02-04 22:47:57,781:INFO:Initializing create_model()
2024-02-04 22:47:57,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:47:57,781:INFO:Checking exceptions
2024-02-04 22:47:57,781:INFO:Importing libraries
2024-02-04 22:47:57,781:INFO:Copying training dataset
2024-02-04 22:47:57,789:INFO:Defining folds
2024-02-04 22:47:57,789:INFO:Declaring metric variables
2024-02-04 22:47:57,794:INFO:Importing untrained model
2024-02-04 22:47:57,798:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:47:57,805:INFO:Starting cross validation
2024-02-04 22:47:57,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:47:59,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,752:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,759:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,759:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,760:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,775:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:47:59,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:00,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:00,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,017:INFO:Calculating mean and std
2024-02-04 22:48:01,018:INFO:Creating metrics dataframe
2024-02-04 22:48:01,021:INFO:Uploading results into container
2024-02-04 22:48:01,022:INFO:Uploading model into container now
2024-02-04 22:48:01,022:INFO:_master_model_container: 10
2024-02-04 22:48:01,022:INFO:_display_container: 2
2024-02-04 22:48:01,023:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:48:01,023:INFO:create_model() successfully completed......................................
2024-02-04 22:48:01,179:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:01,179:INFO:Creating metrics dataframe
2024-02-04 22:48:01,192:INFO:Initializing Linear Discriminant Analysis
2024-02-04 22:48:01,192:INFO:Total runtime is 0.3131710330645243 minutes
2024-02-04 22:48:01,197:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:01,197:INFO:Initializing create_model()
2024-02-04 22:48:01,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:01,197:INFO:Checking exceptions
2024-02-04 22:48:01,197:INFO:Importing libraries
2024-02-04 22:48:01,197:INFO:Copying training dataset
2024-02-04 22:48:01,203:INFO:Defining folds
2024-02-04 22:48:01,203:INFO:Declaring metric variables
2024-02-04 22:48:01,221:INFO:Importing untrained model
2024-02-04 22:48:01,226:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 22:48:01,233:INFO:Starting cross validation
2024-02-04 22:48:01,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:01,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,513:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,518:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,543:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,543:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,682:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:01,707:INFO:Calculating mean and std
2024-02-04 22:48:01,708:INFO:Creating metrics dataframe
2024-02-04 22:48:01,711:INFO:Uploading results into container
2024-02-04 22:48:01,712:INFO:Uploading model into container now
2024-02-04 22:48:01,713:INFO:_master_model_container: 11
2024-02-04 22:48:01,713:INFO:_display_container: 2
2024-02-04 22:48:01,713:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:48:01,713:INFO:create_model() successfully completed......................................
2024-02-04 22:48:01,888:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:01,888:INFO:Creating metrics dataframe
2024-02-04 22:48:01,900:INFO:Initializing Extra Trees Classifier
2024-02-04 22:48:01,900:INFO:Total runtime is 0.3249804854393005 minutes
2024-02-04 22:48:01,905:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:01,905:INFO:Initializing create_model()
2024-02-04 22:48:01,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:01,905:INFO:Checking exceptions
2024-02-04 22:48:01,905:INFO:Importing libraries
2024-02-04 22:48:01,905:INFO:Copying training dataset
2024-02-04 22:48:01,911:INFO:Defining folds
2024-02-04 22:48:01,912:INFO:Declaring metric variables
2024-02-04 22:48:01,915:INFO:Importing untrained model
2024-02-04 22:48:01,921:INFO:Extra Trees Classifier Imported successfully
2024-02-04 22:48:01,928:INFO:Starting cross validation
2024-02-04 22:48:01,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:02,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,852:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,962:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:02,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,390:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:03,410:INFO:Calculating mean and std
2024-02-04 22:48:03,411:INFO:Creating metrics dataframe
2024-02-04 22:48:03,415:INFO:Uploading results into container
2024-02-04 22:48:03,415:INFO:Uploading model into container now
2024-02-04 22:48:03,416:INFO:_master_model_container: 12
2024-02-04 22:48:03,416:INFO:_display_container: 2
2024-02-04 22:48:03,417:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:48:03,417:INFO:create_model() successfully completed......................................
2024-02-04 22:48:03,589:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:03,590:INFO:Creating metrics dataframe
2024-02-04 22:48:03,604:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 22:48:03,604:INFO:Total runtime is 0.35338148673375447 minutes
2024-02-04 22:48:03,608:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:03,608:INFO:Initializing create_model()
2024-02-04 22:48:03,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:03,608:INFO:Checking exceptions
2024-02-04 22:48:03,608:INFO:Importing libraries
2024-02-04 22:48:03,608:INFO:Copying training dataset
2024-02-04 22:48:03,614:INFO:Defining folds
2024-02-04 22:48:03,614:INFO:Declaring metric variables
2024-02-04 22:48:03,620:INFO:Importing untrained model
2024-02-04 22:48:03,623:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 22:48:03,632:INFO:Starting cross validation
2024-02-04 22:48:03,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:04,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,612:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,630:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,637:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,716:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,773:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,773:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,828:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:04,835:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:05,156:INFO:Calculating mean and std
2024-02-04 22:48:05,158:INFO:Creating metrics dataframe
2024-02-04 22:48:05,164:INFO:Uploading results into container
2024-02-04 22:48:05,165:INFO:Uploading model into container now
2024-02-04 22:48:05,166:INFO:_master_model_container: 13
2024-02-04 22:48:05,166:INFO:_display_container: 2
2024-02-04 22:48:05,167:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:48:05,167:INFO:create_model() successfully completed......................................
2024-02-04 22:48:05,351:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:05,351:INFO:Creating metrics dataframe
2024-02-04 22:48:05,365:INFO:Initializing CatBoost Classifier
2024-02-04 22:48:05,365:INFO:Total runtime is 0.3827182133992513 minutes
2024-02-04 22:48:05,369:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:05,370:INFO:Initializing create_model()
2024-02-04 22:48:05,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:05,370:INFO:Checking exceptions
2024-02-04 22:48:05,370:INFO:Importing libraries
2024-02-04 22:48:05,370:INFO:Copying training dataset
2024-02-04 22:48:05,376:INFO:Defining folds
2024-02-04 22:48:05,376:INFO:Declaring metric variables
2024-02-04 22:48:05,381:INFO:Importing untrained model
2024-02-04 22:48:05,385:INFO:CatBoost Classifier Imported successfully
2024-02-04 22:48:05,392:INFO:Starting cross validation
2024-02-04 22:48:05,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:18,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,719:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,839:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,849:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:18,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,085:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,151:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:19,349:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,604:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,605:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:23,624:INFO:Calculating mean and std
2024-02-04 22:48:23,626:INFO:Creating metrics dataframe
2024-02-04 22:48:23,632:INFO:Uploading results into container
2024-02-04 22:48:23,633:INFO:Uploading model into container now
2024-02-04 22:48:23,633:INFO:_master_model_container: 14
2024-02-04 22:48:23,634:INFO:_display_container: 2
2024-02-04 22:48:23,634:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4CE17A00>
2024-02-04 22:48:23,634:INFO:create_model() successfully completed......................................
2024-02-04 22:48:23,837:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:23,837:INFO:Creating metrics dataframe
2024-02-04 22:48:23,852:INFO:Initializing Dummy Classifier
2024-02-04 22:48:23,852:INFO:Total runtime is 0.6908439834912617 minutes
2024-02-04 22:48:23,856:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:23,856:INFO:Initializing create_model()
2024-02-04 22:48:23,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDC00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:23,856:INFO:Checking exceptions
2024-02-04 22:48:23,856:INFO:Importing libraries
2024-02-04 22:48:23,857:INFO:Copying training dataset
2024-02-04 22:48:23,862:INFO:Defining folds
2024-02-04 22:48:23,863:INFO:Declaring metric variables
2024-02-04 22:48:23,867:INFO:Importing untrained model
2024-02-04 22:48:23,871:INFO:Dummy Classifier Imported successfully
2024-02-04 22:48:23,878:INFO:Starting cross validation
2024-02-04 22:48:23,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:24,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,186:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,207:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,230:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,395:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,396:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,398:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:48:24,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:24,409:INFO:Calculating mean and std
2024-02-04 22:48:24,411:INFO:Creating metrics dataframe
2024-02-04 22:48:24,415:INFO:Uploading results into container
2024-02-04 22:48:24,416:INFO:Uploading model into container now
2024-02-04 22:48:24,416:INFO:_master_model_container: 15
2024-02-04 22:48:24,416:INFO:_display_container: 2
2024-02-04 22:48:24,416:INFO:DummyClassifier(constant=None, random_state=2010, strategy='prior')
2024-02-04 22:48:24,417:INFO:create_model() successfully completed......................................
2024-02-04 22:48:24,584:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:24,584:INFO:Creating metrics dataframe
2024-02-04 22:48:24,606:INFO:Initializing create_model()
2024-02-04 22:48:24,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4CE17A00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:24,606:INFO:Checking exceptions
2024-02-04 22:48:24,607:INFO:Importing libraries
2024-02-04 22:48:24,608:INFO:Copying training dataset
2024-02-04 22:48:24,614:INFO:Defining folds
2024-02-04 22:48:24,614:INFO:Declaring metric variables
2024-02-04 22:48:24,614:INFO:Importing untrained model
2024-02-04 22:48:24,614:INFO:Declaring custom model
2024-02-04 22:48:24,614:INFO:CatBoost Classifier Imported successfully
2024-02-04 22:48:24,616:INFO:Cross validation set to False
2024-02-04 22:48:24,616:INFO:Fitting Model
2024-02-04 22:48:28,466:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>
2024-02-04 22:48:28,466:INFO:create_model() successfully completed......................................
2024-02-04 22:48:28,627:INFO:Initializing create_model()
2024-02-04 22:48:28,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:28,627:INFO:Checking exceptions
2024-02-04 22:48:28,629:INFO:Importing libraries
2024-02-04 22:48:28,629:INFO:Copying training dataset
2024-02-04 22:48:28,635:INFO:Defining folds
2024-02-04 22:48:28,635:INFO:Declaring metric variables
2024-02-04 22:48:28,636:INFO:Importing untrained model
2024-02-04 22:48:28,636:INFO:Declaring custom model
2024-02-04 22:48:28,636:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 22:48:28,637:INFO:Cross validation set to False
2024-02-04 22:48:28,638:INFO:Fitting Model
2024-02-04 22:48:28,711:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:48:28,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2024-02-04 22:48:28,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:48:28,713:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:48:28,713:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:48:28,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 22:48:28,713:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 22:48:28,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:48:28,772:INFO:create_model() successfully completed......................................
2024-02-04 22:48:28,973:INFO:Initializing create_model()
2024-02-04 22:48:28,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:28,973:INFO:Checking exceptions
2024-02-04 22:48:28,976:INFO:Importing libraries
2024-02-04 22:48:28,976:INFO:Copying training dataset
2024-02-04 22:48:28,981:INFO:Defining folds
2024-02-04 22:48:28,982:INFO:Declaring metric variables
2024-02-04 22:48:28,982:INFO:Importing untrained model
2024-02-04 22:48:28,982:INFO:Declaring custom model
2024-02-04 22:48:28,983:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:48:28,984:INFO:Cross validation set to False
2024-02-04 22:48:28,984:INFO:Fitting Model
2024-02-04 22:48:30,150:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:48:30,150:INFO:create_model() successfully completed......................................
2024-02-04 22:48:30,326:INFO:Initializing create_model()
2024-02-04 22:48:30,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:30,327:INFO:Checking exceptions
2024-02-04 22:48:30,329:INFO:Importing libraries
2024-02-04 22:48:30,329:INFO:Copying training dataset
2024-02-04 22:48:30,336:INFO:Defining folds
2024-02-04 22:48:30,337:INFO:Declaring metric variables
2024-02-04 22:48:30,337:INFO:Importing untrained model
2024-02-04 22:48:30,337:INFO:Declaring custom model
2024-02-04 22:48:30,338:INFO:Random Forest Classifier Imported successfully
2024-02-04 22:48:30,339:INFO:Cross validation set to False
2024-02-04 22:48:30,339:INFO:Fitting Model
2024-02-04 22:48:30,681:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:48:30,681:INFO:create_model() successfully completed......................................
2024-02-04 22:48:30,858:INFO:Initializing create_model()
2024-02-04 22:48:30,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:30,859:INFO:Checking exceptions
2024-02-04 22:48:30,862:INFO:Importing libraries
2024-02-04 22:48:30,862:INFO:Copying training dataset
2024-02-04 22:48:30,867:INFO:Defining folds
2024-02-04 22:48:30,867:INFO:Declaring metric variables
2024-02-04 22:48:30,867:INFO:Importing untrained model
2024-02-04 22:48:30,867:INFO:Declaring custom model
2024-02-04 22:48:30,868:INFO:Extra Trees Classifier Imported successfully
2024-02-04 22:48:30,870:INFO:Cross validation set to False
2024-02-04 22:48:30,870:INFO:Fitting Model
2024-02-04 22:48:31,123:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:48:31,123:INFO:create_model() successfully completed......................................
2024-02-04 22:48:31,338:INFO:_master_model_container: 15
2024-02-04 22:48:31,339:INFO:_display_container: 2
2024-02-04 22:48:31,340:INFO:[<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)]
2024-02-04 22:48:31,340:INFO:compare_models() successfully completed......................................
2024-02-04 22:48:31,347:INFO:Initializing tune_model()
2024-02-04 22:48:31,347:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>)
2024-02-04 22:48:31,348:INFO:Checking exceptions
2024-02-04 22:48:31,368:INFO:Copying training dataset
2024-02-04 22:48:31,374:INFO:Checking base model
2024-02-04 22:48:31,374:INFO:Base model : CatBoost Classifier
2024-02-04 22:48:31,379:INFO:Declaring metric variables
2024-02-04 22:48:31,384:INFO:Defining Hyperparameters
2024-02-04 22:48:31,587:INFO:Tuning with n_jobs=-1
2024-02-04 22:48:31,587:INFO:Initializing RandomizedSearchCV
2024-02-04 22:48:53,662:INFO:best_params: {'actual_estimator__random_strength': 0.4, 'actual_estimator__n_estimators': 180, 'actual_estimator__l2_leaf_reg': 10, 'actual_estimator__eta': 0.15, 'actual_estimator__depth': 6}
2024-02-04 22:48:53,663:INFO:Hyperparameter search completed
2024-02-04 22:48:53,663:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:53,663:INFO:Initializing create_model()
2024-02-04 22:48:53,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E4B98A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD475EE980>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.4, 'n_estimators': 180, 'l2_leaf_reg': 10, 'eta': 0.15, 'depth': 6})
2024-02-04 22:48:53,664:INFO:Checking exceptions
2024-02-04 22:48:53,664:INFO:Importing libraries
2024-02-04 22:48:53,664:INFO:Copying training dataset
2024-02-04 22:48:53,673:INFO:Defining folds
2024-02-04 22:48:53,673:INFO:Declaring metric variables
2024-02-04 22:48:53,678:INFO:Importing untrained model
2024-02-04 22:48:53,679:INFO:Declaring custom model
2024-02-04 22:48:53,683:INFO:CatBoost Classifier Imported successfully
2024-02-04 22:48:53,694:INFO:Starting cross validation
2024-02-04 22:48:53,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:48:56,571:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,847:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:56,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,819:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:48:57,830:INFO:Calculating mean and std
2024-02-04 22:48:57,832:INFO:Creating metrics dataframe
2024-02-04 22:48:57,841:INFO:Finalizing model
2024-02-04 22:48:58,513:INFO:Uploading results into container
2024-02-04 22:48:58,514:INFO:Uploading model into container now
2024-02-04 22:48:58,515:INFO:_master_model_container: 16
2024-02-04 22:48:58,515:INFO:_display_container: 3
2024-02-04 22:48:58,515:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E14FF40>
2024-02-04 22:48:58,516:INFO:create_model() successfully completed......................................
2024-02-04 22:48:58,683:INFO:SubProcess create_model() end ==================================
2024-02-04 22:48:58,683:INFO:choose_better activated
2024-02-04 22:48:58,686:INFO:SubProcess create_model() called ==================================
2024-02-04 22:48:58,687:INFO:Initializing create_model()
2024-02-04 22:48:58,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:48:58,687:INFO:Checking exceptions
2024-02-04 22:48:58,689:INFO:Importing libraries
2024-02-04 22:48:58,689:INFO:Copying training dataset
2024-02-04 22:48:58,695:INFO:Defining folds
2024-02-04 22:48:58,695:INFO:Declaring metric variables
2024-02-04 22:48:58,696:INFO:Importing untrained model
2024-02-04 22:48:58,696:INFO:Declaring custom model
2024-02-04 22:48:58,696:INFO:CatBoost Classifier Imported successfully
2024-02-04 22:48:58,696:INFO:Starting cross validation
2024-02-04 22:48:58,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:49:12,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,664:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,679:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,745:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:12,971:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:13,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:13,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:13,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,427:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,470:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:17,495:INFO:Calculating mean and std
2024-02-04 22:49:17,495:INFO:Creating metrics dataframe
2024-02-04 22:49:17,498:INFO:Finalizing model
2024-02-04 22:49:21,404:INFO:Uploading results into container
2024-02-04 22:49:21,404:INFO:Uploading model into container now
2024-02-04 22:49:21,405:INFO:_master_model_container: 17
2024-02-04 22:49:21,405:INFO:_display_container: 4
2024-02-04 22:49:21,405:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0>
2024-02-04 22:49:21,405:INFO:create_model() successfully completed......................................
2024-02-04 22:49:21,558:INFO:SubProcess create_model() end ==================================
2024-02-04 22:49:21,558:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0> result for Accuracy is 0.963
2024-02-04 22:49:21,558:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E14FF40> result for Accuracy is 0.9624
2024-02-04 22:49:21,558:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0> is best model
2024-02-04 22:49:21,559:INFO:choose_better completed
2024-02-04 22:49:21,559:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 22:49:21,569:INFO:_master_model_container: 17
2024-02-04 22:49:21,569:INFO:_display_container: 3
2024-02-04 22:49:21,569:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0>
2024-02-04 22:49:21,569:INFO:tune_model() successfully completed......................................
2024-02-04 22:49:21,739:INFO:Initializing tune_model()
2024-02-04 22:49:21,739:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>)
2024-02-04 22:49:21,739:INFO:Checking exceptions
2024-02-04 22:49:21,756:INFO:Copying training dataset
2024-02-04 22:49:21,761:INFO:Checking base model
2024-02-04 22:49:21,761:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 22:49:21,766:INFO:Declaring metric variables
2024-02-04 22:49:21,770:INFO:Defining Hyperparameters
2024-02-04 22:49:21,938:INFO:Tuning with n_jobs=-1
2024-02-04 22:49:21,939:INFO:Initializing RandomizedSearchCV
2024-02-04 22:49:37,249:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 50, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 46, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.9}
2024-02-04 22:49:37,251:INFO:Hyperparameter search completed
2024-02-04 22:49:37,251:INFO:SubProcess create_model() called ==================================
2024-02-04 22:49:37,253:INFO:Initializing create_model()
2024-02-04 22:49:37,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EC040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.3, 'num_leaves': 150, 'n_estimators': 50, 'min_split_gain': 0, 'min_child_samples': 46, 'learning_rate': 0.3, 'feature_fraction': 0.9, 'bagging_freq': 5, 'bagging_fraction': 0.9})
2024-02-04 22:49:37,253:INFO:Checking exceptions
2024-02-04 22:49:37,253:INFO:Importing libraries
2024-02-04 22:49:37,254:INFO:Copying training dataset
2024-02-04 22:49:37,266:INFO:Defining folds
2024-02-04 22:49:37,266:INFO:Declaring metric variables
2024-02-04 22:49:37,274:INFO:Importing untrained model
2024-02-04 22:49:37,275:INFO:Declaring custom model
2024-02-04 22:49:37,285:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 22:49:37,300:INFO:Starting cross validation
2024-02-04 22:49:37,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:49:38,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,065:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,078:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,088:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,096:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,101:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,434:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:38,459:INFO:Calculating mean and std
2024-02-04 22:49:38,461:INFO:Creating metrics dataframe
2024-02-04 22:49:38,472:INFO:Finalizing model
2024-02-04 22:49:38,592:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-02-04 22:49:38,592:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 22:49:38,592:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 22:49:38,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2024-02-04 22:49:38,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 22:49:38,597:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 22:49:38,597:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:49:38,598:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-04 22:49:38,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-04 22:49:38,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-04 22:49:38,599:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:49:38,600:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:49:38,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 22:49:38,600:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 22:49:38,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 22:49:38,692:INFO:Uploading results into container
2024-02-04 22:49:38,694:INFO:Uploading model into container now
2024-02-04 22:49:38,696:INFO:_master_model_container: 18
2024-02-04 22:49:38,697:INFO:_display_container: 4
2024-02-04 22:49:38,698:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0,
               n_estimators=50, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2010, reg_alpha=0.3, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:49:38,698:INFO:create_model() successfully completed......................................
2024-02-04 22:49:38,893:INFO:SubProcess create_model() end ==================================
2024-02-04 22:49:38,893:INFO:choose_better activated
2024-02-04 22:49:38,897:INFO:SubProcess create_model() called ==================================
2024-02-04 22:49:38,898:INFO:Initializing create_model()
2024-02-04 22:49:38,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:49:38,899:INFO:Checking exceptions
2024-02-04 22:49:38,901:INFO:Importing libraries
2024-02-04 22:49:38,901:INFO:Copying training dataset
2024-02-04 22:49:38,907:INFO:Defining folds
2024-02-04 22:49:38,907:INFO:Declaring metric variables
2024-02-04 22:49:38,907:INFO:Importing untrained model
2024-02-04 22:49:38,907:INFO:Declaring custom model
2024-02-04 22:49:38,908:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 22:49:38,908:INFO:Starting cross validation
2024-02-04 22:49:38,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:49:40,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,011:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,085:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,207:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,217:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,234:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,617:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,621:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:40,651:INFO:Calculating mean and std
2024-02-04 22:49:40,652:INFO:Creating metrics dataframe
2024-02-04 22:49:40,656:INFO:Finalizing model
2024-02-04 22:49:40,783:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:49:40,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2024-02-04 22:49:40,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:49:40,784:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:49:40,785:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:49:40,785:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 22:49:40,785:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 22:49:40,940:INFO:Uploading results into container
2024-02-04 22:49:40,941:INFO:Uploading model into container now
2024-02-04 22:49:40,942:INFO:_master_model_container: 19
2024-02-04 22:49:40,942:INFO:_display_container: 5
2024-02-04 22:49:40,943:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:49:40,943:INFO:create_model() successfully completed......................................
2024-02-04 22:49:41,136:INFO:SubProcess create_model() end ==================================
2024-02-04 22:49:41,136:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.959
2024-02-04 22:49:41,137:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0,
               n_estimators=50, n_jobs=-1, num_leaves=150, objective=None,
               random_state=2010, reg_alpha=0.3, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.957
2024-02-04 22:49:41,138:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 22:49:41,138:INFO:choose_better completed
2024-02-04 22:49:41,138:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 22:49:41,149:INFO:_master_model_container: 19
2024-02-04 22:49:41,149:INFO:_display_container: 4
2024-02-04 22:49:41,149:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:49:41,150:INFO:tune_model() successfully completed......................................
2024-02-04 22:49:41,321:INFO:Initializing tune_model()
2024-02-04 22:49:41,321:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>)
2024-02-04 22:49:41,321:INFO:Checking exceptions
2024-02-04 22:49:41,345:INFO:Copying training dataset
2024-02-04 22:49:41,349:INFO:Checking base model
2024-02-04 22:49:41,349:INFO:Base model : Gradient Boosting Classifier
2024-02-04 22:49:41,353:INFO:Declaring metric variables
2024-02-04 22:49:41,358:INFO:Defining Hyperparameters
2024-02-04 22:49:41,560:INFO:Tuning with n_jobs=-1
2024-02-04 22:49:41,560:INFO:Initializing RandomizedSearchCV
2024-02-04 22:49:58,156:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 40, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.1}
2024-02-04 22:49:58,157:INFO:Hyperparameter search completed
2024-02-04 22:49:58,157:INFO:SubProcess create_model() called ==================================
2024-02-04 22:49:58,158:INFO:Initializing create_model()
2024-02-04 22:49:58,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4BCD5AE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 40, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 1.0, 'max_depth': 5, 'learning_rate': 0.1})
2024-02-04 22:49:58,158:INFO:Checking exceptions
2024-02-04 22:49:58,158:INFO:Importing libraries
2024-02-04 22:49:58,159:INFO:Copying training dataset
2024-02-04 22:49:58,165:INFO:Defining folds
2024-02-04 22:49:58,165:INFO:Declaring metric variables
2024-02-04 22:49:58,169:INFO:Importing untrained model
2024-02-04 22:49:58,169:INFO:Declaring custom model
2024-02-04 22:49:58,174:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:49:58,181:INFO:Starting cross validation
2024-02-04 22:49:58,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:49:59,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,325:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,349:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:49:59,985:INFO:Calculating mean and std
2024-02-04 22:49:59,986:INFO:Creating metrics dataframe
2024-02-04 22:49:59,992:INFO:Finalizing model
2024-02-04 22:50:00,517:INFO:Uploading results into container
2024-02-04 22:50:00,517:INFO:Uploading model into container now
2024-02-04 22:50:00,519:INFO:_master_model_container: 20
2024-02-04 22:50:00,519:INFO:_display_container: 5
2024-02-04 22:50:00,520:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=40, n_iter_no_change=None,
                           random_state=2010, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:50:00,520:INFO:create_model() successfully completed......................................
2024-02-04 22:50:00,683:INFO:SubProcess create_model() end ==================================
2024-02-04 22:50:00,684:INFO:choose_better activated
2024-02-04 22:50:00,687:INFO:SubProcess create_model() called ==================================
2024-02-04 22:50:00,687:INFO:Initializing create_model()
2024-02-04 22:50:00,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:50:00,688:INFO:Checking exceptions
2024-02-04 22:50:00,689:INFO:Importing libraries
2024-02-04 22:50:00,690:INFO:Copying training dataset
2024-02-04 22:50:00,694:INFO:Defining folds
2024-02-04 22:50:00,694:INFO:Declaring metric variables
2024-02-04 22:50:00,694:INFO:Importing untrained model
2024-02-04 22:50:00,694:INFO:Declaring custom model
2024-02-04 22:50:00,695:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:50:00,695:INFO:Starting cross validation
2024-02-04 22:50:00,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:50:02,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,828:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,831:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,840:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,855:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,858:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,863:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,872:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,883:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:02,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:04,358:INFO:Calculating mean and std
2024-02-04 22:50:04,359:INFO:Creating metrics dataframe
2024-02-04 22:50:04,361:INFO:Finalizing model
2024-02-04 22:50:05,607:INFO:Uploading results into container
2024-02-04 22:50:05,608:INFO:Uploading model into container now
2024-02-04 22:50:05,608:INFO:_master_model_container: 21
2024-02-04 22:50:05,609:INFO:_display_container: 6
2024-02-04 22:50:05,609:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:50:05,609:INFO:create_model() successfully completed......................................
2024-02-04 22:50:05,785:INFO:SubProcess create_model() end ==================================
2024-02-04 22:50:05,786:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9543
2024-02-04 22:50:05,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=40, n_iter_no_change=None,
                           random_state=2010, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.957
2024-02-04 22:50:05,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=40, n_iter_no_change=None,
                           random_state=2010, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-04 22:50:05,787:INFO:choose_better completed
2024-02-04 22:50:05,797:INFO:_master_model_container: 21
2024-02-04 22:50:05,797:INFO:_display_container: 5
2024-02-04 22:50:05,798:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=40, n_iter_no_change=None,
                           random_state=2010, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:50:05,798:INFO:tune_model() successfully completed......................................
2024-02-04 22:50:05,956:INFO:Initializing tune_model()
2024-02-04 22:50:05,957:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>)
2024-02-04 22:50:05,957:INFO:Checking exceptions
2024-02-04 22:50:05,973:INFO:Copying training dataset
2024-02-04 22:50:05,978:INFO:Checking base model
2024-02-04 22:50:05,979:INFO:Base model : Random Forest Classifier
2024-02-04 22:50:05,984:INFO:Declaring metric variables
2024-02-04 22:50:05,988:INFO:Defining Hyperparameters
2024-02-04 22:50:06,180:INFO:Tuning with n_jobs=-1
2024-02-04 22:50:06,181:INFO:Initializing RandomizedSearchCV
2024-02-04 22:50:43,300:INFO:best_params: {'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2024-02-04 22:50:43,302:INFO:Hyperparameter search completed
2024-02-04 22:50:43,303:INFO:SubProcess create_model() called ==================================
2024-02-04 22:50:43,304:INFO:Initializing create_model()
2024-02-04 22:50:43,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4BCD5990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 170, 'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2024-02-04 22:50:43,305:INFO:Checking exceptions
2024-02-04 22:50:43,305:INFO:Importing libraries
2024-02-04 22:50:43,305:INFO:Copying training dataset
2024-02-04 22:50:43,316:INFO:Defining folds
2024-02-04 22:50:43,316:INFO:Declaring metric variables
2024-02-04 22:50:43,320:INFO:Importing untrained model
2024-02-04 22:50:43,320:INFO:Declaring custom model
2024-02-04 22:50:43,326:INFO:Random Forest Classifier Imported successfully
2024-02-04 22:50:43,334:INFO:Starting cross validation
2024-02-04 22:50:43,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:50:51,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,556:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,559:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,564:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,570:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,742:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,749:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,756:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:51,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,021:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:54,044:INFO:Calculating mean and std
2024-02-04 22:50:54,045:INFO:Creating metrics dataframe
2024-02-04 22:50:54,051:INFO:Finalizing model
2024-02-04 22:50:55,291:INFO:Uploading results into container
2024-02-04 22:50:55,293:INFO:Uploading model into container now
2024-02-04 22:50:55,294:INFO:_master_model_container: 22
2024-02-04 22:50:55,294:INFO:_display_container: 6
2024-02-04 22:50:55,295:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=6, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.002, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=170, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:50:55,296:INFO:create_model() successfully completed......................................
2024-02-04 22:50:55,483:INFO:SubProcess create_model() end ==================================
2024-02-04 22:50:55,484:INFO:choose_better activated
2024-02-04 22:50:55,487:INFO:SubProcess create_model() called ==================================
2024-02-04 22:50:55,488:INFO:Initializing create_model()
2024-02-04 22:50:55,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:50:55,488:INFO:Checking exceptions
2024-02-04 22:50:55,491:INFO:Importing libraries
2024-02-04 22:50:55,491:INFO:Copying training dataset
2024-02-04 22:50:55,497:INFO:Defining folds
2024-02-04 22:50:55,497:INFO:Declaring metric variables
2024-02-04 22:50:55,497:INFO:Importing untrained model
2024-02-04 22:50:55,497:INFO:Declaring custom model
2024-02-04 22:50:55,498:INFO:Random Forest Classifier Imported successfully
2024-02-04 22:50:55,498:INFO:Starting cross validation
2024-02-04 22:50:55,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:50:57,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,331:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,484:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:57,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,067:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:50:58,086:INFO:Calculating mean and std
2024-02-04 22:50:58,087:INFO:Creating metrics dataframe
2024-02-04 22:50:58,089:INFO:Finalizing model
2024-02-04 22:50:58,465:INFO:Uploading results into container
2024-02-04 22:50:58,465:INFO:Uploading model into container now
2024-02-04 22:50:58,466:INFO:_master_model_container: 23
2024-02-04 22:50:58,466:INFO:_display_container: 7
2024-02-04 22:50:58,466:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:50:58,466:INFO:create_model() successfully completed......................................
2024-02-04 22:50:58,631:INFO:SubProcess create_model() end ==================================
2024-02-04 22:50:58,632:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False) result for Accuracy is 0.9523
2024-02-04 22:50:58,633:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=6, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.002, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=170, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False) result for Accuracy is 0.9439
2024-02-04 22:50:58,633:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False) is best model
2024-02-04 22:50:58,633:INFO:choose_better completed
2024-02-04 22:50:58,633:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 22:50:58,644:INFO:_master_model_container: 23
2024-02-04 22:50:58,645:INFO:_display_container: 6
2024-02-04 22:50:58,645:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:50:58,645:INFO:tune_model() successfully completed......................................
2024-02-04 22:50:58,847:INFO:Initializing tune_model()
2024-02-04 22:50:58,848:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>)
2024-02-04 22:50:58,848:INFO:Checking exceptions
2024-02-04 22:50:58,865:INFO:Copying training dataset
2024-02-04 22:50:58,873:INFO:Checking base model
2024-02-04 22:50:58,873:INFO:Base model : Extra Trees Classifier
2024-02-04 22:50:58,880:INFO:Declaring metric variables
2024-02-04 22:50:58,885:INFO:Defining Hyperparameters
2024-02-04 22:50:59,073:INFO:Tuning with n_jobs=-1
2024-02-04 22:50:59,073:INFO:Initializing RandomizedSearchCV
2024-02-04 22:51:15,187:INFO:best_params: {'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2024-02-04 22:51:15,189:INFO:Hyperparameter search completed
2024-02-04 22:51:15,189:INFO:SubProcess create_model() called ==================================
2024-02-04 22:51:15,190:INFO:Initializing create_model()
2024-02-04 22:51:15,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4BCD5990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 170, 'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2024-02-04 22:51:15,191:INFO:Checking exceptions
2024-02-04 22:51:15,191:INFO:Importing libraries
2024-02-04 22:51:15,191:INFO:Copying training dataset
2024-02-04 22:51:15,201:INFO:Defining folds
2024-02-04 22:51:15,201:INFO:Declaring metric variables
2024-02-04 22:51:15,206:INFO:Importing untrained model
2024-02-04 22:51:15,206:INFO:Declaring custom model
2024-02-04 22:51:15,212:INFO:Extra Trees Classifier Imported successfully
2024-02-04 22:51:15,222:INFO:Starting cross validation
2024-02-04 22:51:15,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:51:16,774:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,790:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,818:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,819:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,843:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,957:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,989:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:16,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,574:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,588:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:17,612:INFO:Calculating mean and std
2024-02-04 22:51:17,613:INFO:Creating metrics dataframe
2024-02-04 22:51:17,619:INFO:Finalizing model
2024-02-04 22:51:18,013:INFO:Uploading results into container
2024-02-04 22:51:18,014:INFO:Uploading model into container now
2024-02-04 22:51:18,015:INFO:_master_model_container: 24
2024-02-04 22:51:18,016:INFO:_display_container: 7
2024-02-04 22:51:18,018:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=6, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.002, min_samples_leaf=3,
                     min_samples_split=9, min_weight_fraction_leaf=0.0,
                     n_estimators=170, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:51:18,018:INFO:create_model() successfully completed......................................
2024-02-04 22:51:18,201:INFO:SubProcess create_model() end ==================================
2024-02-04 22:51:18,201:INFO:choose_better activated
2024-02-04 22:51:18,206:INFO:SubProcess create_model() called ==================================
2024-02-04 22:51:18,207:INFO:Initializing create_model()
2024-02-04 22:51:18,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:51:18,207:INFO:Checking exceptions
2024-02-04 22:51:18,210:INFO:Importing libraries
2024-02-04 22:51:18,210:INFO:Copying training dataset
2024-02-04 22:51:18,216:INFO:Defining folds
2024-02-04 22:51:18,216:INFO:Declaring metric variables
2024-02-04 22:51:18,216:INFO:Importing untrained model
2024-02-04 22:51:18,216:INFO:Declaring custom model
2024-02-04 22:51:18,217:INFO:Extra Trees Classifier Imported successfully
2024-02-04 22:51:18,217:INFO:Starting cross validation
2024-02-04 22:51:18,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:51:19,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,407:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,417:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,468:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,481:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:51:19,912:INFO:Calculating mean and std
2024-02-04 22:51:19,913:INFO:Creating metrics dataframe
2024-02-04 22:51:19,915:INFO:Finalizing model
2024-02-04 22:51:20,184:INFO:Uploading results into container
2024-02-04 22:51:20,185:INFO:Uploading model into container now
2024-02-04 22:51:20,185:INFO:_master_model_container: 25
2024-02-04 22:51:20,185:INFO:_display_container: 8
2024-02-04 22:51:20,186:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:51:20,186:INFO:create_model() successfully completed......................................
2024-02-04 22:51:20,345:INFO:SubProcess create_model() end ==================================
2024-02-04 22:51:20,345:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False) result for Accuracy is 0.9284
2024-02-04 22:51:20,346:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=6, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.002, min_samples_leaf=3,
                     min_samples_split=9, min_weight_fraction_leaf=0.0,
                     n_estimators=170, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False) result for Accuracy is 0.9449
2024-02-04 22:51:20,346:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=6, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.002, min_samples_leaf=3,
                     min_samples_split=9, min_weight_fraction_leaf=0.0,
                     n_estimators=170, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False) is best model
2024-02-04 22:51:20,346:INFO:choose_better completed
2024-02-04 22:51:20,356:INFO:_master_model_container: 25
2024-02-04 22:51:20,356:INFO:_display_container: 7
2024-02-04 22:51:20,357:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=6, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.002, min_samples_leaf=3,
                     min_samples_split=9, min_weight_fraction_leaf=0.0,
                     n_estimators=170, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)
2024-02-04 22:51:20,357:INFO:tune_model() successfully completed......................................
2024-02-04 22:51:20,532:INFO:Initializing ensemble_model()
2024-02-04 22:51:20,532:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0>, method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:51:20,532:INFO:Checking exceptions
2024-02-04 22:51:20,552:INFO:Importing libraries
2024-02-04 22:51:20,552:INFO:Copying training dataset
2024-02-04 22:51:20,552:INFO:Checking base model
2024-02-04 22:51:20,552:INFO:Base model : CatBoost Classifier
2024-02-04 22:51:20,560:INFO:Importing untrained ensembler
2024-02-04 22:51:20,560:INFO:Ensemble method set to Bagging
2024-02-04 22:51:20,560:INFO:SubProcess create_model() called ==================================
2024-02-04 22:51:20,561:INFO:Initializing create_model()
2024-02-04 22:51:20,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E6246D0>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD475EE980>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:51:20,561:INFO:Checking exceptions
2024-02-04 22:51:20,562:INFO:Importing libraries
2024-02-04 22:51:20,562:INFO:Copying training dataset
2024-02-04 22:51:20,569:INFO:Defining folds
2024-02-04 22:51:20,569:INFO:Declaring metric variables
2024-02-04 22:51:20,573:INFO:Importing untrained model
2024-02-04 22:51:20,573:INFO:Declaring custom model
2024-02-04 22:51:20,579:INFO:Bagging Classifier Imported successfully
2024-02-04 22:51:20,589:INFO:Starting cross validation
2024-02-04 22:51:20,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:53:34,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:34,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:34,939:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:35,941:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:36,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:36,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:36,930:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,676:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,795:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,872:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:53:38,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,179:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:54:22,190:INFO:Calculating mean and std
2024-02-04 22:54:22,191:INFO:Creating metrics dataframe
2024-02-04 22:54:22,198:INFO:Finalizing model
2024-02-04 22:54:58,479:INFO:Uploading results into container
2024-02-04 22:54:58,480:INFO:Uploading model into container now
2024-02-04 22:54:58,481:INFO:_master_model_container: 26
2024-02-04 22:54:58,481:INFO:_display_container: 8
2024-02-04 22:54:58,482:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E235780>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:54:58,482:INFO:create_model() successfully completed......................................
2024-02-04 22:54:58,670:INFO:SubProcess create_model() end ==================================
2024-02-04 22:54:58,680:INFO:_master_model_container: 26
2024-02-04 22:54:58,681:INFO:_display_container: 8
2024-02-04 22:54:58,681:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E235780>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:54:58,681:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:54:58,836:INFO:Initializing ensemble_model()
2024-02-04 22:54:58,836:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:54:58,836:INFO:Checking exceptions
2024-02-04 22:54:58,853:INFO:Importing libraries
2024-02-04 22:54:58,853:INFO:Copying training dataset
2024-02-04 22:54:58,853:INFO:Checking base model
2024-02-04 22:54:58,853:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 22:54:58,863:INFO:Importing untrained ensembler
2024-02-04 22:54:58,863:INFO:Ensemble method set to Bagging
2024-02-04 22:54:58,864:INFO:SubProcess create_model() called ==================================
2024-02-04 22:54:58,865:INFO:Initializing create_model()
2024-02-04 22:54:58,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2010,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4E4B9E40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:54:58,865:INFO:Checking exceptions
2024-02-04 22:54:58,866:INFO:Importing libraries
2024-02-04 22:54:58,866:INFO:Copying training dataset
2024-02-04 22:54:58,871:INFO:Defining folds
2024-02-04 22:54:58,871:INFO:Declaring metric variables
2024-02-04 22:54:58,874:INFO:Importing untrained model
2024-02-04 22:54:58,874:INFO:Declaring custom model
2024-02-04 22:54:58,883:INFO:Bagging Classifier Imported successfully
2024-02-04 22:54:58,892:INFO:Starting cross validation
2024-02-04 22:54:58,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:55:05,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,682:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,754:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:05,768:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:06,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:06,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:06,242:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:07,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:07,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:07,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,092:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:08,260:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,364:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,548:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:09,576:INFO:Calculating mean and std
2024-02-04 22:55:09,578:INFO:Creating metrics dataframe
2024-02-04 22:55:09,589:INFO:Finalizing model
2024-02-04 22:55:09,717:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:09,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2024-02-04 22:55:09,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:09,718:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:09,718:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:09,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.134118 -> initscore=-1.865032
2024-02-04 22:55:09,719:INFO:[LightGBM] [Info] Start training from score -1.865032
2024-02-04 22:55:09,846:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:09,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2024-02-04 22:55:09,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:09,847:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:09,847:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:09,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149580 -> initscore=-1.737900
2024-02-04 22:55:09,848:INFO:[LightGBM] [Info] Start training from score -1.737900
2024-02-04 22:55:09,981:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:09,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-02-04 22:55:09,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:09,982:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:09,983:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:09,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.157983 -> initscore=-1.673311
2024-02-04 22:55:09,983:INFO:[LightGBM] [Info] Start training from score -1.673311
2024-02-04 22:55:10,113:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2024-02-04 22:55:10,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,114:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,114:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.146218 -> initscore=-1.764573
2024-02-04 22:55:10,115:INFO:[LightGBM] [Info] Start training from score -1.764573
2024-02-04 22:55:10,243:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-04 22:55:10,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,244:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,245:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,245:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.139496 -> initscore=-1.819484
2024-02-04 22:55:10,245:INFO:[LightGBM] [Info] Start training from score -1.819484
2024-02-04 22:55:10,374:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2024-02-04 22:55:10,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,375:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,376:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.138487 -> initscore=-1.827910
2024-02-04 22:55:10,376:INFO:[LightGBM] [Info] Start training from score -1.827910
2024-02-04 22:55:10,509:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-02-04 22:55:10,510:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,510:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,510:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,511:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135462 -> initscore=-1.853503
2024-02-04 22:55:10,511:INFO:[LightGBM] [Info] Start training from score -1.853503
2024-02-04 22:55:10,657:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,657:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-02-04 22:55:10,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,658:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,658:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,658:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143866 -> initscore=-1.783548
2024-02-04 22:55:10,658:INFO:[LightGBM] [Info] Start training from score -1.783548
2024-02-04 22:55:10,782:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2024-02-04 22:55:10,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,784:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,784:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,784:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135126 -> initscore=-1.856376
2024-02-04 22:55:10,784:INFO:[LightGBM] [Info] Start training from score -1.856376
2024-02-04 22:55:10,906:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 22:55:10,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-02-04 22:55:10,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 22:55:10,908:INFO:[LightGBM] [Info] Total Bins 2452
2024-02-04 22:55:10,908:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 22:55:10,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.145882 -> initscore=-1.767268
2024-02-04 22:55:10,909:INFO:[LightGBM] [Info] Start training from score -1.767268
2024-02-04 22:55:11,035:INFO:Uploading results into container
2024-02-04 22:55:11,036:INFO:Uploading model into container now
2024-02-04 22:55:11,037:INFO:_master_model_container: 27
2024-02-04 22:55:11,038:INFO:_display_container: 9
2024-02-04 22:55:11,043:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2010,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:11,043:INFO:create_model() successfully completed......................................
2024-02-04 22:55:11,238:INFO:SubProcess create_model() end ==================================
2024-02-04 22:55:11,249:INFO:_master_model_container: 27
2024-02-04 22:55:11,249:INFO:_display_container: 9
2024-02-04 22:55:11,251:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2010,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:11,251:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:55:11,413:INFO:Initializing ensemble_model()
2024-02-04 22:55:11,413:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=5,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=40, n_iter_no_change=None,
                           random_state=2010, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:55:11,413:INFO:Checking exceptions
2024-02-04 22:55:11,430:INFO:Importing libraries
2024-02-04 22:55:11,430:INFO:Copying training dataset
2024-02-04 22:55:11,430:INFO:Checking base model
2024-02-04 22:55:11,430:INFO:Base model : Gradient Boosting Classifier
2024-02-04 22:55:11,440:INFO:Importing untrained ensembler
2024-02-04 22:55:11,440:INFO:Ensemble method set to Bagging
2024-02-04 22:55:11,440:INFO:SubProcess create_model() called ==================================
2024-02-04 22:55:11,442:INFO:Initializing create_model()
2024-02-04 22:55:11,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=5,
                                                       max_features=1.0,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.05,
                                                       min_samples_leaf=2,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=40,
                                                       n_iter_no_change=None,
                                                       random_state=2010,
                                                       subsample=0.6,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDFF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:55:11,443:INFO:Checking exceptions
2024-02-04 22:55:11,443:INFO:Importing libraries
2024-02-04 22:55:11,443:INFO:Copying training dataset
2024-02-04 22:55:11,451:INFO:Defining folds
2024-02-04 22:55:11,451:INFO:Declaring metric variables
2024-02-04 22:55:11,454:INFO:Importing untrained model
2024-02-04 22:55:11,455:INFO:Declaring custom model
2024-02-04 22:55:11,460:INFO:Bagging Classifier Imported successfully
2024-02-04 22:55:11,468:INFO:Starting cross validation
2024-02-04 22:55:11,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:55:18,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,070:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,398:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:18,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:21,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:22,015:INFO:Calculating mean and std
2024-02-04 22:55:22,016:INFO:Creating metrics dataframe
2024-02-04 22:55:22,021:INFO:Finalizing model
2024-02-04 22:55:25,274:INFO:Uploading results into container
2024-02-04 22:55:25,276:INFO:Uploading model into container now
2024-02-04 22:55:25,277:INFO:_master_model_container: 28
2024-02-04 22:55:25,277:INFO:_display_container: 10
2024-02-04 22:55:25,279:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=5,
                                                       max_features=1.0,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.05,
                                                       min_samples_leaf=2,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=40,
                                                       n_iter_no_change=None,
                                                       random_state=2010,
                                                       subsample=0.6,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:25,280:INFO:create_model() successfully completed......................................
2024-02-04 22:55:25,438:INFO:SubProcess create_model() end ==================================
2024-02-04 22:55:25,447:INFO:_master_model_container: 28
2024-02-04 22:55:25,448:INFO:_display_container: 10
2024-02-04 22:55:25,449:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=5,
                                                       max_features=1.0,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.05,
                                                       min_samples_leaf=2,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=40,
                                                       n_iter_no_change=None,
                                                       random_state=2010,
                                                       subsample=0.6,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:25,450:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:55:25,619:INFO:Initializing ensemble_model()
2024-02-04 22:55:25,619:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:55:25,619:INFO:Checking exceptions
2024-02-04 22:55:25,637:INFO:Importing libraries
2024-02-04 22:55:25,637:INFO:Copying training dataset
2024-02-04 22:55:25,637:INFO:Checking base model
2024-02-04 22:55:25,638:INFO:Base model : Random Forest Classifier
2024-02-04 22:55:25,647:INFO:Importing untrained ensembler
2024-02-04 22:55:25,647:INFO:Ensemble method set to Bagging
2024-02-04 22:55:25,647:INFO:SubProcess create_model() called ==================================
2024-02-04 22:55:25,648:INFO:Initializing create_model()
2024-02-04 22:55:25,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4BCD5990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:55:25,649:INFO:Checking exceptions
2024-02-04 22:55:25,649:INFO:Importing libraries
2024-02-04 22:55:25,649:INFO:Copying training dataset
2024-02-04 22:55:25,656:INFO:Defining folds
2024-02-04 22:55:25,656:INFO:Declaring metric variables
2024-02-04 22:55:25,660:INFO:Importing untrained model
2024-02-04 22:55:25,660:INFO:Declaring custom model
2024-02-04 22:55:25,665:INFO:Bagging Classifier Imported successfully
2024-02-04 22:55:25,678:INFO:Starting cross validation
2024-02-04 22:55:25,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:55:36,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,927:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,980:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:36,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,180:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:37,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,260:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:41,311:INFO:Calculating mean and std
2024-02-04 22:55:41,312:INFO:Creating metrics dataframe
2024-02-04 22:55:41,322:INFO:Finalizing model
2024-02-04 22:55:43,955:INFO:Uploading results into container
2024-02-04 22:55:43,956:INFO:Uploading model into container now
2024-02-04 22:55:43,958:INFO:_master_model_container: 29
2024-02-04 22:55:43,958:INFO:_display_container: 11
2024-02-04 22:55:43,960:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:43,961:INFO:create_model() successfully completed......................................
2024-02-04 22:55:44,125:INFO:SubProcess create_model() end ==================================
2024-02-04 22:55:44,135:INFO:_master_model_container: 29
2024-02-04 22:55:44,135:INFO:_display_container: 11
2024-02-04 22:55:44,137:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:55:44,137:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:55:44,287:INFO:Initializing ensemble_model()
2024-02-04 22:55:44,287:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=6, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.002, min_samples_leaf=3,
                     min_samples_split=9, min_weight_fraction_leaf=0.0,
                     n_estimators=170, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:55:44,287:INFO:Checking exceptions
2024-02-04 22:55:44,302:INFO:Importing libraries
2024-02-04 22:55:44,302:INFO:Copying training dataset
2024-02-04 22:55:44,302:INFO:Checking base model
2024-02-04 22:55:44,302:INFO:Base model : Extra Trees Classifier
2024-02-04 22:55:44,310:INFO:Importing untrained ensembler
2024-02-04 22:55:44,310:INFO:Ensemble method set to Bagging
2024-02-04 22:55:44,310:INFO:SubProcess create_model() called ==================================
2024-02-04 22:55:44,312:INFO:Initializing create_model()
2024-02-04 22:55:44,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='entropy',
                                                 max_depth=6, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.002,
                                                 min_samples_leaf=3,
                                                 min_samples_split=9,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=170, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=2010, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD499EDFF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:55:44,312:INFO:Checking exceptions
2024-02-04 22:55:44,312:INFO:Importing libraries
2024-02-04 22:55:44,312:INFO:Copying training dataset
2024-02-04 22:55:44,317:INFO:Defining folds
2024-02-04 22:55:44,317:INFO:Declaring metric variables
2024-02-04 22:55:44,321:INFO:Importing untrained model
2024-02-04 22:55:44,321:INFO:Declaring custom model
2024-02-04 22:55:44,324:INFO:Bagging Classifier Imported successfully
2024-02-04 22:55:44,331:INFO:Starting cross validation
2024-02-04 22:55:44,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:55:57,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,521:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,601:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,625:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,965:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:57,994:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:55:58,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:03,041:INFO:Calculating mean and std
2024-02-04 22:56:03,044:INFO:Creating metrics dataframe
2024-02-04 22:56:03,051:INFO:Finalizing model
2024-02-04 22:56:05,697:INFO:Uploading results into container
2024-02-04 22:56:05,698:INFO:Uploading model into container now
2024-02-04 22:56:05,698:INFO:_master_model_container: 30
2024-02-04 22:56:05,699:INFO:_display_container: 12
2024-02-04 22:56:05,701:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='entropy',
                                                 max_depth=6, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.002,
                                                 min_samples_leaf=3,
                                                 min_samples_split=9,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=170, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=2010, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:56:05,702:INFO:create_model() successfully completed......................................
2024-02-04 22:56:05,863:INFO:SubProcess create_model() end ==================================
2024-02-04 22:56:05,871:INFO:_master_model_container: 30
2024-02-04 22:56:05,871:INFO:_display_container: 12
2024-02-04 22:56:05,872:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='entropy',
                                                 max_depth=6, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.002,
                                                 min_samples_leaf=3,
                                                 min_samples_split=9,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=170, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=2010, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:56:05,872:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:56:06,028:INFO:Initializing blend_models()
2024-02-04 22:56:06,028:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:56:06,029:INFO:Checking exceptions
2024-02-04 22:56:06,046:INFO:Importing libraries
2024-02-04 22:56:06,048:INFO:Copying training dataset
2024-02-04 22:56:06,055:INFO:Getting model names
2024-02-04 22:56:06,061:INFO:SubProcess create_model() called ==================================
2024-02-04 22:56:06,071:INFO:Initializing create_model()
2024-02-04 22:56:06,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4E4B9210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:56:06,071:INFO:Checking exceptions
2024-02-04 22:56:06,071:INFO:Importing libraries
2024-02-04 22:56:06,071:INFO:Copying training dataset
2024-02-04 22:56:06,076:INFO:Defining folds
2024-02-04 22:56:06,076:INFO:Declaring metric variables
2024-02-04 22:56:06,080:INFO:Importing untrained model
2024-02-04 22:56:06,080:INFO:Declaring custom model
2024-02-04 22:56:06,088:INFO:Voting Classifier Imported successfully
2024-02-04 22:56:06,095:INFO:Starting cross validation
2024-02-04 22:56:06,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:56:23,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,907:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,928:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:23,936:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:24,588:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,129:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,138:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:56:30,161:INFO:Calculating mean and std
2024-02-04 22:56:30,163:INFO:Creating metrics dataframe
2024-02-04 22:56:30,171:INFO:Finalizing model
2024-02-04 22:56:35,007:INFO:Uploading results into container
2024-02-04 22:56:35,008:INFO:Uploading model into container now
2024-02-04 22:56:35,009:INFO:_master_model_container: 31
2024-02-04 22:56:35,009:INFO:_display_container: 13
2024-02-04 22:56:35,022:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001FD4E252A70>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 22:56:35,022:INFO:create_model() successfully completed......................................
2024-02-04 22:56:35,194:INFO:SubProcess create_model() end ==================================
2024-02-04 22:56:35,204:INFO:_master_model_container: 31
2024-02-04 22:56:35,204:INFO:_display_container: 13
2024-02-04 22:56:35,211:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001FD4E252A70>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=2010, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 22:56:35,211:INFO:blend_models() successfully completed......................................
2024-02-04 22:56:35,400:INFO:Initializing stack_models()
2024-02-04 22:56:35,401:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:56:35,401:INFO:Checking exceptions
2024-02-04 22:56:35,404:INFO:Defining meta model
2024-02-04 22:56:35,424:INFO:Getting model names
2024-02-04 22:56:35,425:INFO:[('CatBoost Classifier', <catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>), ('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False))]
2024-02-04 22:56:35,431:INFO:SubProcess create_model() called ==================================
2024-02-04 22:56:35,440:INFO:Initializing create_model()
2024-02-04 22:56:35,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=2010,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=2010,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD4E666EF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:56:35,441:INFO:Checking exceptions
2024-02-04 22:56:35,441:INFO:Importing libraries
2024-02-04 22:56:35,441:INFO:Copying training dataset
2024-02-04 22:56:35,447:INFO:Defining folds
2024-02-04 22:56:35,447:INFO:Declaring metric variables
2024-02-04 22:56:35,452:INFO:Importing untrained model
2024-02-04 22:56:35,452:INFO:Declaring custom model
2024-02-04 22:56:35,458:INFO:Stacking Classifier Imported successfully
2024-02-04 22:56:35,466:INFO:Starting cross validation
2024-02-04 22:56:35,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:58:17,470:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:17,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:17,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:17,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:17,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:17,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,910:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:17,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,021:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,213:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,223:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:18,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:18,605:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:18,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:19,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,346:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:19,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:51,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 22:58:51,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,468:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,638:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:58:51,658:INFO:Calculating mean and std
2024-02-04 22:58:51,659:INFO:Creating metrics dataframe
2024-02-04 22:58:51,666:INFO:Finalizing model
2024-02-04 22:59:07,115:INFO:Uploading results into container
2024-02-04 22:59:07,117:INFO:Uploading model into container now
2024-02-04 22:59:07,119:INFO:_master_model_container: 32
2024-02-04 22:59:07,119:INFO:_display_container: 14
2024-02-04 22:59:07,133:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x000001FD4E2A78B0>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=2010,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=2010,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 22:59:07,134:INFO:create_model() successfully completed......................................
2024-02-04 22:59:07,322:INFO:SubProcess create_model() end ==================================
2024-02-04 22:59:07,333:INFO:_master_model_container: 32
2024-02-04 22:59:07,334:INFO:_display_container: 14
2024-02-04 22:59:07,341:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x000001FD4E2A78B0>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=2010,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=2010,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 22:59:07,341:INFO:stack_models() successfully completed......................................
2024-02-04 22:59:07,516:INFO:Initializing automl()
2024-02-04 22:59:07,516:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2024-02-04 22:59:07,516:INFO:Model Selection Basis : CV Results on Training set
2024-02-04 22:59:07,516:INFO:Checking model 0
2024-02-04 22:59:07,517:INFO:Checking model 1
2024-02-04 22:59:07,518:INFO:Checking model 2
2024-02-04 22:59:07,518:INFO:Checking model 3
2024-02-04 22:59:07,518:INFO:Checking model 4
2024-02-04 22:59:07,518:INFO:Checking model 5
2024-02-04 22:59:07,518:INFO:Checking model 6
2024-02-04 22:59:07,519:INFO:Checking model 7
2024-02-04 22:59:07,519:INFO:Checking model 8
2024-02-04 22:59:07,519:INFO:Checking model 9
2024-02-04 22:59:07,519:INFO:Checking model 10
2024-02-04 22:59:07,519:INFO:Checking model 11
2024-02-04 22:59:07,519:INFO:Checking model 12
2024-02-04 22:59:07,519:INFO:Checking model 13
2024-02-04 22:59:07,520:INFO:Checking model 14
2024-02-04 22:59:07,520:INFO:Checking model 15
2024-02-04 22:59:07,520:INFO:Checking model 16
2024-02-04 22:59:07,520:INFO:Checking model 17
2024-02-04 22:59:07,520:INFO:Checking model 18
2024-02-04 22:59:07,520:INFO:Checking model 19
2024-02-04 22:59:07,521:INFO:Checking model 20
2024-02-04 22:59:07,521:INFO:Checking model 21
2024-02-04 22:59:07,521:INFO:Checking model 22
2024-02-04 22:59:07,521:INFO:Checking model 23
2024-02-04 22:59:07,521:INFO:Checking model 24
2024-02-04 22:59:07,521:INFO:Checking model 25
2024-02-04 22:59:07,522:INFO:Checking model 26
2024-02-04 22:59:07,522:INFO:Checking model 27
2024-02-04 22:59:07,522:INFO:Checking model 28
2024-02-04 22:59:07,522:INFO:Checking model 29
2024-02-04 22:59:07,522:INFO:Checking model 30
2024-02-04 22:59:07,522:INFO:Checking model 31
2024-02-04 22:59:07,523:INFO:Initializing create_model()
2024-02-04 22:59:07,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E235780>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:59:07,523:INFO:Checking exceptions
2024-02-04 22:59:07,525:INFO:Importing libraries
2024-02-04 22:59:07,525:INFO:Copying training dataset
2024-02-04 22:59:07,530:INFO:Defining folds
2024-02-04 22:59:07,530:INFO:Declaring metric variables
2024-02-04 22:59:07,531:INFO:Importing untrained model
2024-02-04 22:59:07,531:INFO:Declaring custom model
2024-02-04 22:59:07,531:INFO:Bagging Classifier Imported successfully
2024-02-04 22:59:07,533:INFO:Cross validation set to False
2024-02-04 22:59:07,533:INFO:Fitting Model
2024-02-04 22:59:43,919:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD499ED240>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:59:43,919:INFO:create_model() successfully completed......................................
2024-02-04 22:59:44,252:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD499ED240>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 22:59:44,252:INFO:automl() successfully completed......................................
2024-02-04 23:04:53,494:INFO:Initializing finalize_model()
2024-02-04 23:04:53,495:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD499ED240>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 23:04:53,496:INFO:Finalizing BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD499ED240>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False)
2024-02-04 23:04:53,502:INFO:Initializing create_model()
2024-02-04 23:04:53,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000001FD499ED240>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2010, verbose=0,
                  warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:04:53,503:INFO:Checking exceptions
2024-02-04 23:04:53,505:INFO:Importing libraries
2024-02-04 23:04:53,506:INFO:Copying training dataset
2024-02-04 23:04:53,506:INFO:Defining folds
2024-02-04 23:04:53,506:INFO:Declaring metric variables
2024-02-04 23:04:53,506:INFO:Importing untrained model
2024-02-04 23:04:53,506:INFO:Declaring custom model
2024-02-04 23:04:53,508:INFO:Bagging Classifier Imported successfully
2024-02-04 23:04:53,509:INFO:Cross validation set to False
2024-02-04 23:04:53,509:INFO:Fitting Model
2024-02-04 23:05:30,192:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                                   bootstrap_features=False,
                                   estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E20BE50>,
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=2010,
                                   verbose=0, warm_start=False))],
         verbose=False)
2024-02-04 23:05:30,192:INFO:create_model() successfully completed......................................
2024-02-04 23:05:30,354:INFO:_master_model_container: 32
2024-02-04 23:05:30,354:INFO:_display_container: 11
2024-02-04 23:05:30,385:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                                   bootstrap_features=False,
                                   estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4E20BE50>,
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=2010,
                                   verbose=0, warm_start=False))],
         verbose=False)
2024-02-04 23:05:30,385:INFO:finalize_model() successfully completed......................................
2024-02-04 23:09:12,206:INFO:Initializing finalize_model()
2024-02-04 23:09:12,206:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=[<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)], fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 23:09:12,209:INFO:Finalizing [<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)]
2024-02-04 23:09:12,214:INFO:Initializing create_model()
2024-02-04 23:09:12,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=[<catboost.core.CatBoostClassifier object at 0x000001FD49A88A00>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2010, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2010, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2010, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2010, verbose=0, warm_start=False)], fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:09:12,214:INFO:Checking exceptions
2024-02-04 23:10:11,271:INFO:Initializing automl()
2024-02-04 23:10:11,271:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, optimize=Accuracy, use_holdout=False, turbo=True, return_train_score=False)
2024-02-04 23:10:11,271:INFO:Model Selection Basis : CV Results on Training set
2024-02-04 23:10:11,271:INFO:Checking model 0
2024-02-04 23:10:11,272:INFO:Checking model 1
2024-02-04 23:10:11,272:INFO:Checking model 2
2024-02-04 23:10:11,272:INFO:Checking model 3
2024-02-04 23:10:11,272:INFO:Checking model 4
2024-02-04 23:10:11,273:INFO:Checking model 5
2024-02-04 23:10:11,273:INFO:Checking model 6
2024-02-04 23:10:11,273:INFO:Checking model 7
2024-02-04 23:10:11,273:INFO:Checking model 8
2024-02-04 23:10:11,273:INFO:Checking model 9
2024-02-04 23:10:11,273:INFO:Checking model 10
2024-02-04 23:10:11,274:INFO:Checking model 11
2024-02-04 23:10:11,274:INFO:Checking model 12
2024-02-04 23:10:11,274:INFO:Checking model 13
2024-02-04 23:10:11,274:INFO:Checking model 14
2024-02-04 23:10:11,274:INFO:Checking model 15
2024-02-04 23:10:11,274:INFO:Checking model 16
2024-02-04 23:10:11,275:INFO:Checking model 17
2024-02-04 23:10:11,275:INFO:Checking model 18
2024-02-04 23:10:11,275:INFO:Checking model 19
2024-02-04 23:10:11,275:INFO:Checking model 20
2024-02-04 23:10:11,275:INFO:Checking model 21
2024-02-04 23:10:11,275:INFO:Checking model 22
2024-02-04 23:10:11,275:INFO:Checking model 23
2024-02-04 23:10:11,276:INFO:Checking model 24
2024-02-04 23:10:11,276:INFO:Checking model 25
2024-02-04 23:10:11,276:INFO:Checking model 26
2024-02-04 23:10:11,276:INFO:Checking model 27
2024-02-04 23:10:11,276:INFO:Checking model 28
2024-02-04 23:10:11,276:INFO:Checking model 29
2024-02-04 23:10:11,276:INFO:Checking model 30
2024-02-04 23:10:11,277:INFO:Checking model 31
2024-02-04 23:10:11,277:INFO:Initializing create_model()
2024-02-04 23:10:11,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD4CE17A00>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:10:11,277:INFO:Checking exceptions
2024-02-04 23:10:11,279:INFO:Importing libraries
2024-02-04 23:10:11,279:INFO:Copying training dataset
2024-02-04 23:10:11,285:INFO:Defining folds
2024-02-04 23:10:11,285:INFO:Declaring metric variables
2024-02-04 23:10:11,285:INFO:Importing untrained model
2024-02-04 23:10:11,285:INFO:Declaring custom model
2024-02-04 23:10:11,286:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:10:11,287:INFO:Cross validation set to False
2024-02-04 23:10:11,287:INFO:Fitting Model
2024-02-04 23:10:14,083:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>
2024-02-04 23:10:14,083:INFO:create_model() successfully completed......................................
2024-02-04 23:10:14,439:INFO:<catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>
2024-02-04 23:10:14,439:INFO:automl() successfully completed......................................
2024-02-04 23:11:33,403:INFO:Initializing finalize_model()
2024-02-04 23:11:33,403:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 23:11:33,404:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>
2024-02-04 23:11:33,408:INFO:Initializing create_model()
2024-02-04 23:11:33,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:11:33,409:INFO:Checking exceptions
2024-02-04 23:11:33,411:INFO:Importing libraries
2024-02-04 23:11:33,411:INFO:Copying training dataset
2024-02-04 23:11:33,411:INFO:Defining folds
2024-02-04 23:11:33,412:INFO:Declaring metric variables
2024-02-04 23:11:33,412:INFO:Importing untrained model
2024-02-04 23:11:33,412:INFO:Declaring custom model
2024-02-04 23:11:33,412:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:11:33,413:INFO:Cross validation set to False
2024-02-04 23:11:33,414:INFO:Fitting Model
2024-02-04 23:11:37,080:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001FD5A5258A0>)],
         verbose=False)
2024-02-04 23:11:37,080:INFO:create_model() successfully completed......................................
2024-02-04 23:11:37,261:INFO:_master_model_container: 32
2024-02-04 23:11:37,261:INFO:_display_container: 8
2024-02-04 23:11:37,284:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001FD5A5258A0>)],
         verbose=False)
2024-02-04 23:11:37,285:INFO:finalize_model() successfully completed......................................
2024-02-04 23:12:33,117:INFO:Initializing predict_model()
2024-02-04 23:12:33,117:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD499ED480>, estimator=<catboost.core.CatBoostClassifier object at 0x000001FD6095FFA0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FD60E40670>)
2024-02-04 23:12:33,117:INFO:Checking exceptions
2024-02-04 23:12:33,118:INFO:Preloading libraries
2024-02-04 23:12:33,120:INFO:Set up data.
2024-02-04 23:12:33,127:INFO:Set up index.
2024-02-04 23:28:12,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 23:28:12,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 23:28:12,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 23:28:12,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-04 23:28:13,683:INFO:PyCaret ClassificationExperiment
2024-02-04 23:28:13,683:INFO:Logging name: clf-default-name
2024-02-04 23:28:13,684:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 23:28:13,684:INFO:version 3.2.0
2024-02-04 23:28:13,684:INFO:Initializing setup()
2024-02-04 23:28:13,684:INFO:self.USI: 638a
2024-02-04 23:28:13,685:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'fold_shuffle_param', '_available_plots', 'X_train', 'fold_generator', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'log_plots_param', 'data', 'is_multiclass', 'y', 'idx', 'fold_groups_param', 'fix_imbalance', 'target_param', 'html_param', 'USI', 'seed', 'X', '_ml_usecase', 'memory', 'gpu_param', 'y_train', 'pipeline', 'y_test', 'exp_name_log'}
2024-02-04 23:28:13,685:INFO:Checking environment
2024-02-04 23:28:13,685:INFO:python_version: 3.10.9
2024-02-04 23:28:13,685:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 23:28:13,686:INFO:machine: AMD64
2024-02-04 23:28:13,686:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 23:28:13,686:INFO:Memory: svmem(total=16856182784, available=8049741824, percent=52.2, used=8806440960, free=8049741824)
2024-02-04 23:28:13,686:INFO:Physical Core: 4
2024-02-04 23:28:13,687:INFO:Logical Core: 8
2024-02-04 23:28:13,687:INFO:Checking libraries
2024-02-04 23:28:13,687:INFO:System:
2024-02-04 23:28:13,687:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 23:28:13,688:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 23:28:13,688:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 23:28:13,688:INFO:PyCaret required dependencies:
2024-02-04 23:28:13,882:INFO:                 pip: 22.3.1
2024-02-04 23:28:13,882:INFO:          setuptools: 65.6.3
2024-02-04 23:28:13,882:INFO:             pycaret: 3.2.0
2024-02-04 23:28:13,882:INFO:             IPython: 8.20.0
2024-02-04 23:28:13,882:INFO:          ipywidgets: 8.0.4
2024-02-04 23:28:13,882:INFO:                tqdm: 4.64.1
2024-02-04 23:28:13,882:INFO:               numpy: 1.25.2
2024-02-04 23:28:13,882:INFO:              pandas: 1.5.3
2024-02-04 23:28:13,882:INFO:              jinja2: 3.1.3
2024-02-04 23:28:13,882:INFO:               scipy: 1.10.1
2024-02-04 23:28:13,882:INFO:              joblib: 1.3.2
2024-02-04 23:28:13,882:INFO:             sklearn: 1.2.2
2024-02-04 23:28:13,882:INFO:                pyod: 1.1.2
2024-02-04 23:28:13,882:INFO:            imblearn: 0.12.0
2024-02-04 23:28:13,882:INFO:   category_encoders: 2.6.3
2024-02-04 23:28:13,882:INFO:            lightgbm: 4.3.0
2024-02-04 23:28:13,883:INFO:               numba: 0.59.0
2024-02-04 23:28:13,883:INFO:            requests: 2.31.0
2024-02-04 23:28:13,883:INFO:          matplotlib: 3.6.0
2024-02-04 23:28:13,883:INFO:          scikitplot: 0.3.7
2024-02-04 23:28:13,883:INFO:         yellowbrick: 1.5
2024-02-04 23:28:13,883:INFO:              plotly: 5.18.0
2024-02-04 23:28:13,883:INFO:    plotly-resampler: Not installed
2024-02-04 23:28:13,883:INFO:             kaleido: 0.2.1
2024-02-04 23:28:13,883:INFO:           schemdraw: 0.15
2024-02-04 23:28:13,883:INFO:         statsmodels: 0.14.1
2024-02-04 23:28:13,883:INFO:              sktime: 0.21.1
2024-02-04 23:28:13,883:INFO:               tbats: 1.1.3
2024-02-04 23:28:13,883:INFO:            pmdarima: 2.0.4
2024-02-04 23:28:13,883:INFO:              psutil: 5.9.0
2024-02-04 23:28:13,883:INFO:          markupsafe: 2.1.3
2024-02-04 23:28:13,883:INFO:             pickle5: Not installed
2024-02-04 23:28:13,883:INFO:         cloudpickle: 3.0.0
2024-02-04 23:28:13,883:INFO:         deprecation: 2.1.0
2024-02-04 23:28:13,883:INFO:              xxhash: 3.4.1
2024-02-04 23:28:13,883:INFO:           wurlitzer: Not installed
2024-02-04 23:28:13,883:INFO:PyCaret optional dependencies:
2024-02-04 23:28:13,895:INFO:                shap: 0.44.1
2024-02-04 23:28:13,895:INFO:           interpret: Not installed
2024-02-04 23:28:13,895:INFO:                umap: Not installed
2024-02-04 23:28:13,895:INFO:     ydata_profiling: Not installed
2024-02-04 23:28:13,895:INFO:  explainerdashboard: 0.4.5
2024-02-04 23:28:13,895:INFO:             autoviz: Not installed
2024-02-04 23:28:13,895:INFO:           fairlearn: Not installed
2024-02-04 23:28:13,895:INFO:          deepchecks: Not installed
2024-02-04 23:28:13,896:INFO:             xgboost: Not installed
2024-02-04 23:28:13,896:INFO:            catboost: 1.2.2
2024-02-04 23:28:13,896:INFO:              kmodes: Not installed
2024-02-04 23:28:13,896:INFO:             mlxtend: Not installed
2024-02-04 23:28:13,896:INFO:       statsforecast: Not installed
2024-02-04 23:28:13,896:INFO:        tune_sklearn: Not installed
2024-02-04 23:28:13,896:INFO:                 ray: Not installed
2024-02-04 23:28:13,896:INFO:            hyperopt: Not installed
2024-02-04 23:28:13,896:INFO:              optuna: Not installed
2024-02-04 23:28:13,896:INFO:               skopt: Not installed
2024-02-04 23:28:13,896:INFO:              mlflow: 2.10.0
2024-02-04 23:28:13,896:INFO:              gradio: Not installed
2024-02-04 23:28:13,896:INFO:             fastapi: Not installed
2024-02-04 23:28:13,896:INFO:             uvicorn: Not installed
2024-02-04 23:28:13,896:INFO:              m2cgen: Not installed
2024-02-04 23:28:13,896:INFO:           evidently: Not installed
2024-02-04 23:28:13,896:INFO:               fugue: Not installed
2024-02-04 23:28:13,896:INFO:           streamlit: Not installed
2024-02-04 23:28:13,896:INFO:             prophet: Not installed
2024-02-04 23:28:13,896:INFO:None
2024-02-04 23:28:13,896:INFO:Set up data.
2024-02-04 23:28:13,921:INFO:Set up folding strategy.
2024-02-04 23:28:13,921:INFO:Set up train/test split.
2024-02-04 23:28:13,932:INFO:Set up index.
2024-02-04 23:28:13,933:INFO:Assigning column types.
2024-02-04 23:28:13,938:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 23:28:13,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 23:28:13,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 23:28:14,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,037:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 23:28:14,132:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 23:28:14,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,166:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,167:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 23:28:14,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 23:28:14,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,268:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,320:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 23:28:14,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,375:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,376:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 23:28:14,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,494:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:14,562:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:14,564:INFO:Preparing preprocessing pipeline...
2024-02-04 23:28:14,566:INFO:Set up label encoding.
2024-02-04 23:28:14,566:INFO:Set up simple imputation.
2024-02-04 23:28:14,572:INFO:Set up encoding of ordinal features.
2024-02-04 23:28:14,576:INFO:Set up encoding of categorical features.
2024-02-04 23:28:14,711:INFO:Finished creating preprocessing pipeline.
2024-02-04 23:28:14,735:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'to...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-02-04 23:28:14,735:INFO:Creating final display dataframe.
2024-02-04 23:28:15,093:INFO:Setup _display_container:                     Description             Value
0                    Session id              5309
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 20)
5        Transformed data shape        (4250, 22)
6   Transformed train set shape        (2975, 22)
7    Transformed test set shape        (1275, 22)
8              Ordinal features                 2
9              Numeric features                15
10         Categorical features                 4
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              638a
2024-02-04 23:28:15,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:15,189:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:15,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 23:28:15,269:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 23:28:15,270:INFO:setup() successfully completed in 1.6s...............
2024-02-04 23:28:15,286:INFO:Initializing compare_models()
2024-02-04 23:28:15,286:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-04 23:28:15,286:INFO:Checking exceptions
2024-02-04 23:28:15,294:INFO:Preparing display monitor
2024-02-04 23:28:15,336:INFO:Initializing Logistic Regression
2024-02-04 23:28:15,336:INFO:Total runtime is 0.0 minutes
2024-02-04 23:28:15,339:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:15,340:INFO:Initializing create_model()
2024-02-04 23:28:15,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:15,340:INFO:Checking exceptions
2024-02-04 23:28:15,341:INFO:Importing libraries
2024-02-04 23:28:15,341:INFO:Copying training dataset
2024-02-04 23:28:15,346:INFO:Defining folds
2024-02-04 23:28:15,347:INFO:Declaring metric variables
2024-02-04 23:28:15,349:INFO:Importing untrained model
2024-02-04 23:28:15,352:INFO:Logistic Regression Imported successfully
2024-02-04 23:28:15,358:INFO:Starting cross validation
2024-02-04 23:28:15,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:21,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:21,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:21,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:21,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:21,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:21,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:21,999:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:22,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:22,082:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,092:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:22,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:22,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:28:22,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:22,739:INFO:Calculating mean and std
2024-02-04 23:28:22,741:INFO:Creating metrics dataframe
2024-02-04 23:28:22,746:INFO:Uploading results into container
2024-02-04 23:28:22,746:INFO:Uploading model into container now
2024-02-04 23:28:22,747:INFO:_master_model_container: 1
2024-02-04 23:28:22,747:INFO:_display_container: 2
2024-02-04 23:28:22,748:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5309, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 23:28:22,748:INFO:create_model() successfully completed......................................
2024-02-04 23:28:22,833:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:22,834:INFO:Creating metrics dataframe
2024-02-04 23:28:22,845:INFO:Initializing K Neighbors Classifier
2024-02-04 23:28:22,845:INFO:Total runtime is 0.12514899174372354 minutes
2024-02-04 23:28:22,849:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:22,849:INFO:Initializing create_model()
2024-02-04 23:28:22,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:22,849:INFO:Checking exceptions
2024-02-04 23:28:22,849:INFO:Importing libraries
2024-02-04 23:28:22,849:INFO:Copying training dataset
2024-02-04 23:28:22,854:INFO:Defining folds
2024-02-04 23:28:22,854:INFO:Declaring metric variables
2024-02-04 23:28:22,859:INFO:Importing untrained model
2024-02-04 23:28:22,865:INFO:K Neighbors Classifier Imported successfully
2024-02-04 23:28:22,872:INFO:Starting cross validation
2024-02-04 23:28:22,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:23,249:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,252:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,256:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,264:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,264:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,485:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,495:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,519:INFO:Calculating mean and std
2024-02-04 23:28:23,522:INFO:Creating metrics dataframe
2024-02-04 23:28:23,532:INFO:Uploading results into container
2024-02-04 23:28:23,533:INFO:Uploading model into container now
2024-02-04 23:28:23,534:INFO:_master_model_container: 2
2024-02-04 23:28:23,534:INFO:_display_container: 2
2024-02-04 23:28:23,535:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 23:28:23,535:INFO:create_model() successfully completed......................................
2024-02-04 23:28:23,628:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:23,628:INFO:Creating metrics dataframe
2024-02-04 23:28:23,637:INFO:Initializing Naive Bayes
2024-02-04 23:28:23,637:INFO:Total runtime is 0.13835983276367186 minutes
2024-02-04 23:28:23,640:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:23,641:INFO:Initializing create_model()
2024-02-04 23:28:23,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:23,641:INFO:Checking exceptions
2024-02-04 23:28:23,641:INFO:Importing libraries
2024-02-04 23:28:23,641:INFO:Copying training dataset
2024-02-04 23:28:23,647:INFO:Defining folds
2024-02-04 23:28:23,647:INFO:Declaring metric variables
2024-02-04 23:28:23,650:INFO:Importing untrained model
2024-02-04 23:28:23,654:INFO:Naive Bayes Imported successfully
2024-02-04 23:28:23,662:INFO:Starting cross validation
2024-02-04 23:28:23,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:23,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,928:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,936:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,960:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,994:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:23,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,010:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,136:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,164:INFO:Calculating mean and std
2024-02-04 23:28:24,165:INFO:Creating metrics dataframe
2024-02-04 23:28:24,174:INFO:Uploading results into container
2024-02-04 23:28:24,176:INFO:Uploading model into container now
2024-02-04 23:28:24,177:INFO:_master_model_container: 3
2024-02-04 23:28:24,178:INFO:_display_container: 2
2024-02-04 23:28:24,178:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 23:28:24,179:INFO:create_model() successfully completed......................................
2024-02-04 23:28:24,283:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:24,283:INFO:Creating metrics dataframe
2024-02-04 23:28:24,294:INFO:Initializing Decision Tree Classifier
2024-02-04 23:28:24,294:INFO:Total runtime is 0.14931219816207886 minutes
2024-02-04 23:28:24,297:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:24,298:INFO:Initializing create_model()
2024-02-04 23:28:24,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:24,299:INFO:Checking exceptions
2024-02-04 23:28:24,299:INFO:Importing libraries
2024-02-04 23:28:24,299:INFO:Copying training dataset
2024-02-04 23:28:24,316:INFO:Defining folds
2024-02-04 23:28:24,316:INFO:Declaring metric variables
2024-02-04 23:28:24,322:INFO:Importing untrained model
2024-02-04 23:28:24,330:INFO:Decision Tree Classifier Imported successfully
2024-02-04 23:28:24,340:INFO:Starting cross validation
2024-02-04 23:28:24,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:24,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,635:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,649:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,656:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,675:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,873:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:24,898:INFO:Calculating mean and std
2024-02-04 23:28:24,899:INFO:Creating metrics dataframe
2024-02-04 23:28:24,902:INFO:Uploading results into container
2024-02-04 23:28:24,902:INFO:Uploading model into container now
2024-02-04 23:28:24,903:INFO:_master_model_container: 4
2024-02-04 23:28:24,903:INFO:_display_container: 2
2024-02-04 23:28:24,904:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5309, splitter='best')
2024-02-04 23:28:24,904:INFO:create_model() successfully completed......................................
2024-02-04 23:28:24,988:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:24,989:INFO:Creating metrics dataframe
2024-02-04 23:28:25,006:INFO:Initializing SVM - Linear Kernel
2024-02-04 23:28:25,006:INFO:Total runtime is 0.16117881933848063 minutes
2024-02-04 23:28:25,013:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:25,014:INFO:Initializing create_model()
2024-02-04 23:28:25,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:25,014:INFO:Checking exceptions
2024-02-04 23:28:25,014:INFO:Importing libraries
2024-02-04 23:28:25,014:INFO:Copying training dataset
2024-02-04 23:28:25,023:INFO:Defining folds
2024-02-04 23:28:25,024:INFO:Declaring metric variables
2024-02-04 23:28:25,030:INFO:Importing untrained model
2024-02-04 23:28:25,041:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 23:28:25,050:INFO:Starting cross validation
2024-02-04 23:28:25,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:25,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,322:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,322:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:25,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,331:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,340:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,340:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,350:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:25,356:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,540:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 23:28:25,543:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:25,544:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:25,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:25,574:INFO:Calculating mean and std
2024-02-04 23:28:25,575:INFO:Creating metrics dataframe
2024-02-04 23:28:25,579:INFO:Uploading results into container
2024-02-04 23:28:25,580:INFO:Uploading model into container now
2024-02-04 23:28:25,581:INFO:_master_model_container: 5
2024-02-04 23:28:25,581:INFO:_display_container: 2
2024-02-04 23:28:25,583:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5309, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 23:28:25,583:INFO:create_model() successfully completed......................................
2024-02-04 23:28:25,682:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:25,682:INFO:Creating metrics dataframe
2024-02-04 23:28:25,708:INFO:Initializing Ridge Classifier
2024-02-04 23:28:25,708:INFO:Total runtime is 0.17286550998687744 minutes
2024-02-04 23:28:25,711:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:25,712:INFO:Initializing create_model()
2024-02-04 23:28:25,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:25,713:INFO:Checking exceptions
2024-02-04 23:28:25,713:INFO:Importing libraries
2024-02-04 23:28:25,713:INFO:Copying training dataset
2024-02-04 23:28:25,729:INFO:Defining folds
2024-02-04 23:28:25,729:INFO:Declaring metric variables
2024-02-04 23:28:25,737:INFO:Importing untrained model
2024-02-04 23:28:25,750:INFO:Ridge Classifier Imported successfully
2024-02-04 23:28:25,758:INFO:Starting cross validation
2024-02-04 23:28:25,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:25,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,011:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,021:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,021:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,202:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 23:28:26,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,219:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:26,236:INFO:Calculating mean and std
2024-02-04 23:28:26,237:INFO:Creating metrics dataframe
2024-02-04 23:28:26,240:INFO:Uploading results into container
2024-02-04 23:28:26,240:INFO:Uploading model into container now
2024-02-04 23:28:26,241:INFO:_master_model_container: 6
2024-02-04 23:28:26,241:INFO:_display_container: 2
2024-02-04 23:28:26,241:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5309, solver='auto',
                tol=0.0001)
2024-02-04 23:28:26,241:INFO:create_model() successfully completed......................................
2024-02-04 23:28:26,335:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:26,336:INFO:Creating metrics dataframe
2024-02-04 23:28:26,350:INFO:Initializing Random Forest Classifier
2024-02-04 23:28:26,350:INFO:Total runtime is 0.18356764316558838 minutes
2024-02-04 23:28:26,353:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:26,354:INFO:Initializing create_model()
2024-02-04 23:28:26,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:26,354:INFO:Checking exceptions
2024-02-04 23:28:26,354:INFO:Importing libraries
2024-02-04 23:28:26,354:INFO:Copying training dataset
2024-02-04 23:28:26,359:INFO:Defining folds
2024-02-04 23:28:26,359:INFO:Declaring metric variables
2024-02-04 23:28:26,369:INFO:Importing untrained model
2024-02-04 23:28:26,377:INFO:Random Forest Classifier Imported successfully
2024-02-04 23:28:26,383:INFO:Starting cross validation
2024-02-04 23:28:26,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:27,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,771:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:27,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,396:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,407:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,416:INFO:Calculating mean and std
2024-02-04 23:28:28,417:INFO:Creating metrics dataframe
2024-02-04 23:28:28,420:INFO:Uploading results into container
2024-02-04 23:28:28,420:INFO:Uploading model into container now
2024-02-04 23:28:28,421:INFO:_master_model_container: 7
2024-02-04 23:28:28,421:INFO:_display_container: 2
2024-02-04 23:28:28,421:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:28:28,422:INFO:create_model() successfully completed......................................
2024-02-04 23:28:28,504:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:28,504:INFO:Creating metrics dataframe
2024-02-04 23:28:28,514:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 23:28:28,515:INFO:Total runtime is 0.21965439716974894 minutes
2024-02-04 23:28:28,518:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:28,518:INFO:Initializing create_model()
2024-02-04 23:28:28,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:28,518:INFO:Checking exceptions
2024-02-04 23:28:28,518:INFO:Importing libraries
2024-02-04 23:28:28,519:INFO:Copying training dataset
2024-02-04 23:28:28,523:INFO:Defining folds
2024-02-04 23:28:28,523:INFO:Declaring metric variables
2024-02-04 23:28:28,527:INFO:Importing untrained model
2024-02-04 23:28:28,533:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 23:28:28,541:INFO:Starting cross validation
2024-02-04 23:28:28,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:28,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,723:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,747:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,754:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,818:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,820:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,835:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,835:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 23:28:28,981:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:28,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,014:INFO:Calculating mean and std
2024-02-04 23:28:29,015:INFO:Creating metrics dataframe
2024-02-04 23:28:29,018:INFO:Uploading results into container
2024-02-04 23:28:29,018:INFO:Uploading model into container now
2024-02-04 23:28:29,019:INFO:_master_model_container: 8
2024-02-04 23:28:29,019:INFO:_display_container: 2
2024-02-04 23:28:29,019:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 23:28:29,019:INFO:create_model() successfully completed......................................
2024-02-04 23:28:29,087:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:29,087:INFO:Creating metrics dataframe
2024-02-04 23:28:29,113:INFO:Initializing Ada Boost Classifier
2024-02-04 23:28:29,113:INFO:Total runtime is 0.2296274979909261 minutes
2024-02-04 23:28:29,117:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:29,118:INFO:Initializing create_model()
2024-02-04 23:28:29,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:29,118:INFO:Checking exceptions
2024-02-04 23:28:29,118:INFO:Importing libraries
2024-02-04 23:28:29,118:INFO:Copying training dataset
2024-02-04 23:28:29,124:INFO:Defining folds
2024-02-04 23:28:29,124:INFO:Declaring metric variables
2024-02-04 23:28:29,128:INFO:Importing untrained model
2024-02-04 23:28:29,132:INFO:Ada Boost Classifier Imported successfully
2024-02-04 23:28:29,139:INFO:Starting cross validation
2024-02-04 23:28:29,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:29,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,907:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,909:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,909:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,909:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,912:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,914:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,926:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:29,928:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,557:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,574:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:30,607:INFO:Calculating mean and std
2024-02-04 23:28:30,609:INFO:Creating metrics dataframe
2024-02-04 23:28:30,619:INFO:Uploading results into container
2024-02-04 23:28:30,620:INFO:Uploading model into container now
2024-02-04 23:28:30,622:INFO:_master_model_container: 9
2024-02-04 23:28:30,622:INFO:_display_container: 2
2024-02-04 23:28:30,622:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5309)
2024-02-04 23:28:30,623:INFO:create_model() successfully completed......................................
2024-02-04 23:28:30,725:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:30,725:INFO:Creating metrics dataframe
2024-02-04 23:28:30,738:INFO:Initializing Gradient Boosting Classifier
2024-02-04 23:28:30,738:INFO:Total runtime is 0.2567044178644816 minutes
2024-02-04 23:28:30,742:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:30,742:INFO:Initializing create_model()
2024-02-04 23:28:30,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:30,742:INFO:Checking exceptions
2024-02-04 23:28:30,742:INFO:Importing libraries
2024-02-04 23:28:30,743:INFO:Copying training dataset
2024-02-04 23:28:30,748:INFO:Defining folds
2024-02-04 23:28:30,748:INFO:Declaring metric variables
2024-02-04 23:28:30,755:INFO:Importing untrained model
2024-02-04 23:28:30,760:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 23:28:30,769:INFO:Starting cross validation
2024-02-04 23:28:30,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:32,675:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,679:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,779:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:32,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:34,469:INFO:Calculating mean and std
2024-02-04 23:28:34,470:INFO:Creating metrics dataframe
2024-02-04 23:28:34,476:INFO:Uploading results into container
2024-02-04 23:28:34,476:INFO:Uploading model into container now
2024-02-04 23:28:34,477:INFO:_master_model_container: 10
2024-02-04 23:28:34,477:INFO:_display_container: 2
2024-02-04 23:28:34,478:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 23:28:34,478:INFO:create_model() successfully completed......................................
2024-02-04 23:28:34,587:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:34,588:INFO:Creating metrics dataframe
2024-02-04 23:28:34,607:INFO:Initializing Linear Discriminant Analysis
2024-02-04 23:28:34,607:INFO:Total runtime is 0.3211946765581767 minutes
2024-02-04 23:28:34,613:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:34,613:INFO:Initializing create_model()
2024-02-04 23:28:34,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:34,613:INFO:Checking exceptions
2024-02-04 23:28:34,614:INFO:Importing libraries
2024-02-04 23:28:34,614:INFO:Copying training dataset
2024-02-04 23:28:34,623:INFO:Defining folds
2024-02-04 23:28:34,624:INFO:Declaring metric variables
2024-02-04 23:28:34,632:INFO:Importing untrained model
2024-02-04 23:28:34,639:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 23:28:34,649:INFO:Starting cross validation
2024-02-04 23:28:34,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:34,999:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,107:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,120:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,314:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:35,334:INFO:Calculating mean and std
2024-02-04 23:28:35,336:INFO:Creating metrics dataframe
2024-02-04 23:28:35,345:INFO:Uploading results into container
2024-02-04 23:28:35,347:INFO:Uploading model into container now
2024-02-04 23:28:35,350:INFO:_master_model_container: 11
2024-02-04 23:28:35,350:INFO:_display_container: 2
2024-02-04 23:28:35,350:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 23:28:35,351:INFO:create_model() successfully completed......................................
2024-02-04 23:28:35,453:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:35,453:INFO:Creating metrics dataframe
2024-02-04 23:28:35,465:INFO:Initializing Extra Trees Classifier
2024-02-04 23:28:35,465:INFO:Total runtime is 0.33549512227376305 minutes
2024-02-04 23:28:35,470:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:35,470:INFO:Initializing create_model()
2024-02-04 23:28:35,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:35,470:INFO:Checking exceptions
2024-02-04 23:28:35,470:INFO:Importing libraries
2024-02-04 23:28:35,471:INFO:Copying training dataset
2024-02-04 23:28:35,481:INFO:Defining folds
2024-02-04 23:28:35,481:INFO:Declaring metric variables
2024-02-04 23:28:35,487:INFO:Importing untrained model
2024-02-04 23:28:35,499:INFO:Extra Trees Classifier Imported successfully
2024-02-04 23:28:35,521:INFO:Starting cross validation
2024-02-04 23:28:35,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:36,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,788:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,844:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,852:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,853:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,980:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:36,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:37,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:37,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:37,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:37,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:37,448:INFO:Calculating mean and std
2024-02-04 23:28:37,451:INFO:Creating metrics dataframe
2024-02-04 23:28:37,457:INFO:Uploading results into container
2024-02-04 23:28:37,458:INFO:Uploading model into container now
2024-02-04 23:28:37,459:INFO:_master_model_container: 12
2024-02-04 23:28:37,459:INFO:_display_container: 2
2024-02-04 23:28:37,461:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:28:37,461:INFO:create_model() successfully completed......................................
2024-02-04 23:28:37,583:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:37,583:INFO:Creating metrics dataframe
2024-02-04 23:28:37,610:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 23:28:37,611:INFO:Total runtime is 0.37125800450642904 minutes
2024-02-04 23:28:37,619:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:37,620:INFO:Initializing create_model()
2024-02-04 23:28:37,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:37,620:INFO:Checking exceptions
2024-02-04 23:28:37,621:INFO:Importing libraries
2024-02-04 23:28:37,621:INFO:Copying training dataset
2024-02-04 23:28:37,633:INFO:Defining folds
2024-02-04 23:28:37,633:INFO:Declaring metric variables
2024-02-04 23:28:37,643:INFO:Importing untrained model
2024-02-04 23:28:37,654:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 23:28:37,670:INFO:Starting cross validation
2024-02-04 23:28:37,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:38,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:38,962:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:38,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:38,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,438:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,676:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:39,700:INFO:Calculating mean and std
2024-02-04 23:28:39,702:INFO:Creating metrics dataframe
2024-02-04 23:28:39,707:INFO:Uploading results into container
2024-02-04 23:28:39,708:INFO:Uploading model into container now
2024-02-04 23:28:39,708:INFO:_master_model_container: 13
2024-02-04 23:28:39,709:INFO:_display_container: 2
2024-02-04 23:28:39,709:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 23:28:39,710:INFO:create_model() successfully completed......................................
2024-02-04 23:28:39,817:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:39,817:INFO:Creating metrics dataframe
2024-02-04 23:28:39,841:INFO:Initializing CatBoost Classifier
2024-02-04 23:28:39,842:INFO:Total runtime is 0.4084187150001526 minutes
2024-02-04 23:28:39,850:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:39,851:INFO:Initializing create_model()
2024-02-04 23:28:39,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:39,851:INFO:Checking exceptions
2024-02-04 23:28:39,852:INFO:Importing libraries
2024-02-04 23:28:39,852:INFO:Copying training dataset
2024-02-04 23:28:39,866:INFO:Defining folds
2024-02-04 23:28:39,866:INFO:Declaring metric variables
2024-02-04 23:28:39,875:INFO:Importing untrained model
2024-02-04 23:28:39,891:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:28:39,916:INFO:Starting cross validation
2024-02-04 23:28:39,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:53,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:53,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:53,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,463:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,469:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,795:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,909:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:54,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:55,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,313:INFO:Calculating mean and std
2024-02-04 23:28:59,314:INFO:Creating metrics dataframe
2024-02-04 23:28:59,320:INFO:Uploading results into container
2024-02-04 23:28:59,320:INFO:Uploading model into container now
2024-02-04 23:28:59,321:INFO:_master_model_container: 14
2024-02-04 23:28:59,321:INFO:_display_container: 2
2024-02-04 23:28:59,322:INFO:<catboost.core.CatBoostClassifier object at 0x0000015834E043D0>
2024-02-04 23:28:59,322:INFO:create_model() successfully completed......................................
2024-02-04 23:28:59,420:INFO:SubProcess create_model() end ==================================
2024-02-04 23:28:59,420:INFO:Creating metrics dataframe
2024-02-04 23:28:59,438:INFO:Initializing Dummy Classifier
2024-02-04 23:28:59,439:INFO:Total runtime is 0.7350579857826233 minutes
2024-02-04 23:28:59,443:INFO:SubProcess create_model() called ==================================
2024-02-04 23:28:59,444:INFO:Initializing create_model()
2024-02-04 23:28:59,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834CEC820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:28:59,444:INFO:Checking exceptions
2024-02-04 23:28:59,444:INFO:Importing libraries
2024-02-04 23:28:59,444:INFO:Copying training dataset
2024-02-04 23:28:59,450:INFO:Defining folds
2024-02-04 23:28:59,450:INFO:Declaring metric variables
2024-02-04 23:28:59,457:INFO:Importing untrained model
2024-02-04 23:28:59,467:INFO:Dummy Classifier Imported successfully
2024-02-04 23:28:59,483:INFO:Starting cross validation
2024-02-04 23:28:59,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:28:59,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,846:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,853:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,857:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,888:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,912:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,926:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,944:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,950:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,955:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,955:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:28:59,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:28:59,963:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,094:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:29:00,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 23:29:00,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:29:00,165:INFO:Calculating mean and std
2024-02-04 23:29:00,165:INFO:Creating metrics dataframe
2024-02-04 23:29:00,170:INFO:Uploading results into container
2024-02-04 23:29:00,171:INFO:Uploading model into container now
2024-02-04 23:29:00,172:INFO:_master_model_container: 15
2024-02-04 23:29:00,172:INFO:_display_container: 2
2024-02-04 23:29:00,173:INFO:DummyClassifier(constant=None, random_state=5309, strategy='prior')
2024-02-04 23:29:00,173:INFO:create_model() successfully completed......................................
2024-02-04 23:29:00,267:INFO:SubProcess create_model() end ==================================
2024-02-04 23:29:00,268:INFO:Creating metrics dataframe
2024-02-04 23:29:00,306:INFO:Initializing create_model()
2024-02-04 23:29:00,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=<catboost.core.CatBoostClassifier object at 0x0000015834E043D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:29:00,307:INFO:Checking exceptions
2024-02-04 23:29:00,309:INFO:Importing libraries
2024-02-04 23:29:00,310:INFO:Copying training dataset
2024-02-04 23:29:00,318:INFO:Defining folds
2024-02-04 23:29:00,318:INFO:Declaring metric variables
2024-02-04 23:29:00,318:INFO:Importing untrained model
2024-02-04 23:29:00,318:INFO:Declaring custom model
2024-02-04 23:29:00,319:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:29:00,321:INFO:Cross validation set to False
2024-02-04 23:29:00,321:INFO:Fitting Model
2024-02-04 23:29:04,150:INFO:<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>
2024-02-04 23:29:04,150:INFO:create_model() successfully completed......................................
2024-02-04 23:29:04,231:INFO:Initializing create_model()
2024-02-04 23:29:04,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:29:04,232:INFO:Checking exceptions
2024-02-04 23:29:04,236:INFO:Importing libraries
2024-02-04 23:29:04,236:INFO:Copying training dataset
2024-02-04 23:29:04,242:INFO:Defining folds
2024-02-04 23:29:04,243:INFO:Declaring metric variables
2024-02-04 23:29:04,243:INFO:Importing untrained model
2024-02-04 23:29:04,243:INFO:Declaring custom model
2024-02-04 23:29:04,243:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 23:29:04,245:INFO:Cross validation set to False
2024-02-04 23:29:04,245:INFO:Fitting Model
2024-02-04 23:29:04,358:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:29:04,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
2024-02-04 23:29:04,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:29:04,359:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:29:04,359:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:29:04,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 23:29:04,360:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 23:29:04,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 23:29:04,474:INFO:create_model() successfully completed......................................
2024-02-04 23:29:04,572:INFO:Initializing create_model()
2024-02-04 23:29:04,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:29:04,573:INFO:Checking exceptions
2024-02-04 23:29:04,577:INFO:Importing libraries
2024-02-04 23:29:04,578:INFO:Copying training dataset
2024-02-04 23:29:04,584:INFO:Defining folds
2024-02-04 23:29:04,584:INFO:Declaring metric variables
2024-02-04 23:29:04,584:INFO:Importing untrained model
2024-02-04 23:29:04,585:INFO:Declaring custom model
2024-02-04 23:29:04,585:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 23:29:04,587:INFO:Cross validation set to False
2024-02-04 23:29:04,587:INFO:Fitting Model
2024-02-04 23:29:05,796:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 23:29:05,796:INFO:create_model() successfully completed......................................
2024-02-04 23:29:05,871:INFO:Initializing create_model()
2024-02-04 23:29:05,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:29:05,872:INFO:Checking exceptions
2024-02-04 23:29:05,874:INFO:Importing libraries
2024-02-04 23:29:05,875:INFO:Copying training dataset
2024-02-04 23:29:05,881:INFO:Defining folds
2024-02-04 23:29:05,881:INFO:Declaring metric variables
2024-02-04 23:29:05,881:INFO:Importing untrained model
2024-02-04 23:29:05,881:INFO:Declaring custom model
2024-02-04 23:29:05,882:INFO:Random Forest Classifier Imported successfully
2024-02-04 23:29:05,883:INFO:Cross validation set to False
2024-02-04 23:29:05,883:INFO:Fitting Model
2024-02-04 23:29:06,177:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:29:06,177:INFO:create_model() successfully completed......................................
2024-02-04 23:29:06,253:INFO:Initializing create_model()
2024-02-04 23:29:06,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:29:06,253:INFO:Checking exceptions
2024-02-04 23:29:06,255:INFO:Importing libraries
2024-02-04 23:29:06,256:INFO:Copying training dataset
2024-02-04 23:29:06,262:INFO:Defining folds
2024-02-04 23:29:06,262:INFO:Declaring metric variables
2024-02-04 23:29:06,262:INFO:Importing untrained model
2024-02-04 23:29:06,262:INFO:Declaring custom model
2024-02-04 23:29:06,263:INFO:Extra Trees Classifier Imported successfully
2024-02-04 23:29:06,264:INFO:Cross validation set to False
2024-02-04 23:29:06,264:INFO:Fitting Model
2024-02-04 23:29:06,489:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:29:06,489:INFO:create_model() successfully completed......................................
2024-02-04 23:29:06,588:INFO:_master_model_container: 15
2024-02-04 23:29:06,589:INFO:_display_container: 2
2024-02-04 23:29:06,590:INFO:[<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)]
2024-02-04 23:29:06,590:INFO:compare_models() successfully completed......................................
2024-02-04 23:30:03,728:INFO:Initializing tune_model()
2024-02-04 23:30:03,728:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>)
2024-02-04 23:30:03,728:INFO:Checking exceptions
2024-02-04 23:30:03,750:INFO:Copying training dataset
2024-02-04 23:30:03,755:INFO:Checking base model
2024-02-04 23:30:03,755:INFO:Base model : CatBoost Classifier
2024-02-04 23:30:03,758:INFO:Declaring metric variables
2024-02-04 23:30:03,763:INFO:Defining Hyperparameters
2024-02-04 23:30:03,860:INFO:Tuning with n_jobs=-1
2024-02-04 23:30:03,861:INFO:Initializing RandomizedSearchCV
2024-02-04 23:32:42,379:INFO:best_params: {'actual_estimator__random_strength': 0.0, 'actual_estimator__n_estimators': 100, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 4}
2024-02-04 23:32:42,380:INFO:Hyperparameter search completed
2024-02-04 23:32:42,380:INFO:SubProcess create_model() called ==================================
2024-02-04 23:32:42,381:INFO:Initializing create_model()
2024-02-04 23:32:42,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=<catboost.core.CatBoostClassifier object at 0x000001580FC7BCD0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158349A7BB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.0, 'n_estimators': 100, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 4})
2024-02-04 23:32:42,381:INFO:Checking exceptions
2024-02-04 23:32:42,381:INFO:Importing libraries
2024-02-04 23:32:42,382:INFO:Copying training dataset
2024-02-04 23:32:42,395:INFO:Defining folds
2024-02-04 23:32:42,395:INFO:Declaring metric variables
2024-02-04 23:32:42,402:INFO:Importing untrained model
2024-02-04 23:32:42,402:INFO:Declaring custom model
2024-02-04 23:32:42,408:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:32:42,418:INFO:Starting cross validation
2024-02-04 23:32:42,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:32:43,502:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,556:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,616:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,635:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,656:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,659:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,664:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:43,676:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,151:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:44,174:INFO:Calculating mean and std
2024-02-04 23:32:44,175:INFO:Creating metrics dataframe
2024-02-04 23:32:44,182:INFO:Finalizing model
2024-02-04 23:32:44,594:INFO:Uploading results into container
2024-02-04 23:32:44,595:INFO:Uploading model into container now
2024-02-04 23:32:44,595:INFO:_master_model_container: 16
2024-02-04 23:32:44,596:INFO:_display_container: 2
2024-02-04 23:32:44,596:INFO:<catboost.core.CatBoostClassifier object at 0x00000158372B66E0>
2024-02-04 23:32:44,596:INFO:create_model() successfully completed......................................
2024-02-04 23:32:44,698:INFO:SubProcess create_model() end ==================================
2024-02-04 23:32:44,698:INFO:choose_better activated
2024-02-04 23:32:44,702:INFO:SubProcess create_model() called ==================================
2024-02-04 23:32:44,703:INFO:Initializing create_model()
2024-02-04 23:32:44,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:32:44,703:INFO:Checking exceptions
2024-02-04 23:32:44,705:INFO:Importing libraries
2024-02-04 23:32:44,705:INFO:Copying training dataset
2024-02-04 23:32:44,712:INFO:Defining folds
2024-02-04 23:32:44,712:INFO:Declaring metric variables
2024-02-04 23:32:44,712:INFO:Importing untrained model
2024-02-04 23:32:44,712:INFO:Declaring custom model
2024-02-04 23:32:44,712:INFO:CatBoost Classifier Imported successfully
2024-02-04 23:32:44,713:INFO:Starting cross validation
2024-02-04 23:32:44,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:32:59,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,401:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,485:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,494:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:32:59,710:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,659:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:04,672:INFO:Calculating mean and std
2024-02-04 23:33:04,673:INFO:Creating metrics dataframe
2024-02-04 23:33:04,677:INFO:Finalizing model
2024-02-04 23:33:08,672:INFO:Uploading results into container
2024-02-04 23:33:08,673:INFO:Uploading model into container now
2024-02-04 23:33:08,673:INFO:_master_model_container: 17
2024-02-04 23:33:08,673:INFO:_display_container: 3
2024-02-04 23:33:08,673:INFO:<catboost.core.CatBoostClassifier object at 0x00000158337B8760>
2024-02-04 23:33:08,674:INFO:create_model() successfully completed......................................
2024-02-04 23:33:08,752:INFO:SubProcess create_model() end ==================================
2024-02-04 23:33:08,753:INFO:<catboost.core.CatBoostClassifier object at 0x00000158337B8760> result for Accuracy is 0.959
2024-02-04 23:33:08,753:INFO:<catboost.core.CatBoostClassifier object at 0x00000158372B66E0> result for Accuracy is 0.9586
2024-02-04 23:33:08,753:INFO:<catboost.core.CatBoostClassifier object at 0x00000158337B8760> is best model
2024-02-04 23:33:08,753:INFO:choose_better completed
2024-02-04 23:33:08,753:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 23:33:08,764:INFO:_master_model_container: 17
2024-02-04 23:33:08,764:INFO:_display_container: 2
2024-02-04 23:33:08,764:INFO:<catboost.core.CatBoostClassifier object at 0x00000158337B8760>
2024-02-04 23:33:08,764:INFO:tune_model() successfully completed......................................
2024-02-04 23:33:08,847:INFO:Initializing tune_model()
2024-02-04 23:33:08,847:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>)
2024-02-04 23:33:08,847:INFO:Checking exceptions
2024-02-04 23:33:08,863:INFO:Copying training dataset
2024-02-04 23:33:08,870:INFO:Checking base model
2024-02-04 23:33:08,870:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 23:33:08,874:INFO:Declaring metric variables
2024-02-04 23:33:08,878:INFO:Defining Hyperparameters
2024-02-04 23:33:08,970:INFO:Tuning with n_jobs=-1
2024-02-04 23:33:08,971:INFO:Initializing RandomizedSearchCV
2024-02-04 23:33:22,789:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 26, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2024-02-04 23:33:22,790:INFO:Hyperparameter search completed
2024-02-04 23:33:22,790:INFO:SubProcess create_model() called ==================================
2024-02-04 23:33:22,791:INFO:Initializing create_model()
2024-02-04 23:33:22,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001580FC37AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 10, 'reg_alpha': 0.005, 'num_leaves': 256, 'n_estimators': 180, 'min_split_gain': 0.6, 'min_child_samples': 26, 'learning_rate': 0.1, 'feature_fraction': 0.6, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2024-02-04 23:33:22,792:INFO:Checking exceptions
2024-02-04 23:33:22,792:INFO:Importing libraries
2024-02-04 23:33:22,792:INFO:Copying training dataset
2024-02-04 23:33:22,803:INFO:Defining folds
2024-02-04 23:33:22,803:INFO:Declaring metric variables
2024-02-04 23:33:22,809:INFO:Importing untrained model
2024-02-04 23:33:22,809:INFO:Declaring custom model
2024-02-04 23:33:22,816:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 23:33:22,827:INFO:Starting cross validation
2024-02-04 23:33:22,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:33:23,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,724:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,726:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,734:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,871:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,912:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:23,952:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,173:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:24,196:INFO:Calculating mean and std
2024-02-04 23:33:24,199:INFO:Creating metrics dataframe
2024-02-04 23:33:24,208:INFO:Finalizing model
2024-02-04 23:33:24,349:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 23:33:24,349:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-04 23:33:24,349:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-02-04 23:33:24,354:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 23:33:24,355:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-04 23:33:24,355:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2024-02-04 23:33:24,355:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:33:24,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2024-02-04 23:33:24,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:33:24,356:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:33:24,358:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:33:24,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 23:33:24,359:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 23:33:24,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,474:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,474:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,475:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,476:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,479:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,480:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,480:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 23:33:24,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 23:33:24,513:INFO:Uploading results into container
2024-02-04 23:33:24,514:INFO:Uploading model into container now
2024-02-04 23:33:24,515:INFO:_master_model_container: 18
2024-02-04 23:33:24,516:INFO:_display_container: 3
2024-02-04 23:33:24,519:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=180, n_jobs=-1, num_leaves=256, objective=None,
               random_state=5309, reg_alpha=0.005, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 23:33:24,519:INFO:create_model() successfully completed......................................
2024-02-04 23:33:24,642:INFO:SubProcess create_model() end ==================================
2024-02-04 23:33:24,642:INFO:choose_better activated
2024-02-04 23:33:24,646:INFO:SubProcess create_model() called ==================================
2024-02-04 23:33:24,647:INFO:Initializing create_model()
2024-02-04 23:33:24,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:33:24,648:INFO:Checking exceptions
2024-02-04 23:33:24,651:INFO:Importing libraries
2024-02-04 23:33:24,651:INFO:Copying training dataset
2024-02-04 23:33:24,658:INFO:Defining folds
2024-02-04 23:33:24,658:INFO:Declaring metric variables
2024-02-04 23:33:24,659:INFO:Importing untrained model
2024-02-04 23:33:24,659:INFO:Declaring custom model
2024-02-04 23:33:24,660:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 23:33:24,660:INFO:Starting cross validation
2024-02-04 23:33:24,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:33:26,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,051:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,053:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,065:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,074:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,082:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,236:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,251:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,401:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,810:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:26,850:INFO:Calculating mean and std
2024-02-04 23:33:26,851:INFO:Creating metrics dataframe
2024-02-04 23:33:26,855:INFO:Finalizing model
2024-02-04 23:33:27,000:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:33:27,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.
2024-02-04 23:33:27,002:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:33:27,002:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:33:27,002:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:33:27,002:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-04 23:33:27,003:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-04 23:33:27,180:INFO:Uploading results into container
2024-02-04 23:33:27,181:INFO:Uploading model into container now
2024-02-04 23:33:27,182:INFO:_master_model_container: 19
2024-02-04 23:33:27,182:INFO:_display_container: 4
2024-02-04 23:33:27,183:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 23:33:27,183:INFO:create_model() successfully completed......................................
2024-02-04 23:33:27,293:INFO:SubProcess create_model() end ==================================
2024-02-04 23:33:27,294:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9583
2024-02-04 23:33:27,295:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=180, n_jobs=-1, num_leaves=256, objective=None,
               random_state=5309, reg_alpha=0.005, reg_lambda=10, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9523
2024-02-04 23:33:27,296:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 23:33:27,296:INFO:choose_better completed
2024-02-04 23:33:27,296:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 23:33:27,310:INFO:_master_model_container: 19
2024-02-04 23:33:27,310:INFO:_display_container: 3
2024-02-04 23:33:27,311:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 23:33:27,312:INFO:tune_model() successfully completed......................................
2024-02-04 23:33:27,414:INFO:Initializing tune_model()
2024-02-04 23:33:27,414:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>)
2024-02-04 23:33:27,414:INFO:Checking exceptions
2024-02-04 23:33:27,437:INFO:Copying training dataset
2024-02-04 23:33:27,445:INFO:Checking base model
2024-02-04 23:33:27,446:INFO:Base model : Gradient Boosting Classifier
2024-02-04 23:33:27,452:INFO:Declaring metric variables
2024-02-04 23:33:27,459:INFO:Defining Hyperparameters
2024-02-04 23:33:27,563:INFO:Tuning with n_jobs=-1
2024-02-04 23:33:27,564:INFO:Initializing RandomizedSearchCV
2024-02-04 23:33:55,237:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.3}
2024-02-04 23:33:55,238:INFO:Hyperparameter search completed
2024-02-04 23:33:55,239:INFO:SubProcess create_model() called ==================================
2024-02-04 23:33:55,240:INFO:Initializing create_model()
2024-02-04 23:33:55,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015830E68070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.75, 'n_estimators': 280, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0, 'max_features': 'log2', 'max_depth': 11, 'learning_rate': 0.3})
2024-02-04 23:33:55,240:INFO:Checking exceptions
2024-02-04 23:33:55,240:INFO:Importing libraries
2024-02-04 23:33:55,241:INFO:Copying training dataset
2024-02-04 23:33:55,250:INFO:Defining folds
2024-02-04 23:33:55,250:INFO:Declaring metric variables
2024-02-04 23:33:55,254:INFO:Importing untrained model
2024-02-04 23:33:55,254:INFO:Declaring custom model
2024-02-04 23:33:55,261:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 23:33:55,270:INFO:Starting cross validation
2024-02-04 23:33:55,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:33:58,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,951:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:58,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:33:59,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,743:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,772:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:00,787:INFO:Calculating mean and std
2024-02-04 23:34:00,788:INFO:Creating metrics dataframe
2024-02-04 23:34:00,797:INFO:Finalizing model
2024-02-04 23:34:02,461:INFO:Uploading results into container
2024-02-04 23:34:02,462:INFO:Uploading model into container now
2024-02-04 23:34:02,463:INFO:_master_model_container: 20
2024-02-04 23:34:02,463:INFO:_display_container: 4
2024-02-04 23:34:02,464:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.3, loss='log_loss', max_depth=11,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=5,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=5309, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 23:34:02,464:INFO:create_model() successfully completed......................................
2024-02-04 23:34:02,553:INFO:SubProcess create_model() end ==================================
2024-02-04 23:34:02,553:INFO:choose_better activated
2024-02-04 23:34:02,556:INFO:SubProcess create_model() called ==================================
2024-02-04 23:34:02,557:INFO:Initializing create_model()
2024-02-04 23:34:02,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:34:02,557:INFO:Checking exceptions
2024-02-04 23:34:02,559:INFO:Importing libraries
2024-02-04 23:34:02,559:INFO:Copying training dataset
2024-02-04 23:34:02,563:INFO:Defining folds
2024-02-04 23:34:02,564:INFO:Declaring metric variables
2024-02-04 23:34:02,564:INFO:Importing untrained model
2024-02-04 23:34:02,564:INFO:Declaring custom model
2024-02-04 23:34:02,564:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 23:34:02,564:INFO:Starting cross validation
2024-02-04 23:34:02,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:34:04,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,571:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,584:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,588:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,602:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,602:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,603:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,621:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:04,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:05,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:05,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:05,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:06,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:06,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:06,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:06,035:INFO:Calculating mean and std
2024-02-04 23:34:06,035:INFO:Creating metrics dataframe
2024-02-04 23:34:06,037:INFO:Finalizing model
2024-02-04 23:34:07,211:INFO:Uploading results into container
2024-02-04 23:34:07,211:INFO:Uploading model into container now
2024-02-04 23:34:07,212:INFO:_master_model_container: 21
2024-02-04 23:34:07,212:INFO:_display_container: 5
2024-02-04 23:34:07,212:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 23:34:07,212:INFO:create_model() successfully completed......................................
2024-02-04 23:34:07,296:INFO:SubProcess create_model() end ==================================
2024-02-04 23:34:07,296:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9576
2024-02-04 23:34:07,297:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.3, loss='log_loss', max_depth=11,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=5,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=5309, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9519
2024-02-04 23:34:07,297:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-04 23:34:07,297:INFO:choose_better completed
2024-02-04 23:34:07,297:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 23:34:07,308:INFO:_master_model_container: 21
2024-02-04 23:34:07,308:INFO:_display_container: 4
2024-02-04 23:34:07,308:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 23:34:07,309:INFO:tune_model() successfully completed......................................
2024-02-04 23:34:07,392:INFO:Initializing tune_model()
2024-02-04 23:34:07,392:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>)
2024-02-04 23:34:07,392:INFO:Checking exceptions
2024-02-04 23:34:07,408:INFO:Copying training dataset
2024-02-04 23:34:07,412:INFO:Checking base model
2024-02-04 23:34:07,412:INFO:Base model : Random Forest Classifier
2024-02-04 23:34:07,416:INFO:Declaring metric variables
2024-02-04 23:34:07,420:INFO:Defining Hyperparameters
2024-02-04 23:34:07,524:INFO:Tuning with n_jobs=-1
2024-02-04 23:34:07,524:INFO:Initializing RandomizedSearchCV
2024-02-04 23:34:40,357:INFO:best_params: {'actual_estimator__n_estimators': 110, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': True}
2024-02-04 23:34:40,359:INFO:Hyperparameter search completed
2024-02-04 23:34:40,360:INFO:SubProcess create_model() called ==================================
2024-02-04 23:34:40,361:INFO:Initializing create_model()
2024-02-04 23:34:40,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015837455E40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 110, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 10, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': True})
2024-02-04 23:34:40,361:INFO:Checking exceptions
2024-02-04 23:34:40,362:INFO:Importing libraries
2024-02-04 23:34:40,362:INFO:Copying training dataset
2024-02-04 23:34:40,377:INFO:Defining folds
2024-02-04 23:34:40,378:INFO:Declaring metric variables
2024-02-04 23:34:40,386:INFO:Importing untrained model
2024-02-04 23:34:40,387:INFO:Declaring custom model
2024-02-04 23:34:40,397:INFO:Random Forest Classifier Imported successfully
2024-02-04 23:34:40,412:INFO:Starting cross validation
2024-02-04 23:34:40,415:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:34:45,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,713:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,719:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,729:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,729:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,745:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,914:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,941:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:45,950:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,502:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:47,550:INFO:Calculating mean and std
2024-02-04 23:34:47,551:INFO:Creating metrics dataframe
2024-02-04 23:34:47,557:INFO:Finalizing model
2024-02-04 23:34:48,466:INFO:Uploading results into container
2024-02-04 23:34:48,467:INFO:Uploading model into container now
2024-02-04 23:34:48,468:INFO:_master_model_container: 22
2024-02-04 23:34:48,468:INFO:_display_container: 5
2024-02-04 23:34:48,469:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=10, max_features=1.0, max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=110,
                       n_jobs=-1, oob_score=False, random_state=5309, verbose=0,
                       warm_start=False)
2024-02-04 23:34:48,470:INFO:create_model() successfully completed......................................
2024-02-04 23:34:48,579:INFO:SubProcess create_model() end ==================================
2024-02-04 23:34:48,579:INFO:choose_better activated
2024-02-04 23:34:48,583:INFO:SubProcess create_model() called ==================================
2024-02-04 23:34:48,584:INFO:Initializing create_model()
2024-02-04 23:34:48,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:34:48,584:INFO:Checking exceptions
2024-02-04 23:34:48,586:INFO:Importing libraries
2024-02-04 23:34:48,587:INFO:Copying training dataset
2024-02-04 23:34:48,592:INFO:Defining folds
2024-02-04 23:34:48,592:INFO:Declaring metric variables
2024-02-04 23:34:48,593:INFO:Importing untrained model
2024-02-04 23:34:48,593:INFO:Declaring custom model
2024-02-04 23:34:48,593:INFO:Random Forest Classifier Imported successfully
2024-02-04 23:34:48,594:INFO:Starting cross validation
2024-02-04 23:34:48,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:34:50,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,397:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,397:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,397:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,405:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,412:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,510:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,540:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:50,556:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,133:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:34:51,159:INFO:Calculating mean and std
2024-02-04 23:34:51,159:INFO:Creating metrics dataframe
2024-02-04 23:34:51,162:INFO:Finalizing model
2024-02-04 23:34:51,554:INFO:Uploading results into container
2024-02-04 23:34:51,554:INFO:Uploading model into container now
2024-02-04 23:34:51,555:INFO:_master_model_container: 23
2024-02-04 23:34:51,555:INFO:_display_container: 6
2024-02-04 23:34:51,555:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:34:51,555:INFO:create_model() successfully completed......................................
2024-02-04 23:34:51,632:INFO:SubProcess create_model() end ==================================
2024-02-04 23:34:51,633:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False) result for Accuracy is 0.9506
2024-02-04 23:34:51,634:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=10, max_features=1.0, max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=110,
                       n_jobs=-1, oob_score=False, random_state=5309, verbose=0,
                       warm_start=False) result for Accuracy is 0.9523
2024-02-04 23:34:51,634:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=10, max_features=1.0, max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=110,
                       n_jobs=-1, oob_score=False, random_state=5309, verbose=0,
                       warm_start=False) is best model
2024-02-04 23:34:51,634:INFO:choose_better completed
2024-02-04 23:34:51,645:INFO:_master_model_container: 23
2024-02-04 23:34:51,645:INFO:_display_container: 5
2024-02-04 23:34:51,646:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=10, max_features=1.0, max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=110,
                       n_jobs=-1, oob_score=False, random_state=5309, verbose=0,
                       warm_start=False)
2024-02-04 23:34:51,647:INFO:tune_model() successfully completed......................................
2024-02-04 23:34:51,725:INFO:Initializing tune_model()
2024-02-04 23:34:51,725:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>)
2024-02-04 23:34:51,725:INFO:Checking exceptions
2024-02-04 23:34:51,743:INFO:Copying training dataset
2024-02-04 23:34:51,748:INFO:Checking base model
2024-02-04 23:34:51,748:INFO:Base model : Extra Trees Classifier
2024-02-04 23:34:51,753:INFO:Declaring metric variables
2024-02-04 23:34:51,757:INFO:Defining Hyperparameters
2024-02-04 23:34:51,861:INFO:Tuning with n_jobs=-1
2024-02-04 23:34:51,861:INFO:Initializing RandomizedSearchCV
2024-02-04 23:35:06,665:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2024-02-04 23:35:06,666:INFO:Hyperparameter search completed
2024-02-04 23:35:06,666:INFO:SubProcess create_model() called ==================================
2024-02-04 23:35:06,667:INFO:Initializing create_model()
2024-02-04 23:35:06,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015830E68070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 70, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.001, 'max_features': 1.0, 'max_depth': 11, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2024-02-04 23:35:06,668:INFO:Checking exceptions
2024-02-04 23:35:06,668:INFO:Importing libraries
2024-02-04 23:35:06,669:INFO:Copying training dataset
2024-02-04 23:35:06,679:INFO:Defining folds
2024-02-04 23:35:06,679:INFO:Declaring metric variables
2024-02-04 23:35:06,684:INFO:Importing untrained model
2024-02-04 23:35:06,685:INFO:Declaring custom model
2024-02-04 23:35:06,692:INFO:Extra Trees Classifier Imported successfully
2024-02-04 23:35:06,702:INFO:Starting cross validation
2024-02-04 23:35:06,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:35:07,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,530:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,544:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,574:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,620:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,962:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:07,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:08,004:INFO:Calculating mean and std
2024-02-04 23:35:08,005:INFO:Creating metrics dataframe
2024-02-04 23:35:08,011:INFO:Finalizing model
2024-02-04 23:35:08,214:INFO:Uploading results into container
2024-02-04 23:35:08,215:INFO:Uploading model into container now
2024-02-04 23:35:08,216:INFO:_master_model_container: 24
2024-02-04 23:35:08,216:INFO:_display_container: 6
2024-02-04 23:35:08,217:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=11, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.001, min_samples_leaf=4,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=70, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:35:08,218:INFO:create_model() successfully completed......................................
2024-02-04 23:35:08,301:INFO:SubProcess create_model() end ==================================
2024-02-04 23:35:08,301:INFO:choose_better activated
2024-02-04 23:35:08,304:INFO:SubProcess create_model() called ==================================
2024-02-04 23:35:08,305:INFO:Initializing create_model()
2024-02-04 23:35:08,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:35:08,305:INFO:Checking exceptions
2024-02-04 23:35:08,306:INFO:Importing libraries
2024-02-04 23:35:08,306:INFO:Copying training dataset
2024-02-04 23:35:08,312:INFO:Defining folds
2024-02-04 23:35:08,312:INFO:Declaring metric variables
2024-02-04 23:35:08,312:INFO:Importing untrained model
2024-02-04 23:35:08,312:INFO:Declaring custom model
2024-02-04 23:35:08,313:INFO:Extra Trees Classifier Imported successfully
2024-02-04 23:35:08,313:INFO:Starting cross validation
2024-02-04 23:35:08,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:35:09,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,485:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,846:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:35:09,863:INFO:Calculating mean and std
2024-02-04 23:35:09,863:INFO:Creating metrics dataframe
2024-02-04 23:35:09,867:INFO:Finalizing model
2024-02-04 23:35:10,101:INFO:Uploading results into container
2024-02-04 23:35:10,102:INFO:Uploading model into container now
2024-02-04 23:35:10,102:INFO:_master_model_container: 25
2024-02-04 23:35:10,102:INFO:_display_container: 7
2024-02-04 23:35:10,102:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:35:10,103:INFO:create_model() successfully completed......................................
2024-02-04 23:35:10,176:INFO:SubProcess create_model() end ==================================
2024-02-04 23:35:10,177:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False) result for Accuracy is 0.9271
2024-02-04 23:35:10,177:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=11, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.001, min_samples_leaf=4,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=70, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False) result for Accuracy is 0.9449
2024-02-04 23:35:10,178:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=11, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.001, min_samples_leaf=4,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=70, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False) is best model
2024-02-04 23:35:10,178:INFO:choose_better completed
2024-02-04 23:35:10,187:INFO:_master_model_container: 25
2024-02-04 23:35:10,187:INFO:_display_container: 6
2024-02-04 23:35:10,187:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=11, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.001, min_samples_leaf=4,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=70, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)
2024-02-04 23:35:10,187:INFO:tune_model() successfully completed......................................
2024-02-04 23:35:10,278:INFO:Initializing ensemble_model()
2024-02-04 23:35:10,278:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=<catboost.core.CatBoostClassifier object at 0x00000158337B8760>, method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:35:10,278:INFO:Checking exceptions
2024-02-04 23:35:10,299:INFO:Importing libraries
2024-02-04 23:35:10,300:INFO:Copying training dataset
2024-02-04 23:35:10,300:INFO:Checking base model
2024-02-04 23:35:10,300:INFO:Base model : CatBoost Classifier
2024-02-04 23:35:10,308:INFO:Importing untrained ensembler
2024-02-04 23:35:10,308:INFO:Ensemble method set to Bagging
2024-02-04 23:35:10,308:INFO:SubProcess create_model() called ==================================
2024-02-04 23:35:10,309:INFO:Initializing create_model()
2024-02-04 23:35:10,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x00000158337B8760>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001581016F790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:35:10,309:INFO:Checking exceptions
2024-02-04 23:35:10,310:INFO:Importing libraries
2024-02-04 23:35:10,310:INFO:Copying training dataset
2024-02-04 23:35:10,317:INFO:Defining folds
2024-02-04 23:35:10,317:INFO:Declaring metric variables
2024-02-04 23:35:10,321:INFO:Importing untrained model
2024-02-04 23:35:10,321:INFO:Declaring custom model
2024-02-04 23:35:10,327:INFO:Bagging Classifier Imported successfully
2024-02-04 23:35:10,335:INFO:Starting cross validation
2024-02-04 23:35:10,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:37:27,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:27,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:27,675:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:27,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:27,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:27,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:28,442:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:28,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:28,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:30,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:30,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:30,773:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:31,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:31,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:31,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,045:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:37:32,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:38:17,341:INFO:Calculating mean and std
2024-02-04 23:38:17,343:INFO:Creating metrics dataframe
2024-02-04 23:38:17,350:INFO:Finalizing model
2024-02-04 23:38:54,386:INFO:Uploading results into container
2024-02-04 23:38:54,387:INFO:Uploading model into container now
2024-02-04 23:38:54,388:INFO:_master_model_container: 26
2024-02-04 23:38:54,389:INFO:_display_container: 7
2024-02-04 23:38:54,390:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x00000158372A48B0>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:38:54,390:INFO:create_model() successfully completed......................................
2024-02-04 23:38:54,489:INFO:SubProcess create_model() end ==================================
2024-02-04 23:38:54,499:INFO:_master_model_container: 26
2024-02-04 23:38:54,499:INFO:_display_container: 7
2024-02-04 23:38:54,500:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x00000158372A48B0>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:38:54,500:INFO:ensemble_model() successfully completed......................................
2024-02-04 23:38:54,577:INFO:Initializing ensemble_model()
2024-02-04 23:38:54,577:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:38:54,577:INFO:Checking exceptions
2024-02-04 23:38:54,594:INFO:Importing libraries
2024-02-04 23:38:54,594:INFO:Copying training dataset
2024-02-04 23:38:54,595:INFO:Checking base model
2024-02-04 23:38:54,595:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 23:38:54,602:INFO:Importing untrained ensembler
2024-02-04 23:38:54,602:INFO:Ensemble method set to Bagging
2024-02-04 23:38:54,602:INFO:SubProcess create_model() called ==================================
2024-02-04 23:38:54,604:INFO:Initializing create_model()
2024-02-04 23:38:54,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=5309,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015837443CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:38:54,604:INFO:Checking exceptions
2024-02-04 23:38:54,604:INFO:Importing libraries
2024-02-04 23:38:54,604:INFO:Copying training dataset
2024-02-04 23:38:54,609:INFO:Defining folds
2024-02-04 23:38:54,610:INFO:Declaring metric variables
2024-02-04 23:38:54,613:INFO:Importing untrained model
2024-02-04 23:38:54,613:INFO:Declaring custom model
2024-02-04 23:38:54,618:INFO:Bagging Classifier Imported successfully
2024-02-04 23:38:54,629:INFO:Starting cross validation
2024-02-04 23:38:54,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:39:00,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,607:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,676:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,866:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,874:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:00,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:01,358:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:01,365:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:01,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:02,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:02,820:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:02,828:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:03,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:03,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:03,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:04,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:04,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:04,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:05,190:INFO:Calculating mean and std
2024-02-04 23:39:05,192:INFO:Creating metrics dataframe
2024-02-04 23:39:05,201:INFO:Finalizing model
2024-02-04 23:39:05,358:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:05,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-02-04 23:39:05,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:05,359:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:05,359:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:05,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.144538 -> initscore=-1.778101
2024-02-04 23:39:05,360:INFO:[LightGBM] [Info] Start training from score -1.778101
2024-02-04 23:39:05,524:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:05,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-04 23:39:05,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:05,525:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:05,525:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:05,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.148571 -> initscore=-1.745850
2024-02-04 23:39:05,526:INFO:[LightGBM] [Info] Start training from score -1.745850
2024-02-04 23:39:05,682:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:05,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2024-02-04 23:39:05,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:05,683:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:05,684:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:05,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141513 -> initscore=-1.802783
2024-02-04 23:39:05,684:INFO:[LightGBM] [Info] Start training from score -1.802783
2024-02-04 23:39:05,826:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:05,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.
2024-02-04 23:39:05,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:05,827:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:05,827:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:05,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.134454 -> initscore=-1.862140
2024-02-04 23:39:05,828:INFO:[LightGBM] [Info] Start training from score -1.862140
2024-02-04 23:39:05,976:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:05,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000484 seconds.
2024-02-04 23:39:05,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:05,977:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:05,977:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:05,977:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117311 -> initscore=-2.018145
2024-02-04 23:39:05,977:INFO:[LightGBM] [Info] Start training from score -2.018145
2024-02-04 23:39:06,138:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:06,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2024-02-04 23:39:06,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:06,139:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:06,139:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:06,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143866 -> initscore=-1.783548
2024-02-04 23:39:06,140:INFO:[LightGBM] [Info] Start training from score -1.783548
2024-02-04 23:39:06,278:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:06,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2024-02-04 23:39:06,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:06,279:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:06,280:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:06,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.130420 -> initscore=-1.897249
2024-02-04 23:39:06,280:INFO:[LightGBM] [Info] Start training from score -1.897249
2024-02-04 23:39:06,425:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:06,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-02-04 23:39:06,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:06,426:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:06,426:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:06,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142521 -> initscore=-1.794507
2024-02-04 23:39:06,426:INFO:[LightGBM] [Info] Start training from score -1.794507
2024-02-04 23:39:06,560:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:06,561:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2024-02-04 23:39:06,561:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:06,562:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:06,562:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:06,562:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135462 -> initscore=-1.853503
2024-02-04 23:39:06,562:INFO:[LightGBM] [Info] Start training from score -1.853503
2024-02-04 23:39:06,747:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-04 23:39:06,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-04 23:39:06,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 23:39:06,748:INFO:[LightGBM] [Info] Total Bins 2453
2024-02-04 23:39:06,749:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 21
2024-02-04 23:39:06,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.145210 -> initscore=-1.772674
2024-02-04 23:39:06,749:INFO:[LightGBM] [Info] Start training from score -1.772674
2024-02-04 23:39:06,908:INFO:Uploading results into container
2024-02-04 23:39:06,914:INFO:Uploading model into container now
2024-02-04 23:39:06,916:INFO:_master_model_container: 27
2024-02-04 23:39:06,916:INFO:_display_container: 8
2024-02-04 23:39:06,920:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=5309,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:39:06,920:INFO:create_model() successfully completed......................................
2024-02-04 23:39:07,036:INFO:SubProcess create_model() end ==================================
2024-02-04 23:39:07,048:INFO:_master_model_container: 27
2024-02-04 23:39:07,048:INFO:_display_container: 8
2024-02-04 23:39:07,051:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=5309,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:39:07,051:INFO:ensemble_model() successfully completed......................................
2024-02-04 23:39:07,140:INFO:Initializing ensemble_model()
2024-02-04 23:39:07,140:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:39:07,140:INFO:Checking exceptions
2024-02-04 23:39:07,165:INFO:Importing libraries
2024-02-04 23:39:07,165:INFO:Copying training dataset
2024-02-04 23:39:07,166:INFO:Checking base model
2024-02-04 23:39:07,166:INFO:Base model : Gradient Boosting Classifier
2024-02-04 23:39:07,177:INFO:Importing untrained ensembler
2024-02-04 23:39:07,177:INFO:Ensemble method set to Bagging
2024-02-04 23:39:07,177:INFO:SubProcess create_model() called ==================================
2024-02-04 23:39:07,180:INFO:Initializing create_model()
2024-02-04 23:39:07,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=5309,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015837443CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:39:07,181:INFO:Checking exceptions
2024-02-04 23:39:07,181:INFO:Importing libraries
2024-02-04 23:39:07,181:INFO:Copying training dataset
2024-02-04 23:39:07,193:INFO:Defining folds
2024-02-04 23:39:07,193:INFO:Declaring metric variables
2024-02-04 23:39:07,199:INFO:Importing untrained model
2024-02-04 23:39:07,200:INFO:Declaring custom model
2024-02-04 23:39:07,206:INFO:Bagging Classifier Imported successfully
2024-02-04 23:39:07,216:INFO:Starting cross validation
2024-02-04 23:39:07,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:39:21,577:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,584:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,828:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,836:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,906:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,915:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,952:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,975:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:21,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,107:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:22,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,112:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:39:29,293:INFO:Calculating mean and std
2024-02-04 23:39:29,295:INFO:Creating metrics dataframe
2024-02-04 23:39:29,300:INFO:Finalizing model
2024-02-04 23:39:36,675:INFO:Uploading results into container
2024-02-04 23:39:36,675:INFO:Uploading model into container now
2024-02-04 23:39:36,677:INFO:_master_model_container: 28
2024-02-04 23:39:36,677:INFO:_display_container: 9
2024-02-04 23:39:36,679:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=5309,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:39:36,680:INFO:create_model() successfully completed......................................
2024-02-04 23:39:36,765:INFO:SubProcess create_model() end ==================================
2024-02-04 23:39:36,774:INFO:_master_model_container: 28
2024-02-04 23:39:36,774:INFO:_display_container: 9
2024-02-04 23:39:36,775:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=5309,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:39:36,775:INFO:ensemble_model() successfully completed......................................
2024-02-04 23:39:36,855:INFO:Initializing ensemble_model()
2024-02-04 23:39:36,855:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=10, max_features=1.0, max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=110,
                       n_jobs=-1, oob_score=False, random_state=5309, verbose=0,
                       warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:39:36,855:INFO:Checking exceptions
2024-02-04 23:39:36,874:INFO:Importing libraries
2024-02-04 23:39:36,874:INFO:Copying training dataset
2024-02-04 23:39:36,874:INFO:Checking base model
2024-02-04 23:39:36,874:INFO:Base model : Random Forest Classifier
2024-02-04 23:39:36,883:INFO:Importing untrained ensembler
2024-02-04 23:39:36,883:INFO:Ensemble method set to Bagging
2024-02-04 23:39:36,883:INFO:SubProcess create_model() called ==================================
2024-02-04 23:39:36,885:INFO:Initializing create_model()
2024-02-04 23:39:36,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced_subsample',
                                                   criterion='entropy',
                                                   max_depth=10,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=6,
                                                   min_samples_split=9,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=110, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158101B6EC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:39:36,885:INFO:Checking exceptions
2024-02-04 23:39:36,885:INFO:Importing libraries
2024-02-04 23:39:36,886:INFO:Copying training dataset
2024-02-04 23:39:36,892:INFO:Defining folds
2024-02-04 23:39:36,892:INFO:Declaring metric variables
2024-02-04 23:39:36,895:INFO:Importing untrained model
2024-02-04 23:39:36,896:INFO:Declaring custom model
2024-02-04 23:39:36,901:INFO:Bagging Classifier Imported successfully
2024-02-04 23:39:36,913:INFO:Starting cross validation
2024-02-04 23:39:36,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:40:13,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,557:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,590:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,608:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,741:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,770:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:13,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,834:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,839:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:23,923:INFO:Calculating mean and std
2024-02-04 23:40:23,925:INFO:Creating metrics dataframe
2024-02-04 23:40:23,931:INFO:Finalizing model
2024-02-04 23:40:29,894:INFO:Uploading results into container
2024-02-04 23:40:29,896:INFO:Uploading model into container now
2024-02-04 23:40:29,896:INFO:_master_model_container: 29
2024-02-04 23:40:29,896:INFO:_display_container: 10
2024-02-04 23:40:29,900:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced_subsample',
                                                   criterion='entropy',
                                                   max_depth=10,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=6,
                                                   min_samples_split=9,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=110, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:40:29,901:INFO:create_model() successfully completed......................................
2024-02-04 23:40:29,995:INFO:SubProcess create_model() end ==================================
2024-02-04 23:40:30,006:INFO:_master_model_container: 29
2024-02-04 23:40:30,006:INFO:_display_container: 10
2024-02-04 23:40:30,008:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced_subsample',
                                                   criterion='entropy',
                                                   max_depth=10,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=6,
                                                   min_samples_split=9,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=110, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:40:30,008:INFO:ensemble_model() successfully completed......................................
2024-02-04 23:40:30,089:INFO:Initializing ensemble_model()
2024-02-04 23:40:30,089:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                     criterion='gini', max_depth=11, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.001, min_samples_leaf=4,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=70, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:40:30,089:INFO:Checking exceptions
2024-02-04 23:40:30,106:INFO:Importing libraries
2024-02-04 23:40:30,107:INFO:Copying training dataset
2024-02-04 23:40:30,107:INFO:Checking base model
2024-02-04 23:40:30,107:INFO:Base model : Extra Trees Classifier
2024-02-04 23:40:30,114:INFO:Importing untrained ensembler
2024-02-04 23:40:30,114:INFO:Ensemble method set to Bagging
2024-02-04 23:40:30,115:INFO:SubProcess create_model() called ==================================
2024-02-04 23:40:30,116:INFO:Initializing create_model()
2024-02-04 23:40:30,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='gini', max_depth=11,
                                                 max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.001,
                                                 min_samples_leaf=4,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=70, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=5309, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834B9F700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:40:30,116:INFO:Checking exceptions
2024-02-04 23:40:30,117:INFO:Importing libraries
2024-02-04 23:40:30,117:INFO:Copying training dataset
2024-02-04 23:40:30,122:INFO:Defining folds
2024-02-04 23:40:30,122:INFO:Declaring metric variables
2024-02-04 23:40:30,125:INFO:Importing untrained model
2024-02-04 23:40:30,126:INFO:Declaring custom model
2024-02-04 23:40:30,130:INFO:Bagging Classifier Imported successfully
2024-02-04 23:40:30,140:INFO:Starting cross validation
2024-02-04 23:40:30,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:40:36,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,314:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:36,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:38,919:INFO:Calculating mean and std
2024-02-04 23:40:38,920:INFO:Creating metrics dataframe
2024-02-04 23:40:38,926:INFO:Finalizing model
2024-02-04 23:40:40,477:INFO:Uploading results into container
2024-02-04 23:40:40,479:INFO:Uploading model into container now
2024-02-04 23:40:40,480:INFO:_master_model_container: 30
2024-02-04 23:40:40,480:INFO:_display_container: 11
2024-02-04 23:40:40,484:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='gini', max_depth=11,
                                                 max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.001,
                                                 min_samples_leaf=4,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=70, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=5309, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:40:40,484:INFO:create_model() successfully completed......................................
2024-02-04 23:40:40,577:INFO:SubProcess create_model() end ==================================
2024-02-04 23:40:40,588:INFO:_master_model_container: 30
2024-02-04 23:40:40,588:INFO:_display_container: 11
2024-02-04 23:40:40,589:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight={},
                                                 criterion='gini', max_depth=11,
                                                 max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.001,
                                                 min_samples_leaf=4,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=70, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=5309, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=5309, verbose=0,
                  warm_start=False)
2024-02-04 23:40:40,589:INFO:ensemble_model() successfully completed......................................
2024-02-04 23:40:40,695:INFO:Initializing blend_models()
2024-02-04 23:40:40,696:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:40:40,696:INFO:Checking exceptions
2024-02-04 23:40:40,716:INFO:Importing libraries
2024-02-04 23:40:40,717:INFO:Copying training dataset
2024-02-04 23:40:40,721:INFO:Getting model names
2024-02-04 23:40:40,727:INFO:SubProcess create_model() called ==================================
2024-02-04 23:40:40,740:INFO:Initializing create_model()
2024-02-04 23:40:40,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000158349F94B0>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158349C4C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:40:40,741:INFO:Checking exceptions
2024-02-04 23:40:40,741:INFO:Importing libraries
2024-02-04 23:40:40,741:INFO:Copying training dataset
2024-02-04 23:40:40,750:INFO:Defining folds
2024-02-04 23:40:40,751:INFO:Declaring metric variables
2024-02-04 23:40:40,754:INFO:Importing untrained model
2024-02-04 23:40:40,755:INFO:Declaring custom model
2024-02-04 23:40:40,761:INFO:Voting Classifier Imported successfully
2024-02-04 23:40:40,770:INFO:Starting cross validation
2024-02-04 23:40:40,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:40:58,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,914:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,914:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:58,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,256:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:40:59,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,314:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:41:05,324:INFO:Calculating mean and std
2024-02-04 23:41:05,325:INFO:Creating metrics dataframe
2024-02-04 23:41:05,331:INFO:Finalizing model
2024-02-04 23:41:09,994:INFO:Uploading results into container
2024-02-04 23:41:09,996:INFO:Uploading model into container now
2024-02-04 23:41:09,996:INFO:_master_model_container: 31
2024-02-04 23:41:09,997:INFO:_display_container: 12
2024-02-04 23:41:10,006:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000015838E83FA0>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 23:41:10,007:INFO:create_model() successfully completed......................................
2024-02-04 23:41:10,100:INFO:SubProcess create_model() end ==================================
2024-02-04 23:41:10,109:INFO:_master_model_container: 31
2024-02-04 23:41:10,109:INFO:_display_container: 12
2024-02-04 23:41:10,116:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000015838E83FA0>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=5309, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 23:41:10,116:INFO:blend_models() successfully completed......................................
2024-02-04 23:41:10,214:INFO:Initializing stack_models()
2024-02-04 23:41:10,214:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000158349F94B0>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 23:41:10,214:INFO:Checking exceptions
2024-02-04 23:41:10,217:INFO:Defining meta model
2024-02-04 23:41:10,233:INFO:Getting model names
2024-02-04 23:41:10,234:INFO:[('CatBoost Classifier', <catboost.core.CatBoostClassifier object at 0x00000158349F94B0>), ('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5309, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5309, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5309, verbose=0, warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5309, verbose=0, warm_start=False))]
2024-02-04 23:41:10,238:INFO:SubProcess create_model() called ==================================
2024-02-04 23:41:10,247:INFO:Initializing create_model()
2024-02-04 23:41:10,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x00000158349F94B0>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001581016F7F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:41:10,248:INFO:Checking exceptions
2024-02-04 23:41:10,248:INFO:Importing libraries
2024-02-04 23:41:10,248:INFO:Copying training dataset
2024-02-04 23:41:10,256:INFO:Defining folds
2024-02-04 23:41:10,256:INFO:Declaring metric variables
2024-02-04 23:41:10,259:INFO:Importing untrained model
2024-02-04 23:41:10,260:INFO:Declaring custom model
2024-02-04 23:41:10,267:INFO:Stacking Classifier Imported successfully
2024-02-04 23:41:10,275:INFO:Starting cross validation
2024-02-04 23:41:10,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 23:42:55,193:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:55,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:55,234:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:55,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:55,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,559:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,792:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,951:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:55,965:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:56,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:56,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:56,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,682:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:56,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:57,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:42:57,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:57,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:42:57,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:43:29,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-04 23:43:29,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,775:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 23:43:29,785:INFO:Calculating mean and std
2024-02-04 23:43:29,788:INFO:Creating metrics dataframe
2024-02-04 23:43:29,796:INFO:Finalizing model
2024-02-04 23:43:45,930:INFO:Uploading results into container
2024-02-04 23:43:45,932:INFO:Uploading model into container now
2024-02-04 23:43:45,933:INFO:_master_model_container: 32
2024-02-04 23:43:45,933:INFO:_display_container: 13
2024-02-04 23:43:45,949:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015834E04D60>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 23:43:45,950:INFO:create_model() successfully completed......................................
2024-02-04 23:43:46,051:INFO:SubProcess create_model() end ==================================
2024-02-04 23:43:46,062:INFO:_master_model_container: 32
2024-02-04 23:43:46,062:INFO:_display_container: 13
2024-02-04 23:43:46,070:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015834E04D60>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 23:43:46,070:INFO:stack_models() successfully completed......................................
2024-02-04 23:43:46,172:INFO:Initializing automl()
2024-02-04 23:43:46,173:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, optimize=Accuracy, use_holdout=False, turbo=True, return_train_score=False)
2024-02-04 23:43:46,174:INFO:Model Selection Basis : CV Results on Training set
2024-02-04 23:43:46,174:INFO:Checking model 0
2024-02-04 23:43:46,175:INFO:Checking model 1
2024-02-04 23:43:46,175:INFO:Checking model 2
2024-02-04 23:43:46,175:INFO:Checking model 3
2024-02-04 23:43:46,175:INFO:Checking model 4
2024-02-04 23:43:46,176:INFO:Checking model 5
2024-02-04 23:43:46,176:INFO:Checking model 6
2024-02-04 23:43:46,176:INFO:Checking model 7
2024-02-04 23:43:46,177:INFO:Checking model 8
2024-02-04 23:43:46,177:INFO:Checking model 9
2024-02-04 23:43:46,178:INFO:Checking model 10
2024-02-04 23:43:46,178:INFO:Checking model 11
2024-02-04 23:43:46,178:INFO:Checking model 12
2024-02-04 23:43:46,178:INFO:Checking model 13
2024-02-04 23:43:46,178:INFO:Checking model 14
2024-02-04 23:43:46,178:INFO:Checking model 15
2024-02-04 23:43:46,178:INFO:Checking model 16
2024-02-04 23:43:46,178:INFO:Checking model 17
2024-02-04 23:43:46,179:INFO:Checking model 18
2024-02-04 23:43:46,179:INFO:Checking model 19
2024-02-04 23:43:46,180:INFO:Checking model 20
2024-02-04 23:43:46,180:INFO:Checking model 21
2024-02-04 23:43:46,180:INFO:Checking model 22
2024-02-04 23:43:46,180:INFO:Checking model 23
2024-02-04 23:43:46,180:INFO:Checking model 24
2024-02-04 23:43:46,181:INFO:Checking model 25
2024-02-04 23:43:46,181:INFO:Checking model 26
2024-02-04 23:43:46,181:INFO:Checking model 27
2024-02-04 23:43:46,181:INFO:Checking model 28
2024-02-04 23:43:46,181:INFO:Checking model 29
2024-02-04 23:43:46,181:INFO:Checking model 30
2024-02-04 23:43:46,182:INFO:Checking model 31
2024-02-04 23:43:46,189:INFO:Initializing create_model()
2024-02-04 23:43:46,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015834E04D60>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:43:46,189:INFO:Checking exceptions
2024-02-04 23:43:46,191:INFO:Importing libraries
2024-02-04 23:43:46,191:INFO:Copying training dataset
2024-02-04 23:43:46,196:INFO:Defining folds
2024-02-04 23:43:46,196:INFO:Declaring metric variables
2024-02-04 23:43:46,196:INFO:Importing untrained model
2024-02-04 23:43:46,196:INFO:Declaring custom model
2024-02-04 23:43:46,200:INFO:Stacking Classifier Imported successfully
2024-02-04 23:43:46,201:INFO:Cross validation set to False
2024-02-04 23:43:46,201:INFO:Fitting Model
2024-02-04 23:44:02,572:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 23:44:02,572:INFO:create_model() successfully completed......................................
2024-02-04 23:44:02,748:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 23:44:02,748:INFO:automl() successfully completed......................................
2024-02-04 23:44:02,783:INFO:Initializing finalize_model()
2024-02-04 23:44:02,783:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 23:44:02,791:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 23:44:02,806:INFO:Initializing create_model()
2024-02-04 23:44:02,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 23:44:02,806:INFO:Checking exceptions
2024-02-04 23:44:02,810:INFO:Importing libraries
2024-02-04 23:44:02,811:INFO:Copying training dataset
2024-02-04 23:44:02,811:INFO:Defining folds
2024-02-04 23:44:02,811:INFO:Declaring metric variables
2024-02-04 23:44:02,812:INFO:Importing untrained model
2024-02-04 23:44:02,812:INFO:Declaring custom model
2024-02-04 23:44:02,815:INFO:Stacking Classifier Imported successfully
2024-02-04 23:44:02,817:INFO:Cross validation set to False
2024-02-04 23:44:02,817:INFO:Fitting Model
2024-02-04 23:44:21,297:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                                                                      verbose=0,
                                                                      warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=5309,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-02-04 23:44:21,297:INFO:create_model() successfully completed......................................
2024-02-04 23:44:21,380:INFO:_master_model_container: 32
2024-02-04 23:44:21,380:INFO:_display_container: 12
2024-02-04 23:44:21,428:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'total_eve_calls',
                                             'tot...
                                                                      verbose=0,
                                                                      warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=5309,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-02-04 23:44:21,428:INFO:finalize_model() successfully completed......................................
2024-02-04 23:44:21,542:INFO:Initializing predict_model()
2024-02-04 23:44:21,542:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000015834759E10>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000015838E80370>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                                     random_state=5309,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=5309,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001583472F5B0>)
2024-02-04 23:44:21,542:INFO:Checking exceptions
2024-02-04 23:44:21,542:INFO:Preloading libraries
2024-02-04 23:44:21,545:INFO:Set up data.
2024-02-04 23:44:21,554:INFO:Set up index.
2024-02-05 00:01:02,299:INFO:PyCaret ClassificationExperiment
2024-02-05 00:01:02,299:INFO:Logging name: clf-default-name
2024-02-05 00:01:02,299:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 00:01:02,299:INFO:version 3.2.0
2024-02-05 00:01:02,299:INFO:Initializing setup()
2024-02-05 00:01:02,299:INFO:self.USI: 105e
2024-02-05 00:01:02,299:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'fold_shuffle_param', '_available_plots', 'X_train', 'fold_generator', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'log_plots_param', 'data', 'is_multiclass', 'y', 'idx', 'fold_groups_param', 'fix_imbalance', 'target_param', 'html_param', 'USI', 'seed', 'X', '_ml_usecase', 'memory', 'gpu_param', 'y_train', 'pipeline', 'y_test', 'exp_name_log'}
2024-02-05 00:01:02,299:INFO:Checking environment
2024-02-05 00:01:02,299:INFO:python_version: 3.10.9
2024-02-05 00:01:02,299:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 00:01:02,299:INFO:machine: AMD64
2024-02-05 00:01:02,299:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 00:01:02,299:INFO:Memory: svmem(total=16856182784, available=8473161728, percent=49.7, used=8383021056, free=8473161728)
2024-02-05 00:01:02,300:INFO:Physical Core: 4
2024-02-05 00:01:02,300:INFO:Logical Core: 8
2024-02-05 00:01:02,300:INFO:Checking libraries
2024-02-05 00:01:02,300:INFO:System:
2024-02-05 00:01:02,300:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 00:01:02,300:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 00:01:02,300:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 00:01:02,300:INFO:PyCaret required dependencies:
2024-02-05 00:01:02,300:INFO:                 pip: 22.3.1
2024-02-05 00:01:02,300:INFO:          setuptools: 65.6.3
2024-02-05 00:01:02,300:INFO:             pycaret: 3.2.0
2024-02-05 00:01:02,300:INFO:             IPython: 8.20.0
2024-02-05 00:01:02,300:INFO:          ipywidgets: 8.0.4
2024-02-05 00:01:02,301:INFO:                tqdm: 4.64.1
2024-02-05 00:01:02,301:INFO:               numpy: 1.25.2
2024-02-05 00:01:02,301:INFO:              pandas: 1.5.3
2024-02-05 00:01:02,301:INFO:              jinja2: 3.1.3
2024-02-05 00:01:02,301:INFO:               scipy: 1.10.1
2024-02-05 00:01:02,301:INFO:              joblib: 1.3.2
2024-02-05 00:01:02,301:INFO:             sklearn: 1.2.2
2024-02-05 00:01:02,301:INFO:                pyod: 1.1.2
2024-02-05 00:01:02,301:INFO:            imblearn: 0.12.0
2024-02-05 00:01:02,301:INFO:   category_encoders: 2.6.3
2024-02-05 00:01:02,301:INFO:            lightgbm: 4.3.0
2024-02-05 00:01:02,301:INFO:               numba: 0.59.0
2024-02-05 00:01:02,302:INFO:            requests: 2.31.0
2024-02-05 00:01:02,302:INFO:          matplotlib: 3.6.0
2024-02-05 00:01:02,302:INFO:          scikitplot: 0.3.7
2024-02-05 00:01:02,302:INFO:         yellowbrick: 1.5
2024-02-05 00:01:02,302:INFO:              plotly: 5.18.0
2024-02-05 00:01:02,302:INFO:    plotly-resampler: Not installed
2024-02-05 00:01:02,302:INFO:             kaleido: 0.2.1
2024-02-05 00:01:02,302:INFO:           schemdraw: 0.15
2024-02-05 00:01:02,302:INFO:         statsmodels: 0.14.1
2024-02-05 00:01:02,302:INFO:              sktime: 0.21.1
2024-02-05 00:01:02,302:INFO:               tbats: 1.1.3
2024-02-05 00:01:02,302:INFO:            pmdarima: 2.0.4
2024-02-05 00:01:02,302:INFO:              psutil: 5.9.0
2024-02-05 00:01:02,302:INFO:          markupsafe: 2.1.3
2024-02-05 00:01:02,302:INFO:             pickle5: Not installed
2024-02-05 00:01:02,302:INFO:         cloudpickle: 3.0.0
2024-02-05 00:01:02,302:INFO:         deprecation: 2.1.0
2024-02-05 00:01:02,302:INFO:              xxhash: 3.4.1
2024-02-05 00:01:02,302:INFO:           wurlitzer: Not installed
2024-02-05 00:01:02,302:INFO:PyCaret optional dependencies:
2024-02-05 00:01:02,302:INFO:                shap: 0.44.1
2024-02-05 00:01:02,303:INFO:           interpret: Not installed
2024-02-05 00:01:02,303:INFO:                umap: Not installed
2024-02-05 00:01:02,303:INFO:     ydata_profiling: Not installed
2024-02-05 00:01:02,303:INFO:  explainerdashboard: 0.4.5
2024-02-05 00:01:02,303:INFO:             autoviz: Not installed
2024-02-05 00:01:02,303:INFO:           fairlearn: Not installed
2024-02-05 00:01:02,303:INFO:          deepchecks: Not installed
2024-02-05 00:01:02,303:INFO:             xgboost: Not installed
2024-02-05 00:01:02,303:INFO:            catboost: 1.2.2
2024-02-05 00:01:02,303:INFO:              kmodes: Not installed
2024-02-05 00:01:02,303:INFO:             mlxtend: Not installed
2024-02-05 00:01:02,303:INFO:       statsforecast: Not installed
2024-02-05 00:01:02,303:INFO:        tune_sklearn: Not installed
2024-02-05 00:01:02,303:INFO:                 ray: Not installed
2024-02-05 00:01:02,303:INFO:            hyperopt: Not installed
2024-02-05 00:01:02,303:INFO:              optuna: Not installed
2024-02-05 00:01:02,303:INFO:               skopt: Not installed
2024-02-05 00:01:02,303:INFO:              mlflow: 2.10.0
2024-02-05 00:01:02,303:INFO:              gradio: Not installed
2024-02-05 00:01:02,303:INFO:             fastapi: Not installed
2024-02-05 00:01:02,303:INFO:             uvicorn: Not installed
2024-02-05 00:01:02,303:INFO:              m2cgen: Not installed
2024-02-05 00:01:02,304:INFO:           evidently: Not installed
2024-02-05 00:01:02,304:INFO:               fugue: Not installed
2024-02-05 00:01:02,304:INFO:           streamlit: Not installed
2024-02-05 00:01:02,304:INFO:             prophet: Not installed
2024-02-05 00:01:02,304:INFO:None
2024-02-05 00:01:02,304:INFO:Set up GPU usage.
2024-02-05 00:01:02,304:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,304:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 00:01:02,304:INFO:Set up data.
2024-02-05 00:01:02,321:INFO:Set up folding strategy.
2024-02-05 00:01:02,321:INFO:Set up train/test split.
2024-02-05 00:01:02,333:INFO:Set up index.
2024-02-05 00:01:02,333:INFO:Assigning column types.
2024-02-05 00:01:02,338:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 00:01:02,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 00:01:02,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,385:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,385:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 00:01:02,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:02,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:08,607:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:08,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 00:01:08,655:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 00:01:08,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:08,758:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:08,759:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 00:01:08,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 00:01:08,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:08,876:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:08,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 00:01:08,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:08,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:08,997:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:08,997:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 00:01:08,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:09,111:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:09,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:09,214:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:09,216:INFO:Preparing preprocessing pipeline...
2024-02-05 00:01:09,218:INFO:Set up label encoding.
2024-02-05 00:01:09,218:INFO:Set up simple imputation.
2024-02-05 00:01:09,223:INFO:Set up encoding of ordinal features.
2024-02-05 00:01:09,227:INFO:Set up encoding of categorical features.
2024-02-05 00:01:09,227:INFO:Set up removing multicollinearity.
2024-02-05 00:01:09,227:INFO:Set up removing outliers.
2024-02-05 00:01:09,227:INFO:Set up imbalanced handling.
2024-02-05 00:01:09,227:INFO:Set up column transformation.
2024-02-05 00:01:09,227:INFO:Set up feature normalization.
2024-02-05 00:01:09,227:INFO:Set up PCA.
2024-02-05 00:01:09,227:INFO:Set up feature selection.
2024-02-05 00:01:09,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:09,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:09,333:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:10,299:INFO:Finished creating preprocessing pipeline.
2024-02-05 00:01:10,351:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'to...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-05 00:01:10,351:INFO:Creating final display dataframe.
2024-02-05 00:01:11,666:INFO:Setup _display_container:                     Description             Value
0                    Session id               207
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 20)
5        Transformed data shape         (6213, 4)
6   Transformed train set shape         (4938, 4)
7    Transformed test set shape         (1275, 4)
8              Ordinal features                 2
9              Numeric features                15
10         Categorical features                 4
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21                Fix imbalance              True
22         Fix imbalance method             SMOTE
23               Transformation              True
24        Transformation method       yeo-johnson
25                    Normalize              True
26             Normalize method            zscore
27                          PCA              True
28                   PCA method            linear
29               PCA components              None
30            Feature selection              True
31     Feature selection method           classic
32  Feature selection estimator          lightgbm
33  Number of features selected               0.2
34               Fold Generator   StratifiedKFold
35                  Fold Number                10
36                     CPU Jobs                -1
37                      Use GPU              True
38               Log Experiment             False
39              Experiment Name  clf-default-name
40                          USI              105e
2024-02-05 00:01:11,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,731:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:11,778:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:11,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:01:11,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 00:01:11,890:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 00:01:11,891:INFO:setup() successfully completed in 9.6s...............
2024-02-05 00:01:51,790:INFO:Initializing compare_models()
2024-02-05 00:01:51,790:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 00:01:51,790:INFO:Checking exceptions
2024-02-05 00:01:51,796:INFO:Preparing display monitor
2024-02-05 00:01:51,828:INFO:Initializing Logistic Regression
2024-02-05 00:01:51,828:INFO:Total runtime is 0.0 minutes
2024-02-05 00:01:51,832:INFO:SubProcess create_model() called ==================================
2024-02-05 00:01:51,832:INFO:Initializing create_model()
2024-02-05 00:01:51,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:01:51,833:INFO:Checking exceptions
2024-02-05 00:01:51,833:INFO:Importing libraries
2024-02-05 00:01:51,833:INFO:Copying training dataset
2024-02-05 00:01:51,838:INFO:Defining folds
2024-02-05 00:01:51,838:INFO:Declaring metric variables
2024-02-05 00:01:51,842:INFO:Importing untrained model
2024-02-05 00:01:51,845:INFO:Logistic Regression Imported successfully
2024-02-05 00:01:51,853:INFO:Starting cross validation
2024-02-05 00:01:52,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:01:52,605:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:01:52,606:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-02-05 00:01:52,606:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:52,606:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:52,607:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:01:52,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:53,280:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:01:53,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-02-05 00:01:53,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:53,283:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:53,283:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:01:53,283:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:54,011:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:01:54,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-02-05 00:01:54,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:54,011:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:54,012:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:01:54,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:54,634:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:01:54,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-02-05 00:01:54,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:54,634:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:54,635:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:01:54,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:55,325:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:01:55,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-02-05 00:01:55,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:55,325:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:55,325:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:01:55,326:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:56,005:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:01:56,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-02-05 00:01:56,006:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:56,006:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:56,006:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:01:56,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:56,690:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:01:56,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-02-05 00:01:56,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:56,691:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:56,691:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:01:56,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:57,408:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:01:57,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-02-05 00:01:57,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:57,409:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:57,409:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:01:57,409:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:58,125:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:01:58,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-02-05 00:01:58,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:58,125:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:58,126:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:01:58,126:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:58,815:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:01:58,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-02-05 00:01:58,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:58,816:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:58,816:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:01:58,816:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:01:58,979:INFO:Calculating mean and std
2024-02-05 00:01:58,980:INFO:Creating metrics dataframe
2024-02-05 00:01:58,983:INFO:Uploading results into container
2024-02-05 00:01:58,985:INFO:Uploading model into container now
2024-02-05 00:01:58,985:INFO:_master_model_container: 1
2024-02-05 00:01:58,986:INFO:_display_container: 2
2024-02-05 00:01:58,986:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=207, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-05 00:01:58,987:INFO:create_model() successfully completed......................................
2024-02-05 00:01:59,166:INFO:SubProcess create_model() end ==================================
2024-02-05 00:01:59,166:INFO:Creating metrics dataframe
2024-02-05 00:01:59,176:INFO:Initializing K Neighbors Classifier
2024-02-05 00:01:59,176:INFO:Total runtime is 0.12246013879776001 minutes
2024-02-05 00:01:59,180:INFO:SubProcess create_model() called ==================================
2024-02-05 00:01:59,180:INFO:Initializing create_model()
2024-02-05 00:01:59,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:01:59,180:INFO:Checking exceptions
2024-02-05 00:01:59,180:INFO:Importing libraries
2024-02-05 00:01:59,180:INFO:Copying training dataset
2024-02-05 00:01:59,187:INFO:Defining folds
2024-02-05 00:01:59,187:INFO:Declaring metric variables
2024-02-05 00:01:59,193:INFO:Importing untrained model
2024-02-05 00:01:59,198:INFO:K Neighbors Classifier Imported successfully
2024-02-05 00:01:59,207:INFO:Starting cross validation
2024-02-05 00:01:59,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:01:59,756:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:01:59,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.
2024-02-05 00:01:59,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:01:59,756:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:01:59,757:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:01:59,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:00,494:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:00,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-02-05 00:02:00,495:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:00,495:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:00,495:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:00,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:01,175:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:01,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2024-02-05 00:02:01,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:01,175:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:01,176:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:01,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:01,828:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:01,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-02-05 00:02:01,829:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:01,829:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:01,829:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:01,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:02,504:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:02,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-02-05 00:02:02,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:02,505:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:02,505:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:02,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:03,255:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:03,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-02-05 00:02:03,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:03,255:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:03,255:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:03,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:03,908:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:03,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-02-05 00:02:03,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:03,908:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:03,908:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:03,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:04,572:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:04,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-02-05 00:02:04,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:04,573:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:04,573:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:04,573:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:05,215:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:05,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-02-05 00:02:05,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:05,216:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:05,216:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:05,216:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:05,918:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:05,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-02-05 00:02:05,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:05,919:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:05,919:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:05,919:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:06,143:INFO:Calculating mean and std
2024-02-05 00:02:06,145:INFO:Creating metrics dataframe
2024-02-05 00:02:06,149:INFO:Uploading results into container
2024-02-05 00:02:06,149:INFO:Uploading model into container now
2024-02-05 00:02:06,150:INFO:_master_model_container: 2
2024-02-05 00:02:06,151:INFO:_display_container: 2
2024-02-05 00:02:06,151:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-05 00:02:06,151:INFO:create_model() successfully completed......................................
2024-02-05 00:02:06,327:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:06,328:INFO:Creating metrics dataframe
2024-02-05 00:02:06,336:INFO:Initializing Naive Bayes
2024-02-05 00:02:06,336:INFO:Total runtime is 0.241802450021108 minutes
2024-02-05 00:02:06,340:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:06,340:INFO:Initializing create_model()
2024-02-05 00:02:06,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:06,340:INFO:Checking exceptions
2024-02-05 00:02:06,340:INFO:Importing libraries
2024-02-05 00:02:06,341:INFO:Copying training dataset
2024-02-05 00:02:06,347:INFO:Defining folds
2024-02-05 00:02:06,347:INFO:Declaring metric variables
2024-02-05 00:02:06,351:INFO:Importing untrained model
2024-02-05 00:02:06,358:INFO:Naive Bayes Imported successfully
2024-02-05 00:02:06,367:INFO:Starting cross validation
2024-02-05 00:02:06,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:06,947:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:06,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-02-05 00:02:06,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:06,948:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:06,948:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:06,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:07,650:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:07,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2024-02-05 00:02:07,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:07,651:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:07,651:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:07,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:08,398:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:08,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-02-05 00:02:08,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:08,398:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:08,398:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:08,399:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:09,155:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:09,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-02-05 00:02:09,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:09,156:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:09,156:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:09,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:09,848:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:09,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-02-05 00:02:09,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:09,849:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:09,849:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:09,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:10,539:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:10,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-02-05 00:02:10,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:10,540:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:10,540:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:10,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:11,217:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:11,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-02-05 00:02:11,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:11,217:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:11,218:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:11,218:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:11,966:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:11,967:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-02-05 00:02:11,967:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:11,967:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:11,967:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:11,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:12,590:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:12,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-02-05 00:02:12,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:12,591:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:12,591:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:12,591:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:13,295:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:13,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:02:13,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:13,296:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:13,296:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:13,296:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:13,418:INFO:Calculating mean and std
2024-02-05 00:02:13,419:INFO:Creating metrics dataframe
2024-02-05 00:02:13,423:INFO:Uploading results into container
2024-02-05 00:02:13,423:INFO:Uploading model into container now
2024-02-05 00:02:13,424:INFO:_master_model_container: 3
2024-02-05 00:02:13,424:INFO:_display_container: 2
2024-02-05 00:02:13,424:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-05 00:02:13,424:INFO:create_model() successfully completed......................................
2024-02-05 00:02:13,582:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:13,582:INFO:Creating metrics dataframe
2024-02-05 00:02:13,590:INFO:Initializing Decision Tree Classifier
2024-02-05 00:02:13,591:INFO:Total runtime is 0.36271897951761883 minutes
2024-02-05 00:02:13,595:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:13,596:INFO:Initializing create_model()
2024-02-05 00:02:13,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:13,596:INFO:Checking exceptions
2024-02-05 00:02:13,596:INFO:Importing libraries
2024-02-05 00:02:13,596:INFO:Copying training dataset
2024-02-05 00:02:13,601:INFO:Defining folds
2024-02-05 00:02:13,601:INFO:Declaring metric variables
2024-02-05 00:02:13,605:INFO:Importing untrained model
2024-02-05 00:02:13,614:INFO:Decision Tree Classifier Imported successfully
2024-02-05 00:02:13,622:INFO:Starting cross validation
2024-02-05 00:02:13,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:14,183:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:14,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-02-05 00:02:14,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:14,184:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:14,184:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:14,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:14,839:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:14,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-02-05 00:02:14,839:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:14,839:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:14,840:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:14,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:15,552:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:15,552:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-02-05 00:02:15,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:15,552:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:15,552:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:15,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:16,247:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:16,247:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-02-05 00:02:16,247:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:16,247:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:16,248:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:16,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:16,958:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:16,959:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-02-05 00:02:16,959:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:16,959:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:16,959:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:16,960:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:17,649:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:17,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-02-05 00:02:17,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:17,650:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:17,650:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:17,650:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:18,359:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:18,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2024-02-05 00:02:18,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:18,360:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:18,360:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:18,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:19,060:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:19,061:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-02-05 00:02:19,061:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:19,061:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:19,061:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:19,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:19,737:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:19,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:02:19,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:19,738:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:19,738:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:19,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:20,359:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:20,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-02-05 00:02:20,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:20,360:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:20,360:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:20,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:20,520:INFO:Calculating mean and std
2024-02-05 00:02:20,521:INFO:Creating metrics dataframe
2024-02-05 00:02:20,525:INFO:Uploading results into container
2024-02-05 00:02:20,526:INFO:Uploading model into container now
2024-02-05 00:02:20,527:INFO:_master_model_container: 4
2024-02-05 00:02:20,527:INFO:_display_container: 2
2024-02-05 00:02:20,527:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=207, splitter='best')
2024-02-05 00:02:20,528:INFO:create_model() successfully completed......................................
2024-02-05 00:02:20,679:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:20,679:INFO:Creating metrics dataframe
2024-02-05 00:02:20,689:INFO:Initializing SVM - Linear Kernel
2024-02-05 00:02:20,689:INFO:Total runtime is 0.4810102303822835 minutes
2024-02-05 00:02:20,692:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:20,693:INFO:Initializing create_model()
2024-02-05 00:02:20,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:20,693:INFO:Checking exceptions
2024-02-05 00:02:20,693:INFO:Importing libraries
2024-02-05 00:02:20,693:INFO:Copying training dataset
2024-02-05 00:02:20,699:INFO:Defining folds
2024-02-05 00:02:20,699:INFO:Declaring metric variables
2024-02-05 00:02:20,703:INFO:Importing untrained model
2024-02-05 00:02:20,709:INFO:SVM - Linear Kernel Imported successfully
2024-02-05 00:02:20,716:INFO:Starting cross validation
2024-02-05 00:02:20,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:21,227:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:21,228:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-02-05 00:02:21,228:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:21,228:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:21,228:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:21,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:21,879:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:21,879:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 00:02:21,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:21,880:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:21,880:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:21,880:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:22,582:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:22,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-02-05 00:02:22,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:22,582:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:22,582:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:22,582:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:23,203:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:23,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-02-05 00:02:23,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:23,203:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:23,203:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:23,204:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:23,853:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:23,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-02-05 00:02:23,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:23,853:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:23,854:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:23,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:24,535:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:24,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-02-05 00:02:24,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:24,536:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:24,536:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:24,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:25,196:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:25,197:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-02-05 00:02:25,197:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:25,197:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:25,197:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:25,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:25,937:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:25,937:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2024-02-05 00:02:25,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:25,937:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:25,938:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:25,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:26,623:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:26,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-02-05 00:02:26,624:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:26,624:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:26,624:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:26,624:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:27,344:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:27,345:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-02-05 00:02:27,345:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:27,345:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:27,345:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:27,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:27,518:INFO:Calculating mean and std
2024-02-05 00:02:27,519:INFO:Creating metrics dataframe
2024-02-05 00:02:27,525:INFO:Uploading results into container
2024-02-05 00:02:27,527:INFO:Uploading model into container now
2024-02-05 00:02:27,528:INFO:_master_model_container: 5
2024-02-05 00:02:27,528:INFO:_display_container: 2
2024-02-05 00:02:27,529:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=207, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-05 00:02:27,529:INFO:create_model() successfully completed......................................
2024-02-05 00:02:27,703:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:27,703:INFO:Creating metrics dataframe
2024-02-05 00:02:27,714:INFO:Initializing Ridge Classifier
2024-02-05 00:02:27,714:INFO:Total runtime is 0.598094391822815 minutes
2024-02-05 00:02:27,718:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:27,718:INFO:Initializing create_model()
2024-02-05 00:02:27,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:27,718:INFO:Checking exceptions
2024-02-05 00:02:27,718:INFO:Importing libraries
2024-02-05 00:02:27,719:INFO:Copying training dataset
2024-02-05 00:02:27,728:INFO:Defining folds
2024-02-05 00:02:27,728:INFO:Declaring metric variables
2024-02-05 00:02:27,733:INFO:Importing untrained model
2024-02-05 00:02:27,739:INFO:Ridge Classifier Imported successfully
2024-02-05 00:02:27,752:INFO:Starting cross validation
2024-02-05 00:02:27,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:28,306:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:28,307:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-02-05 00:02:28,307:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:28,307:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:28,307:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:28,307:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:28,994:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:28,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-02-05 00:02:28,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:28,995:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:28,995:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:28,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:29,659:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:29,660:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-02-05 00:02:29,660:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:29,660:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:29,660:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:29,660:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:30,277:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:30,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:02:30,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:30,278:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:30,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:30,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:30,914:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:30,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-02-05 00:02:30,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:30,914:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:30,914:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:30,914:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:31,521:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:31,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-02-05 00:02:31,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:31,521:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:31,521:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:31,522:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:32,145:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:32,146:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-02-05 00:02:32,146:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:32,146:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:32,146:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:32,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:32,768:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:32,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-02-05 00:02:32,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:32,769:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:32,769:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:32,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:33,353:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:33,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
2024-02-05 00:02:33,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:33,353:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:33,353:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:33,354:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:33,954:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:33,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-02-05 00:02:33,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:33,955:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:33,955:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:33,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:34,077:INFO:Calculating mean and std
2024-02-05 00:02:34,079:INFO:Creating metrics dataframe
2024-02-05 00:02:34,083:INFO:Uploading results into container
2024-02-05 00:02:34,084:INFO:Uploading model into container now
2024-02-05 00:02:34,085:INFO:_master_model_container: 6
2024-02-05 00:02:34,085:INFO:_display_container: 2
2024-02-05 00:02:34,086:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=207, solver='auto',
                tol=0.0001)
2024-02-05 00:02:34,086:INFO:create_model() successfully completed......................................
2024-02-05 00:02:34,236:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:34,236:INFO:Creating metrics dataframe
2024-02-05 00:02:34,246:INFO:Initializing Random Forest Classifier
2024-02-05 00:02:34,246:INFO:Total runtime is 0.7069537242253622 minutes
2024-02-05 00:02:34,249:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:34,250:INFO:Initializing create_model()
2024-02-05 00:02:34,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:34,250:INFO:Checking exceptions
2024-02-05 00:02:34,250:INFO:Importing libraries
2024-02-05 00:02:34,250:INFO:Copying training dataset
2024-02-05 00:02:34,257:INFO:Defining folds
2024-02-05 00:02:34,257:INFO:Declaring metric variables
2024-02-05 00:02:34,261:INFO:Importing untrained model
2024-02-05 00:02:34,267:INFO:Random Forest Classifier Imported successfully
2024-02-05 00:02:34,276:INFO:Starting cross validation
2024-02-05 00:02:34,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:34,856:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:34,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-02-05 00:02:34,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:34,857:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:34,857:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:34,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:35,885:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:35,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-02-05 00:02:35,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:35,886:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:35,886:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:35,886:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:36,887:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:36,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-02-05 00:02:36,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:36,887:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:36,888:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:36,888:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:37,911:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:37,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-02-05 00:02:37,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:37,912:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:37,912:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:37,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:38,941:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:38,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-02-05 00:02:38,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:38,942:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:38,942:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:38,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:39,951:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:39,951:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-02-05 00:02:39,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:39,951:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:39,952:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:39,952:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:40,856:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:40,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-02-05 00:02:40,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:40,857:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:40,857:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:40,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:41,762:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:41,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-02-05 00:02:41,762:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:41,762:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:41,762:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:41,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:42,671:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:42,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-02-05 00:02:42,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:42,671:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:42,671:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:42,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:43,588:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:43,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-02-05 00:02:43,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:43,589:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:43,589:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:43,589:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:44,033:INFO:Calculating mean and std
2024-02-05 00:02:44,034:INFO:Creating metrics dataframe
2024-02-05 00:02:44,037:INFO:Uploading results into container
2024-02-05 00:02:44,037:INFO:Uploading model into container now
2024-02-05 00:02:44,038:INFO:_master_model_container: 7
2024-02-05 00:02:44,038:INFO:_display_container: 2
2024-02-05 00:02:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=207, verbose=0, warm_start=False)
2024-02-05 00:02:44,038:INFO:create_model() successfully completed......................................
2024-02-05 00:02:44,186:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:44,186:INFO:Creating metrics dataframe
2024-02-05 00:02:44,202:INFO:Initializing Quadratic Discriminant Analysis
2024-02-05 00:02:44,202:INFO:Total runtime is 0.872897203763326 minutes
2024-02-05 00:02:44,206:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:44,207:INFO:Initializing create_model()
2024-02-05 00:02:44,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:44,207:INFO:Checking exceptions
2024-02-05 00:02:44,207:INFO:Importing libraries
2024-02-05 00:02:44,207:INFO:Copying training dataset
2024-02-05 00:02:44,215:INFO:Defining folds
2024-02-05 00:02:44,216:INFO:Declaring metric variables
2024-02-05 00:02:44,220:INFO:Importing untrained model
2024-02-05 00:02:44,225:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-05 00:02:44,232:INFO:Starting cross validation
2024-02-05 00:02:44,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:44,775:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:44,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-02-05 00:02:44,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:44,776:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:44,776:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:44,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:45,503:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:45,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-02-05 00:02:45,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:45,504:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:45,504:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:45,504:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:46,233:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:46,234:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-02-05 00:02:46,234:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:46,234:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:46,234:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:46,234:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:46,961:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:46,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-02-05 00:02:46,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:46,962:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:46,962:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:46,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:47,688:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:47,688:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-02-05 00:02:47,688:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:47,688:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:47,688:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:47,689:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:48,402:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:48,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2024-02-05 00:02:48,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:48,403:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:48,404:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:48,404:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:49,114:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:49,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-02-05 00:02:49,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:49,115:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:49,115:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:49,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:49,739:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:49,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-02-05 00:02:49,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:49,740:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:49,740:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:49,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:50,459:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:50,459:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-02-05 00:02:50,459:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:50,459:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:50,460:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:50,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:51,155:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:51,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-02-05 00:02:51,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:51,156:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:51,156:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:51,156:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:51,331:INFO:Calculating mean and std
2024-02-05 00:02:51,332:INFO:Creating metrics dataframe
2024-02-05 00:02:51,338:INFO:Uploading results into container
2024-02-05 00:02:51,339:INFO:Uploading model into container now
2024-02-05 00:02:51,339:INFO:_master_model_container: 8
2024-02-05 00:02:51,340:INFO:_display_container: 2
2024-02-05 00:02:51,340:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-05 00:02:51,340:INFO:create_model() successfully completed......................................
2024-02-05 00:02:51,522:INFO:SubProcess create_model() end ==================================
2024-02-05 00:02:51,522:INFO:Creating metrics dataframe
2024-02-05 00:02:51,534:INFO:Initializing Ada Boost Classifier
2024-02-05 00:02:51,534:INFO:Total runtime is 0.9951001803080242 minutes
2024-02-05 00:02:51,538:INFO:SubProcess create_model() called ==================================
2024-02-05 00:02:51,538:INFO:Initializing create_model()
2024-02-05 00:02:51,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:02:51,538:INFO:Checking exceptions
2024-02-05 00:02:51,539:INFO:Importing libraries
2024-02-05 00:02:51,539:INFO:Copying training dataset
2024-02-05 00:02:51,544:INFO:Defining folds
2024-02-05 00:02:51,545:INFO:Declaring metric variables
2024-02-05 00:02:51,548:INFO:Importing untrained model
2024-02-05 00:02:51,554:INFO:Ada Boost Classifier Imported successfully
2024-02-05 00:02:51,562:INFO:Starting cross validation
2024-02-05 00:02:51,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:02:52,080:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:02:52,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-02-05 00:02:52,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:52,081:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:52,081:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:02:52,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:52,907:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:02:52,907:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-02-05 00:02:52,907:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:52,907:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:52,908:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:02:52,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:53,712:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:02:53,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-02-05 00:02:53,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:53,712:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:53,712:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:02:53,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:54,633:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:02:54,633:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-02-05 00:02:54,633:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:54,634:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:54,634:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:02:54,634:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:55,606:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:02:55,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 00:02:55,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:55,607:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:55,607:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:02:55,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:56,546:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:02:56,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-02-05 00:02:56,546:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:56,546:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:56,547:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:02:56,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:57,496:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:02:57,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2024-02-05 00:02:57,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:57,497:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:57,497:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:02:57,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:58,477:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:02:58,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-02-05 00:02:58,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:58,478:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:58,478:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:02:58,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:02:59,345:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:02:59,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-02-05 00:02:59,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:02:59,346:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:02:59,346:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:02:59,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:00,197:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:00,197:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-02-05 00:03:00,197:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:00,197:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:00,197:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:00,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:00,548:INFO:Calculating mean and std
2024-02-05 00:03:00,549:INFO:Creating metrics dataframe
2024-02-05 00:03:00,552:INFO:Uploading results into container
2024-02-05 00:03:00,552:INFO:Uploading model into container now
2024-02-05 00:03:00,553:INFO:_master_model_container: 9
2024-02-05 00:03:00,553:INFO:_display_container: 2
2024-02-05 00:03:00,553:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=207)
2024-02-05 00:03:00,553:INFO:create_model() successfully completed......................................
2024-02-05 00:03:00,690:INFO:SubProcess create_model() end ==================================
2024-02-05 00:03:00,690:INFO:Creating metrics dataframe
2024-02-05 00:03:00,706:INFO:Initializing Gradient Boosting Classifier
2024-02-05 00:03:00,706:INFO:Total runtime is 1.1479653437932333 minutes
2024-02-05 00:03:00,713:INFO:SubProcess create_model() called ==================================
2024-02-05 00:03:00,713:INFO:Initializing create_model()
2024-02-05 00:03:00,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:03:00,714:INFO:Checking exceptions
2024-02-05 00:03:00,714:INFO:Importing libraries
2024-02-05 00:03:00,714:INFO:Copying training dataset
2024-02-05 00:03:00,720:INFO:Defining folds
2024-02-05 00:03:00,720:INFO:Declaring metric variables
2024-02-05 00:03:00,725:INFO:Importing untrained model
2024-02-05 00:03:00,730:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:03:00,738:INFO:Starting cross validation
2024-02-05 00:03:00,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:03:01,262:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:01,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-02-05 00:03:01,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:01,263:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:01,263:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:03:01,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:02,549:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:03:02,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-02-05 00:03:02,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:02,550:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:02,550:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:03:02,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:03,833:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:03:03,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-02-05 00:03:03,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:03,834:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:03,834:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:03:03,834:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:05,252:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:03:05,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-02-05 00:03:05,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:05,252:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:05,253:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:03:05,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:06,711:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:03:06,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-02-05 00:03:06,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:06,712:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:06,712:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:03:06,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:08,175:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:03:08,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-02-05 00:03:08,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:08,175:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:08,176:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:03:08,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:09,502:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:09,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:03:09,502:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:09,502:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:09,503:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:09,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:10,811:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:03:10,811:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-02-05 00:03:10,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:10,811:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:10,811:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:03:10,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:12,141:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:03:12,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-02-05 00:03:12,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:12,141:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:12,142:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:03:12,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:13,512:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:13,512:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-02-05 00:03:13,512:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:13,512:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:13,512:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:13,513:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:14,422:INFO:Calculating mean and std
2024-02-05 00:03:14,424:INFO:Creating metrics dataframe
2024-02-05 00:03:14,429:INFO:Uploading results into container
2024-02-05 00:03:14,430:INFO:Uploading model into container now
2024-02-05 00:03:14,430:INFO:_master_model_container: 10
2024-02-05 00:03:14,431:INFO:_display_container: 2
2024-02-05 00:03:14,431:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:03:14,432:INFO:create_model() successfully completed......................................
2024-02-05 00:03:14,606:INFO:SubProcess create_model() end ==================================
2024-02-05 00:03:14,606:INFO:Creating metrics dataframe
2024-02-05 00:03:14,618:INFO:Initializing Linear Discriminant Analysis
2024-02-05 00:03:14,619:INFO:Total runtime is 1.3798392097155254 minutes
2024-02-05 00:03:14,622:INFO:SubProcess create_model() called ==================================
2024-02-05 00:03:14,623:INFO:Initializing create_model()
2024-02-05 00:03:14,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:03:14,623:INFO:Checking exceptions
2024-02-05 00:03:14,623:INFO:Importing libraries
2024-02-05 00:03:14,623:INFO:Copying training dataset
2024-02-05 00:03:14,629:INFO:Defining folds
2024-02-05 00:03:14,629:INFO:Declaring metric variables
2024-02-05 00:03:14,633:INFO:Importing untrained model
2024-02-05 00:03:14,639:INFO:Linear Discriminant Analysis Imported successfully
2024-02-05 00:03:14,652:INFO:Starting cross validation
2024-02-05 00:03:14,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:03:15,183:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:15,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-02-05 00:03:15,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:15,184:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:15,184:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:03:15,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:15,888:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:03:15,889:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-02-05 00:03:15,889:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:15,889:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:15,889:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:03:15,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:16,579:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:03:16,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-02-05 00:03:16,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:16,579:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:16,580:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:03:16,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:17,262:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:03:17,262:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2024-02-05 00:03:17,262:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:17,262:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:17,262:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:03:17,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:17,964:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:03:17,965:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-02-05 00:03:17,965:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:17,965:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:17,965:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:03:17,965:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:18,610:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:03:18,611:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-02-05 00:03:18,611:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:18,611:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:18,611:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:03:18,611:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:19,236:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:19,236:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-02-05 00:03:19,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:19,237:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:19,237:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:19,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:19,836:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:03:19,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:03:19,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:19,836:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:19,836:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:03:19,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:20,413:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:03:20,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2024-02-05 00:03:20,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:20,414:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:20,414:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:03:20,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:21,022:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:21,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-02-05 00:03:21,023:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:21,023:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:21,023:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:21,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:21,148:INFO:Calculating mean and std
2024-02-05 00:03:21,149:INFO:Creating metrics dataframe
2024-02-05 00:03:21,155:INFO:Uploading results into container
2024-02-05 00:03:21,156:INFO:Uploading model into container now
2024-02-05 00:03:21,157:INFO:_master_model_container: 11
2024-02-05 00:03:21,157:INFO:_display_container: 2
2024-02-05 00:03:21,158:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-05 00:03:21,158:INFO:create_model() successfully completed......................................
2024-02-05 00:03:21,312:INFO:SubProcess create_model() end ==================================
2024-02-05 00:03:21,313:INFO:Creating metrics dataframe
2024-02-05 00:03:21,324:INFO:Initializing Extra Trees Classifier
2024-02-05 00:03:21,324:INFO:Total runtime is 1.4915942112604779 minutes
2024-02-05 00:03:21,327:INFO:SubProcess create_model() called ==================================
2024-02-05 00:03:21,328:INFO:Initializing create_model()
2024-02-05 00:03:21,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:03:21,328:INFO:Checking exceptions
2024-02-05 00:03:21,328:INFO:Importing libraries
2024-02-05 00:03:21,328:INFO:Copying training dataset
2024-02-05 00:03:21,334:INFO:Defining folds
2024-02-05 00:03:21,334:INFO:Declaring metric variables
2024-02-05 00:03:21,338:INFO:Importing untrained model
2024-02-05 00:03:21,344:INFO:Extra Trees Classifier Imported successfully
2024-02-05 00:03:21,353:INFO:Starting cross validation
2024-02-05 00:03:21,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:03:21,858:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:21,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-02-05 00:03:21,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:21,859:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:21,859:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:03:21,859:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:22,725:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:03:22,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2024-02-05 00:03:22,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:22,725:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:22,726:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:03:22,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:23,598:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:03:23,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2024-02-05 00:03:23,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:23,599:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:23,599:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:03:23,600:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:24,537:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:03:24,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-02-05 00:03:24,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:24,538:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:24,538:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:03:24,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:25,506:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:03:25,507:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2024-02-05 00:03:25,507:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:25,507:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:25,507:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:03:25,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:26,496:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:03:26,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-02-05 00:03:26,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:26,497:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:26,497:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:03:26,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:27,443:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:27,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-02-05 00:03:27,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:27,444:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:27,444:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:27,445:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:28,374:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:03:28,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-02-05 00:03:28,374:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:28,374:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:28,374:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:03:28,375:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:29,199:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:03:29,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-02-05 00:03:29,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:29,199:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:29,199:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:03:29,200:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:30,028:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:30,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-02-05 00:03:30,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:30,029:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:30,029:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:30,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:30,388:INFO:Calculating mean and std
2024-02-05 00:03:30,389:INFO:Creating metrics dataframe
2024-02-05 00:03:30,393:INFO:Uploading results into container
2024-02-05 00:03:30,394:INFO:Uploading model into container now
2024-02-05 00:03:30,394:INFO:_master_model_container: 12
2024-02-05 00:03:30,394:INFO:_display_container: 2
2024-02-05 00:03:30,395:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False)
2024-02-05 00:03:30,395:INFO:create_model() successfully completed......................................
2024-02-05 00:03:30,548:INFO:SubProcess create_model() end ==================================
2024-02-05 00:03:30,548:INFO:Creating metrics dataframe
2024-02-05 00:03:30,565:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 00:03:30,565:INFO:Total runtime is 1.6456117272377015 minutes
2024-02-05 00:03:30,569:INFO:SubProcess create_model() called ==================================
2024-02-05 00:03:30,569:INFO:Initializing create_model()
2024-02-05 00:03:30,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:03:30,569:INFO:Checking exceptions
2024-02-05 00:03:30,569:INFO:Importing libraries
2024-02-05 00:03:30,570:INFO:Copying training dataset
2024-02-05 00:03:30,576:INFO:Defining folds
2024-02-05 00:03:30,576:INFO:Declaring metric variables
2024-02-05 00:03:30,580:INFO:Importing untrained model
2024-02-05 00:03:30,585:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 00:03:30,595:INFO:Starting cross validation
2024-02-05 00:03:30,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:03:31,102:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:31,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-02-05 00:03:31,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:31,103:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:31,103:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:03:31,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:31,179:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:31,179:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:31,179:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:31,179:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 3
2024-02-05 00:03:31,181:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:31,182:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:36,532:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:36,538:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:36,541:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000191 secs. 0 sparse feature groups
2024-02-05 00:03:36,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:38,678:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:03:38,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-02-05 00:03:38,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:38,679:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:38,680:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:03:38,680:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 3
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:38,809:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:38,878:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:38,880:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:38,883:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000183 secs. 0 sparse feature groups
2024-02-05 00:03:38,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:41,014:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:03:41,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
2024-02-05 00:03:41,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:41,015:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:41,015:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:03:41,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 3
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:41,101:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:41,106:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:41,109:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:41,111:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000122 secs. 0 sparse feature groups
2024-02-05 00:03:41,112:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:43,059:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:03:43,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-02-05 00:03:43,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:43,060:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:43,060:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:03:43,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:43,143:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:03:43,143:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:43,144:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:43,144:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 3
2024-02-05 00:03:43,144:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:43,144:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:43,150:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:43,152:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:43,154:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000165 secs. 0 sparse feature groups
2024-02-05 00:03:43,155:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:45,064:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:03:45,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2024-02-05 00:03:45,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:45,065:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:45,065:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:03:45,066:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 3
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:45,141:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:45,146:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:45,147:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:45,149:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000086 secs. 0 sparse feature groups
2024-02-05 00:03:45,150:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:47,140:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:03:47,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-02-05 00:03:47,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:47,141:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:47,141:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:03:47,141:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:47,291:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:03:47,291:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:47,291:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:47,291:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 3
2024-02-05 00:03:47,293:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:47,293:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:47,308:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:47,311:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:47,315:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000271 secs. 0 sparse feature groups
2024-02-05 00:03:47,315:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:49,729:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:49,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2024-02-05 00:03:49,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:49,730:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:49,731:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:49,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:49,862:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:49,863:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:49,863:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:49,863:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 3
2024-02-05 00:03:49,863:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:49,863:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:49,870:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:49,872:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:49,875:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000177 secs. 0 sparse feature groups
2024-02-05 00:03:49,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:51,991:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:03:51,992:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000654 seconds.
2024-02-05 00:03:51,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:51,992:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:51,992:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:03:51,992:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:52,113:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:03:52,113:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:52,114:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:52,114:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 3
2024-02-05 00:03:52,114:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:52,114:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:52,120:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:52,123:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:52,125:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000129 secs. 0 sparse feature groups
2024-02-05 00:03:52,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:52,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 00:03:53,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 00:03:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 00:03:53,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 00:03:53,976:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:03:53,977:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-02-05 00:03:53,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:53,977:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:53,977:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:03:53,978:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:54,080:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:03:54,080:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:54,080:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:54,080:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 3
2024-02-05 00:03:54,080:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:54,081:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:54,087:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:54,090:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:54,092:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000144 secs. 0 sparse feature groups
2024-02-05 00:03:54,093:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:55,982:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:55,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-02-05 00:03:55,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:55,983:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:55,983:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:03:55,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 3
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:03:56,100:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:03:56,107:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:03:56,110:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:03:56,112:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000200 secs. 0 sparse feature groups
2024-02-05 00:03:56,112:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:03:57,291:INFO:Calculating mean and std
2024-02-05 00:03:57,293:INFO:Creating metrics dataframe
2024-02-05 00:03:57,301:INFO:Uploading results into container
2024-02-05 00:03:57,302:INFO:Uploading model into container now
2024-02-05 00:03:57,303:INFO:_master_model_container: 13
2024-02-05 00:03:57,303:INFO:_display_container: 2
2024-02-05 00:03:57,305:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 00:03:57,305:INFO:create_model() successfully completed......................................
2024-02-05 00:03:57,480:INFO:SubProcess create_model() end ==================================
2024-02-05 00:03:57,480:INFO:Creating metrics dataframe
2024-02-05 00:03:57,495:INFO:Initializing CatBoost Classifier
2024-02-05 00:03:57,495:INFO:Total runtime is 2.0944451530774435 minutes
2024-02-05 00:03:57,499:INFO:SubProcess create_model() called ==================================
2024-02-05 00:03:57,499:INFO:Initializing create_model()
2024-02-05 00:03:57,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:03:57,499:INFO:Checking exceptions
2024-02-05 00:03:57,499:INFO:Importing libraries
2024-02-05 00:03:57,499:INFO:Copying training dataset
2024-02-05 00:03:57,506:INFO:Defining folds
2024-02-05 00:03:57,506:INFO:Declaring metric variables
2024-02-05 00:03:57,510:INFO:Importing untrained model
2024-02-05 00:03:57,515:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:03:57,524:INFO:Starting cross validation
2024-02-05 00:03:57,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:03:58,092:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:03:58,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-02-05 00:03:58,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:03:58,093:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:03:58,093:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:03:58,093:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:04:36,544:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:04:36,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.
2024-02-05 00:04:36,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:04:36,545:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:04:36,545:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:04:36,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:05:07,475:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:05:07,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
2024-02-05 00:05:07,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:05:07,476:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:05:07,477:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:05:07,477:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:05:51,195:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:05:51,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-02-05 00:05:51,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:05:51,196:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:05:51,196:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:05:51,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:06:38,127:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:06:38,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001286 seconds.
2024-02-05 00:06:38,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:06:38,130:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:06:38,131:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:06:38,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:07:16,510:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:07:16,512:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.
2024-02-05 00:07:16,512:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:07:16,512:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:07:16,513:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:07:16,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:08:06,431:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:08:06,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.
2024-02-05 00:08:06,433:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:08:06,433:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:08:06,434:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:08:06,434:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:08:53,112:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:08:53,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
2024-02-05 00:08:53,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:08:53,113:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:08:53,113:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:08:53,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:09:47,092:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:09:47,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.
2024-02-05 00:09:47,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:09:47,094:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:09:47,095:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:09:47,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:10:41,072:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:10:41,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.
2024-02-05 00:10:41,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:10:41,074:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:10:41,075:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:10:41,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:19,474:INFO:Calculating mean and std
2024-02-05 00:11:19,476:INFO:Creating metrics dataframe
2024-02-05 00:11:19,483:INFO:Uploading results into container
2024-02-05 00:11:19,485:INFO:Uploading model into container now
2024-02-05 00:11:19,486:INFO:_master_model_container: 14
2024-02-05 00:11:19,486:INFO:_display_container: 2
2024-02-05 00:11:19,487:INFO:<catboost.core.CatBoostClassifier object at 0x00000158457EFFA0>
2024-02-05 00:11:19,487:INFO:create_model() successfully completed......................................
2024-02-05 00:11:19,723:INFO:SubProcess create_model() end ==================================
2024-02-05 00:11:19,723:INFO:Creating metrics dataframe
2024-02-05 00:11:19,750:INFO:Initializing Dummy Classifier
2024-02-05 00:11:19,750:INFO:Total runtime is 9.465360462665558 minutes
2024-02-05 00:11:19,756:INFO:SubProcess create_model() called ==================================
2024-02-05 00:11:19,756:INFO:Initializing create_model()
2024-02-05 00:11:19,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158455BC400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:11:19,757:INFO:Checking exceptions
2024-02-05 00:11:19,757:INFO:Importing libraries
2024-02-05 00:11:19,757:INFO:Copying training dataset
2024-02-05 00:11:19,769:INFO:Defining folds
2024-02-05 00:11:19,769:INFO:Declaring metric variables
2024-02-05 00:11:19,775:INFO:Importing untrained model
2024-02-05 00:11:19,784:INFO:Dummy Classifier Imported successfully
2024-02-05 00:11:19,800:INFO:Starting cross validation
2024-02-05 00:11:19,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:11:20,467:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:11:20,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.
2024-02-05 00:11:20,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:20,468:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:20,469:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:11:20,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:21,728:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:11:21,730:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.
2024-02-05 00:11:21,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:21,730:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:21,730:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:11:21,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:23,382:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:11:23,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.
2024-02-05 00:11:23,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:23,383:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:23,383:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:11:23,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:24,439:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:11:24,439:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2024-02-05 00:11:24,439:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:24,440:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:24,440:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:11:24,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:25,503:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:11:25,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.
2024-02-05 00:11:25,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:25,504:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:25,505:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:11:25,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:26,672:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:11:26,673:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.
2024-02-05 00:11:26,673:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:26,673:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:26,674:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:11:26,674:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:27,755:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:11:27,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000608 seconds.
2024-02-05 00:11:27,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:27,757:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:27,757:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:11:27,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:28,810:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:11:28,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-02-05 00:11:28,811:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:28,811:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:28,811:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:11:28,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:29,744:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:11:29,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-02-05 00:11:29,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:29,745:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:29,745:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:11:29,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:30,595:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:11:30,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2024-02-05 00:11:30,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:30,596:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:30,597:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:11:30,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:30,782:INFO:Calculating mean and std
2024-02-05 00:11:30,783:INFO:Creating metrics dataframe
2024-02-05 00:11:30,789:INFO:Uploading results into container
2024-02-05 00:11:30,790:INFO:Uploading model into container now
2024-02-05 00:11:30,791:INFO:_master_model_container: 15
2024-02-05 00:11:30,791:INFO:_display_container: 2
2024-02-05 00:11:30,791:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:11:30,791:INFO:create_model() successfully completed......................................
2024-02-05 00:11:30,960:INFO:SubProcess create_model() end ==================================
2024-02-05 00:11:30,960:INFO:Creating metrics dataframe
2024-02-05 00:11:30,989:INFO:Initializing create_model()
2024-02-05 00:11:30,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=DummyClassifier(constant=None, random_state=207, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:11:30,989:INFO:Checking exceptions
2024-02-05 00:11:30,992:INFO:Importing libraries
2024-02-05 00:11:30,992:INFO:Copying training dataset
2024-02-05 00:11:31,000:INFO:Defining folds
2024-02-05 00:11:31,000:INFO:Declaring metric variables
2024-02-05 00:11:31,001:INFO:Importing untrained model
2024-02-05 00:11:31,001:INFO:Declaring custom model
2024-02-05 00:11:31,001:INFO:Dummy Classifier Imported successfully
2024-02-05 00:11:31,023:INFO:Cross validation set to False
2024-02-05 00:11:31,024:INFO:Fitting Model
2024-02-05 00:11:31,707:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:11:31,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-02-05 00:11:31,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:31,708:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:31,708:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:11:31,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:11:31,901:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:11:31,902:INFO:create_model() successfully completed......................................
2024-02-05 00:11:32,194:INFO:Initializing create_model()
2024-02-05 00:11:32,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=<catboost.core.CatBoostClassifier object at 0x00000158457EFFA0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:11:32,194:INFO:Checking exceptions
2024-02-05 00:11:32,197:INFO:Importing libraries
2024-02-05 00:11:32,198:INFO:Copying training dataset
2024-02-05 00:11:32,221:INFO:Defining folds
2024-02-05 00:11:32,222:INFO:Declaring metric variables
2024-02-05 00:11:32,222:INFO:Importing untrained model
2024-02-05 00:11:32,223:INFO:Declaring custom model
2024-02-05 00:11:32,223:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:11:32,258:INFO:Cross validation set to False
2024-02-05 00:11:32,258:INFO:Fitting Model
2024-02-05 00:11:33,294:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:11:33,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.
2024-02-05 00:11:33,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:11:33,295:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:11:33,296:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:11:33,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:12:15,048:INFO:<catboost.core.CatBoostClassifier object at 0x00000158456D6200>
2024-02-05 00:12:15,048:INFO:create_model() successfully completed......................................
2024-02-05 00:12:15,376:INFO:Initializing create_model()
2024-02-05 00:12:15,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:12:15,377:INFO:Checking exceptions
2024-02-05 00:12:15,380:INFO:Importing libraries
2024-02-05 00:12:15,380:INFO:Copying training dataset
2024-02-05 00:12:15,400:INFO:Defining folds
2024-02-05 00:12:15,400:INFO:Declaring metric variables
2024-02-05 00:12:15,401:INFO:Importing untrained model
2024-02-05 00:12:15,401:INFO:Declaring custom model
2024-02-05 00:12:15,403:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:12:15,452:INFO:Cross validation set to False
2024-02-05 00:12:15,452:INFO:Fitting Model
2024-02-05 00:12:16,655:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:12:16,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
2024-02-05 00:12:16,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:12:16,657:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:12:16,657:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:12:16,657:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:12:19,163:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:12:19,163:INFO:create_model() successfully completed......................................
2024-02-05 00:12:19,464:INFO:Initializing create_model()
2024-02-05 00:12:19,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:12:19,465:INFO:Checking exceptions
2024-02-05 00:12:19,471:INFO:Importing libraries
2024-02-05 00:12:19,472:INFO:Copying training dataset
2024-02-05 00:12:19,495:INFO:Defining folds
2024-02-05 00:12:19,496:INFO:Declaring metric variables
2024-02-05 00:12:19,496:INFO:Importing untrained model
2024-02-05 00:12:19,496:INFO:Declaring custom model
2024-02-05 00:12:19,497:INFO:Extra Trees Classifier Imported successfully
2024-02-05 00:12:19,555:INFO:Cross validation set to False
2024-02-05 00:12:19,555:INFO:Fitting Model
2024-02-05 00:12:21,547:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:12:21,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.
2024-02-05 00:12:21,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:12:21,550:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:12:21,550:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:12:21,551:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:12:22,401:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False)
2024-02-05 00:12:22,401:INFO:create_model() successfully completed......................................
2024-02-05 00:12:22,569:INFO:Initializing create_model()
2024-02-05 00:12:22,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=207, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:12:22,569:INFO:Checking exceptions
2024-02-05 00:12:22,571:INFO:Importing libraries
2024-02-05 00:12:22,571:INFO:Copying training dataset
2024-02-05 00:12:22,580:INFO:Defining folds
2024-02-05 00:12:22,581:INFO:Declaring metric variables
2024-02-05 00:12:22,581:INFO:Importing untrained model
2024-02-05 00:12:22,581:INFO:Declaring custom model
2024-02-05 00:12:22,582:INFO:Random Forest Classifier Imported successfully
2024-02-05 00:12:22,599:INFO:Cross validation set to False
2024-02-05 00:12:22,599:INFO:Fitting Model
2024-02-05 00:12:23,370:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:12:23,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-02-05 00:12:23,371:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:12:23,371:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:12:23,371:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:12:23,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:12:24,029:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=207, verbose=0, warm_start=False)
2024-02-05 00:12:24,029:INFO:create_model() successfully completed......................................
2024-02-05 00:12:24,272:INFO:_master_model_container: 15
2024-02-05 00:12:24,272:INFO:_display_container: 2
2024-02-05 00:12:24,274:INFO:[DummyClassifier(constant=None, random_state=207, strategy='prior'), <catboost.core.CatBoostClassifier object at 0x00000158456D6200>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=207, verbose=0, warm_start=False)]
2024-02-05 00:12:24,274:INFO:compare_models() successfully completed......................................
2024-02-05 00:14:10,005:INFO:Initializing compare_models()
2024-02-05 00:14:10,006:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 00:14:10,006:INFO:Checking exceptions
2024-02-05 00:14:10,010:INFO:Preparing display monitor
2024-02-05 00:14:10,042:INFO:Initializing Logistic Regression
2024-02-05 00:14:10,042:INFO:Total runtime is 0.0 minutes
2024-02-05 00:14:10,045:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:10,045:INFO:Initializing create_model()
2024-02-05 00:14:10,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:10,047:INFO:Checking exceptions
2024-02-05 00:14:10,047:INFO:Importing libraries
2024-02-05 00:14:10,047:INFO:Copying training dataset
2024-02-05 00:14:10,055:INFO:Defining folds
2024-02-05 00:14:10,055:INFO:Declaring metric variables
2024-02-05 00:14:10,059:INFO:Importing untrained model
2024-02-05 00:14:10,066:INFO:Logistic Regression Imported successfully
2024-02-05 00:14:10,074:INFO:Starting cross validation
2024-02-05 00:14:10,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:10,647:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:10,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-05 00:14:10,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:10,648:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:10,648:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:10,648:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:11,343:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:11,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-02-05 00:14:11,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:11,343:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:11,344:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:11,344:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:12,075:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:12,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-02-05 00:14:12,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:12,076:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:12,076:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:12,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:12,909:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:12,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-02-05 00:14:12,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:12,910:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:12,910:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:12,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:13,674:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:13,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2024-02-05 00:14:13,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:13,675:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:13,675:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:13,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:14,393:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:14,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
2024-02-05 00:14:14,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:14,394:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:14,394:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:14,395:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:15,122:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:15,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-02-05 00:14:15,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:15,123:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:15,123:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:15,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:15,913:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:15,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-02-05 00:14:15,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:15,914:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:15,914:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:15,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:16,644:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:16,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-02-05 00:14:16,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:16,645:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:16,645:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:16,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:17,510:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:17,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
2024-02-05 00:14:17,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:17,511:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:17,512:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:17,512:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:17,759:INFO:Calculating mean and std
2024-02-05 00:14:17,760:INFO:Creating metrics dataframe
2024-02-05 00:14:17,765:INFO:Uploading results into container
2024-02-05 00:14:17,766:INFO:Uploading model into container now
2024-02-05 00:14:17,766:INFO:_master_model_container: 16
2024-02-05 00:14:17,766:INFO:_display_container: 3
2024-02-05 00:14:17,767:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=207, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-05 00:14:17,767:INFO:create_model() successfully completed......................................
2024-02-05 00:14:18,050:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:18,050:INFO:Creating metrics dataframe
2024-02-05 00:14:18,079:INFO:Initializing K Neighbors Classifier
2024-02-05 00:14:18,079:INFO:Total runtime is 0.13395816882451375 minutes
2024-02-05 00:14:18,092:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:18,093:INFO:Initializing create_model()
2024-02-05 00:14:18,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:18,094:INFO:Checking exceptions
2024-02-05 00:14:18,094:INFO:Importing libraries
2024-02-05 00:14:18,094:INFO:Copying training dataset
2024-02-05 00:14:18,114:INFO:Defining folds
2024-02-05 00:14:18,115:INFO:Declaring metric variables
2024-02-05 00:14:18,127:INFO:Importing untrained model
2024-02-05 00:14:18,138:INFO:K Neighbors Classifier Imported successfully
2024-02-05 00:14:18,166:INFO:Starting cross validation
2024-02-05 00:14:18,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:19,198:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:19,198:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2024-02-05 00:14:19,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:19,199:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:19,199:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:19,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:20,506:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:20,506:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2024-02-05 00:14:20,506:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:20,507:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:20,507:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:20,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:21,367:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:21,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-02-05 00:14:21,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:21,368:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:21,368:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:21,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:22,130:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:22,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-02-05 00:14:22,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:22,131:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:22,131:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:22,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:22,908:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:22,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-02-05 00:14:22,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:22,908:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:22,909:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:22,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:23,681:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:23,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-02-05 00:14:23,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:23,682:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:23,682:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:23,682:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:24,449:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:24,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-02-05 00:14:24,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:24,450:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:24,450:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:24,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:25,230:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:25,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-02-05 00:14:25,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:25,231:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:25,231:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:25,232:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:26,008:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:26,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-02-05 00:14:26,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:26,009:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:26,009:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:26,009:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:26,779:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:26,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-02-05 00:14:26,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:26,780:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:26,780:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:26,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:26,964:INFO:Calculating mean and std
2024-02-05 00:14:26,966:INFO:Creating metrics dataframe
2024-02-05 00:14:26,970:INFO:Uploading results into container
2024-02-05 00:14:26,970:INFO:Uploading model into container now
2024-02-05 00:14:26,971:INFO:_master_model_container: 17
2024-02-05 00:14:26,971:INFO:_display_container: 3
2024-02-05 00:14:26,971:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-05 00:14:26,971:INFO:create_model() successfully completed......................................
2024-02-05 00:14:27,134:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:27,134:INFO:Creating metrics dataframe
2024-02-05 00:14:27,145:INFO:Initializing Naive Bayes
2024-02-05 00:14:27,145:INFO:Total runtime is 0.28504826227823893 minutes
2024-02-05 00:14:27,149:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:27,149:INFO:Initializing create_model()
2024-02-05 00:14:27,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:27,149:INFO:Checking exceptions
2024-02-05 00:14:27,150:INFO:Importing libraries
2024-02-05 00:14:27,150:INFO:Copying training dataset
2024-02-05 00:14:27,156:INFO:Defining folds
2024-02-05 00:14:27,156:INFO:Declaring metric variables
2024-02-05 00:14:27,160:INFO:Importing untrained model
2024-02-05 00:14:27,166:INFO:Naive Bayes Imported successfully
2024-02-05 00:14:27,175:INFO:Starting cross validation
2024-02-05 00:14:27,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:27,731:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:27,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-02-05 00:14:27,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:27,732:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:27,732:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:27,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:28,425:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:28,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-02-05 00:14:28,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:28,426:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:28,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:28,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:29,069:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:29,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-02-05 00:14:29,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:29,070:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:29,070:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:29,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:29,726:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:29,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-02-05 00:14:29,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:29,727:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:29,727:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:29,727:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:30,382:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:30,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2024-02-05 00:14:30,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:30,383:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:30,384:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:30,384:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:31,086:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:31,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2024-02-05 00:14:31,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:31,087:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:31,087:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:31,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:31,796:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:31,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2024-02-05 00:14:31,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:31,796:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:31,797:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:31,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:32,616:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:32,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-02-05 00:14:32,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:32,617:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:32,617:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:32,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:33,347:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:33,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-02-05 00:14:33,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:33,348:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:33,348:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:33,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:34,091:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:34,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-02-05 00:14:34,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:34,092:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:34,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:34,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:34,283:INFO:Calculating mean and std
2024-02-05 00:14:34,284:INFO:Creating metrics dataframe
2024-02-05 00:14:34,288:INFO:Uploading results into container
2024-02-05 00:14:34,289:INFO:Uploading model into container now
2024-02-05 00:14:34,290:INFO:_master_model_container: 18
2024-02-05 00:14:34,290:INFO:_display_container: 3
2024-02-05 00:14:34,290:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-05 00:14:34,291:INFO:create_model() successfully completed......................................
2024-02-05 00:14:34,468:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:34,468:INFO:Creating metrics dataframe
2024-02-05 00:14:34,479:INFO:Initializing Decision Tree Classifier
2024-02-05 00:14:34,479:INFO:Total runtime is 0.40729168653488157 minutes
2024-02-05 00:14:34,482:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:34,482:INFO:Initializing create_model()
2024-02-05 00:14:34,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:34,483:INFO:Checking exceptions
2024-02-05 00:14:34,483:INFO:Importing libraries
2024-02-05 00:14:34,483:INFO:Copying training dataset
2024-02-05 00:14:34,489:INFO:Defining folds
2024-02-05 00:14:34,489:INFO:Declaring metric variables
2024-02-05 00:14:34,494:INFO:Importing untrained model
2024-02-05 00:14:34,500:INFO:Decision Tree Classifier Imported successfully
2024-02-05 00:14:34,515:INFO:Starting cross validation
2024-02-05 00:14:34,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:35,100:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:35,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-02-05 00:14:35,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:35,101:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:35,101:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:35,101:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:35,864:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:35,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-02-05 00:14:35,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:35,864:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:35,865:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:35,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:36,661:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:36,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-02-05 00:14:36,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:36,662:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:36,662:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:36,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:37,417:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:37,417:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.
2024-02-05 00:14:37,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:37,418:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:37,418:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:37,418:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:38,107:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:38,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-02-05 00:14:38,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:38,108:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:38,108:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:38,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:38,817:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:38,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2024-02-05 00:14:38,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:38,818:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:38,818:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:38,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:39,464:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:39,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-02-05 00:14:39,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:39,464:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:39,464:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:39,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:40,164:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:40,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-02-05 00:14:40,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:40,165:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:40,165:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:40,165:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:40,826:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:40,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-02-05 00:14:40,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:40,826:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:40,826:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:40,827:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:41,487:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:41,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-02-05 00:14:41,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:41,488:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:41,488:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:41,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:41,679:INFO:Calculating mean and std
2024-02-05 00:14:41,680:INFO:Creating metrics dataframe
2024-02-05 00:14:41,686:INFO:Uploading results into container
2024-02-05 00:14:41,687:INFO:Uploading model into container now
2024-02-05 00:14:41,688:INFO:_master_model_container: 19
2024-02-05 00:14:41,688:INFO:_display_container: 3
2024-02-05 00:14:41,689:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=207, splitter='best')
2024-02-05 00:14:41,690:INFO:create_model() successfully completed......................................
2024-02-05 00:14:41,862:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:41,862:INFO:Creating metrics dataframe
2024-02-05 00:14:41,871:INFO:Initializing SVM - Linear Kernel
2024-02-05 00:14:41,871:INFO:Total runtime is 0.530495818456014 minutes
2024-02-05 00:14:41,874:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:41,875:INFO:Initializing create_model()
2024-02-05 00:14:41,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:41,875:INFO:Checking exceptions
2024-02-05 00:14:41,875:INFO:Importing libraries
2024-02-05 00:14:41,875:INFO:Copying training dataset
2024-02-05 00:14:41,881:INFO:Defining folds
2024-02-05 00:14:41,881:INFO:Declaring metric variables
2024-02-05 00:14:41,885:INFO:Importing untrained model
2024-02-05 00:14:41,892:INFO:SVM - Linear Kernel Imported successfully
2024-02-05 00:14:41,899:INFO:Starting cross validation
2024-02-05 00:14:41,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:42,486:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:42,487:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.
2024-02-05 00:14:42,487:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:42,487:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:42,487:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:42,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:43,240:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:43,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-02-05 00:14:43,240:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:43,240:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:43,240:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:43,241:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:43,994:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:43,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2024-02-05 00:14:43,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:43,995:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:43,995:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:43,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:44,723:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:44,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-02-05 00:14:44,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:44,724:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:44,724:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:44,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:45,480:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:45,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-02-05 00:14:45,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:45,481:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:45,481:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:45,481:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:46,223:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:46,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.
2024-02-05 00:14:46,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:46,225:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:46,225:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:46,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:46,928:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:46,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-02-05 00:14:46,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:46,929:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:46,929:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:46,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:47,602:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:47,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.
2024-02-05 00:14:47,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:47,603:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:47,603:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:47,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:48,291:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:48,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-02-05 00:14:48,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:48,291:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:48,292:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:48,292:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:48,953:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:48,953:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-02-05 00:14:48,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:48,954:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:48,954:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:48,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:49,094:INFO:Calculating mean and std
2024-02-05 00:14:49,095:INFO:Creating metrics dataframe
2024-02-05 00:14:49,098:INFO:Uploading results into container
2024-02-05 00:14:49,099:INFO:Uploading model into container now
2024-02-05 00:14:49,100:INFO:_master_model_container: 20
2024-02-05 00:14:49,100:INFO:_display_container: 3
2024-02-05 00:14:49,100:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=207, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-05 00:14:49,101:INFO:create_model() successfully completed......................................
2024-02-05 00:14:49,253:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:49,253:INFO:Creating metrics dataframe
2024-02-05 00:14:49,263:INFO:Initializing Ridge Classifier
2024-02-05 00:14:49,263:INFO:Total runtime is 0.6536908229192098 minutes
2024-02-05 00:14:49,266:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:49,267:INFO:Initializing create_model()
2024-02-05 00:14:49,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:49,267:INFO:Checking exceptions
2024-02-05 00:14:49,267:INFO:Importing libraries
2024-02-05 00:14:49,267:INFO:Copying training dataset
2024-02-05 00:14:49,272:INFO:Defining folds
2024-02-05 00:14:49,272:INFO:Declaring metric variables
2024-02-05 00:14:49,277:INFO:Importing untrained model
2024-02-05 00:14:49,282:INFO:Ridge Classifier Imported successfully
2024-02-05 00:14:49,291:INFO:Starting cross validation
2024-02-05 00:14:49,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:49,822:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:49,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-02-05 00:14:49,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:49,822:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:49,822:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:49,823:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:50,484:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:50,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2024-02-05 00:14:50,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:50,485:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:50,485:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:50,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:51,156:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:51,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-02-05 00:14:51,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:51,157:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:51,157:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:51,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:51,828:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:14:51,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-02-05 00:14:51,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:51,828:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:51,830:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:14:51,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:52,573:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:14:52,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2024-02-05 00:14:52,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:52,574:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:52,574:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:14:52,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:53,322:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:14:53,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-02-05 00:14:53,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:53,323:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:53,323:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:14:53,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:54,038:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:54,039:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-02-05 00:14:54,039:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:54,039:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:54,039:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:54,040:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:54,795:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:14:54,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-02-05 00:14:54,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:54,796:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:54,796:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:14:54,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:55,535:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:14:55,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
2024-02-05 00:14:55,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:55,536:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:55,536:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:14:55,536:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:56,240:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:14:56,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-02-05 00:14:56,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:56,241:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:56,241:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:14:56,241:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:56,385:INFO:Calculating mean and std
2024-02-05 00:14:56,387:INFO:Creating metrics dataframe
2024-02-05 00:14:56,391:INFO:Uploading results into container
2024-02-05 00:14:56,391:INFO:Uploading model into container now
2024-02-05 00:14:56,392:INFO:_master_model_container: 21
2024-02-05 00:14:56,392:INFO:_display_container: 3
2024-02-05 00:14:56,393:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=207, solver='auto',
                tol=0.0001)
2024-02-05 00:14:56,393:INFO:create_model() successfully completed......................................
2024-02-05 00:14:56,548:INFO:SubProcess create_model() end ==================================
2024-02-05 00:14:56,548:INFO:Creating metrics dataframe
2024-02-05 00:14:56,559:INFO:Initializing Random Forest Classifier
2024-02-05 00:14:56,559:INFO:Total runtime is 0.7752809723218281 minutes
2024-02-05 00:14:56,563:INFO:SubProcess create_model() called ==================================
2024-02-05 00:14:56,563:INFO:Initializing create_model()
2024-02-05 00:14:56,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:14:56,563:INFO:Checking exceptions
2024-02-05 00:14:56,564:INFO:Importing libraries
2024-02-05 00:14:56,564:INFO:Copying training dataset
2024-02-05 00:14:56,569:INFO:Defining folds
2024-02-05 00:14:56,569:INFO:Declaring metric variables
2024-02-05 00:14:56,573:INFO:Importing untrained model
2024-02-05 00:14:56,579:INFO:Random Forest Classifier Imported successfully
2024-02-05 00:14:56,586:INFO:Starting cross validation
2024-02-05 00:14:56,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:14:57,111:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:14:57,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-02-05 00:14:57,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:57,111:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:57,112:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:14:57,112:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:58,104:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:14:58,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-02-05 00:14:58,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:58,104:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:58,105:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:14:58,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:14:59,069:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:14:59,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-02-05 00:14:59,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:14:59,070:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:14:59,070:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:14:59,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:00,050:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:15:00,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-02-05 00:15:00,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:00,051:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:00,051:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:15:00,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:00,989:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:15:00,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
2024-02-05 00:15:00,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:00,990:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:00,990:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:15:00,990:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:02,091:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:15:02,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-02-05 00:15:02,091:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:02,092:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:02,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:15:02,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:03,162:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:03,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-02-05 00:15:03,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:03,162:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:03,163:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:03,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:04,248:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:15:04,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2024-02-05 00:15:04,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:04,249:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:04,249:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:15:04,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:05,376:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:15:05,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-02-05 00:15:05,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:05,377:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:05,377:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:15:05,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:06,634:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:06,635:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-02-05 00:15:06,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:06,635:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:06,635:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:06,635:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:07,169:INFO:Calculating mean and std
2024-02-05 00:15:07,171:INFO:Creating metrics dataframe
2024-02-05 00:15:07,175:INFO:Uploading results into container
2024-02-05 00:15:07,176:INFO:Uploading model into container now
2024-02-05 00:15:07,176:INFO:_master_model_container: 22
2024-02-05 00:15:07,176:INFO:_display_container: 3
2024-02-05 00:15:07,177:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=207, verbose=0, warm_start=False)
2024-02-05 00:15:07,177:INFO:create_model() successfully completed......................................
2024-02-05 00:15:07,335:INFO:SubProcess create_model() end ==================================
2024-02-05 00:15:07,335:INFO:Creating metrics dataframe
2024-02-05 00:15:07,347:INFO:Initializing Quadratic Discriminant Analysis
2024-02-05 00:15:07,347:INFO:Total runtime is 0.9550840934117635 minutes
2024-02-05 00:15:07,351:INFO:SubProcess create_model() called ==================================
2024-02-05 00:15:07,351:INFO:Initializing create_model()
2024-02-05 00:15:07,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:15:07,351:INFO:Checking exceptions
2024-02-05 00:15:07,351:INFO:Importing libraries
2024-02-05 00:15:07,351:INFO:Copying training dataset
2024-02-05 00:15:07,358:INFO:Defining folds
2024-02-05 00:15:07,358:INFO:Declaring metric variables
2024-02-05 00:15:07,362:INFO:Importing untrained model
2024-02-05 00:15:07,369:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-05 00:15:07,380:INFO:Starting cross validation
2024-02-05 00:15:07,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:15:07,950:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:15:07,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-02-05 00:15:07,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:07,951:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:07,951:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:15:07,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:08,642:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:15:08,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.
2024-02-05 00:15:08,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:08,643:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:08,643:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:15:08,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:09,330:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:15:09,331:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.
2024-02-05 00:15:09,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:09,331:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:09,331:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:15:09,331:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:10,023:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:15:10,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-02-05 00:15:10,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:10,024:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:10,024:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:15:10,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:10,741:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:15:10,741:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2024-02-05 00:15:10,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:10,742:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:10,742:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:15:10,742:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:11,448:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:15:11,449:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2024-02-05 00:15:11,449:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:11,449:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:11,449:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:15:11,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:12,355:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:12,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2024-02-05 00:15:12,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:12,356:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:12,356:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:12,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:13,259:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:15:13,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2024-02-05 00:15:13,259:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:13,260:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:13,260:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:15:13,260:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:14,135:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:15:14,136:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-02-05 00:15:14,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:14,136:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:14,136:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:15:14,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:15,026:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:15,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-02-05 00:15:15,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:15,027:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:15,028:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:15,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:15,247:INFO:Calculating mean and std
2024-02-05 00:15:15,248:INFO:Creating metrics dataframe
2024-02-05 00:15:15,254:INFO:Uploading results into container
2024-02-05 00:15:15,255:INFO:Uploading model into container now
2024-02-05 00:15:15,255:INFO:_master_model_container: 23
2024-02-05 00:15:15,255:INFO:_display_container: 3
2024-02-05 00:15:15,256:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-05 00:15:15,256:INFO:create_model() successfully completed......................................
2024-02-05 00:15:15,438:INFO:SubProcess create_model() end ==================================
2024-02-05 00:15:15,438:INFO:Creating metrics dataframe
2024-02-05 00:15:15,453:INFO:Initializing Ada Boost Classifier
2024-02-05 00:15:15,453:INFO:Total runtime is 1.090193514029185 minutes
2024-02-05 00:15:15,457:INFO:SubProcess create_model() called ==================================
2024-02-05 00:15:15,458:INFO:Initializing create_model()
2024-02-05 00:15:15,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:15:15,459:INFO:Checking exceptions
2024-02-05 00:15:15,459:INFO:Importing libraries
2024-02-05 00:15:15,459:INFO:Copying training dataset
2024-02-05 00:15:15,466:INFO:Defining folds
2024-02-05 00:15:15,466:INFO:Declaring metric variables
2024-02-05 00:15:15,470:INFO:Importing untrained model
2024-02-05 00:15:15,476:INFO:Ada Boost Classifier Imported successfully
2024-02-05 00:15:15,486:INFO:Starting cross validation
2024-02-05 00:15:15,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:15:16,187:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:15:16,188:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-02-05 00:15:16,188:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:16,188:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:16,188:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:15:16,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:17,260:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:15:17,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-02-05 00:15:17,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:17,261:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:17,261:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:15:17,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:18,152:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:15:18,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-02-05 00:15:18,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:18,153:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:18,153:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:15:18,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:19,026:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:15:19,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-02-05 00:15:19,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:19,027:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:19,027:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:15:19,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:19,903:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:15:19,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-02-05 00:15:19,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:19,904:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:19,904:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:15:19,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:20,807:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:15:20,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-02-05 00:15:20,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:20,807:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:20,808:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:15:20,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:21,686:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:21,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-02-05 00:15:21,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:21,687:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:21,687:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:21,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:22,700:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:15:22,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2024-02-05 00:15:22,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:22,700:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:22,701:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:15:22,701:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:23,840:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:15:23,841:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2024-02-05 00:15:23,841:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:23,841:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:23,841:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:15:23,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:24,970:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:24,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-02-05 00:15:24,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:24,970:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:24,971:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:24,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:25,490:INFO:Calculating mean and std
2024-02-05 00:15:25,491:INFO:Creating metrics dataframe
2024-02-05 00:15:25,495:INFO:Uploading results into container
2024-02-05 00:15:25,496:INFO:Uploading model into container now
2024-02-05 00:15:25,496:INFO:_master_model_container: 24
2024-02-05 00:15:25,497:INFO:_display_container: 3
2024-02-05 00:15:25,497:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=207)
2024-02-05 00:15:25,497:INFO:create_model() successfully completed......................................
2024-02-05 00:15:25,663:INFO:SubProcess create_model() end ==================================
2024-02-05 00:15:25,663:INFO:Creating metrics dataframe
2024-02-05 00:15:25,677:INFO:Initializing Gradient Boosting Classifier
2024-02-05 00:15:25,677:INFO:Total runtime is 1.2605827490488688 minutes
2024-02-05 00:15:25,683:INFO:SubProcess create_model() called ==================================
2024-02-05 00:15:25,683:INFO:Initializing create_model()
2024-02-05 00:15:25,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:15:25,684:INFO:Checking exceptions
2024-02-05 00:15:25,684:INFO:Importing libraries
2024-02-05 00:15:25,685:INFO:Copying training dataset
2024-02-05 00:15:25,692:INFO:Defining folds
2024-02-05 00:15:25,692:INFO:Declaring metric variables
2024-02-05 00:15:25,697:INFO:Importing untrained model
2024-02-05 00:15:25,703:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:15:25,714:INFO:Starting cross validation
2024-02-05 00:15:25,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:15:26,395:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:15:26,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-02-05 00:15:26,396:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:26,396:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:26,396:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:15:26,397:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:27,921:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:15:27,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-02-05 00:15:27,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:27,922:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:27,922:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:15:27,922:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:29,277:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:15:29,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-02-05 00:15:29,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:29,277:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:29,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:15:29,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:31,075:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:15:31,075:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-02-05 00:15:31,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:31,075:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:31,076:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:15:31,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:32,726:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:15:32,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2024-02-05 00:15:32,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:32,727:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:32,727:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:15:32,727:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:34,933:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:15:34,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
2024-02-05 00:15:34,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:34,934:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:34,935:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:15:34,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:37,858:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:37,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000944 seconds.
2024-02-05 00:15:37,860:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:37,861:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:37,861:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:37,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:39,826:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:15:39,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-02-05 00:15:39,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:39,827:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:39,827:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:15:39,827:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:41,750:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:15:41,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
2024-02-05 00:15:41,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:41,751:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:41,751:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:15:41,752:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:43,748:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:43,749:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2024-02-05 00:15:43,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:43,749:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:43,749:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:43,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:45,103:INFO:Calculating mean and std
2024-02-05 00:15:45,105:INFO:Creating metrics dataframe
2024-02-05 00:15:45,113:INFO:Uploading results into container
2024-02-05 00:15:45,115:INFO:Uploading model into container now
2024-02-05 00:15:45,116:INFO:_master_model_container: 25
2024-02-05 00:15:45,116:INFO:_display_container: 3
2024-02-05 00:15:45,118:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:15:45,119:INFO:create_model() successfully completed......................................
2024-02-05 00:15:45,387:INFO:SubProcess create_model() end ==================================
2024-02-05 00:15:45,387:INFO:Creating metrics dataframe
2024-02-05 00:15:45,414:INFO:Initializing Linear Discriminant Analysis
2024-02-05 00:15:45,414:INFO:Total runtime is 1.5895365476608276 minutes
2024-02-05 00:15:45,422:INFO:SubProcess create_model() called ==================================
2024-02-05 00:15:45,423:INFO:Initializing create_model()
2024-02-05 00:15:45,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:15:45,423:INFO:Checking exceptions
2024-02-05 00:15:45,423:INFO:Importing libraries
2024-02-05 00:15:45,423:INFO:Copying training dataset
2024-02-05 00:15:45,439:INFO:Defining folds
2024-02-05 00:15:45,439:INFO:Declaring metric variables
2024-02-05 00:15:45,447:INFO:Importing untrained model
2024-02-05 00:15:45,456:INFO:Linear Discriminant Analysis Imported successfully
2024-02-05 00:15:45,474:INFO:Starting cross validation
2024-02-05 00:15:45,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:15:46,328:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:15:46,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.
2024-02-05 00:15:46,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:46,329:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:46,329:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:15:46,329:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:47,514:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:15:47,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.
2024-02-05 00:15:47,516:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:47,517:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:47,517:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:15:47,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:48,294:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:15:48,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-02-05 00:15:48,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:48,295:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:48,295:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:15:48,296:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:49,138:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:15:49,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2024-02-05 00:15:49,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:49,140:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:49,140:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:15:49,141:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:49,919:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:15:49,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000710 seconds.
2024-02-05 00:15:49,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:49,920:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:49,920:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:15:49,921:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:50,865:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:15:50,866:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.
2024-02-05 00:15:50,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:50,867:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:50,867:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:15:50,868:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:51,906:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:51,907:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2024-02-05 00:15:51,907:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:51,907:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:51,908:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:51,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:52,987:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:15:52,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-02-05 00:15:52,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:52,988:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:52,988:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:15:52,989:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:54,016:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:15:54,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2024-02-05 00:15:54,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:54,017:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:54,018:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:15:54,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:55,125:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:15:55,127:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.
2024-02-05 00:15:55,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:55,127:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:55,128:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:15:55,128:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:55,354:INFO:Calculating mean and std
2024-02-05 00:15:55,355:INFO:Creating metrics dataframe
2024-02-05 00:15:55,361:INFO:Uploading results into container
2024-02-05 00:15:55,364:INFO:Uploading model into container now
2024-02-05 00:15:55,364:INFO:_master_model_container: 26
2024-02-05 00:15:55,365:INFO:_display_container: 3
2024-02-05 00:15:55,365:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-05 00:15:55,365:INFO:create_model() successfully completed......................................
2024-02-05 00:15:55,570:INFO:SubProcess create_model() end ==================================
2024-02-05 00:15:55,571:INFO:Creating metrics dataframe
2024-02-05 00:15:55,595:INFO:Initializing Extra Trees Classifier
2024-02-05 00:15:55,596:INFO:Total runtime is 1.7592333118120829 minutes
2024-02-05 00:15:55,601:INFO:SubProcess create_model() called ==================================
2024-02-05 00:15:55,602:INFO:Initializing create_model()
2024-02-05 00:15:55,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:15:55,602:INFO:Checking exceptions
2024-02-05 00:15:55,603:INFO:Importing libraries
2024-02-05 00:15:55,603:INFO:Copying training dataset
2024-02-05 00:15:55,616:INFO:Defining folds
2024-02-05 00:15:55,616:INFO:Declaring metric variables
2024-02-05 00:15:55,625:INFO:Importing untrained model
2024-02-05 00:15:55,636:INFO:Extra Trees Classifier Imported successfully
2024-02-05 00:15:55,659:INFO:Starting cross validation
2024-02-05 00:15:55,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:15:56,420:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:15:56,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.
2024-02-05 00:15:56,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:56,421:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:56,422:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:15:56,422:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:57,778:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:15:57,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-02-05 00:15:57,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:57,779:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:57,779:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:15:57,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:15:59,114:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:15:59,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-02-05 00:15:59,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:15:59,115:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:15:59,115:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:15:59,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:00,116:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:16:00,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-02-05 00:16:00,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:00,117:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:00,117:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:16:00,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:01,073:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:16:01,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-02-05 00:16:01,073:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:01,074:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:01,074:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:16:01,074:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:02,046:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:16:02,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-02-05 00:16:02,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:02,046:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:02,047:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:16:02,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:03,006:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:03,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-02-05 00:16:03,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:03,007:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:03,008:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:16:03,008:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:04,310:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:16:04,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-02-05 00:16:04,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:04,311:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:04,311:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:16:04,311:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:05,460:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:16:05,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-02-05 00:16:05,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:05,462:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:05,462:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:16:05,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:06,587:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:06,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000333 seconds.
2024-02-05 00:16:06,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:06,588:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:06,588:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:16:06,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:07,016:INFO:Calculating mean and std
2024-02-05 00:16:07,017:INFO:Creating metrics dataframe
2024-02-05 00:16:07,026:INFO:Uploading results into container
2024-02-05 00:16:07,027:INFO:Uploading model into container now
2024-02-05 00:16:07,028:INFO:_master_model_container: 27
2024-02-05 00:16:07,028:INFO:_display_container: 3
2024-02-05 00:16:07,030:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False)
2024-02-05 00:16:07,030:INFO:create_model() successfully completed......................................
2024-02-05 00:16:07,223:INFO:SubProcess create_model() end ==================================
2024-02-05 00:16:07,223:INFO:Creating metrics dataframe
2024-02-05 00:16:07,235:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 00:16:07,235:INFO:Total runtime is 1.9532144904136657 minutes
2024-02-05 00:16:07,240:INFO:SubProcess create_model() called ==================================
2024-02-05 00:16:07,241:INFO:Initializing create_model()
2024-02-05 00:16:07,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:16:07,242:INFO:Checking exceptions
2024-02-05 00:16:07,243:INFO:Importing libraries
2024-02-05 00:16:07,243:INFO:Copying training dataset
2024-02-05 00:16:07,255:INFO:Defining folds
2024-02-05 00:16:07,256:INFO:Declaring metric variables
2024-02-05 00:16:07,262:INFO:Importing untrained model
2024-02-05 00:16:07,270:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 00:16:07,279:INFO:Starting cross validation
2024-02-05 00:16:07,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:16:07,859:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:16:07,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2024-02-05 00:16:07,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:07,859:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:07,860:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:16:07,860:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:07,969:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:16:07,969:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:07,969:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:07,970:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 3
2024-02-05 00:16:07,970:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:07,970:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:07,977:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:07,978:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:07,981:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000132 secs. 0 sparse feature groups
2024-02-05 00:16:07,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:10,253:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:16:10,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.
2024-02-05 00:16:10,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:10,255:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:10,255:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:16:10,256:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:10,385:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:16:10,386:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:10,386:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:10,386:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 3
2024-02-05 00:16:10,386:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:10,386:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:10,392:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:10,394:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:10,396:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000118 secs. 0 sparse feature groups
2024-02-05 00:16:10,396:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:13,171:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:16:13,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.
2024-02-05 00:16:13,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:13,172:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:13,173:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:16:13,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:13,377:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:16:13,378:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:13,378:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:13,378:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 3
2024-02-05 00:16:13,378:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:13,378:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:13,386:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:13,388:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:13,392:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000291 secs. 0 sparse feature groups
2024-02-05 00:16:13,392:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:16,539:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:16:16,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.
2024-02-05 00:16:16,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:16,540:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:16,540:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:16:16,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 3
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:16,710:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:16,717:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:16,720:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:16,724:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000218 secs. 0 sparse feature groups
2024-02-05 00:16:16,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:18,848:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:16:18,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-02-05 00:16:18,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:18,849:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:18,849:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:16:18,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:18,959:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:16:18,959:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:18,960:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:18,960:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 3
2024-02-05 00:16:18,960:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:18,960:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:18,965:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:18,966:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:18,968:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000091 secs. 0 sparse feature groups
2024-02-05 00:16:18,969:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:21,096:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:16:21,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.
2024-02-05 00:16:21,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:21,098:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:21,099:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:16:21,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:21,224:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:16:21,225:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:21,225:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:21,225:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 3
2024-02-05 00:16:21,225:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:21,225:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:21,234:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:21,236:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:21,238:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000125 secs. 0 sparse feature groups
2024-02-05 00:16:21,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:24,007:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:24,009:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.
2024-02-05 00:16:24,009:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:24,009:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:24,010:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:16:24,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:24,204:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:24,204:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:24,205:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:24,205:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 3
2024-02-05 00:16:24,205:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:24,205:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:24,213:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:24,216:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:24,218:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000240 secs. 0 sparse feature groups
2024-02-05 00:16:24,219:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:27,234:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:16:27,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.
2024-02-05 00:16:27,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:27,236:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:27,236:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:16:27,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:27,390:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:16:27,390:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:27,390:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:27,390:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 3
2024-02-05 00:16:27,390:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:27,391:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:27,400:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:27,402:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:27,404:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000139 secs. 0 sparse feature groups
2024-02-05 00:16:27,404:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:29,495:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:16:29,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
2024-02-05 00:16:29,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:29,497:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:29,498:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:16:29,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:29,632:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:16:29,633:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:29,633:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:29,633:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 3
2024-02-05 00:16:29,633:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:29,633:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:29,639:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:29,641:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:29,643:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000133 secs. 0 sparse feature groups
2024-02-05 00:16:29,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:31,616:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:31,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-02-05 00:16:31,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:31,617:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:31,617:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:16:31,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 3
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:16:31,724:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:16:31,732:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:16:31,734:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:16:31,736:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000129 secs. 0 sparse feature groups
2024-02-05 00:16:31,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:16:33,151:INFO:Calculating mean and std
2024-02-05 00:16:33,156:INFO:Creating metrics dataframe
2024-02-05 00:16:33,164:INFO:Uploading results into container
2024-02-05 00:16:33,167:INFO:Uploading model into container now
2024-02-05 00:16:33,168:INFO:_master_model_container: 28
2024-02-05 00:16:33,168:INFO:_display_container: 3
2024-02-05 00:16:33,170:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 00:16:33,170:INFO:create_model() successfully completed......................................
2024-02-05 00:16:33,446:INFO:SubProcess create_model() end ==================================
2024-02-05 00:16:33,446:INFO:Creating metrics dataframe
2024-02-05 00:16:33,483:INFO:Initializing CatBoost Classifier
2024-02-05 00:16:33,483:INFO:Total runtime is 2.3906935612360636 minutes
2024-02-05 00:16:33,490:INFO:SubProcess create_model() called ==================================
2024-02-05 00:16:33,491:INFO:Initializing create_model()
2024-02-05 00:16:33,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:16:33,492:INFO:Checking exceptions
2024-02-05 00:16:33,492:INFO:Importing libraries
2024-02-05 00:16:33,492:INFO:Copying training dataset
2024-02-05 00:16:33,508:INFO:Defining folds
2024-02-05 00:16:33,508:INFO:Declaring metric variables
2024-02-05 00:16:33,515:INFO:Importing untrained model
2024-02-05 00:16:33,524:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:16:33,545:INFO:Starting cross validation
2024-02-05 00:16:33,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:16:34,817:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:16:34,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000578 seconds.
2024-02-05 00:16:34,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:16:34,818:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:16:34,819:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:16:34,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:17:14,229:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:17:14,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.
2024-02-05 00:17:14,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:17:14,230:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:17:14,231:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:17:14,232:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:17:52,378:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:17:52,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.
2024-02-05 00:17:52,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:17:52,379:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:17:52,380:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:17:52,380:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:18:33,885:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:18:33,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.
2024-02-05 00:18:33,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:18:33,887:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:18:33,888:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:18:33,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:19:08,514:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:19:08,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.
2024-02-05 00:19:08,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:19:08,515:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:19:08,516:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:19:08,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:19:39,431:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:19:39,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.
2024-02-05 00:19:39,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:19:39,432:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:19:39,433:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:19:39,433:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:20:12,871:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:20:12,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
2024-02-05 00:20:12,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:20:12,872:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:20:12,873:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:20:12,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:20:45,794:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:20:45,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000601 seconds.
2024-02-05 00:20:45,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:20:45,796:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:20:45,796:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:20:45,797:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:21:20,392:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:21:20,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000579 seconds.
2024-02-05 00:21:20,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:21:20,394:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:21:20,394:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:21:20,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:21:59,891:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:21:59,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
2024-02-05 00:21:59,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:21:59,892:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:21:59,893:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:21:59,893:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:36,487:INFO:Calculating mean and std
2024-02-05 00:22:36,490:INFO:Creating metrics dataframe
2024-02-05 00:22:36,501:INFO:Uploading results into container
2024-02-05 00:22:36,503:INFO:Uploading model into container now
2024-02-05 00:22:36,505:INFO:_master_model_container: 29
2024-02-05 00:22:36,505:INFO:_display_container: 3
2024-02-05 00:22:36,505:INFO:<catboost.core.CatBoostClassifier object at 0x0000015844B4DCF0>
2024-02-05 00:22:36,505:INFO:create_model() successfully completed......................................
2024-02-05 00:22:36,887:INFO:SubProcess create_model() end ==================================
2024-02-05 00:22:36,888:INFO:Creating metrics dataframe
2024-02-05 00:22:36,935:INFO:Initializing Dummy Classifier
2024-02-05 00:22:36,935:INFO:Total runtime is 8.448218142986297 minutes
2024-02-05 00:22:36,945:INFO:SubProcess create_model() called ==================================
2024-02-05 00:22:36,946:INFO:Initializing create_model()
2024-02-05 00:22:36,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015844B4CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:22:36,946:INFO:Checking exceptions
2024-02-05 00:22:36,947:INFO:Importing libraries
2024-02-05 00:22:36,948:INFO:Copying training dataset
2024-02-05 00:22:36,964:INFO:Defining folds
2024-02-05 00:22:36,965:INFO:Declaring metric variables
2024-02-05 00:22:36,975:INFO:Importing untrained model
2024-02-05 00:22:36,986:INFO:Dummy Classifier Imported successfully
2024-02-05 00:22:37,007:INFO:Starting cross validation
2024-02-05 00:22:37,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:22:38,377:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:22:38,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000635 seconds.
2024-02-05 00:22:38,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:38,378:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:38,379:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:22:38,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:40,079:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:22:40,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.
2024-02-05 00:22:40,080:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:40,080:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:40,081:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:22:40,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:41,779:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:22:41,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000776 seconds.
2024-02-05 00:22:41,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:41,781:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:41,781:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:22:41,782:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:43,429:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:22:43,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001056 seconds.
2024-02-05 00:22:43,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:43,431:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:43,432:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:22:43,432:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:44,946:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:22:44,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2024-02-05 00:22:44,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:44,947:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:44,948:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:22:44,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:46,150:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:22:46,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.
2024-02-05 00:22:46,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:46,152:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:46,152:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:22:46,152:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:47,340:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:22:47,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000566 seconds.
2024-02-05 00:22:47,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:47,341:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:47,341:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:22:47,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:48,503:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:22:48,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2024-02-05 00:22:48,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:48,504:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:48,504:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:22:48,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:49,777:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:22:49,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000626 seconds.
2024-02-05 00:22:49,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:49,778:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:49,778:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:22:49,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:51,431:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:22:51,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.
2024-02-05 00:22:51,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:51,432:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:51,433:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:22:51,433:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:51,878:INFO:Calculating mean and std
2024-02-05 00:22:51,881:INFO:Creating metrics dataframe
2024-02-05 00:22:51,891:INFO:Uploading results into container
2024-02-05 00:22:51,893:INFO:Uploading model into container now
2024-02-05 00:22:51,894:INFO:_master_model_container: 30
2024-02-05 00:22:51,894:INFO:_display_container: 3
2024-02-05 00:22:51,895:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:22:51,897:INFO:create_model() successfully completed......................................
2024-02-05 00:22:52,175:INFO:SubProcess create_model() end ==================================
2024-02-05 00:22:52,175:INFO:Creating metrics dataframe
2024-02-05 00:22:52,231:INFO:Initializing create_model()
2024-02-05 00:22:52,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=DummyClassifier(constant=None, random_state=207, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:22:52,232:INFO:Checking exceptions
2024-02-05 00:22:52,237:INFO:Importing libraries
2024-02-05 00:22:52,238:INFO:Copying training dataset
2024-02-05 00:22:52,257:INFO:Defining folds
2024-02-05 00:22:52,257:INFO:Declaring metric variables
2024-02-05 00:22:52,258:INFO:Importing untrained model
2024-02-05 00:22:52,258:INFO:Declaring custom model
2024-02-05 00:22:52,259:INFO:Dummy Classifier Imported successfully
2024-02-05 00:22:52,300:INFO:Cross validation set to False
2024-02-05 00:22:52,300:INFO:Fitting Model
2024-02-05 00:22:53,119:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:22:53,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.
2024-02-05 00:22:53,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:53,120:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:53,121:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:22:53,121:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:22:53,276:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:22:53,276:INFO:create_model() successfully completed......................................
2024-02-05 00:22:53,510:INFO:Initializing create_model()
2024-02-05 00:22:53,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=<catboost.core.CatBoostClassifier object at 0x0000015844B4DCF0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:22:53,510:INFO:Checking exceptions
2024-02-05 00:22:53,516:INFO:Importing libraries
2024-02-05 00:22:53,516:INFO:Copying training dataset
2024-02-05 00:22:53,527:INFO:Defining folds
2024-02-05 00:22:53,528:INFO:Declaring metric variables
2024-02-05 00:22:53,528:INFO:Importing untrained model
2024-02-05 00:22:53,528:INFO:Declaring custom model
2024-02-05 00:22:53,529:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:22:53,560:INFO:Cross validation set to False
2024-02-05 00:22:53,560:INFO:Fitting Model
2024-02-05 00:22:54,468:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:22:54,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
2024-02-05 00:22:54,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:22:54,469:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:22:54,470:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:22:54,470:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:23:27,195:INFO:<catboost.core.CatBoostClassifier object at 0x000001583746CFA0>
2024-02-05 00:23:27,196:INFO:create_model() successfully completed......................................
2024-02-05 00:23:27,375:INFO:Initializing create_model()
2024-02-05 00:23:27,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:23:27,376:INFO:Checking exceptions
2024-02-05 00:23:27,379:INFO:Importing libraries
2024-02-05 00:23:27,379:INFO:Copying training dataset
2024-02-05 00:23:27,389:INFO:Defining folds
2024-02-05 00:23:27,389:INFO:Declaring metric variables
2024-02-05 00:23:27,389:INFO:Importing untrained model
2024-02-05 00:23:27,389:INFO:Declaring custom model
2024-02-05 00:23:27,390:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:23:27,419:INFO:Cross validation set to False
2024-02-05 00:23:27,419:INFO:Fitting Model
2024-02-05 00:23:28,425:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:23:28,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
2024-02-05 00:23:28,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:23:28,426:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:23:28,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:23:28,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:23:30,347:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:23:30,347:INFO:create_model() successfully completed......................................
2024-02-05 00:23:30,566:INFO:Initializing create_model()
2024-02-05 00:23:30,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:23:30,566:INFO:Checking exceptions
2024-02-05 00:23:30,570:INFO:Importing libraries
2024-02-05 00:23:30,571:INFO:Copying training dataset
2024-02-05 00:23:30,582:INFO:Defining folds
2024-02-05 00:23:30,582:INFO:Declaring metric variables
2024-02-05 00:23:30,582:INFO:Importing untrained model
2024-02-05 00:23:30,582:INFO:Declaring custom model
2024-02-05 00:23:30,584:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 00:23:30,617:INFO:Cross validation set to False
2024-02-05 00:23:30,617:INFO:Fitting Model
2024-02-05 00:23:31,725:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:23:31,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.
2024-02-05 00:23:31,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:23:31,726:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:23:31,727:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:23:31,727:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:23:31,937:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:23:31,938:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 00:23:31,938:INFO:[LightGBM] [Info] Total Bins 765
2024-02-05 00:23:31,938:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 3
2024-02-05 00:23:31,938:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 00:23:31,939:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 00:23:31,948:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 00:23:31,952:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 00:23:31,957:INFO:[LightGBM] [Info] 3 dense feature groups (0.02 MB) transferred to GPU in 0.000309 secs. 0 sparse feature groups
2024-02-05 00:23:31,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:23:34,694:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 00:23:34,695:INFO:create_model() successfully completed......................................
2024-02-05 00:23:35,028:INFO:Initializing create_model()
2024-02-05 00:23:35,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:23:35,029:INFO:Checking exceptions
2024-02-05 00:23:35,037:INFO:Importing libraries
2024-02-05 00:23:35,038:INFO:Copying training dataset
2024-02-05 00:23:35,055:INFO:Defining folds
2024-02-05 00:23:35,055:INFO:Declaring metric variables
2024-02-05 00:23:35,056:INFO:Importing untrained model
2024-02-05 00:23:35,056:INFO:Declaring custom model
2024-02-05 00:23:35,058:INFO:Extra Trees Classifier Imported successfully
2024-02-05 00:23:35,101:INFO:Cross validation set to False
2024-02-05 00:23:35,102:INFO:Fitting Model
2024-02-05 00:23:36,368:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:23:36,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.
2024-02-05 00:23:36,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:23:36,369:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:23:36,370:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:23:36,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:23:37,019:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False)
2024-02-05 00:23:37,019:INFO:create_model() successfully completed......................................
2024-02-05 00:23:37,316:INFO:_master_model_container: 30
2024-02-05 00:23:37,316:INFO:_display_container: 3
2024-02-05 00:23:37,320:INFO:[DummyClassifier(constant=None, random_state=207, strategy='prior'), <catboost.core.CatBoostClassifier object at 0x000001583746CFA0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=207, verbose=0, warm_start=False)]
2024-02-05 00:23:37,320:INFO:compare_models() successfully completed......................................
2024-02-05 00:23:37,384:INFO:Initializing tune_model()
2024-02-05 00:23:37,385:INFO:tune_model(estimator=DummyClassifier(constant=None, random_state=207, strategy='prior'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>)
2024-02-05 00:23:37,385:INFO:Checking exceptions
2024-02-05 00:23:37,426:INFO:Copying training dataset
2024-02-05 00:23:37,444:INFO:Checking base model
2024-02-05 00:23:37,445:INFO:Base model : Dummy Classifier
2024-02-05 00:23:37,453:INFO:Declaring metric variables
2024-02-05 00:23:37,461:INFO:Defining Hyperparameters
2024-02-05 00:23:37,462:INFO:10 is bigger than total combinations 4, setting search algorithm to grid
2024-02-05 00:23:37,781:INFO:Tuning with n_jobs=-1
2024-02-05 00:23:37,782:INFO:Initializing GridSearchCV
2024-02-05 00:23:50,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:50,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:51,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:54,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:55,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:55,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:55,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:56,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:57,231:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:57,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:58,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:59,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:59,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:23:59,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:00,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:00,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:01,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:01,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:02,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:03,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:03,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:03,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:04,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:04,713:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:05,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:05,873:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:06,449:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:06,819:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:07,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:07,499:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:08,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:09,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:09,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:10,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:10,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:24:11,350:INFO:best_params: {'actual_estimator__strategy': 'most_frequent'}
2024-02-05 00:24:11,351:INFO:Hyperparameter search completed
2024-02-05 00:24:11,352:INFO:SubProcess create_model() called ==================================
2024-02-05 00:24:11,353:INFO:Initializing create_model()
2024-02-05 00:24:11,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=DummyClassifier(constant=None, random_state=207, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015834E2BAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'strategy': 'most_frequent'})
2024-02-05 00:24:11,353:INFO:Checking exceptions
2024-02-05 00:24:11,354:INFO:Importing libraries
2024-02-05 00:24:11,354:INFO:Copying training dataset
2024-02-05 00:24:11,371:INFO:Defining folds
2024-02-05 00:24:11,371:INFO:Declaring metric variables
2024-02-05 00:24:11,376:INFO:Importing untrained model
2024-02-05 00:24:11,376:INFO:Declaring custom model
2024-02-05 00:24:11,383:INFO:Dummy Classifier Imported successfully
2024-02-05 00:24:11,399:INFO:Starting cross validation
2024-02-05 00:24:11,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:24:12,439:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:24:12,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000588 seconds.
2024-02-05 00:24:12,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:12,440:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:12,441:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:24:12,441:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:13,702:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:24:13,702:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-02-05 00:24:13,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:13,703:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:13,703:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:24:13,703:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:14,607:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:24:14,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2024-02-05 00:24:14,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:14,608:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:14,608:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:24:14,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:15,446:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:24:15,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-02-05 00:24:15,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:15,447:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:15,447:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:24:15,447:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:16,236:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:24:16,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2024-02-05 00:24:16,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:16,237:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:16,237:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:24:16,237:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:17,033:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:24:17,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2024-02-05 00:24:17,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:17,034:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:17,034:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:24:17,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:17,819:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:24:17,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-02-05 00:24:17,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:17,819:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:17,820:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:24:17,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:18,574:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:24:18,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-02-05 00:24:18,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:18,575:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:18,575:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:24:18,576:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:19,518:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:24:19,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.
2024-02-05 00:24:19,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:19,520:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:19,520:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:24:19,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:20,533:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:24:20,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2024-02-05 00:24:20,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:20,534:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:20,534:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:24:20,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:20,785:INFO:Calculating mean and std
2024-02-05 00:24:20,787:INFO:Creating metrics dataframe
2024-02-05 00:24:20,794:INFO:Finalizing model
2024-02-05 00:24:21,562:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:24:21,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
2024-02-05 00:24:21,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:21,563:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:21,563:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:24:21,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:21,720:INFO:Uploading results into container
2024-02-05 00:24:21,723:INFO:Uploading model into container now
2024-02-05 00:24:21,724:INFO:_master_model_container: 31
2024-02-05 00:24:21,725:INFO:_display_container: 3
2024-02-05 00:24:21,725:INFO:DummyClassifier(constant=None, random_state=207, strategy='most_frequent')
2024-02-05 00:24:21,726:INFO:create_model() successfully completed......................................
2024-02-05 00:24:21,930:INFO:SubProcess create_model() end ==================================
2024-02-05 00:24:21,930:INFO:choose_better activated
2024-02-05 00:24:21,935:INFO:SubProcess create_model() called ==================================
2024-02-05 00:24:21,935:INFO:Initializing create_model()
2024-02-05 00:24:21,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=DummyClassifier(constant=None, random_state=207, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:24:21,936:INFO:Checking exceptions
2024-02-05 00:24:21,938:INFO:Importing libraries
2024-02-05 00:24:21,938:INFO:Copying training dataset
2024-02-05 00:24:21,945:INFO:Defining folds
2024-02-05 00:24:21,946:INFO:Declaring metric variables
2024-02-05 00:24:21,946:INFO:Importing untrained model
2024-02-05 00:24:21,946:INFO:Declaring custom model
2024-02-05 00:24:21,946:INFO:Dummy Classifier Imported successfully
2024-02-05 00:24:21,947:INFO:Starting cross validation
2024-02-05 00:24:21,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:24:22,735:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:24:22,736:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
2024-02-05 00:24:22,736:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:22,737:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:22,737:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:24:22,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:23,722:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:24:23,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2024-02-05 00:24:23,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:23,723:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:23,723:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:24:23,723:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:24,670:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:24:24,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2024-02-05 00:24:24,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:24,671:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:24,671:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:24:24,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:25,455:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:24:25,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-02-05 00:24:25,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:25,456:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:25,456:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:24:25,456:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:26,191:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:24:26,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-02-05 00:24:26,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:26,192:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:26,192:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:24:26,193:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:26,926:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:24:26,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2024-02-05 00:24:26,927:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:26,927:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:26,927:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:24:26,928:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:27,665:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:24:27,665:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-02-05 00:24:27,665:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:27,666:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:27,666:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:24:27,666:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:28,381:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:24:28,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-02-05 00:24:28,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:28,381:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:28,381:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:24:28,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:29,093:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:24:29,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2024-02-05 00:24:29,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:29,094:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:29,094:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:24:29,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:29,852:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:24:29,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2024-02-05 00:24:29,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:29,853:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:29,854:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:24:29,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:30,094:INFO:Calculating mean and std
2024-02-05 00:24:30,094:INFO:Creating metrics dataframe
2024-02-05 00:24:30,097:INFO:Finalizing model
2024-02-05 00:24:30,829:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:24:30,829:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2024-02-05 00:24:30,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:24:30,830:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:24:30,830:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:24:30,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:24:30,980:INFO:Uploading results into container
2024-02-05 00:24:30,981:INFO:Uploading model into container now
2024-02-05 00:24:30,982:INFO:_master_model_container: 32
2024-02-05 00:24:30,982:INFO:_display_container: 4
2024-02-05 00:24:30,982:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:24:30,982:INFO:create_model() successfully completed......................................
2024-02-05 00:24:31,183:INFO:SubProcess create_model() end ==================================
2024-02-05 00:24:31,184:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior') result for Accuracy is 0.8592
2024-02-05 00:24:31,184:INFO:DummyClassifier(constant=None, random_state=207, strategy='most_frequent') result for Accuracy is 0.8592
2024-02-05 00:24:31,184:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior') is best model
2024-02-05 00:24:31,184:INFO:choose_better completed
2024-02-05 00:24:31,184:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-05 00:24:31,203:INFO:_master_model_container: 32
2024-02-05 00:24:31,204:INFO:_display_container: 3
2024-02-05 00:24:31,204:INFO:DummyClassifier(constant=None, random_state=207, strategy='prior')
2024-02-05 00:24:31,204:INFO:tune_model() successfully completed......................................
2024-02-05 00:24:31,418:INFO:Initializing tune_model()
2024-02-05 00:24:31,418:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001583746CFA0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>)
2024-02-05 00:24:31,418:INFO:Checking exceptions
2024-02-05 00:24:31,443:INFO:Copying training dataset
2024-02-05 00:24:31,450:INFO:Checking base model
2024-02-05 00:24:31,450:INFO:Base model : CatBoost Classifier
2024-02-05 00:24:31,455:INFO:Declaring metric variables
2024-02-05 00:24:31,463:INFO:Defining Hyperparameters
2024-02-05 00:24:31,702:INFO:Tuning with n_jobs=1
2024-02-05 00:24:31,702:INFO:Initializing RandomizedSearchCV
2024-02-05 00:28:06,359:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 130, 'actual_estimator__l2_leaf_reg': 5, 'actual_estimator__eta': 0.15, 'actual_estimator__depth': 3}
2024-02-05 00:28:06,360:INFO:Hyperparameter search completed
2024-02-05 00:28:06,361:INFO:SubProcess create_model() called ==================================
2024-02-05 00:28:06,361:INFO:Initializing create_model()
2024-02-05 00:28:06,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=<catboost.core.CatBoostClassifier object at 0x0000015834E2BAF0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000015837D13D60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.8, 'n_estimators': 130, 'l2_leaf_reg': 5, 'eta': 0.15, 'depth': 3})
2024-02-05 00:28:06,361:INFO:Checking exceptions
2024-02-05 00:28:06,362:INFO:Importing libraries
2024-02-05 00:28:06,362:INFO:Copying training dataset
2024-02-05 00:28:06,377:INFO:Defining folds
2024-02-05 00:28:06,377:INFO:Declaring metric variables
2024-02-05 00:28:06,383:INFO:Importing untrained model
2024-02-05 00:28:06,383:INFO:Declaring custom model
2024-02-05 00:28:06,390:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:28:06,404:INFO:Starting cross validation
2024-02-05 00:28:06,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:28:07,435:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:28:07,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
2024-02-05 00:28:07,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:07,436:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:07,437:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:28:07,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:09,341:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:28:09,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000685 seconds.
2024-02-05 00:28:09,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:09,343:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:09,343:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:28:09,344:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:11,288:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:28:11,289:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000627 seconds.
2024-02-05 00:28:11,289:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:11,289:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:11,290:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:28:11,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:13,112:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:28:13,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
2024-02-05 00:28:13,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:13,113:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:13,113:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:28:13,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:14,673:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:28:14,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2024-02-05 00:28:14,674:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:14,674:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:14,675:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:28:14,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:16,153:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:28:16,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
2024-02-05 00:28:16,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:16,154:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:16,154:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:28:16,155:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:17,648:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:28:17,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
2024-02-05 00:28:17,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:17,649:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:17,650:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:28:17,650:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:19,496:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:28:19,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000690 seconds.
2024-02-05 00:28:19,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:19,497:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:19,498:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:28:19,498:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:21,424:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:28:21,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000643 seconds.
2024-02-05 00:28:21,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:21,426:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:21,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:28:21,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:23,349:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:28:23,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
2024-02-05 00:28:23,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:23,350:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:23,350:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:28:23,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:24,363:INFO:Calculating mean and std
2024-02-05 00:28:24,365:INFO:Creating metrics dataframe
2024-02-05 00:28:24,372:INFO:Finalizing model
2024-02-05 00:28:25,361:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:28:25,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000679 seconds.
2024-02-05 00:28:25,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:25,363:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:25,363:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:28:25,363:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:26,254:INFO:Uploading results into container
2024-02-05 00:28:26,256:INFO:Uploading model into container now
2024-02-05 00:28:26,257:INFO:_master_model_container: 33
2024-02-05 00:28:26,257:INFO:_display_container: 4
2024-02-05 00:28:26,258:INFO:<catboost.core.CatBoostClassifier object at 0x000001583739E560>
2024-02-05 00:28:26,259:INFO:create_model() successfully completed......................................
2024-02-05 00:28:26,471:INFO:SubProcess create_model() end ==================================
2024-02-05 00:28:26,471:INFO:choose_better activated
2024-02-05 00:28:26,476:INFO:SubProcess create_model() called ==================================
2024-02-05 00:28:26,476:INFO:Initializing create_model()
2024-02-05 00:28:26,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=<catboost.core.CatBoostClassifier object at 0x000001583746CFA0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:28:26,477:INFO:Checking exceptions
2024-02-05 00:28:26,479:INFO:Importing libraries
2024-02-05 00:28:26,479:INFO:Copying training dataset
2024-02-05 00:28:26,487:INFO:Defining folds
2024-02-05 00:28:26,487:INFO:Declaring metric variables
2024-02-05 00:28:26,487:INFO:Importing untrained model
2024-02-05 00:28:26,487:INFO:Declaring custom model
2024-02-05 00:28:26,488:INFO:CatBoost Classifier Imported successfully
2024-02-05 00:28:26,488:INFO:Starting cross validation
2024-02-05 00:28:26,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:28:27,325:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:28:27,326:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.
2024-02-05 00:28:27,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:27,326:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:27,327:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:28:27,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:28:59,102:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:28:59,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
2024-02-05 00:28:59,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:28:59,103:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:28:59,104:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:28:59,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:29:29,275:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:29:29,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.
2024-02-05 00:29:29,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:29:29,276:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:29:29,276:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:29:29,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:30:03,028:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:30:03,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
2024-02-05 00:30:03,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:30:03,029:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:30:03,029:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:30:03,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:30:37,816:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:30:37,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000656 seconds.
2024-02-05 00:30:37,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:30:37,818:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:30:37,818:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:30:37,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:31:09,693:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:31:09,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2024-02-05 00:31:09,694:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:31:09,694:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:31:09,695:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:31:09,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:31:46,358:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:31:46,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.
2024-02-05 00:31:46,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:31:46,360:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:31:46,360:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:31:46,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:32:21,573:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:32:21,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.
2024-02-05 00:32:21,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:32:21,575:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:32:21,575:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:32:21,576:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:32:59,956:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:32:59,957:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2024-02-05 00:32:59,957:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:32:59,958:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:32:59,958:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:32:59,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:33:42,849:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:33:42,850:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000773 seconds.
2024-02-05 00:33:42,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:33:42,851:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:33:42,851:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:33:42,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:34:25,996:INFO:Calculating mean and std
2024-02-05 00:34:25,997:INFO:Creating metrics dataframe
2024-02-05 00:34:26,000:INFO:Finalizing model
2024-02-05 00:34:27,210:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:34:27,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000884 seconds.
2024-02-05 00:34:27,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:34:27,212:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:34:27,212:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:34:27,213:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:35:15,685:INFO:Uploading results into container
2024-02-05 00:35:15,687:INFO:Uploading model into container now
2024-02-05 00:35:15,689:INFO:_master_model_container: 34
2024-02-05 00:35:15,689:INFO:_display_container: 5
2024-02-05 00:35:15,690:INFO:<catboost.core.CatBoostClassifier object at 0x00000158373E42E0>
2024-02-05 00:35:15,690:INFO:create_model() successfully completed......................................
2024-02-05 00:35:16,188:INFO:SubProcess create_model() end ==================================
2024-02-05 00:35:16,189:INFO:<catboost.core.CatBoostClassifier object at 0x00000158373E42E0> result for Accuracy is 0.802
2024-02-05 00:35:16,190:INFO:<catboost.core.CatBoostClassifier object at 0x000001583739E560> result for Accuracy is 0.7986
2024-02-05 00:35:16,190:INFO:<catboost.core.CatBoostClassifier object at 0x00000158373E42E0> is best model
2024-02-05 00:35:16,190:INFO:choose_better completed
2024-02-05 00:35:16,191:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-05 00:35:16,243:INFO:_master_model_container: 34
2024-02-05 00:35:16,244:INFO:_display_container: 4
2024-02-05 00:35:16,245:INFO:<catboost.core.CatBoostClassifier object at 0x00000158373E42E0>
2024-02-05 00:35:16,246:INFO:tune_model() successfully completed......................................
2024-02-05 00:35:16,761:INFO:Initializing tune_model()
2024-02-05 00:35:16,761:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>)
2024-02-05 00:35:16,762:INFO:Checking exceptions
2024-02-05 00:35:16,820:INFO:Copying training dataset
2024-02-05 00:35:16,836:INFO:Checking base model
2024-02-05 00:35:16,837:INFO:Base model : Gradient Boosting Classifier
2024-02-05 00:35:16,850:INFO:Declaring metric variables
2024-02-05 00:35:16,861:INFO:Defining Hyperparameters
2024-02-05 00:35:17,216:INFO:Tuning with n_jobs=-1
2024-02-05 00:35:17,216:INFO:Initializing RandomizedSearchCV
2024-02-05 00:35:39,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:39,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:45,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:46,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:46,358:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:46,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:46,523:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:46,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:49,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:50,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:53,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:53,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:54,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:54,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:54,355:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:54,630:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:57,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:57,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:58,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:58,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:58,501:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:35:59,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:01,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:03,820:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:04,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:04,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:05,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:06,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:08,361:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:08,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:08,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:10,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:11,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:11,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:12,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:13,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:13,873:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:14,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:14,264:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:15,223:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:16,085:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:16,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:18,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:18,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:18,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:19,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:19,503:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:21,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:21,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:21,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:23,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:24,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:24,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:25,846:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:26,777:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:27,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:27,502:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:27,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:30,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:30,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:30,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:31,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:32,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:33,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:34,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:35,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:36,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:36,759:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:36,766:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:38,855:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:39,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:40,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:40,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:42,070:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:43,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:43,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:43,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:45,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:46,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:46,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:47,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:48,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:53,709:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:53,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:53,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:55,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:36:56,356:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:01,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:01,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:03,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:05,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:05,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:07,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:10,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-05 00:37:15,848:INFO:best_params: {'actual_estimator__subsample': 0.5, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 1e-06}
2024-02-05 00:37:15,850:INFO:Hyperparameter search completed
2024-02-05 00:37:15,850:INFO:SubProcess create_model() called ==================================
2024-02-05 00:37:15,851:INFO:Initializing create_model()
2024-02-05 00:37:15,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000158391FF850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.5, 'n_estimators': 170, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0005, 'max_features': 'sqrt', 'max_depth': 8, 'learning_rate': 1e-06})
2024-02-05 00:37:15,851:INFO:Checking exceptions
2024-02-05 00:37:15,852:INFO:Importing libraries
2024-02-05 00:37:15,852:INFO:Copying training dataset
2024-02-05 00:37:15,867:INFO:Defining folds
2024-02-05 00:37:15,867:INFO:Declaring metric variables
2024-02-05 00:37:15,874:INFO:Importing untrained model
2024-02-05 00:37:15,874:INFO:Declaring custom model
2024-02-05 00:37:15,884:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:37:15,898:INFO:Starting cross validation
2024-02-05 00:37:15,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:37:16,928:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:37:16,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2024-02-05 00:37:16,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:16,929:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:16,929:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:37:16,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:18,945:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:37:18,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2024-02-05 00:37:18,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:18,946:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:18,946:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:37:18,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:20,918:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:37:20,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2024-02-05 00:37:20,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:20,919:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:20,919:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:37:20,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:23,245:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:37:23,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
2024-02-05 00:37:23,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:23,246:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:23,247:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:37:23,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:26,566:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:37:26,567:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
2024-02-05 00:37:26,567:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:26,567:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:26,567:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:37:26,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:28,590:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:37:28,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2024-02-05 00:37:28,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:28,591:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:28,591:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:37:28,592:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:30,421:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:37:30,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2024-02-05 00:37:30,422:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:30,422:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:30,422:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:37:30,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:32,512:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:37:32,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000806 seconds.
2024-02-05 00:37:32,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:32,514:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:32,514:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:37:32,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:35,778:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:37:35,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.
2024-02-05 00:37:35,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:35,780:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:35,780:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:37:35,780:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:37,986:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:37:37,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2024-02-05 00:37:37,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:37,987:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:37,988:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:37:37,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:39,266:INFO:Calculating mean and std
2024-02-05 00:37:39,267:INFO:Creating metrics dataframe
2024-02-05 00:37:39,276:INFO:Finalizing model
2024-02-05 00:37:39,875:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:37:39,876:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-02-05 00:37:39,876:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:39,876:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:39,876:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:37:39,876:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:41,305:INFO:Uploading results into container
2024-02-05 00:37:41,307:INFO:Uploading model into container now
2024-02-05 00:37:41,308:INFO:_master_model_container: 35
2024-02-05 00:37:41,308:INFO:_display_container: 5
2024-02-05 00:37:41,309:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=1e-06, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=170, n_iter_no_change=None,
                           random_state=207, subsample=0.5, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:37:41,309:INFO:create_model() successfully completed......................................
2024-02-05 00:37:41,497:INFO:SubProcess create_model() end ==================================
2024-02-05 00:37:41,497:INFO:choose_better activated
2024-02-05 00:37:41,500:INFO:SubProcess create_model() called ==================================
2024-02-05 00:37:41,501:INFO:Initializing create_model()
2024-02-05 00:37:41,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 00:37:41,501:INFO:Checking exceptions
2024-02-05 00:37:41,502:INFO:Importing libraries
2024-02-05 00:37:41,502:INFO:Copying training dataset
2024-02-05 00:37:41,508:INFO:Defining folds
2024-02-05 00:37:41,508:INFO:Declaring metric variables
2024-02-05 00:37:41,508:INFO:Importing untrained model
2024-02-05 00:37:41,508:INFO:Declaring custom model
2024-02-05 00:37:41,509:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 00:37:41,509:INFO:Starting cross validation
2024-02-05 00:37:41,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 00:37:42,357:INFO:[LightGBM] [Info] Number of positive: 2222, number of negative: 2222
2024-02-05 00:37:42,357:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000541 seconds.
2024-02-05 00:37:42,357:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:42,357:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:42,358:INFO:[LightGBM] [Info] Number of data points in the train set: 4444, number of used features: 16
2024-02-05 00:37:42,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:44,944:INFO:[LightGBM] [Info] Number of positive: 2226, number of negative: 2226
2024-02-05 00:37:44,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.
2024-02-05 00:37:44,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:44,945:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:44,945:INFO:[LightGBM] [Info] Number of data points in the train set: 4452, number of used features: 16
2024-02-05 00:37:44,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:46,952:INFO:[LightGBM] [Info] Number of positive: 2221, number of negative: 2221
2024-02-05 00:37:46,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2024-02-05 00:37:46,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:46,952:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:46,953:INFO:[LightGBM] [Info] Number of data points in the train set: 4442, number of used features: 16
2024-02-05 00:37:46,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:48,466:INFO:[LightGBM] [Info] Number of positive: 2219, number of negative: 2219
2024-02-05 00:37:48,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2024-02-05 00:37:48,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:48,467:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:48,467:INFO:[LightGBM] [Info] Number of data points in the train set: 4438, number of used features: 16
2024-02-05 00:37:48,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:49,948:INFO:[LightGBM] [Info] Number of positive: 2216, number of negative: 2216
2024-02-05 00:37:49,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2024-02-05 00:37:49,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:49,949:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:49,949:INFO:[LightGBM] [Info] Number of data points in the train set: 4432, number of used features: 16
2024-02-05 00:37:49,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:51,627:INFO:[LightGBM] [Info] Number of positive: 2223, number of negative: 2223
2024-02-05 00:37:51,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-02-05 00:37:51,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:51,627:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:51,628:INFO:[LightGBM] [Info] Number of data points in the train set: 4446, number of used features: 16
2024-02-05 00:37:51,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:54,196:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:37:54,197:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000762 seconds.
2024-02-05 00:37:54,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:54,198:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:54,198:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:37:54,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:56,373:INFO:[LightGBM] [Info] Number of positive: 2213, number of negative: 2213
2024-02-05 00:37:56,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-02-05 00:37:56,374:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:56,374:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:56,374:INFO:[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 16
2024-02-05 00:37:56,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:57,925:INFO:[LightGBM] [Info] Number of positive: 2227, number of negative: 2227
2024-02-05 00:37:57,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-02-05 00:37:57,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:57,926:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:57,926:INFO:[LightGBM] [Info] Number of data points in the train set: 4454, number of used features: 16
2024-02-05 00:37:57,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:37:59,424:INFO:[LightGBM] [Info] Number of positive: 2220, number of negative: 2220
2024-02-05 00:37:59,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000657 seconds.
2024-02-05 00:37:59,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:37:59,426:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:37:59,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4440, number of used features: 16
2024-02-05 00:37:59,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:38:00,439:INFO:Calculating mean and std
2024-02-05 00:38:00,439:INFO:Creating metrics dataframe
2024-02-05 00:38:00,442:INFO:Finalizing model
2024-02-05 00:38:01,074:INFO:[LightGBM] [Info] Number of positive: 2469, number of negative: 2469
2024-02-05 00:38:01,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-02-05 00:38:01,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 00:38:01,074:INFO:[LightGBM] [Info] Total Bins 4080
2024-02-05 00:38:01,075:INFO:[LightGBM] [Info] Number of data points in the train set: 4938, number of used features: 16
2024-02-05 00:38:01,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 00:38:02,383:INFO:Uploading results into container
2024-02-05 00:38:02,384:INFO:Uploading model into container now
2024-02-05 00:38:02,384:INFO:_master_model_container: 36
2024-02-05 00:38:02,384:INFO:_display_container: 6
2024-02-05 00:38:02,386:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:38:02,386:INFO:create_model() successfully completed......................................
2024-02-05 00:38:02,579:INFO:SubProcess create_model() end ==================================
2024-02-05 00:38:02,580:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=207, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8007
2024-02-05 00:38:02,582:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=1e-06, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=170, n_iter_no_change=None,
                           random_state=207, subsample=0.5, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8081
2024-02-05 00:38:02,582:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=1e-06, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=170, n_iter_no_change=None,
                           random_state=207, subsample=0.5, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-05 00:38:02,582:INFO:choose_better completed
2024-02-05 00:38:02,598:INFO:_master_model_container: 36
2024-02-05 00:38:02,600:INFO:_display_container: 5
2024-02-05 00:38:02,601:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=1e-06, loss='log_loss', max_depth=8,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0005, min_samples_leaf=2,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=170, n_iter_no_change=None,
                           random_state=207, subsample=0.5, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 00:38:02,601:INFO:tune_model() successfully completed......................................
2024-02-05 00:38:02,802:INFO:Initializing tune_model()
2024-02-05 00:38:02,802:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=207, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000158447CDC90>)
2024-02-05 00:38:02,802:INFO:Checking exceptions
2024-02-05 00:38:02,824:INFO:Copying training dataset
2024-02-05 00:38:02,832:INFO:Checking base model
2024-02-05 00:38:02,833:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 00:38:02,841:INFO:Declaring metric variables
2024-02-05 00:38:02,848:INFO:Defining Hyperparameters
2024-02-05 00:38:03,102:INFO:Tuning with n_jobs=1
2024-02-05 00:38:03,102:INFO:Initializing RandomizedSearchCV
2024-02-05 00:45:23,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:45:23,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:45:23,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 00:45:23,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:13:36,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:13:36,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:13:36,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:13:36,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:07,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:07,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:07,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:07,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:43,948:INFO:PyCaret ClassificationExperiment
2024-02-05 01:33:43,948:INFO:Logging name: clf-default-name
2024-02-05 01:33:43,949:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:33:43,949:INFO:version 3.2.0
2024-02-05 01:33:43,949:INFO:Initializing setup()
2024-02-05 01:33:43,949:INFO:self.USI: 1360
2024-02-05 01:33:43,949:INFO:self._variable_keys: {'n_jobs_param', 'memory', '_available_plots', 'logging_param', 'y_test', 'X_train', 'exp_name_log', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'seed', 'idx', 'gpu_n_jobs_param', 'html_param', 'X', 'exp_id', 'target_param', 'fix_imbalance', '_ml_usecase', 'fold_groups_param', 'pipeline', 'USI', 'y_train', 'is_multiclass', 'y', 'gpu_param', 'data'}
2024-02-05 01:33:43,949:INFO:Checking environment
2024-02-05 01:33:43,949:INFO:python_version: 3.10.9
2024-02-05 01:33:43,949:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:33:43,949:INFO:machine: AMD64
2024-02-05 01:33:43,949:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:33:43,949:INFO:Memory: svmem(total=16856182784, available=9638682624, percent=42.8, used=7217500160, free=9638682624)
2024-02-05 01:33:43,949:INFO:Physical Core: 4
2024-02-05 01:33:43,950:INFO:Logical Core: 8
2024-02-05 01:33:43,950:INFO:Checking libraries
2024-02-05 01:33:43,950:INFO:System:
2024-02-05 01:33:43,950:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:33:43,950:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:33:43,950:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:33:43,950:INFO:PyCaret required dependencies:
2024-02-05 01:33:44,061:INFO:                 pip: 22.3.1
2024-02-05 01:33:44,062:INFO:          setuptools: 65.6.3
2024-02-05 01:33:44,062:INFO:             pycaret: 3.2.0
2024-02-05 01:33:44,062:INFO:             IPython: 8.20.0
2024-02-05 01:33:44,062:INFO:          ipywidgets: 8.0.4
2024-02-05 01:33:44,062:INFO:                tqdm: 4.64.1
2024-02-05 01:33:44,062:INFO:               numpy: 1.25.2
2024-02-05 01:33:44,062:INFO:              pandas: 1.5.3
2024-02-05 01:33:44,062:INFO:              jinja2: 3.1.3
2024-02-05 01:33:44,062:INFO:               scipy: 1.10.1
2024-02-05 01:33:44,062:INFO:              joblib: 1.3.2
2024-02-05 01:33:44,062:INFO:             sklearn: 1.2.2
2024-02-05 01:33:44,062:INFO:                pyod: 1.1.2
2024-02-05 01:33:44,062:INFO:            imblearn: 0.12.0
2024-02-05 01:33:44,062:INFO:   category_encoders: 2.6.3
2024-02-05 01:33:44,062:INFO:            lightgbm: 4.3.0
2024-02-05 01:33:44,062:INFO:               numba: 0.59.0
2024-02-05 01:33:44,062:INFO:            requests: 2.31.0
2024-02-05 01:33:44,062:INFO:          matplotlib: 3.6.0
2024-02-05 01:33:44,062:INFO:          scikitplot: 0.3.7
2024-02-05 01:33:44,063:INFO:         yellowbrick: 1.5
2024-02-05 01:33:44,063:INFO:              plotly: 5.18.0
2024-02-05 01:33:44,063:INFO:    plotly-resampler: Not installed
2024-02-05 01:33:44,063:INFO:             kaleido: 0.2.1
2024-02-05 01:33:44,063:INFO:           schemdraw: 0.15
2024-02-05 01:33:44,063:INFO:         statsmodels: 0.14.1
2024-02-05 01:33:44,063:INFO:              sktime: 0.21.1
2024-02-05 01:33:44,063:INFO:               tbats: 1.1.3
2024-02-05 01:33:44,063:INFO:            pmdarima: 2.0.4
2024-02-05 01:33:44,063:INFO:              psutil: 5.9.0
2024-02-05 01:33:44,063:INFO:          markupsafe: 2.1.3
2024-02-05 01:33:44,063:INFO:             pickle5: Not installed
2024-02-05 01:33:44,063:INFO:         cloudpickle: 3.0.0
2024-02-05 01:33:44,063:INFO:         deprecation: 2.1.0
2024-02-05 01:33:44,063:INFO:              xxhash: 3.4.1
2024-02-05 01:33:44,063:INFO:           wurlitzer: Not installed
2024-02-05 01:33:44,063:INFO:PyCaret optional dependencies:
2024-02-05 01:33:44,077:INFO:                shap: 0.44.1
2024-02-05 01:33:44,077:INFO:           interpret: Not installed
2024-02-05 01:33:44,077:INFO:                umap: Not installed
2024-02-05 01:33:44,077:INFO:     ydata_profiling: Not installed
2024-02-05 01:33:44,077:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:33:44,077:INFO:             autoviz: Not installed
2024-02-05 01:33:44,077:INFO:           fairlearn: Not installed
2024-02-05 01:33:44,077:INFO:          deepchecks: Not installed
2024-02-05 01:33:44,077:INFO:             xgboost: Not installed
2024-02-05 01:33:44,077:INFO:            catboost: 1.2.2
2024-02-05 01:33:44,077:INFO:              kmodes: Not installed
2024-02-05 01:33:44,077:INFO:             mlxtend: Not installed
2024-02-05 01:33:44,077:INFO:       statsforecast: Not installed
2024-02-05 01:33:44,077:INFO:        tune_sklearn: Not installed
2024-02-05 01:33:44,077:INFO:                 ray: Not installed
2024-02-05 01:33:44,077:INFO:            hyperopt: Not installed
2024-02-05 01:33:44,077:INFO:              optuna: Not installed
2024-02-05 01:33:44,078:INFO:               skopt: Not installed
2024-02-05 01:33:44,078:INFO:              mlflow: 2.10.0
2024-02-05 01:33:44,078:INFO:              gradio: Not installed
2024-02-05 01:33:44,078:INFO:             fastapi: Not installed
2024-02-05 01:33:44,078:INFO:             uvicorn: Not installed
2024-02-05 01:33:44,078:INFO:              m2cgen: Not installed
2024-02-05 01:33:44,078:INFO:           evidently: Not installed
2024-02-05 01:33:44,078:INFO:               fugue: Not installed
2024-02-05 01:33:44,078:INFO:           streamlit: Not installed
2024-02-05 01:33:44,078:INFO:             prophet: Not installed
2024-02-05 01:33:44,078:INFO:None
2024-02-05 01:33:44,078:INFO:Set up GPU usage.
2024-02-05 01:33:44,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,078:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:33:44,078:INFO:Set up data.
2024-02-05 01:33:44,092:INFO:Set up folding strategy.
2024-02-05 01:33:44,092:INFO:Set up train/test split.
2024-02-05 01:33:44,106:INFO:Set up index.
2024-02-05 01:33:44,107:INFO:Assigning column types.
2024-02-05 01:33:44,115:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:33:44,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:33:44,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,173:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:33:44,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:44,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,140:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:33:45,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:33:45,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,305:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:33:45,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,390:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,391:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:33:45,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,453:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,454:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,553:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:33:45,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,612:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,613:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:33:45,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,681:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,682:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,743:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,858:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:45,881:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:33:45,883:INFO:Preparing preprocessing pipeline...
2024-02-05 01:33:45,884:INFO:Set up label encoding.
2024-02-05 01:33:45,885:INFO:Set up simple imputation.
2024-02-05 01:33:45,888:INFO:Set up encoding of categorical features.
2024-02-05 01:33:45,888:INFO:Set up imbalanced handling.
2024-02-05 01:33:45,888:INFO:Set up feature normalization.
2024-02-05 01:33:45,888:INFO:Set up feature selection.
2024-02-05 01:33:45,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:45,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:46,000:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:46,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:33:46,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:33:46,025:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:53,745:INFO:PyCaret ClassificationExperiment
2024-02-05 01:38:53,746:INFO:Logging name: clf-default-name
2024-02-05 01:38:53,746:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:38:53,746:INFO:version 3.2.0
2024-02-05 01:38:53,746:INFO:Initializing setup()
2024-02-05 01:38:53,746:INFO:self.USI: 2657
2024-02-05 01:38:53,746:INFO:self._variable_keys: {'n_jobs_param', 'memory', '_available_plots', 'logging_param', 'y_test', 'X_train', 'exp_name_log', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'seed', 'idx', 'gpu_n_jobs_param', 'html_param', 'X', 'exp_id', 'target_param', 'fix_imbalance', '_ml_usecase', 'fold_groups_param', 'pipeline', 'USI', 'y_train', 'is_multiclass', 'y', 'gpu_param', 'data'}
2024-02-05 01:38:53,747:INFO:Checking environment
2024-02-05 01:38:53,747:INFO:python_version: 3.10.9
2024-02-05 01:38:53,747:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:38:53,747:INFO:machine: AMD64
2024-02-05 01:38:53,747:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:38:53,747:INFO:Memory: svmem(total=16856182784, available=8806150144, percent=47.8, used=8050032640, free=8806150144)
2024-02-05 01:38:53,747:INFO:Physical Core: 4
2024-02-05 01:38:53,747:INFO:Logical Core: 8
2024-02-05 01:38:53,747:INFO:Checking libraries
2024-02-05 01:38:53,747:INFO:System:
2024-02-05 01:38:53,747:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:38:53,747:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:38:53,747:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:38:53,747:INFO:PyCaret required dependencies:
2024-02-05 01:38:53,747:INFO:                 pip: 22.3.1
2024-02-05 01:38:53,747:INFO:          setuptools: 65.6.3
2024-02-05 01:38:53,747:INFO:             pycaret: 3.2.0
2024-02-05 01:38:53,748:INFO:             IPython: 8.20.0
2024-02-05 01:38:53,748:INFO:          ipywidgets: 8.0.4
2024-02-05 01:38:53,748:INFO:                tqdm: 4.64.1
2024-02-05 01:38:53,748:INFO:               numpy: 1.25.2
2024-02-05 01:38:53,748:INFO:              pandas: 1.5.3
2024-02-05 01:38:53,748:INFO:              jinja2: 3.1.3
2024-02-05 01:38:53,748:INFO:               scipy: 1.10.1
2024-02-05 01:38:53,748:INFO:              joblib: 1.3.2
2024-02-05 01:38:53,748:INFO:             sklearn: 1.2.2
2024-02-05 01:38:53,748:INFO:                pyod: 1.1.2
2024-02-05 01:38:53,748:INFO:            imblearn: 0.12.0
2024-02-05 01:38:53,748:INFO:   category_encoders: 2.6.3
2024-02-05 01:38:53,748:INFO:            lightgbm: 4.3.0
2024-02-05 01:38:53,748:INFO:               numba: 0.59.0
2024-02-05 01:38:53,748:INFO:            requests: 2.31.0
2024-02-05 01:38:53,748:INFO:          matplotlib: 3.6.0
2024-02-05 01:38:53,748:INFO:          scikitplot: 0.3.7
2024-02-05 01:38:53,748:INFO:         yellowbrick: 1.5
2024-02-05 01:38:53,748:INFO:              plotly: 5.18.0
2024-02-05 01:38:53,748:INFO:    plotly-resampler: Not installed
2024-02-05 01:38:53,748:INFO:             kaleido: 0.2.1
2024-02-05 01:38:53,748:INFO:           schemdraw: 0.15
2024-02-05 01:38:53,748:INFO:         statsmodels: 0.14.1
2024-02-05 01:38:53,748:INFO:              sktime: 0.21.1
2024-02-05 01:38:53,748:INFO:               tbats: 1.1.3
2024-02-05 01:38:53,749:INFO:            pmdarima: 2.0.4
2024-02-05 01:38:53,749:INFO:              psutil: 5.9.0
2024-02-05 01:38:53,749:INFO:          markupsafe: 2.1.3
2024-02-05 01:38:53,749:INFO:             pickle5: Not installed
2024-02-05 01:38:53,749:INFO:         cloudpickle: 3.0.0
2024-02-05 01:38:53,749:INFO:         deprecation: 2.1.0
2024-02-05 01:38:53,749:INFO:              xxhash: 3.4.1
2024-02-05 01:38:53,749:INFO:           wurlitzer: Not installed
2024-02-05 01:38:53,749:INFO:PyCaret optional dependencies:
2024-02-05 01:38:53,749:INFO:                shap: 0.44.1
2024-02-05 01:38:53,749:INFO:           interpret: Not installed
2024-02-05 01:38:53,749:INFO:                umap: Not installed
2024-02-05 01:38:53,749:INFO:     ydata_profiling: Not installed
2024-02-05 01:38:53,749:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:38:53,749:INFO:             autoviz: Not installed
2024-02-05 01:38:53,749:INFO:           fairlearn: Not installed
2024-02-05 01:38:53,749:INFO:          deepchecks: Not installed
2024-02-05 01:38:53,749:INFO:             xgboost: Not installed
2024-02-05 01:38:53,749:INFO:            catboost: 1.2.2
2024-02-05 01:38:53,749:INFO:              kmodes: Not installed
2024-02-05 01:38:53,749:INFO:             mlxtend: Not installed
2024-02-05 01:38:53,749:INFO:       statsforecast: Not installed
2024-02-05 01:38:53,749:INFO:        tune_sklearn: Not installed
2024-02-05 01:38:53,749:INFO:                 ray: Not installed
2024-02-05 01:38:53,750:INFO:            hyperopt: Not installed
2024-02-05 01:38:53,750:INFO:              optuna: Not installed
2024-02-05 01:38:53,750:INFO:               skopt: Not installed
2024-02-05 01:38:53,750:INFO:              mlflow: 2.10.0
2024-02-05 01:38:53,750:INFO:              gradio: Not installed
2024-02-05 01:38:53,750:INFO:             fastapi: Not installed
2024-02-05 01:38:53,750:INFO:             uvicorn: Not installed
2024-02-05 01:38:53,750:INFO:              m2cgen: Not installed
2024-02-05 01:38:53,750:INFO:           evidently: Not installed
2024-02-05 01:38:53,750:INFO:               fugue: Not installed
2024-02-05 01:38:53,750:INFO:           streamlit: Not installed
2024-02-05 01:38:53,750:INFO:             prophet: Not installed
2024-02-05 01:38:53,750:INFO:None
2024-02-05 01:38:53,750:INFO:Set up GPU usage.
2024-02-05 01:38:53,750:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,750:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:38:53,750:INFO:Set up data.
2024-02-05 01:38:53,763:INFO:Set up folding strategy.
2024-02-05 01:38:53,763:INFO:Set up train/test split.
2024-02-05 01:38:53,772:INFO:Set up index.
2024-02-05 01:38:53,773:INFO:Assigning column types.
2024-02-05 01:38:53,777:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:38:53,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:38:53,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:38:53,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:53,870:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:53,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:38:53,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,926:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:38:53,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:53,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:53,976:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:53,977:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:38:53,977:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:38:54,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:54,117:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:54,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:38:54,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:54,230:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:54,230:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:38:54,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:54,342:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:54,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,411:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:54,465:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:38:54,466:INFO:Preparing preprocessing pipeline...
2024-02-05 01:38:54,468:INFO:Set up label encoding.
2024-02-05 01:38:54,468:INFO:Set up simple imputation.
2024-02-05 01:38:54,473:INFO:Set up encoding of categorical features.
2024-02-05 01:38:54,474:INFO:Set up imbalanced handling.
2024-02-05 01:38:54,474:INFO:Set up feature normalization.
2024-02-05 01:38:54,474:INFO:Set up feature selection.
2024-02-05 01:38:54,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:38:54,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:38:54,594:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:52,730:INFO:PyCaret ClassificationExperiment
2024-02-05 01:39:52,730:INFO:Logging name: clf-default-name
2024-02-05 01:39:52,731:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:39:52,731:INFO:version 3.2.0
2024-02-05 01:39:52,731:INFO:Initializing setup()
2024-02-05 01:39:52,731:INFO:self.USI: 1860
2024-02-05 01:39:52,731:INFO:self._variable_keys: {'n_jobs_param', 'memory', '_available_plots', 'logging_param', 'y_test', 'X_train', 'exp_name_log', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'seed', 'idx', 'gpu_n_jobs_param', 'html_param', 'X', 'exp_id', 'target_param', 'fix_imbalance', '_ml_usecase', 'fold_groups_param', 'pipeline', 'USI', 'y_train', 'is_multiclass', 'y', 'gpu_param', 'data'}
2024-02-05 01:39:52,731:INFO:Checking environment
2024-02-05 01:39:52,731:INFO:python_version: 3.10.9
2024-02-05 01:39:52,731:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:39:52,731:INFO:machine: AMD64
2024-02-05 01:39:52,731:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:39:52,731:INFO:Memory: svmem(total=16856182784, available=8627216384, percent=48.8, used=8228966400, free=8627216384)
2024-02-05 01:39:52,731:INFO:Physical Core: 4
2024-02-05 01:39:52,731:INFO:Logical Core: 8
2024-02-05 01:39:52,731:INFO:Checking libraries
2024-02-05 01:39:52,731:INFO:System:
2024-02-05 01:39:52,731:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:39:52,731:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:39:52,731:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:39:52,731:INFO:PyCaret required dependencies:
2024-02-05 01:39:52,732:INFO:                 pip: 22.3.1
2024-02-05 01:39:52,732:INFO:          setuptools: 65.6.3
2024-02-05 01:39:52,732:INFO:             pycaret: 3.2.0
2024-02-05 01:39:52,732:INFO:             IPython: 8.20.0
2024-02-05 01:39:52,732:INFO:          ipywidgets: 8.0.4
2024-02-05 01:39:52,732:INFO:                tqdm: 4.64.1
2024-02-05 01:39:52,732:INFO:               numpy: 1.25.2
2024-02-05 01:39:52,732:INFO:              pandas: 1.5.3
2024-02-05 01:39:52,732:INFO:              jinja2: 3.1.3
2024-02-05 01:39:52,732:INFO:               scipy: 1.10.1
2024-02-05 01:39:52,732:INFO:              joblib: 1.3.2
2024-02-05 01:39:52,732:INFO:             sklearn: 1.2.2
2024-02-05 01:39:52,732:INFO:                pyod: 1.1.2
2024-02-05 01:39:52,732:INFO:            imblearn: 0.12.0
2024-02-05 01:39:52,732:INFO:   category_encoders: 2.6.3
2024-02-05 01:39:52,732:INFO:            lightgbm: 4.3.0
2024-02-05 01:39:52,732:INFO:               numba: 0.59.0
2024-02-05 01:39:52,732:INFO:            requests: 2.31.0
2024-02-05 01:39:52,732:INFO:          matplotlib: 3.6.0
2024-02-05 01:39:52,732:INFO:          scikitplot: 0.3.7
2024-02-05 01:39:52,732:INFO:         yellowbrick: 1.5
2024-02-05 01:39:52,732:INFO:              plotly: 5.18.0
2024-02-05 01:39:52,733:INFO:    plotly-resampler: Not installed
2024-02-05 01:39:52,733:INFO:             kaleido: 0.2.1
2024-02-05 01:39:52,733:INFO:           schemdraw: 0.15
2024-02-05 01:39:52,733:INFO:         statsmodels: 0.14.1
2024-02-05 01:39:52,733:INFO:              sktime: 0.21.1
2024-02-05 01:39:52,733:INFO:               tbats: 1.1.3
2024-02-05 01:39:52,733:INFO:            pmdarima: 2.0.4
2024-02-05 01:39:52,733:INFO:              psutil: 5.9.0
2024-02-05 01:39:52,733:INFO:          markupsafe: 2.1.3
2024-02-05 01:39:52,733:INFO:             pickle5: Not installed
2024-02-05 01:39:52,733:INFO:         cloudpickle: 3.0.0
2024-02-05 01:39:52,733:INFO:         deprecation: 2.1.0
2024-02-05 01:39:52,733:INFO:              xxhash: 3.4.1
2024-02-05 01:39:52,733:INFO:           wurlitzer: Not installed
2024-02-05 01:39:52,733:INFO:PyCaret optional dependencies:
2024-02-05 01:39:52,733:INFO:                shap: 0.44.1
2024-02-05 01:39:52,733:INFO:           interpret: Not installed
2024-02-05 01:39:52,733:INFO:                umap: Not installed
2024-02-05 01:39:52,733:INFO:     ydata_profiling: Not installed
2024-02-05 01:39:52,733:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:39:52,733:INFO:             autoviz: Not installed
2024-02-05 01:39:52,733:INFO:           fairlearn: Not installed
2024-02-05 01:39:52,733:INFO:          deepchecks: Not installed
2024-02-05 01:39:52,733:INFO:             xgboost: Not installed
2024-02-05 01:39:52,734:INFO:            catboost: 1.2.2
2024-02-05 01:39:52,734:INFO:              kmodes: Not installed
2024-02-05 01:39:52,734:INFO:             mlxtend: Not installed
2024-02-05 01:39:52,734:INFO:       statsforecast: Not installed
2024-02-05 01:39:52,734:INFO:        tune_sklearn: Not installed
2024-02-05 01:39:52,734:INFO:                 ray: Not installed
2024-02-05 01:39:52,734:INFO:            hyperopt: Not installed
2024-02-05 01:39:52,734:INFO:              optuna: Not installed
2024-02-05 01:39:52,734:INFO:               skopt: Not installed
2024-02-05 01:39:52,734:INFO:              mlflow: 2.10.0
2024-02-05 01:39:52,734:INFO:              gradio: Not installed
2024-02-05 01:39:52,734:INFO:             fastapi: Not installed
2024-02-05 01:39:52,735:INFO:             uvicorn: Not installed
2024-02-05 01:39:52,735:INFO:              m2cgen: Not installed
2024-02-05 01:39:52,735:INFO:           evidently: Not installed
2024-02-05 01:39:52,735:INFO:               fugue: Not installed
2024-02-05 01:39:52,735:INFO:           streamlit: Not installed
2024-02-05 01:39:52,735:INFO:             prophet: Not installed
2024-02-05 01:39:52,735:INFO:None
2024-02-05 01:39:52,735:INFO:Set up GPU usage.
2024-02-05 01:39:52,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,735:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:39:52,735:INFO:Set up data.
2024-02-05 01:39:52,748:INFO:Set up folding strategy.
2024-02-05 01:39:52,748:INFO:Set up train/test split.
2024-02-05 01:39:52,757:INFO:Set up index.
2024-02-05 01:39:52,757:INFO:Assigning column types.
2024-02-05 01:39:52,761:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:39:52,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:39:52,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,802:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,803:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:39:52,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:52,840:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:52,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:39:52,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:39:52,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,921:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,927:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:52,939:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:52,939:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:39:52,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,981:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:52,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:39:52,981:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:53,022:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:53,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:39:53,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:53,144:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:53,145:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:39:53,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:53,252:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:53,253:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,314:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,314:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:53,353:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:39:53,355:INFO:Preparing preprocessing pipeline...
2024-02-05 01:39:53,356:INFO:Set up label encoding.
2024-02-05 01:39:53,356:INFO:Set up simple imputation.
2024-02-05 01:39:53,358:INFO:Set up encoding of categorical features.
2024-02-05 01:39:53,359:INFO:Set up imbalanced handling.
2024-02-05 01:39:53,359:INFO:Set up feature normalization.
2024-02-05 01:39:53,359:INFO:Set up feature selection.
2024-02-05 01:39:53,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:39:53,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:39:53,458:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:39,520:INFO:PyCaret ClassificationExperiment
2024-02-05 01:40:39,520:INFO:Logging name: clf-default-name
2024-02-05 01:40:39,520:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:40:39,521:INFO:version 3.2.0
2024-02-05 01:40:39,521:INFO:Initializing setup()
2024-02-05 01:40:39,521:INFO:self.USI: 1d63
2024-02-05 01:40:39,521:INFO:self._variable_keys: {'n_jobs_param', 'memory', '_available_plots', 'logging_param', 'y_test', 'X_train', 'exp_name_log', 'log_plots_param', 'X_test', 'fold_generator', 'fold_shuffle_param', 'seed', 'idx', 'gpu_n_jobs_param', 'html_param', 'X', 'exp_id', 'target_param', 'fix_imbalance', '_ml_usecase', 'fold_groups_param', 'pipeline', 'USI', 'y_train', 'is_multiclass', 'y', 'gpu_param', 'data'}
2024-02-05 01:40:39,521:INFO:Checking environment
2024-02-05 01:40:39,521:INFO:python_version: 3.10.9
2024-02-05 01:40:39,521:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:40:39,521:INFO:machine: AMD64
2024-02-05 01:40:39,521:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:40:39,521:INFO:Memory: svmem(total=16856182784, available=8616267776, percent=48.9, used=8239915008, free=8616267776)
2024-02-05 01:40:39,521:INFO:Physical Core: 4
2024-02-05 01:40:39,521:INFO:Logical Core: 8
2024-02-05 01:40:39,521:INFO:Checking libraries
2024-02-05 01:40:39,521:INFO:System:
2024-02-05 01:40:39,521:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:40:39,521:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:40:39,521:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:40:39,522:INFO:PyCaret required dependencies:
2024-02-05 01:40:39,522:INFO:                 pip: 22.3.1
2024-02-05 01:40:39,522:INFO:          setuptools: 65.6.3
2024-02-05 01:40:39,522:INFO:             pycaret: 3.2.0
2024-02-05 01:40:39,522:INFO:             IPython: 8.20.0
2024-02-05 01:40:39,522:INFO:          ipywidgets: 8.0.4
2024-02-05 01:40:39,522:INFO:                tqdm: 4.64.1
2024-02-05 01:40:39,522:INFO:               numpy: 1.25.2
2024-02-05 01:40:39,522:INFO:              pandas: 1.5.3
2024-02-05 01:40:39,522:INFO:              jinja2: 3.1.3
2024-02-05 01:40:39,522:INFO:               scipy: 1.10.1
2024-02-05 01:40:39,522:INFO:              joblib: 1.3.2
2024-02-05 01:40:39,523:INFO:             sklearn: 1.2.2
2024-02-05 01:40:39,523:INFO:                pyod: 1.1.2
2024-02-05 01:40:39,523:INFO:            imblearn: 0.12.0
2024-02-05 01:40:39,523:INFO:   category_encoders: 2.6.3
2024-02-05 01:40:39,523:INFO:            lightgbm: 4.3.0
2024-02-05 01:40:39,523:INFO:               numba: 0.59.0
2024-02-05 01:40:39,523:INFO:            requests: 2.31.0
2024-02-05 01:40:39,523:INFO:          matplotlib: 3.6.0
2024-02-05 01:40:39,523:INFO:          scikitplot: 0.3.7
2024-02-05 01:40:39,523:INFO:         yellowbrick: 1.5
2024-02-05 01:40:39,523:INFO:              plotly: 5.18.0
2024-02-05 01:40:39,523:INFO:    plotly-resampler: Not installed
2024-02-05 01:40:39,523:INFO:             kaleido: 0.2.1
2024-02-05 01:40:39,523:INFO:           schemdraw: 0.15
2024-02-05 01:40:39,523:INFO:         statsmodels: 0.14.1
2024-02-05 01:40:39,524:INFO:              sktime: 0.21.1
2024-02-05 01:40:39,524:INFO:               tbats: 1.1.3
2024-02-05 01:40:39,524:INFO:            pmdarima: 2.0.4
2024-02-05 01:40:39,524:INFO:              psutil: 5.9.0
2024-02-05 01:40:39,524:INFO:          markupsafe: 2.1.3
2024-02-05 01:40:39,524:INFO:             pickle5: Not installed
2024-02-05 01:40:39,524:INFO:         cloudpickle: 3.0.0
2024-02-05 01:40:39,524:INFO:         deprecation: 2.1.0
2024-02-05 01:40:39,524:INFO:              xxhash: 3.4.1
2024-02-05 01:40:39,524:INFO:           wurlitzer: Not installed
2024-02-05 01:40:39,524:INFO:PyCaret optional dependencies:
2024-02-05 01:40:39,524:INFO:                shap: 0.44.1
2024-02-05 01:40:39,524:INFO:           interpret: Not installed
2024-02-05 01:40:39,524:INFO:                umap: Not installed
2024-02-05 01:40:39,524:INFO:     ydata_profiling: Not installed
2024-02-05 01:40:39,524:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:40:39,524:INFO:             autoviz: Not installed
2024-02-05 01:40:39,524:INFO:           fairlearn: Not installed
2024-02-05 01:40:39,524:INFO:          deepchecks: Not installed
2024-02-05 01:40:39,524:INFO:             xgboost: Not installed
2024-02-05 01:40:39,524:INFO:            catboost: 1.2.2
2024-02-05 01:40:39,525:INFO:              kmodes: Not installed
2024-02-05 01:40:39,525:INFO:             mlxtend: Not installed
2024-02-05 01:40:39,525:INFO:       statsforecast: Not installed
2024-02-05 01:40:39,525:INFO:        tune_sklearn: Not installed
2024-02-05 01:40:39,525:INFO:                 ray: Not installed
2024-02-05 01:40:39,525:INFO:            hyperopt: Not installed
2024-02-05 01:40:39,525:INFO:              optuna: Not installed
2024-02-05 01:40:39,525:INFO:               skopt: Not installed
2024-02-05 01:40:39,525:INFO:              mlflow: 2.10.0
2024-02-05 01:40:39,525:INFO:              gradio: Not installed
2024-02-05 01:40:39,525:INFO:             fastapi: Not installed
2024-02-05 01:40:39,525:INFO:             uvicorn: Not installed
2024-02-05 01:40:39,525:INFO:              m2cgen: Not installed
2024-02-05 01:40:39,525:INFO:           evidently: Not installed
2024-02-05 01:40:39,525:INFO:               fugue: Not installed
2024-02-05 01:40:39,525:INFO:           streamlit: Not installed
2024-02-05 01:40:39,525:INFO:             prophet: Not installed
2024-02-05 01:40:39,525:INFO:None
2024-02-05 01:40:39,525:INFO:Set up GPU usage.
2024-02-05 01:40:39,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,525:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:40:39,525:INFO:Set up data.
2024-02-05 01:40:39,544:INFO:Set up folding strategy.
2024-02-05 01:40:39,544:INFO:Set up train/test split.
2024-02-05 01:40:39,553:INFO:Set up index.
2024-02-05 01:40:39,554:INFO:Assigning column types.
2024-02-05 01:40:39,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:40:39,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,603:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:39,647:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:39,647:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,733:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:39,751:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:39,752:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:40:39,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,797:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:39,837:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:39,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:40:39,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:39,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:39,977:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:39,979:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:40:39,979:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,081:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:40,097:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:40,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:40,221:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:40:40,223:INFO:Preparing preprocessing pipeline...
2024-02-05 01:40:40,224:INFO:Set up label encoding.
2024-02-05 01:40:40,224:INFO:Set up simple imputation.
2024-02-05 01:40:40,227:INFO:Set up encoding of categorical features.
2024-02-05 01:40:40,227:INFO:Set up imbalanced handling.
2024-02-05 01:40:40,227:INFO:Set up feature normalization.
2024-02-05 01:40:40,227:INFO:Set up feature selection.
2024-02-05 01:40:40,227:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:40:40,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:40:40,319:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:32,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:32,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:32,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:32,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,683:INFO:PyCaret ClassificationExperiment
2024-02-05 01:41:33,683:INFO:Logging name: clf-default-name
2024-02-05 01:41:33,683:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:41:33,683:INFO:version 3.2.0
2024-02-05 01:41:33,683:INFO:Initializing setup()
2024-02-05 01:41:33,684:INFO:self.USI: a5be
2024-02-05 01:41:33,684:INFO:self._variable_keys: {'X_test', 'pipeline', 'n_jobs_param', 'y_test', 'X_train', 'logging_param', 'fold_shuffle_param', 'X', 'y_train', 'target_param', 'y', 'is_multiclass', '_ml_usecase', 'idx', 'gpu_n_jobs_param', 'exp_id', 'log_plots_param', '_available_plots', 'gpu_param', 'fix_imbalance', 'html_param', 'exp_name_log', 'seed', 'USI', 'fold_groups_param', 'data', 'memory', 'fold_generator'}
2024-02-05 01:41:33,684:INFO:Checking environment
2024-02-05 01:41:33,684:INFO:python_version: 3.10.9
2024-02-05 01:41:33,684:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:41:33,684:INFO:machine: AMD64
2024-02-05 01:41:33,684:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:41:33,684:INFO:Memory: svmem(total=16856182784, available=8739737600, percent=48.2, used=8116445184, free=8739737600)
2024-02-05 01:41:33,684:INFO:Physical Core: 4
2024-02-05 01:41:33,684:INFO:Logical Core: 8
2024-02-05 01:41:33,684:INFO:Checking libraries
2024-02-05 01:41:33,684:INFO:System:
2024-02-05 01:41:33,684:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:41:33,684:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:41:33,684:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:41:33,684:INFO:PyCaret required dependencies:
2024-02-05 01:41:33,836:INFO:                 pip: 22.3.1
2024-02-05 01:41:33,836:INFO:          setuptools: 65.6.3
2024-02-05 01:41:33,836:INFO:             pycaret: 3.2.0
2024-02-05 01:41:33,837:INFO:             IPython: 8.20.0
2024-02-05 01:41:33,837:INFO:          ipywidgets: 8.0.4
2024-02-05 01:41:33,837:INFO:                tqdm: 4.64.1
2024-02-05 01:41:33,837:INFO:               numpy: 1.25.2
2024-02-05 01:41:33,837:INFO:              pandas: 1.5.3
2024-02-05 01:41:33,837:INFO:              jinja2: 3.1.3
2024-02-05 01:41:33,837:INFO:               scipy: 1.10.1
2024-02-05 01:41:33,837:INFO:              joblib: 1.3.2
2024-02-05 01:41:33,837:INFO:             sklearn: 1.2.2
2024-02-05 01:41:33,837:INFO:                pyod: 1.1.2
2024-02-05 01:41:33,837:INFO:            imblearn: 0.12.0
2024-02-05 01:41:33,837:INFO:   category_encoders: 2.6.3
2024-02-05 01:41:33,837:INFO:            lightgbm: 4.3.0
2024-02-05 01:41:33,837:INFO:               numba: 0.59.0
2024-02-05 01:41:33,837:INFO:            requests: 2.31.0
2024-02-05 01:41:33,837:INFO:          matplotlib: 3.6.0
2024-02-05 01:41:33,837:INFO:          scikitplot: 0.3.7
2024-02-05 01:41:33,837:INFO:         yellowbrick: 1.5
2024-02-05 01:41:33,837:INFO:              plotly: 5.18.0
2024-02-05 01:41:33,838:INFO:    plotly-resampler: Not installed
2024-02-05 01:41:33,838:INFO:             kaleido: 0.2.1
2024-02-05 01:41:33,838:INFO:           schemdraw: 0.15
2024-02-05 01:41:33,838:INFO:         statsmodels: 0.14.1
2024-02-05 01:41:33,838:INFO:              sktime: 0.21.1
2024-02-05 01:41:33,838:INFO:               tbats: 1.1.3
2024-02-05 01:41:33,838:INFO:            pmdarima: 2.0.4
2024-02-05 01:41:33,838:INFO:              psutil: 5.9.0
2024-02-05 01:41:33,838:INFO:          markupsafe: 2.1.3
2024-02-05 01:41:33,838:INFO:             pickle5: Not installed
2024-02-05 01:41:33,838:INFO:         cloudpickle: 3.0.0
2024-02-05 01:41:33,838:INFO:         deprecation: 2.1.0
2024-02-05 01:41:33,838:INFO:              xxhash: 3.4.1
2024-02-05 01:41:33,838:INFO:           wurlitzer: Not installed
2024-02-05 01:41:33,838:INFO:PyCaret optional dependencies:
2024-02-05 01:41:33,850:INFO:                shap: 0.44.1
2024-02-05 01:41:33,850:INFO:           interpret: Not installed
2024-02-05 01:41:33,850:INFO:                umap: Not installed
2024-02-05 01:41:33,850:INFO:     ydata_profiling: Not installed
2024-02-05 01:41:33,850:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:41:33,850:INFO:             autoviz: Not installed
2024-02-05 01:41:33,850:INFO:           fairlearn: Not installed
2024-02-05 01:41:33,850:INFO:          deepchecks: Not installed
2024-02-05 01:41:33,850:INFO:             xgboost: Not installed
2024-02-05 01:41:33,850:INFO:            catboost: 1.2.2
2024-02-05 01:41:33,850:INFO:              kmodes: Not installed
2024-02-05 01:41:33,850:INFO:             mlxtend: Not installed
2024-02-05 01:41:33,850:INFO:       statsforecast: Not installed
2024-02-05 01:41:33,850:INFO:        tune_sklearn: Not installed
2024-02-05 01:41:33,851:INFO:                 ray: Not installed
2024-02-05 01:41:33,851:INFO:            hyperopt: Not installed
2024-02-05 01:41:33,851:INFO:              optuna: Not installed
2024-02-05 01:41:33,851:INFO:               skopt: Not installed
2024-02-05 01:41:33,851:INFO:              mlflow: 2.10.0
2024-02-05 01:41:33,851:INFO:              gradio: Not installed
2024-02-05 01:41:33,851:INFO:             fastapi: Not installed
2024-02-05 01:41:33,851:INFO:             uvicorn: Not installed
2024-02-05 01:41:33,851:INFO:              m2cgen: Not installed
2024-02-05 01:41:33,851:INFO:           evidently: Not installed
2024-02-05 01:41:33,851:INFO:               fugue: Not installed
2024-02-05 01:41:33,851:INFO:           streamlit: Not installed
2024-02-05 01:41:33,851:INFO:             prophet: Not installed
2024-02-05 01:41:33,851:INFO:None
2024-02-05 01:41:33,851:INFO:Set up GPU usage.
2024-02-05 01:41:33,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,851:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:41:33,851:INFO:Set up data.
2024-02-05 01:41:33,863:INFO:Set up folding strategy.
2024-02-05 01:41:33,864:INFO:Set up train/test split.
2024-02-05 01:41:33,872:INFO:Set up index.
2024-02-05 01:41:33,872:INFO:Assigning column types.
2024-02-05 01:41:33,877:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:41:33,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:41:33,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:41:33,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:33,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:34,783:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:34,810:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:41:34,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,880:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:41:34,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:34,926:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:34,927:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:41:34,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:34,990:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:41:34,991:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:35,044:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:35,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:41:35,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:35,166:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:35,167:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:41:35,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:35,273:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:35,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,324:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,324:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:35,365:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:41:35,368:INFO:Preparing preprocessing pipeline...
2024-02-05 01:41:35,369:INFO:Set up label encoding.
2024-02-05 01:41:35,369:INFO:Set up simple imputation.
2024-02-05 01:41:35,372:INFO:Set up encoding of categorical features.
2024-02-05 01:41:35,373:INFO:Set up imbalanced handling.
2024-02-05 01:41:35,373:INFO:Set up feature normalization.
2024-02-05 01:41:35,373:INFO:Set up feature selection.
2024-02-05 01:41:35,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,421:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,422:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:41:35,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:41:35,472:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:07,678:INFO:PyCaret ClassificationExperiment
2024-02-05 01:42:07,679:INFO:Logging name: clf-default-name
2024-02-05 01:42:07,679:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:42:07,679:INFO:version 3.2.0
2024-02-05 01:42:07,679:INFO:Initializing setup()
2024-02-05 01:42:07,679:INFO:self.USI: f55b
2024-02-05 01:42:07,679:INFO:self._variable_keys: {'X_test', 'pipeline', 'n_jobs_param', 'y_test', 'X_train', 'logging_param', 'fold_shuffle_param', 'X', 'y_train', 'target_param', 'y', 'is_multiclass', '_ml_usecase', 'idx', 'gpu_n_jobs_param', 'exp_id', 'log_plots_param', '_available_plots', 'gpu_param', 'fix_imbalance', 'html_param', 'exp_name_log', 'seed', 'USI', 'fold_groups_param', 'data', 'memory', 'fold_generator'}
2024-02-05 01:42:07,679:INFO:Checking environment
2024-02-05 01:42:07,679:INFO:python_version: 3.10.9
2024-02-05 01:42:07,679:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:42:07,680:INFO:machine: AMD64
2024-02-05 01:42:07,680:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:42:07,680:INFO:Memory: svmem(total=16856182784, available=8672514048, percent=48.5, used=8183668736, free=8672514048)
2024-02-05 01:42:07,680:INFO:Physical Core: 4
2024-02-05 01:42:07,680:INFO:Logical Core: 8
2024-02-05 01:42:07,680:INFO:Checking libraries
2024-02-05 01:42:07,680:INFO:System:
2024-02-05 01:42:07,680:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:42:07,680:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:42:07,680:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:42:07,680:INFO:PyCaret required dependencies:
2024-02-05 01:42:07,680:INFO:                 pip: 22.3.1
2024-02-05 01:42:07,680:INFO:          setuptools: 65.6.3
2024-02-05 01:42:07,680:INFO:             pycaret: 3.2.0
2024-02-05 01:42:07,680:INFO:             IPython: 8.20.0
2024-02-05 01:42:07,680:INFO:          ipywidgets: 8.0.4
2024-02-05 01:42:07,680:INFO:                tqdm: 4.64.1
2024-02-05 01:42:07,680:INFO:               numpy: 1.25.2
2024-02-05 01:42:07,680:INFO:              pandas: 1.5.3
2024-02-05 01:42:07,681:INFO:              jinja2: 3.1.3
2024-02-05 01:42:07,681:INFO:               scipy: 1.10.1
2024-02-05 01:42:07,681:INFO:              joblib: 1.3.2
2024-02-05 01:42:07,681:INFO:             sklearn: 1.2.2
2024-02-05 01:42:07,681:INFO:                pyod: 1.1.2
2024-02-05 01:42:07,681:INFO:            imblearn: 0.12.0
2024-02-05 01:42:07,681:INFO:   category_encoders: 2.6.3
2024-02-05 01:42:07,681:INFO:            lightgbm: 4.3.0
2024-02-05 01:42:07,681:INFO:               numba: 0.59.0
2024-02-05 01:42:07,681:INFO:            requests: 2.31.0
2024-02-05 01:42:07,681:INFO:          matplotlib: 3.6.0
2024-02-05 01:42:07,681:INFO:          scikitplot: 0.3.7
2024-02-05 01:42:07,681:INFO:         yellowbrick: 1.5
2024-02-05 01:42:07,681:INFO:              plotly: 5.18.0
2024-02-05 01:42:07,681:INFO:    plotly-resampler: Not installed
2024-02-05 01:42:07,681:INFO:             kaleido: 0.2.1
2024-02-05 01:42:07,681:INFO:           schemdraw: 0.15
2024-02-05 01:42:07,681:INFO:         statsmodels: 0.14.1
2024-02-05 01:42:07,682:INFO:              sktime: 0.21.1
2024-02-05 01:42:07,682:INFO:               tbats: 1.1.3
2024-02-05 01:42:07,682:INFO:            pmdarima: 2.0.4
2024-02-05 01:42:07,682:INFO:              psutil: 5.9.0
2024-02-05 01:42:07,682:INFO:          markupsafe: 2.1.3
2024-02-05 01:42:07,682:INFO:             pickle5: Not installed
2024-02-05 01:42:07,682:INFO:         cloudpickle: 3.0.0
2024-02-05 01:42:07,682:INFO:         deprecation: 2.1.0
2024-02-05 01:42:07,682:INFO:              xxhash: 3.4.1
2024-02-05 01:42:07,682:INFO:           wurlitzer: Not installed
2024-02-05 01:42:07,682:INFO:PyCaret optional dependencies:
2024-02-05 01:42:07,682:INFO:                shap: 0.44.1
2024-02-05 01:42:07,682:INFO:           interpret: Not installed
2024-02-05 01:42:07,682:INFO:                umap: Not installed
2024-02-05 01:42:07,682:INFO:     ydata_profiling: Not installed
2024-02-05 01:42:07,682:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:42:07,682:INFO:             autoviz: Not installed
2024-02-05 01:42:07,682:INFO:           fairlearn: Not installed
2024-02-05 01:42:07,682:INFO:          deepchecks: Not installed
2024-02-05 01:42:07,682:INFO:             xgboost: Not installed
2024-02-05 01:42:07,682:INFO:            catboost: 1.2.2
2024-02-05 01:42:07,682:INFO:              kmodes: Not installed
2024-02-05 01:42:07,683:INFO:             mlxtend: Not installed
2024-02-05 01:42:07,683:INFO:       statsforecast: Not installed
2024-02-05 01:42:07,683:INFO:        tune_sklearn: Not installed
2024-02-05 01:42:07,683:INFO:                 ray: Not installed
2024-02-05 01:42:07,683:INFO:            hyperopt: Not installed
2024-02-05 01:42:07,683:INFO:              optuna: Not installed
2024-02-05 01:42:07,683:INFO:               skopt: Not installed
2024-02-05 01:42:07,683:INFO:              mlflow: 2.10.0
2024-02-05 01:42:07,683:INFO:              gradio: Not installed
2024-02-05 01:42:07,683:INFO:             fastapi: Not installed
2024-02-05 01:42:07,683:INFO:             uvicorn: Not installed
2024-02-05 01:42:07,683:INFO:              m2cgen: Not installed
2024-02-05 01:42:07,683:INFO:           evidently: Not installed
2024-02-05 01:42:07,683:INFO:               fugue: Not installed
2024-02-05 01:42:07,683:INFO:           streamlit: Not installed
2024-02-05 01:42:07,683:INFO:             prophet: Not installed
2024-02-05 01:42:07,683:INFO:None
2024-02-05 01:42:07,683:INFO:Set up GPU usage.
2024-02-05 01:42:07,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,684:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:42:07,684:INFO:Set up data.
2024-02-05 01:42:07,696:INFO:Set up folding strategy.
2024-02-05 01:42:07,696:INFO:Set up train/test split.
2024-02-05 01:42:07,705:INFO:Set up index.
2024-02-05 01:42:07,705:INFO:Assigning column types.
2024-02-05 01:42:07,709:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:42:07,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:42:07,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,748:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:42:07,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:07,784:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:07,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:42:07,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:42:07,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:07,901:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:07,901:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:42:07,902:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:42:07,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,982:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:07,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:08,001:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:08,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:42:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:08,094:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:08,095:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:42:08,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,188:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:08,205:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:08,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,282:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:08,298:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:42:08,299:INFO:Preparing preprocessing pipeline...
2024-02-05 01:42:08,301:INFO:Set up label encoding.
2024-02-05 01:42:08,301:INFO:Set up simple imputation.
2024-02-05 01:42:08,305:INFO:Set up encoding of categorical features.
2024-02-05 01:42:08,305:INFO:Set up imbalanced handling.
2024-02-05 01:42:08,305:INFO:Set up feature normalization.
2024-02-05 01:42:08,305:INFO:Set up feature selection.
2024-02-05 01:42:08,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,375:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,381:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:42:08,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:42:08,396:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,393:INFO:PyCaret ClassificationExperiment
2024-02-05 01:45:33,393:INFO:Logging name: clf-default-name
2024-02-05 01:45:33,393:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:45:33,393:INFO:version 3.2.0
2024-02-05 01:45:33,394:INFO:Initializing setup()
2024-02-05 01:45:33,394:INFO:self.USI: 5226
2024-02-05 01:45:33,394:INFO:self._variable_keys: {'X_test', 'pipeline', 'n_jobs_param', 'y_test', 'X_train', 'logging_param', 'fold_shuffle_param', 'X', 'y_train', 'target_param', 'y', 'is_multiclass', '_ml_usecase', 'idx', 'gpu_n_jobs_param', 'exp_id', 'log_plots_param', '_available_plots', 'gpu_param', 'fix_imbalance', 'html_param', 'exp_name_log', 'seed', 'USI', 'fold_groups_param', 'data', 'memory', 'fold_generator'}
2024-02-05 01:45:33,394:INFO:Checking environment
2024-02-05 01:45:33,394:INFO:python_version: 3.10.9
2024-02-05 01:45:33,394:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:45:33,394:INFO:machine: AMD64
2024-02-05 01:45:33,394:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:45:33,394:INFO:Memory: svmem(total=16856182784, available=8578392064, percent=49.1, used=8277790720, free=8578392064)
2024-02-05 01:45:33,394:INFO:Physical Core: 4
2024-02-05 01:45:33,394:INFO:Logical Core: 8
2024-02-05 01:45:33,394:INFO:Checking libraries
2024-02-05 01:45:33,394:INFO:System:
2024-02-05 01:45:33,394:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:45:33,395:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:45:33,395:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:45:33,395:INFO:PyCaret required dependencies:
2024-02-05 01:45:33,395:INFO:                 pip: 22.3.1
2024-02-05 01:45:33,395:INFO:          setuptools: 65.6.3
2024-02-05 01:45:33,395:INFO:             pycaret: 3.2.0
2024-02-05 01:45:33,395:INFO:             IPython: 8.20.0
2024-02-05 01:45:33,395:INFO:          ipywidgets: 8.0.4
2024-02-05 01:45:33,395:INFO:                tqdm: 4.64.1
2024-02-05 01:45:33,395:INFO:               numpy: 1.25.2
2024-02-05 01:45:33,395:INFO:              pandas: 1.5.3
2024-02-05 01:45:33,395:INFO:              jinja2: 3.1.3
2024-02-05 01:45:33,395:INFO:               scipy: 1.10.1
2024-02-05 01:45:33,395:INFO:              joblib: 1.3.2
2024-02-05 01:45:33,395:INFO:             sklearn: 1.2.2
2024-02-05 01:45:33,395:INFO:                pyod: 1.1.2
2024-02-05 01:45:33,395:INFO:            imblearn: 0.12.0
2024-02-05 01:45:33,395:INFO:   category_encoders: 2.6.3
2024-02-05 01:45:33,395:INFO:            lightgbm: 4.3.0
2024-02-05 01:45:33,395:INFO:               numba: 0.59.0
2024-02-05 01:45:33,395:INFO:            requests: 2.31.0
2024-02-05 01:45:33,395:INFO:          matplotlib: 3.6.0
2024-02-05 01:45:33,395:INFO:          scikitplot: 0.3.7
2024-02-05 01:45:33,395:INFO:         yellowbrick: 1.5
2024-02-05 01:45:33,395:INFO:              plotly: 5.18.0
2024-02-05 01:45:33,396:INFO:    plotly-resampler: Not installed
2024-02-05 01:45:33,396:INFO:             kaleido: 0.2.1
2024-02-05 01:45:33,396:INFO:           schemdraw: 0.15
2024-02-05 01:45:33,396:INFO:         statsmodels: 0.14.1
2024-02-05 01:45:33,396:INFO:              sktime: 0.21.1
2024-02-05 01:45:33,396:INFO:               tbats: 1.1.3
2024-02-05 01:45:33,396:INFO:            pmdarima: 2.0.4
2024-02-05 01:45:33,396:INFO:              psutil: 5.9.0
2024-02-05 01:45:33,396:INFO:          markupsafe: 2.1.3
2024-02-05 01:45:33,396:INFO:             pickle5: Not installed
2024-02-05 01:45:33,396:INFO:         cloudpickle: 3.0.0
2024-02-05 01:45:33,396:INFO:         deprecation: 2.1.0
2024-02-05 01:45:33,396:INFO:              xxhash: 3.4.1
2024-02-05 01:45:33,396:INFO:           wurlitzer: Not installed
2024-02-05 01:45:33,396:INFO:PyCaret optional dependencies:
2024-02-05 01:45:33,396:INFO:                shap: 0.44.1
2024-02-05 01:45:33,396:INFO:           interpret: Not installed
2024-02-05 01:45:33,397:INFO:                umap: Not installed
2024-02-05 01:45:33,397:INFO:     ydata_profiling: Not installed
2024-02-05 01:45:33,397:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:45:33,397:INFO:             autoviz: Not installed
2024-02-05 01:45:33,397:INFO:           fairlearn: Not installed
2024-02-05 01:45:33,397:INFO:          deepchecks: Not installed
2024-02-05 01:45:33,397:INFO:             xgboost: Not installed
2024-02-05 01:45:33,397:INFO:            catboost: 1.2.2
2024-02-05 01:45:33,397:INFO:              kmodes: Not installed
2024-02-05 01:45:33,397:INFO:             mlxtend: Not installed
2024-02-05 01:45:33,397:INFO:       statsforecast: Not installed
2024-02-05 01:45:33,397:INFO:        tune_sklearn: Not installed
2024-02-05 01:45:33,397:INFO:                 ray: Not installed
2024-02-05 01:45:33,397:INFO:            hyperopt: Not installed
2024-02-05 01:45:33,397:INFO:              optuna: Not installed
2024-02-05 01:45:33,397:INFO:               skopt: Not installed
2024-02-05 01:45:33,397:INFO:              mlflow: 2.10.0
2024-02-05 01:45:33,397:INFO:              gradio: Not installed
2024-02-05 01:45:33,397:INFO:             fastapi: Not installed
2024-02-05 01:45:33,398:INFO:             uvicorn: Not installed
2024-02-05 01:45:33,398:INFO:              m2cgen: Not installed
2024-02-05 01:45:33,398:INFO:           evidently: Not installed
2024-02-05 01:45:33,398:INFO:               fugue: Not installed
2024-02-05 01:45:33,398:INFO:           streamlit: Not installed
2024-02-05 01:45:33,398:INFO:             prophet: Not installed
2024-02-05 01:45:33,398:INFO:None
2024-02-05 01:45:33,398:INFO:Set up GPU usage.
2024-02-05 01:45:33,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,398:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:45:33,398:INFO:Set up data.
2024-02-05 01:45:33,411:INFO:Set up folding strategy.
2024-02-05 01:45:33,411:INFO:Set up train/test split.
2024-02-05 01:45:33,419:INFO:Set up index.
2024-02-05 01:45:33,419:INFO:Assigning column types.
2024-02-05 01:45:33,423:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:45:33,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,464:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,464:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:33,500:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,561:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,561:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,588:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:33,611:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,612:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:45:33,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,672:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,697:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:33,717:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,718:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:45:33,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:33,813:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,814:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:45:33,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,892:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:33,909:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:33,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,988:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:33,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:34,007:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:45:34,009:INFO:Preparing preprocessing pipeline...
2024-02-05 01:45:34,012:INFO:Set up label encoding.
2024-02-05 01:45:34,012:INFO:Set up simple imputation.
2024-02-05 01:45:34,018:INFO:Set up encoding of categorical features.
2024-02-05 01:45:34,019:INFO:Set up imbalanced handling.
2024-02-05 01:45:34,019:INFO:Set up feature normalization.
2024-02-05 01:45:34,019:INFO:Set up feature selection.
2024-02-05 01:45:34,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:45:34,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:45:34,135:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:47:02,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:47:02,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:47:02,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:47:02,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:47:11,435:INFO:PyCaret ClassificationExperiment
2024-02-05 01:47:11,435:INFO:Logging name: clf-default-name
2024-02-05 01:47:11,435:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:47:11,435:INFO:version 3.2.0
2024-02-05 01:47:11,435:INFO:Initializing setup()
2024-02-05 01:47:11,435:INFO:self.USI: 2429
2024-02-05 01:47:11,435:INFO:self._variable_keys: {'exp_id', 'USI', 'fold_generator', 'pipeline', 'X_train', 'y', 'fix_imbalance', '_ml_usecase', '_available_plots', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'memory', 'log_plots_param', 'data', 'fold_groups_param', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'target_param', 'exp_name_log', 'seed', 'n_jobs_param', 'idx', 'html_param', 'X', 'gpu_n_jobs_param'}
2024-02-05 01:47:11,435:INFO:Checking environment
2024-02-05 01:47:11,435:INFO:python_version: 3.10.9
2024-02-05 01:47:11,435:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:47:11,435:INFO:machine: AMD64
2024-02-05 01:47:11,435:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:47:11,436:INFO:Memory: svmem(total=16856182784, available=8397205504, percent=50.2, used=8458977280, free=8397205504)
2024-02-05 01:47:11,436:INFO:Physical Core: 4
2024-02-05 01:47:11,436:INFO:Logical Core: 8
2024-02-05 01:47:11,436:INFO:Checking libraries
2024-02-05 01:47:11,436:INFO:System:
2024-02-05 01:47:11,436:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:47:11,436:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:47:11,436:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:47:11,436:INFO:PyCaret required dependencies:
2024-02-05 01:47:11,517:INFO:                 pip: 22.3.1
2024-02-05 01:47:11,517:INFO:          setuptools: 65.6.3
2024-02-05 01:47:11,518:INFO:             pycaret: 3.2.0
2024-02-05 01:47:11,518:INFO:             IPython: 8.20.0
2024-02-05 01:47:11,518:INFO:          ipywidgets: 8.0.4
2024-02-05 01:47:11,518:INFO:                tqdm: 4.64.1
2024-02-05 01:47:11,518:INFO:               numpy: 1.25.2
2024-02-05 01:47:11,518:INFO:              pandas: 1.5.3
2024-02-05 01:47:11,518:INFO:              jinja2: 3.1.3
2024-02-05 01:47:11,518:INFO:               scipy: 1.10.1
2024-02-05 01:47:11,518:INFO:              joblib: 1.3.2
2024-02-05 01:47:11,518:INFO:             sklearn: 1.2.2
2024-02-05 01:47:11,518:INFO:                pyod: 1.1.2
2024-02-05 01:47:11,518:INFO:            imblearn: 0.12.0
2024-02-05 01:47:11,518:INFO:   category_encoders: 2.6.3
2024-02-05 01:47:11,518:INFO:            lightgbm: 4.3.0
2024-02-05 01:47:11,518:INFO:               numba: 0.59.0
2024-02-05 01:47:11,518:INFO:            requests: 2.31.0
2024-02-05 01:47:11,518:INFO:          matplotlib: 3.6.0
2024-02-05 01:47:11,518:INFO:          scikitplot: 0.3.7
2024-02-05 01:47:11,518:INFO:         yellowbrick: 1.5
2024-02-05 01:47:11,518:INFO:              plotly: 5.18.0
2024-02-05 01:47:11,518:INFO:    plotly-resampler: Not installed
2024-02-05 01:47:11,518:INFO:             kaleido: 0.2.1
2024-02-05 01:47:11,518:INFO:           schemdraw: 0.15
2024-02-05 01:47:11,519:INFO:         statsmodels: 0.14.1
2024-02-05 01:47:11,519:INFO:              sktime: 0.21.1
2024-02-05 01:47:11,519:INFO:               tbats: 1.1.3
2024-02-05 01:47:11,519:INFO:            pmdarima: 2.0.4
2024-02-05 01:47:11,519:INFO:              psutil: 5.9.0
2024-02-05 01:47:11,519:INFO:          markupsafe: 2.1.3
2024-02-05 01:47:11,519:INFO:             pickle5: Not installed
2024-02-05 01:47:11,519:INFO:         cloudpickle: 3.0.0
2024-02-05 01:47:11,519:INFO:         deprecation: 2.1.0
2024-02-05 01:47:11,519:INFO:              xxhash: 3.4.1
2024-02-05 01:47:11,519:INFO:           wurlitzer: Not installed
2024-02-05 01:47:11,519:INFO:PyCaret optional dependencies:
2024-02-05 01:47:11,531:INFO:                shap: 0.44.1
2024-02-05 01:47:11,531:INFO:           interpret: Not installed
2024-02-05 01:47:11,531:INFO:                umap: Not installed
2024-02-05 01:47:11,531:INFO:     ydata_profiling: Not installed
2024-02-05 01:47:11,531:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:47:11,531:INFO:             autoviz: Not installed
2024-02-05 01:47:11,531:INFO:           fairlearn: Not installed
2024-02-05 01:47:11,531:INFO:          deepchecks: Not installed
2024-02-05 01:47:11,531:INFO:             xgboost: Not installed
2024-02-05 01:47:11,531:INFO:            catboost: 1.2.2
2024-02-05 01:47:11,531:INFO:              kmodes: Not installed
2024-02-05 01:47:11,531:INFO:             mlxtend: Not installed
2024-02-05 01:47:11,531:INFO:       statsforecast: Not installed
2024-02-05 01:47:11,531:INFO:        tune_sklearn: Not installed
2024-02-05 01:47:11,531:INFO:                 ray: Not installed
2024-02-05 01:47:11,531:INFO:            hyperopt: Not installed
2024-02-05 01:47:11,531:INFO:              optuna: Not installed
2024-02-05 01:47:11,531:INFO:               skopt: Not installed
2024-02-05 01:47:11,531:INFO:              mlflow: 2.10.0
2024-02-05 01:47:11,531:INFO:              gradio: Not installed
2024-02-05 01:47:11,531:INFO:             fastapi: Not installed
2024-02-05 01:47:11,531:INFO:             uvicorn: Not installed
2024-02-05 01:47:11,532:INFO:              m2cgen: Not installed
2024-02-05 01:47:11,532:INFO:           evidently: Not installed
2024-02-05 01:47:11,532:INFO:               fugue: Not installed
2024-02-05 01:47:11,532:INFO:           streamlit: Not installed
2024-02-05 01:47:11,532:INFO:             prophet: Not installed
2024-02-05 01:47:11,532:INFO:None
2024-02-05 01:47:11,532:INFO:Set up GPU usage.
2024-02-05 01:47:11,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:47:11,532:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:47:11,532:INFO:Set up data.
2024-02-05 01:48:56,097:INFO:PyCaret ClassificationExperiment
2024-02-05 01:48:56,097:INFO:Logging name: clf-default-name
2024-02-05 01:48:56,097:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 01:48:56,097:INFO:version 3.2.0
2024-02-05 01:48:56,097:INFO:Initializing setup()
2024-02-05 01:48:56,097:INFO:self.USI: 7923
2024-02-05 01:48:56,097:INFO:self._variable_keys: {'exp_id', 'USI', 'fold_generator', 'pipeline', 'X_train', 'y', 'fix_imbalance', '_ml_usecase', '_available_plots', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'memory', 'log_plots_param', 'data', 'fold_groups_param', 'y_test', 'y_train', 'X_test', 'is_multiclass', 'target_param', 'exp_name_log', 'seed', 'n_jobs_param', 'idx', 'html_param', 'X', 'gpu_n_jobs_param'}
2024-02-05 01:48:56,097:INFO:Checking environment
2024-02-05 01:48:56,097:INFO:python_version: 3.10.9
2024-02-05 01:48:56,098:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 01:48:56,098:INFO:machine: AMD64
2024-02-05 01:48:56,098:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 01:48:56,098:INFO:Memory: svmem(total=16856182784, available=8381333504, percent=50.3, used=8474849280, free=8381333504)
2024-02-05 01:48:56,098:INFO:Physical Core: 4
2024-02-05 01:48:56,098:INFO:Logical Core: 8
2024-02-05 01:48:56,098:INFO:Checking libraries
2024-02-05 01:48:56,098:INFO:System:
2024-02-05 01:48:56,098:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 01:48:56,098:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 01:48:56,098:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 01:48:56,098:INFO:PyCaret required dependencies:
2024-02-05 01:48:56,098:INFO:                 pip: 22.3.1
2024-02-05 01:48:56,098:INFO:          setuptools: 65.6.3
2024-02-05 01:48:56,098:INFO:             pycaret: 3.2.0
2024-02-05 01:48:56,099:INFO:             IPython: 8.20.0
2024-02-05 01:48:56,099:INFO:          ipywidgets: 8.0.4
2024-02-05 01:48:56,099:INFO:                tqdm: 4.64.1
2024-02-05 01:48:56,099:INFO:               numpy: 1.25.2
2024-02-05 01:48:56,099:INFO:              pandas: 1.5.3
2024-02-05 01:48:56,099:INFO:              jinja2: 3.1.3
2024-02-05 01:48:56,099:INFO:               scipy: 1.10.1
2024-02-05 01:48:56,099:INFO:              joblib: 1.3.2
2024-02-05 01:48:56,099:INFO:             sklearn: 1.2.2
2024-02-05 01:48:56,099:INFO:                pyod: 1.1.2
2024-02-05 01:48:56,099:INFO:            imblearn: 0.12.0
2024-02-05 01:48:56,099:INFO:   category_encoders: 2.6.3
2024-02-05 01:48:56,099:INFO:            lightgbm: 4.3.0
2024-02-05 01:48:56,099:INFO:               numba: 0.59.0
2024-02-05 01:48:56,100:INFO:            requests: 2.31.0
2024-02-05 01:48:56,100:INFO:          matplotlib: 3.6.0
2024-02-05 01:48:56,100:INFO:          scikitplot: 0.3.7
2024-02-05 01:48:56,100:INFO:         yellowbrick: 1.5
2024-02-05 01:48:56,100:INFO:              plotly: 5.18.0
2024-02-05 01:48:56,100:INFO:    plotly-resampler: Not installed
2024-02-05 01:48:56,100:INFO:             kaleido: 0.2.1
2024-02-05 01:48:56,100:INFO:           schemdraw: 0.15
2024-02-05 01:48:56,100:INFO:         statsmodels: 0.14.1
2024-02-05 01:48:56,100:INFO:              sktime: 0.21.1
2024-02-05 01:48:56,100:INFO:               tbats: 1.1.3
2024-02-05 01:48:56,100:INFO:            pmdarima: 2.0.4
2024-02-05 01:48:56,100:INFO:              psutil: 5.9.0
2024-02-05 01:48:56,100:INFO:          markupsafe: 2.1.3
2024-02-05 01:48:56,101:INFO:             pickle5: Not installed
2024-02-05 01:48:56,101:INFO:         cloudpickle: 3.0.0
2024-02-05 01:48:56,101:INFO:         deprecation: 2.1.0
2024-02-05 01:48:56,101:INFO:              xxhash: 3.4.1
2024-02-05 01:48:56,101:INFO:           wurlitzer: Not installed
2024-02-05 01:48:56,101:INFO:PyCaret optional dependencies:
2024-02-05 01:48:56,101:INFO:                shap: 0.44.1
2024-02-05 01:48:56,101:INFO:           interpret: Not installed
2024-02-05 01:48:56,101:INFO:                umap: Not installed
2024-02-05 01:48:56,101:INFO:     ydata_profiling: Not installed
2024-02-05 01:48:56,101:INFO:  explainerdashboard: 0.4.5
2024-02-05 01:48:56,101:INFO:             autoviz: Not installed
2024-02-05 01:48:56,102:INFO:           fairlearn: Not installed
2024-02-05 01:48:56,102:INFO:          deepchecks: Not installed
2024-02-05 01:48:56,102:INFO:             xgboost: Not installed
2024-02-05 01:48:56,102:INFO:            catboost: 1.2.2
2024-02-05 01:48:56,102:INFO:              kmodes: Not installed
2024-02-05 01:48:56,102:INFO:             mlxtend: Not installed
2024-02-05 01:48:56,102:INFO:       statsforecast: Not installed
2024-02-05 01:48:56,102:INFO:        tune_sklearn: Not installed
2024-02-05 01:48:56,102:INFO:                 ray: Not installed
2024-02-05 01:48:56,102:INFO:            hyperopt: Not installed
2024-02-05 01:48:56,102:INFO:              optuna: Not installed
2024-02-05 01:48:56,102:INFO:               skopt: Not installed
2024-02-05 01:48:56,103:INFO:              mlflow: 2.10.0
2024-02-05 01:48:56,103:INFO:              gradio: Not installed
2024-02-05 01:48:56,103:INFO:             fastapi: Not installed
2024-02-05 01:48:56,103:INFO:             uvicorn: Not installed
2024-02-05 01:48:56,103:INFO:              m2cgen: Not installed
2024-02-05 01:48:56,103:INFO:           evidently: Not installed
2024-02-05 01:48:56,103:INFO:               fugue: Not installed
2024-02-05 01:48:56,103:INFO:           streamlit: Not installed
2024-02-05 01:48:56,103:INFO:             prophet: Not installed
2024-02-05 01:48:56,103:INFO:None
2024-02-05 01:48:56,103:INFO:Set up GPU usage.
2024-02-05 01:48:56,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,104:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-02-05 01:48:56,104:INFO:Set up data.
2024-02-05 01:48:56,119:INFO:Set up folding strategy.
2024-02-05 01:48:56,119:INFO:Set up train/test split.
2024-02-05 01:48:56,129:INFO:Set up index.
2024-02-05 01:48:56,129:INFO:Assigning column types.
2024-02-05 01:48:56,135:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 01:48:56,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,178:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:48:56,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:48:56,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,205:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:56,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,123:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 01:48:57,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:48:57,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,251:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,251:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 01:48:57,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:48:57,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,363:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,364:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 01:48:57,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,491:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,492:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 01:48:57,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,617:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,729:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,746:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:57,750:INFO:Preparing preprocessing pipeline...
2024-02-05 01:48:57,751:INFO:Set up label encoding.
2024-02-05 01:48:57,752:INFO:Set up simple imputation.
2024-02-05 01:48:57,757:INFO:Set up encoding of categorical features.
2024-02-05 01:48:57,757:INFO:Set up imbalanced handling.
2024-02-05 01:48:57,757:INFO:Set up feature normalization.
2024-02-05 01:48:57,757:INFO:Set up feature selection.
2024-02-05 01:48:57,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,828:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:57,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:57,876:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:58,373:INFO:Finished creating preprocessing pipeline.
2024-02-05 01:48:58,397:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'tot...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-05 01:48:58,397:INFO:Creating final display dataframe.
2024-02-05 01:48:58,876:INFO:Setup _display_container:                     Description             Value
0                    Session id               667
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 22)
5        Transformed data shape         (6387, 5)
6   Transformed train set shape         (5112, 5)
7    Transformed test set shape         (1275, 5)
8              Numeric features                18
9          Categorical features                 2
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19                    Normalize              True
20             Normalize method            zscore
21            Feature selection              True
22     Feature selection method           classic
23  Feature selection estimator          lightgbm
24  Number of features selected               0.2
25               Fold Generator   StratifiedKFold
26                  Fold Number                10
27                     CPU Jobs                -1
28                      Use GPU              True
29               Log Experiment             False
30              Experiment Name  clf-default-name
31                          USI              7923
2024-02-05 01:48:58,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,926:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,954:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:58,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:58,967:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:58,968:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 01:48:59,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 01:48:59,073:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 01:48:59,074:INFO:setup() successfully completed in 2.99s...............
2024-02-05 01:49:07,508:INFO:Initializing compare_models()
2024-02-05 01:49:07,508:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 01:49:07,509:INFO:Checking exceptions
2024-02-05 01:49:07,514:INFO:Preparing display monitor
2024-02-05 01:49:07,551:INFO:Initializing Logistic Regression
2024-02-05 01:49:07,552:INFO:Total runtime is 1.6661485036214194e-05 minutes
2024-02-05 01:49:07,556:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:07,557:INFO:Initializing create_model()
2024-02-05 01:49:07,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:07,557:INFO:Checking exceptions
2024-02-05 01:49:07,557:INFO:Importing libraries
2024-02-05 01:49:07,557:INFO:Copying training dataset
2024-02-05 01:49:07,564:INFO:Defining folds
2024-02-05 01:49:07,564:INFO:Declaring metric variables
2024-02-05 01:49:07,569:INFO:Importing untrained model
2024-02-05 01:49:07,574:INFO:Logistic Regression Imported successfully
2024-02-05 01:49:07,593:INFO:Starting cross validation
2024-02-05 01:49:07,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:07,773:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:07,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2024-02-05 01:49:07,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:07,774:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:07,774:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:07,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:08,409:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:08,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000505 seconds.
2024-02-05 01:49:08,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:08,410:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:08,411:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:08,411:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:08,740:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:08,741:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2024-02-05 01:49:08,741:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:08,741:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:08,741:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:08,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:09,057:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:09,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-02-05 01:49:09,057:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:09,058:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:09,058:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:09,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:09,452:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:09,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2024-02-05 01:49:09,453:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:09,453:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:09,454:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:09,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:09,732:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:09,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-02-05 01:49:09,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:09,733:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:09,734:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:09,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:10,010:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:10,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-02-05 01:49:10,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:10,011:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:10,012:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:10,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:10,281:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:10,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2024-02-05 01:49:10,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:10,282:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:10,282:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:10,282:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:10,554:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:10,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2024-02-05 01:49:10,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:10,555:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:10,555:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:10,556:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:10,815:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:10,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2024-02-05 01:49:10,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:10,816:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:10,816:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:10,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:10,999:INFO:Calculating mean and std
2024-02-05 01:49:11,000:INFO:Creating metrics dataframe
2024-02-05 01:49:11,004:INFO:Uploading results into container
2024-02-05 01:49:11,004:INFO:Uploading model into container now
2024-02-05 01:49:11,005:INFO:_master_model_container: 1
2024-02-05 01:49:11,005:INFO:_display_container: 2
2024-02-05 01:49:11,005:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=667, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-05 01:49:11,005:INFO:create_model() successfully completed......................................
2024-02-05 01:49:11,096:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:11,096:INFO:Creating metrics dataframe
2024-02-05 01:49:11,104:INFO:Initializing K Neighbors Classifier
2024-02-05 01:49:11,104:INFO:Total runtime is 0.059227975209554036 minutes
2024-02-05 01:49:11,107:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:11,108:INFO:Initializing create_model()
2024-02-05 01:49:11,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:11,108:INFO:Checking exceptions
2024-02-05 01:49:11,108:INFO:Importing libraries
2024-02-05 01:49:11,108:INFO:Copying training dataset
2024-02-05 01:49:11,115:INFO:Defining folds
2024-02-05 01:49:11,116:INFO:Declaring metric variables
2024-02-05 01:49:11,119:INFO:Importing untrained model
2024-02-05 01:49:11,126:INFO:K Neighbors Classifier Imported successfully
2024-02-05 01:49:11,134:INFO:Starting cross validation
2024-02-05 01:49:11,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:11,249:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:11,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2024-02-05 01:49:11,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:11,250:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:11,250:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:11,250:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:11,586:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:11,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2024-02-05 01:49:11,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:11,587:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:11,587:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:11,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:11,883:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:11,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2024-02-05 01:49:11,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:11,884:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:11,884:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:11,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:12,170:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:12,170:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-02-05 01:49:12,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:12,171:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:12,171:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:12,171:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:12,449:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:12,449:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
2024-02-05 01:49:12,449:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:12,449:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:12,449:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:12,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:12,739:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:12,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-02-05 01:49:12,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:12,739:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:12,740:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:12,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:13,038:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:13,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-02-05 01:49:13,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-05 01:49:13,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-05 01:49:13,039:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:13,039:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:13,039:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:13,354:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:13,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-02-05 01:49:13,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:13,355:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:13,355:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:13,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:13,639:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:13,640:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-02-05 01:49:13,640:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:13,640:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:13,640:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:13,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:13,949:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:13,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-02-05 01:49:13,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:13,950:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:13,950:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:13,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:14,164:INFO:Calculating mean and std
2024-02-05 01:49:14,165:INFO:Creating metrics dataframe
2024-02-05 01:49:14,170:INFO:Uploading results into container
2024-02-05 01:49:14,170:INFO:Uploading model into container now
2024-02-05 01:49:14,171:INFO:_master_model_container: 2
2024-02-05 01:49:14,172:INFO:_display_container: 2
2024-02-05 01:49:14,173:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-05 01:49:14,173:INFO:create_model() successfully completed......................................
2024-02-05 01:49:14,265:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:14,265:INFO:Creating metrics dataframe
2024-02-05 01:49:14,274:INFO:Initializing Naive Bayes
2024-02-05 01:49:14,274:INFO:Total runtime is 0.11205885012944539 minutes
2024-02-05 01:49:14,277:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:14,278:INFO:Initializing create_model()
2024-02-05 01:49:14,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:14,279:INFO:Checking exceptions
2024-02-05 01:49:14,279:INFO:Importing libraries
2024-02-05 01:49:14,279:INFO:Copying training dataset
2024-02-05 01:49:14,285:INFO:Defining folds
2024-02-05 01:49:14,285:INFO:Declaring metric variables
2024-02-05 01:49:14,289:INFO:Importing untrained model
2024-02-05 01:49:14,295:INFO:Naive Bayes Imported successfully
2024-02-05 01:49:14,301:INFO:Starting cross validation
2024-02-05 01:49:14,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:14,409:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:14,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-02-05 01:49:14,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:14,410:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:14,410:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:14,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:14,637:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:14,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-02-05 01:49:14,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:14,637:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:14,638:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:14,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:14,872:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:14,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.
2024-02-05 01:49:14,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:14,873:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:14,873:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:14,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:15,112:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:15,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2024-02-05 01:49:15,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:15,113:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:15,114:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:15,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:15,363:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:15,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-02-05 01:49:15,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:15,363:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:15,364:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:15,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:15,591:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:15,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-02-05 01:49:15,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:15,592:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:15,592:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:15,592:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:15,832:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:15,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000272 seconds.
2024-02-05 01:49:15,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:15,833:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:15,833:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:15,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:16,116:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:16,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2024-02-05 01:49:16,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:16,117:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:16,117:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:16,118:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:16,397:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:16,398:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2024-02-05 01:49:16,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:16,398:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:16,398:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:16,399:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:16,715:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:16,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2024-02-05 01:49:16,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:16,716:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:16,716:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:16,716:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:16,901:INFO:Calculating mean and std
2024-02-05 01:49:16,902:INFO:Creating metrics dataframe
2024-02-05 01:49:16,907:INFO:Uploading results into container
2024-02-05 01:49:16,908:INFO:Uploading model into container now
2024-02-05 01:49:16,908:INFO:_master_model_container: 3
2024-02-05 01:49:16,909:INFO:_display_container: 2
2024-02-05 01:49:16,909:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-05 01:49:16,909:INFO:create_model() successfully completed......................................
2024-02-05 01:49:17,008:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:17,008:INFO:Creating metrics dataframe
2024-02-05 01:49:17,018:INFO:Initializing Decision Tree Classifier
2024-02-05 01:49:17,018:INFO:Total runtime is 0.15777933200200397 minutes
2024-02-05 01:49:17,020:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:17,021:INFO:Initializing create_model()
2024-02-05 01:49:17,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:17,021:INFO:Checking exceptions
2024-02-05 01:49:17,021:INFO:Importing libraries
2024-02-05 01:49:17,021:INFO:Copying training dataset
2024-02-05 01:49:17,029:INFO:Defining folds
2024-02-05 01:49:17,029:INFO:Declaring metric variables
2024-02-05 01:49:17,033:INFO:Importing untrained model
2024-02-05 01:49:17,039:INFO:Decision Tree Classifier Imported successfully
2024-02-05 01:49:17,046:INFO:Starting cross validation
2024-02-05 01:49:17,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:17,174:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:17,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000593 seconds.
2024-02-05 01:49:17,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:17,175:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:17,176:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:17,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:17,506:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:17,507:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2024-02-05 01:49:17,507:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:17,507:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:17,507:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:17,508:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:17,800:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:17,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-02-05 01:49:17,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:17,801:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:17,801:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:17,801:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:18,095:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:18,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2024-02-05 01:49:18,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:18,096:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:18,097:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:18,097:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:18,394:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:18,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2024-02-05 01:49:18,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:18,395:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:18,395:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:18,396:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:18,724:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:18,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2024-02-05 01:49:18,725:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:18,725:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:18,726:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:18,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:19,036:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:19,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-02-05 01:49:19,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:19,037:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:19,037:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:19,038:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:19,343:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:19,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-02-05 01:49:19,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:19,344:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:19,345:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:19,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:19,674:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:19,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2024-02-05 01:49:19,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:19,675:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:19,675:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:19,676:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:19,976:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:19,977:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2024-02-05 01:49:19,977:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:19,977:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:19,977:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:19,977:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:20,191:INFO:Calculating mean and std
2024-02-05 01:49:20,192:INFO:Creating metrics dataframe
2024-02-05 01:49:20,200:INFO:Uploading results into container
2024-02-05 01:49:20,201:INFO:Uploading model into container now
2024-02-05 01:49:20,202:INFO:_master_model_container: 4
2024-02-05 01:49:20,202:INFO:_display_container: 2
2024-02-05 01:49:20,203:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=667, splitter='best')
2024-02-05 01:49:20,203:INFO:create_model() successfully completed......................................
2024-02-05 01:49:20,295:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:20,296:INFO:Creating metrics dataframe
2024-02-05 01:49:20,305:INFO:Initializing SVM - Linear Kernel
2024-02-05 01:49:20,306:INFO:Total runtime is 0.21259278059005737 minutes
2024-02-05 01:49:20,309:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:20,309:INFO:Initializing create_model()
2024-02-05 01:49:20,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:20,309:INFO:Checking exceptions
2024-02-05 01:49:20,310:INFO:Importing libraries
2024-02-05 01:49:20,310:INFO:Copying training dataset
2024-02-05 01:49:20,316:INFO:Defining folds
2024-02-05 01:49:20,316:INFO:Declaring metric variables
2024-02-05 01:49:20,322:INFO:Importing untrained model
2024-02-05 01:49:20,327:INFO:SVM - Linear Kernel Imported successfully
2024-02-05 01:49:20,334:INFO:Starting cross validation
2024-02-05 01:49:20,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:20,447:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:20,448:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2024-02-05 01:49:20,448:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:20,448:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:20,448:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:20,448:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:20,763:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:20,764:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2024-02-05 01:49:20,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:20,764:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:20,764:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:20,764:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:21,070:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:21,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 01:49:21,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:21,071:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:21,071:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:21,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:21,333:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:21,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-02-05 01:49:21,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:21,334:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:21,334:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:21,335:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:21,595:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:21,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-02-05 01:49:21,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:21,596:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:21,596:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:21,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:21,863:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:21,863:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2024-02-05 01:49:21,863:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:21,864:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:21,864:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:21,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:22,160:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:22,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2024-02-05 01:49:22,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:22,161:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:22,161:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:22,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:22,425:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:22,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-02-05 01:49:22,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:22,426:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:22,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:22,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:22,690:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:22,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2024-02-05 01:49:22,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:22,691:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:22,691:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:22,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:22,942:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:22,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-02-05 01:49:22,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:22,943:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:22,943:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:22,943:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:23,102:INFO:Calculating mean and std
2024-02-05 01:49:23,103:INFO:Creating metrics dataframe
2024-02-05 01:49:23,107:INFO:Uploading results into container
2024-02-05 01:49:23,108:INFO:Uploading model into container now
2024-02-05 01:49:23,109:INFO:_master_model_container: 5
2024-02-05 01:49:23,109:INFO:_display_container: 2
2024-02-05 01:49:23,110:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=667, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-05 01:49:23,110:INFO:create_model() successfully completed......................................
2024-02-05 01:49:23,200:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:23,200:INFO:Creating metrics dataframe
2024-02-05 01:49:23,209:INFO:Initializing Ridge Classifier
2024-02-05 01:49:23,209:INFO:Total runtime is 0.2609743118286133 minutes
2024-02-05 01:49:23,212:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:23,213:INFO:Initializing create_model()
2024-02-05 01:49:23,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:23,213:INFO:Checking exceptions
2024-02-05 01:49:23,213:INFO:Importing libraries
2024-02-05 01:49:23,213:INFO:Copying training dataset
2024-02-05 01:49:23,220:INFO:Defining folds
2024-02-05 01:49:23,221:INFO:Declaring metric variables
2024-02-05 01:49:23,225:INFO:Importing untrained model
2024-02-05 01:49:23,230:INFO:Ridge Classifier Imported successfully
2024-02-05 01:49:23,238:INFO:Starting cross validation
2024-02-05 01:49:23,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:23,338:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:23,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-02-05 01:49:23,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:23,339:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:23,339:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:23,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:23,588:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:23,588:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-02-05 01:49:23,588:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:23,588:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:23,588:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:23,589:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:23,842:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:23,842:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-02-05 01:49:23,842:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:23,843:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:23,843:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:23,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:24,112:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:24,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2024-02-05 01:49:24,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:24,113:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:24,113:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:24,113:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:24,356:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:24,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 01:49:24,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:24,356:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:24,356:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:24,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:24,605:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:24,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2024-02-05 01:49:24,605:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:24,605:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:24,605:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:24,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:24,877:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:24,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-02-05 01:49:24,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:24,878:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:24,878:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:24,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:25,141:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:25,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2024-02-05 01:49:25,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:25,142:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:25,142:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:25,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:25,392:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:25,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-02-05 01:49:25,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:25,393:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:25,393:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:25,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:25,647:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:25,648:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2024-02-05 01:49:25,648:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:25,648:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:25,649:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:25,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:25,821:INFO:Calculating mean and std
2024-02-05 01:49:25,822:INFO:Creating metrics dataframe
2024-02-05 01:49:25,827:INFO:Uploading results into container
2024-02-05 01:49:25,827:INFO:Uploading model into container now
2024-02-05 01:49:25,828:INFO:_master_model_container: 6
2024-02-05 01:49:25,828:INFO:_display_container: 2
2024-02-05 01:49:25,828:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=667, solver='auto',
                tol=0.0001)
2024-02-05 01:49:25,828:INFO:create_model() successfully completed......................................
2024-02-05 01:49:25,919:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:25,919:INFO:Creating metrics dataframe
2024-02-05 01:49:25,929:INFO:Initializing Random Forest Classifier
2024-02-05 01:49:25,929:INFO:Total runtime is 0.3063002705574036 minutes
2024-02-05 01:49:25,932:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:25,933:INFO:Initializing create_model()
2024-02-05 01:49:25,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:25,933:INFO:Checking exceptions
2024-02-05 01:49:25,933:INFO:Importing libraries
2024-02-05 01:49:25,933:INFO:Copying training dataset
2024-02-05 01:49:25,939:INFO:Defining folds
2024-02-05 01:49:25,939:INFO:Declaring metric variables
2024-02-05 01:49:25,942:INFO:Importing untrained model
2024-02-05 01:49:25,946:INFO:Random Forest Classifier Imported successfully
2024-02-05 01:49:25,953:INFO:Starting cross validation
2024-02-05 01:49:25,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:26,070:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:26,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
2024-02-05 01:49:26,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:26,071:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:26,072:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:26,072:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:26,700:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:26,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2024-02-05 01:49:26,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:26,701:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:26,701:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:26,701:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:27,332:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:27,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-02-05 01:49:27,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:27,333:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:27,333:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:27,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:27,980:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:27,981:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-02-05 01:49:27,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:27,981:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:27,982:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:27,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:28,626:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:28,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2024-02-05 01:49:28,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:28,628:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:28,628:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:28,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:29,244:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:29,245:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2024-02-05 01:49:29,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:29,245:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:29,245:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:29,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:29,911:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:29,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-02-05 01:49:29,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:29,912:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:29,913:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:29,913:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:30,537:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:30,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
2024-02-05 01:49:30,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:30,539:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:30,539:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:30,539:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:31,182:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:31,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2024-02-05 01:49:31,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:31,183:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:31,183:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:31,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:31,789:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:31,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2024-02-05 01:49:31,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:31,789:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:31,790:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:31,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:32,235:INFO:Calculating mean and std
2024-02-05 01:49:32,237:INFO:Creating metrics dataframe
2024-02-05 01:49:32,240:INFO:Uploading results into container
2024-02-05 01:49:32,241:INFO:Uploading model into container now
2024-02-05 01:49:32,241:INFO:_master_model_container: 7
2024-02-05 01:49:32,241:INFO:_display_container: 2
2024-02-05 01:49:32,242:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=667, verbose=0, warm_start=False)
2024-02-05 01:49:32,242:INFO:create_model() successfully completed......................................
2024-02-05 01:49:32,332:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:32,333:INFO:Creating metrics dataframe
2024-02-05 01:49:32,345:INFO:Initializing Quadratic Discriminant Analysis
2024-02-05 01:49:32,345:INFO:Total runtime is 0.4132317384084066 minutes
2024-02-05 01:49:32,349:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:32,349:INFO:Initializing create_model()
2024-02-05 01:49:32,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:32,350:INFO:Checking exceptions
2024-02-05 01:49:32,350:INFO:Importing libraries
2024-02-05 01:49:32,350:INFO:Copying training dataset
2024-02-05 01:49:32,357:INFO:Defining folds
2024-02-05 01:49:32,358:INFO:Declaring metric variables
2024-02-05 01:49:32,362:INFO:Importing untrained model
2024-02-05 01:49:32,366:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-05 01:49:32,372:INFO:Starting cross validation
2024-02-05 01:49:32,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:32,476:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:32,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-02-05 01:49:32,477:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:32,477:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:32,477:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:32,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:32,714:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:32,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
2024-02-05 01:49:32,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:32,715:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:32,715:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:32,715:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:32,956:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:32,957:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-02-05 01:49:32,957:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:32,957:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:32,957:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:32,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:33,210:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:33,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2024-02-05 01:49:33,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:33,211:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:33,212:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:33,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:33,489:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:33,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2024-02-05 01:49:33,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:33,490:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:33,490:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:33,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:33,791:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:33,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2024-02-05 01:49:33,792:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:33,792:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:33,792:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:33,792:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:34,049:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:34,050:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
2024-02-05 01:49:34,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:34,050:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:34,051:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:34,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:34,295:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:34,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-02-05 01:49:34,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:34,296:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:34,296:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:34,296:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:34,545:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:34,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2024-02-05 01:49:34,546:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:34,546:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:34,547:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:34,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:34,801:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:34,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-02-05 01:49:34,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:34,802:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:34,802:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:34,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:34,947:INFO:Calculating mean and std
2024-02-05 01:49:34,948:INFO:Creating metrics dataframe
2024-02-05 01:49:34,952:INFO:Uploading results into container
2024-02-05 01:49:34,953:INFO:Uploading model into container now
2024-02-05 01:49:34,953:INFO:_master_model_container: 8
2024-02-05 01:49:34,954:INFO:_display_container: 2
2024-02-05 01:49:34,954:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-05 01:49:34,954:INFO:create_model() successfully completed......................................
2024-02-05 01:49:35,043:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:35,044:INFO:Creating metrics dataframe
2024-02-05 01:49:35,054:INFO:Initializing Ada Boost Classifier
2024-02-05 01:49:35,055:INFO:Total runtime is 0.45840444962183635 minutes
2024-02-05 01:49:35,058:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:35,058:INFO:Initializing create_model()
2024-02-05 01:49:35,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:35,058:INFO:Checking exceptions
2024-02-05 01:49:35,058:INFO:Importing libraries
2024-02-05 01:49:35,058:INFO:Copying training dataset
2024-02-05 01:49:35,064:INFO:Defining folds
2024-02-05 01:49:35,064:INFO:Declaring metric variables
2024-02-05 01:49:35,068:INFO:Importing untrained model
2024-02-05 01:49:35,074:INFO:Ada Boost Classifier Imported successfully
2024-02-05 01:49:35,083:INFO:Starting cross validation
2024-02-05 01:49:35,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:35,186:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:35,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2024-02-05 01:49:35,187:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:35,187:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:35,188:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:35,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:35,630:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:35,631:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 01:49:35,631:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:35,631:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:35,631:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:35,631:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:36,117:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:36,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2024-02-05 01:49:36,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:36,118:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:36,118:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:36,118:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:36,596:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:36,597:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
2024-02-05 01:49:36,597:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:36,597:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:36,597:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:36,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:37,109:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:37,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2024-02-05 01:49:37,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:37,111:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:37,111:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:37,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:37,638:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:37,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-02-05 01:49:37,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:37,639:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:37,639:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:37,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:38,162:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:38,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-02-05 01:49:38,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:38,163:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:38,163:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:38,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:38,695:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:38,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.
2024-02-05 01:49:38,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:38,696:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:38,696:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:38,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:39,230:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:39,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2024-02-05 01:49:39,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:39,231:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:39,231:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:39,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:39,753:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:39,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.
2024-02-05 01:49:39,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:39,755:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:39,755:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:39,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:40,179:INFO:Calculating mean and std
2024-02-05 01:49:40,180:INFO:Creating metrics dataframe
2024-02-05 01:49:40,185:INFO:Uploading results into container
2024-02-05 01:49:40,187:INFO:Uploading model into container now
2024-02-05 01:49:40,187:INFO:_master_model_container: 9
2024-02-05 01:49:40,187:INFO:_display_container: 2
2024-02-05 01:49:40,187:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=667)
2024-02-05 01:49:40,187:INFO:create_model() successfully completed......................................
2024-02-05 01:49:40,294:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:40,294:INFO:Creating metrics dataframe
2024-02-05 01:49:40,309:INFO:Initializing Gradient Boosting Classifier
2024-02-05 01:49:40,309:INFO:Total runtime is 0.545969545841217 minutes
2024-02-05 01:49:40,314:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:40,314:INFO:Initializing create_model()
2024-02-05 01:49:40,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:40,314:INFO:Checking exceptions
2024-02-05 01:49:40,315:INFO:Importing libraries
2024-02-05 01:49:40,315:INFO:Copying training dataset
2024-02-05 01:49:40,321:INFO:Defining folds
2024-02-05 01:49:40,321:INFO:Declaring metric variables
2024-02-05 01:49:40,325:INFO:Importing untrained model
2024-02-05 01:49:40,331:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 01:49:40,340:INFO:Starting cross validation
2024-02-05 01:49:40,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:40,462:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:40,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-02-05 01:49:40,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:40,463:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:40,463:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:40,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:41,372:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:41,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-02-05 01:49:41,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:41,373:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:41,374:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:41,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:42,234:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:42,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2024-02-05 01:49:42,235:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:42,235:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:42,235:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:42,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:43,063:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:43,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-02-05 01:49:43,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:43,064:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:43,064:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:43,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:43,868:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:43,869:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 01:49:43,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:43,869:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:43,869:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:43,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:44,640:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:44,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2024-02-05 01:49:44,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:44,641:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:44,641:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:44,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:45,441:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:45,442:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-02-05 01:49:45,442:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:45,442:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:45,442:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:45,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:46,274:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:46,275:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-02-05 01:49:46,275:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:46,275:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:46,275:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:46,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:47,161:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:47,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2024-02-05 01:49:47,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:47,162:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:47,163:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:47,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:48,031:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:48,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-02-05 01:49:48,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:48,032:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:48,032:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:48,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:48,836:INFO:Calculating mean and std
2024-02-05 01:49:48,837:INFO:Creating metrics dataframe
2024-02-05 01:49:48,842:INFO:Uploading results into container
2024-02-05 01:49:48,842:INFO:Uploading model into container now
2024-02-05 01:49:48,843:INFO:_master_model_container: 10
2024-02-05 01:49:48,843:INFO:_display_container: 2
2024-02-05 01:49:48,844:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=667, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 01:49:48,845:INFO:create_model() successfully completed......................................
2024-02-05 01:49:48,940:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:48,941:INFO:Creating metrics dataframe
2024-02-05 01:49:48,954:INFO:Initializing Linear Discriminant Analysis
2024-02-05 01:49:48,954:INFO:Total runtime is 0.6900465369224549 minutes
2024-02-05 01:49:48,958:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:48,958:INFO:Initializing create_model()
2024-02-05 01:49:48,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:48,958:INFO:Checking exceptions
2024-02-05 01:49:48,958:INFO:Importing libraries
2024-02-05 01:49:48,958:INFO:Copying training dataset
2024-02-05 01:49:48,964:INFO:Defining folds
2024-02-05 01:49:48,964:INFO:Declaring metric variables
2024-02-05 01:49:48,967:INFO:Importing untrained model
2024-02-05 01:49:48,973:INFO:Linear Discriminant Analysis Imported successfully
2024-02-05 01:49:48,982:INFO:Starting cross validation
2024-02-05 01:49:48,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:49,106:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:49,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2024-02-05 01:49:49,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:49,107:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:49,108:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:49,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:49,411:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:49,412:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-02-05 01:49:49,412:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:49,412:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:49,412:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:49,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:49,726:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:49,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-02-05 01:49:49,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:49,727:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:49,727:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:49,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:50,025:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:50,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-02-05 01:49:50,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:50,026:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:50,026:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:50,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:50,335:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:50,336:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.
2024-02-05 01:49:50,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:50,337:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:50,337:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:50,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:50,697:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:50,698:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000604 seconds.
2024-02-05 01:49:50,698:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:50,698:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:50,699:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:50,699:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:51,015:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:51,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2024-02-05 01:49:51,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:51,016:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:51,016:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:51,016:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:51,310:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:51,310:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000282 seconds.
2024-02-05 01:49:51,310:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:51,310:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:51,310:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:51,311:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:51,576:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:51,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-02-05 01:49:51,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:51,577:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:51,577:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:51,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:51,827:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:51,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2024-02-05 01:49:51,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:51,828:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:51,829:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:51,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:52,001:INFO:Calculating mean and std
2024-02-05 01:49:52,002:INFO:Creating metrics dataframe
2024-02-05 01:49:52,006:INFO:Uploading results into container
2024-02-05 01:49:52,006:INFO:Uploading model into container now
2024-02-05 01:49:52,007:INFO:_master_model_container: 11
2024-02-05 01:49:52,007:INFO:_display_container: 2
2024-02-05 01:49:52,008:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-05 01:49:52,008:INFO:create_model() successfully completed......................................
2024-02-05 01:49:52,102:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:52,102:INFO:Creating metrics dataframe
2024-02-05 01:49:52,113:INFO:Initializing Extra Trees Classifier
2024-02-05 01:49:52,113:INFO:Total runtime is 0.7427062392234802 minutes
2024-02-05 01:49:52,117:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:52,118:INFO:Initializing create_model()
2024-02-05 01:49:52,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:52,118:INFO:Checking exceptions
2024-02-05 01:49:52,118:INFO:Importing libraries
2024-02-05 01:49:52,118:INFO:Copying training dataset
2024-02-05 01:49:52,125:INFO:Defining folds
2024-02-05 01:49:52,126:INFO:Declaring metric variables
2024-02-05 01:49:52,132:INFO:Importing untrained model
2024-02-05 01:49:52,136:INFO:Extra Trees Classifier Imported successfully
2024-02-05 01:49:52,144:INFO:Starting cross validation
2024-02-05 01:49:52,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:52,250:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:52,250:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2024-02-05 01:49:52,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:52,251:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:52,251:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:52,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:52,746:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:52,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-02-05 01:49:52,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:52,746:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:52,747:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:52,747:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:53,216:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:53,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-02-05 01:49:53,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:53,217:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:53,217:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:53,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:53,660:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:53,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-02-05 01:49:53,661:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:53,661:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:49:53,661:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:53,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:54,114:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:54,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2024-02-05 01:49:54,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:54,115:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:49:54,115:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:54,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:54,561:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:54,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-02-05 01:49:54,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:54,562:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:54,562:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:54,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:55,014:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:55,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2024-02-05 01:49:55,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:55,015:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:49:55,015:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:55,016:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:55,491:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:55,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-02-05 01:49:55,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:55,491:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:55,492:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:55,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:55,932:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:55,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-02-05 01:49:55,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:55,933:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:49:55,933:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:55,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:56,409:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:49:56,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.
2024-02-05 01:49:56,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:56,410:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:49:56,410:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:49:56,411:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:56,834:INFO:Calculating mean and std
2024-02-05 01:49:56,835:INFO:Creating metrics dataframe
2024-02-05 01:49:56,840:INFO:Uploading results into container
2024-02-05 01:49:56,840:INFO:Uploading model into container now
2024-02-05 01:49:56,841:INFO:_master_model_container: 12
2024-02-05 01:49:56,841:INFO:_display_container: 2
2024-02-05 01:49:56,842:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=667, verbose=0, warm_start=False)
2024-02-05 01:49:56,842:INFO:create_model() successfully completed......................................
2024-02-05 01:49:56,943:INFO:SubProcess create_model() end ==================================
2024-02-05 01:49:56,943:INFO:Creating metrics dataframe
2024-02-05 01:49:56,956:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 01:49:56,957:INFO:Total runtime is 0.8234385967254638 minutes
2024-02-05 01:49:56,961:INFO:SubProcess create_model() called ==================================
2024-02-05 01:49:56,961:INFO:Initializing create_model()
2024-02-05 01:49:56,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:49:56,962:INFO:Checking exceptions
2024-02-05 01:49:56,962:INFO:Importing libraries
2024-02-05 01:49:56,962:INFO:Copying training dataset
2024-02-05 01:49:56,968:INFO:Defining folds
2024-02-05 01:49:56,968:INFO:Declaring metric variables
2024-02-05 01:49:56,974:INFO:Importing untrained model
2024-02-05 01:49:56,979:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 01:49:56,990:INFO:Starting cross validation
2024-02-05 01:49:56,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:49:57,109:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:57,110:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2024-02-05 01:49:57,110:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:57,110:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:49:57,110:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:57,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:57,249:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:57,250:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:49:57,250:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:49:57,250:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:49:57,250:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:49:57,250:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:49:57,256:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:49:57,259:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:49:57,261:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000181 secs. 0 sparse feature groups
2024-02-05 01:49:57,262:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:58,578:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:58,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2024-02-05 01:49:58,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:49:58,579:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:49:58,579:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:49:58,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:49:58,729:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:49:58,729:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:49:58,729:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:49:58,730:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:49:58,730:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:49:58,730:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:49:58,735:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:49:58,737:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:49:58,740:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000142 secs. 0 sparse feature groups
2024-02-05 01:49:58,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:00,090:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:00,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2024-02-05 01:50:00,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:00,092:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:50:00,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:00,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:00,248:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:00,248:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:00,249:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:00,249:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:50:00,249:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:00,249:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:00,254:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:00,256:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:00,259:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000154 secs. 0 sparse feature groups
2024-02-05 01:50:00,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:01,737:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:01,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000648 seconds.
2024-02-05 01:50:01,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:01,739:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:50:01,739:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:01,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:01,927:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:01,933:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:01,936:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:01,939:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000146 secs. 0 sparse feature groups
2024-02-05 01:50:01,939:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:03,582:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:03,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001779 seconds.
2024-02-05 01:50:03,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:03,585:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:50:03,586:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:03,587:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:03,808:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:03,808:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:03,808:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:03,808:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:50:03,809:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:03,809:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:03,815:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:03,819:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:03,821:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000164 secs. 0 sparse feature groups
2024-02-05 01:50:03,821:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:05,277:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:05,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
2024-02-05 01:50:05,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:05,278:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:50:05,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:05,279:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:05,434:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:05,435:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:05,435:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:05,435:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 4
2024-02-05 01:50:05,435:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:05,435:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:05,441:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:05,443:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:05,446:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000171 secs. 0 sparse feature groups
2024-02-05 01:50:05,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:06,812:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:06,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.
2024-02-05 01:50:06,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:06,813:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:50:06,814:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:50:06,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 4
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:06,943:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:06,949:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:06,951:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:06,954:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000133 secs. 0 sparse feature groups
2024-02-05 01:50:06,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:08,544:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:08,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
2024-02-05 01:50:08,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:08,545:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:50:08,546:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:50:08,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:08,719:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:08,719:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:08,719:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:08,720:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 4
2024-02-05 01:50:08,720:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:08,720:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:08,726:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:08,728:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:08,731:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000135 secs. 0 sparse feature groups
2024-02-05 01:50:08,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:10,262:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:10,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.
2024-02-05 01:50:10,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:10,263:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:50:10,263:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:50:10,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:10,448:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:10,448:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:10,448:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:10,448:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 4
2024-02-05 01:50:10,449:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:10,449:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:10,455:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:10,457:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:10,460:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000162 secs. 0 sparse feature groups
2024-02-05 01:50:10,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:12,050:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:12,051:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.
2024-02-05 01:50:12,051:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:12,052:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:50:12,052:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:50:12,052:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:12,232:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:50:12,232:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:50:12,232:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:50:12,232:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 4
2024-02-05 01:50:12,232:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:50:12,233:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:50:12,239:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:50:12,241:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:50:12,244:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000173 secs. 0 sparse feature groups
2024-02-05 01:50:12,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:13,677:INFO:Calculating mean and std
2024-02-05 01:50:13,679:INFO:Creating metrics dataframe
2024-02-05 01:50:13,688:INFO:Uploading results into container
2024-02-05 01:50:13,689:INFO:Uploading model into container now
2024-02-05 01:50:13,690:INFO:_master_model_container: 13
2024-02-05 01:50:13,690:INFO:_display_container: 2
2024-02-05 01:50:13,692:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=667, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 01:50:13,692:INFO:create_model() successfully completed......................................
2024-02-05 01:50:13,815:INFO:SubProcess create_model() end ==================================
2024-02-05 01:50:13,815:INFO:Creating metrics dataframe
2024-02-05 01:50:13,833:INFO:Initializing CatBoost Classifier
2024-02-05 01:50:13,834:INFO:Total runtime is 1.104727602005005 minutes
2024-02-05 01:50:13,840:INFO:SubProcess create_model() called ==================================
2024-02-05 01:50:13,840:INFO:Initializing create_model()
2024-02-05 01:50:13,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:50:13,841:INFO:Checking exceptions
2024-02-05 01:50:13,841:INFO:Importing libraries
2024-02-05 01:50:13,841:INFO:Copying training dataset
2024-02-05 01:50:13,850:INFO:Defining folds
2024-02-05 01:50:13,850:INFO:Declaring metric variables
2024-02-05 01:50:13,855:INFO:Importing untrained model
2024-02-05 01:50:13,865:INFO:CatBoost Classifier Imported successfully
2024-02-05 01:50:13,877:INFO:Starting cross validation
2024-02-05 01:50:13,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:50:14,043:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:14,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.
2024-02-05 01:50:14,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:14,044:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:50:14,045:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:14,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:50:46,311:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:50:46,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.
2024-02-05 01:50:46,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:50:46,313:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:50:46,313:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:50:46,313:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:51:16,712:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:51:16,714:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000641 seconds.
2024-02-05 01:51:16,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:51:16,714:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:51:16,714:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:51:16,714:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:51:54,857:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:51:54,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000737 seconds.
2024-02-05 01:51:54,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:51:54,859:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:51:54,859:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:51:54,860:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:52:29,469:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:52:29,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.
2024-02-05 01:52:29,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-05 01:52:29,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-05 01:52:29,470:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:52:29,470:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:52:29,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:53:07,067:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:53:07,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.
2024-02-05 01:53:07,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:53:07,069:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:53:07,069:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:53:07,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:53:42,536:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:53:42,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
2024-02-05 01:53:42,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:53:42,537:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:53:42,537:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:53:42,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:54:21,128:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:54:21,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.
2024-02-05 01:54:21,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:54:21,129:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:54:21,130:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:54:21,130:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:55:02,033:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:55:02,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001194 seconds.
2024-02-05 01:55:02,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:55:02,035:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:55:02,035:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:55:02,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:55:48,026:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:55:48,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001355 seconds.
2024-02-05 01:55:48,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:55:48,029:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:55:48,029:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:55:48,030:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:34,041:INFO:Calculating mean and std
2024-02-05 01:56:34,044:INFO:Creating metrics dataframe
2024-02-05 01:56:34,057:INFO:Uploading results into container
2024-02-05 01:56:34,059:INFO:Uploading model into container now
2024-02-05 01:56:34,061:INFO:_master_model_container: 14
2024-02-05 01:56:34,062:INFO:_display_container: 2
2024-02-05 01:56:34,062:INFO:<catboost.core.CatBoostClassifier object at 0x000002F2A65935E0>
2024-02-05 01:56:34,062:INFO:create_model() successfully completed......................................
2024-02-05 01:56:34,303:INFO:SubProcess create_model() end ==================================
2024-02-05 01:56:34,304:INFO:Creating metrics dataframe
2024-02-05 01:56:34,368:INFO:Initializing Dummy Classifier
2024-02-05 01:56:34,368:INFO:Total runtime is 7.446949950853984 minutes
2024-02-05 01:56:34,380:INFO:SubProcess create_model() called ==================================
2024-02-05 01:56:34,381:INFO:Initializing create_model()
2024-02-05 01:56:34,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002F2A25E17B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:56:34,384:INFO:Checking exceptions
2024-02-05 01:56:34,384:INFO:Importing libraries
2024-02-05 01:56:34,384:INFO:Copying training dataset
2024-02-05 01:56:34,415:INFO:Defining folds
2024-02-05 01:56:34,415:INFO:Declaring metric variables
2024-02-05 01:56:34,429:INFO:Importing untrained model
2024-02-05 01:56:34,450:INFO:Dummy Classifier Imported successfully
2024-02-05 01:56:34,486:INFO:Starting cross validation
2024-02-05 01:56:34,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-02-05 01:56:34,950:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:34,953:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001859 seconds.
2024-02-05 01:56:34,953:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:34,954:INFO:[LightGBM] [Info] Total Bins 5347
2024-02-05 01:56:34,955:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:34,956:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:36,119:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:36,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001701 seconds.
2024-02-05 01:56:36,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:36,122:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:56:36,122:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:36,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:37,167:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:37,170:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001554 seconds.
2024-02-05 01:56:37,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:37,171:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:56:37,171:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:37,172:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:38,130:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:38,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001673 seconds.
2024-02-05 01:56:38,133:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:38,133:INFO:[LightGBM] [Info] Total Bins 5349
2024-02-05 01:56:38,134:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:38,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:39,095:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:39,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001978 seconds.
2024-02-05 01:56:39,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:39,098:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:56:39,099:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:39,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:40,104:INFO:[LightGBM] [Info] Number of positive: 2300, number of negative: 2300
2024-02-05 01:56:40,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.
2024-02-05 01:56:40,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:40,108:INFO:[LightGBM] [Info] Total Bins 5346
2024-02-05 01:56:40,109:INFO:[LightGBM] [Info] Number of data points in the train set: 4600, number of used features: 22
2024-02-05 01:56:40,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:41,188:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:56:41,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001657 seconds.
2024-02-05 01:56:41,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:41,191:INFO:[LightGBM] [Info] Total Bins 5354
2024-02-05 01:56:41,192:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:56:41,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:42,140:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:56:42,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.
2024-02-05 01:56:42,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:42,142:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:56:42,143:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:56:42,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:43,146:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:56:43,149:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001738 seconds.
2024-02-05 01:56:43,149:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:43,150:INFO:[LightGBM] [Info] Total Bins 5345
2024-02-05 01:56:43,151:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:56:43,152:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:44,330:INFO:[LightGBM] [Info] Number of positive: 2301, number of negative: 2301
2024-02-05 01:56:44,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001799 seconds.
2024-02-05 01:56:44,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:44,335:INFO:[LightGBM] [Info] Total Bins 5348
2024-02-05 01:56:44,335:INFO:[LightGBM] [Info] Number of data points in the train set: 4602, number of used features: 22
2024-02-05 01:56:44,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:45,214:INFO:Calculating mean and std
2024-02-05 01:56:45,218:INFO:Creating metrics dataframe
2024-02-05 01:56:45,235:INFO:Uploading results into container
2024-02-05 01:56:45,239:INFO:Uploading model into container now
2024-02-05 01:56:45,240:INFO:_master_model_container: 15
2024-02-05 01:56:45,241:INFO:_display_container: 2
2024-02-05 01:56:45,242:INFO:DummyClassifier(constant=None, random_state=667, strategy='prior')
2024-02-05 01:56:45,244:INFO:create_model() successfully completed......................................
2024-02-05 01:56:45,499:INFO:SubProcess create_model() end ==================================
2024-02-05 01:56:45,499:INFO:Creating metrics dataframe
2024-02-05 01:56:45,609:INFO:Initializing create_model()
2024-02-05 01:56:45,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=667, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:56:45,610:INFO:Checking exceptions
2024-02-05 01:56:45,621:INFO:Importing libraries
2024-02-05 01:56:45,623:INFO:Copying training dataset
2024-02-05 01:56:45,654:INFO:Defining folds
2024-02-05 01:56:45,654:INFO:Declaring metric variables
2024-02-05 01:56:45,655:INFO:Importing untrained model
2024-02-05 01:56:45,655:INFO:Declaring custom model
2024-02-05 01:56:45,658:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 01:56:45,696:INFO:Cross validation set to False
2024-02-05 01:56:45,696:INFO:Fitting Model
2024-02-05 01:56:46,149:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:56:46,153:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.
2024-02-05 01:56:46,153:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:46,153:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:56:46,154:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 22
2024-02-05 01:56:46,155:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:46,852:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:56:46,853:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-02-05 01:56:46,853:INFO:[LightGBM] [Info] Total Bins 1020
2024-02-05 01:56:46,854:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 4
2024-02-05 01:56:46,855:INFO:[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Plus Graphics, Vendor: Intel(R) Corporation
2024-02-05 01:56:46,855:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2024-02-05 01:56:46,876:INFO:[LightGBM] [Info] GPU programs have been built
2024-02-05 01:56:46,883:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-02-05 01:56:46,893:INFO:[LightGBM] [Info] 4 dense feature groups (0.02 MB) transferred to GPU in 0.000594 secs. 0 sparse feature groups
2024-02-05 01:56:46,894:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:50,876:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=667, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 01:56:50,876:INFO:create_model() successfully completed......................................
2024-02-05 01:56:51,033:INFO:Initializing create_model()
2024-02-05 01:56:51,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=667, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:56:51,034:INFO:Checking exceptions
2024-02-05 01:56:51,036:INFO:Importing libraries
2024-02-05 01:56:51,037:INFO:Copying training dataset
2024-02-05 01:56:51,051:INFO:Defining folds
2024-02-05 01:56:51,051:INFO:Declaring metric variables
2024-02-05 01:56:51,052:INFO:Importing untrained model
2024-02-05 01:56:51,052:INFO:Declaring custom model
2024-02-05 01:56:51,053:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 01:56:51,069:INFO:Cross validation set to False
2024-02-05 01:56:51,069:INFO:Fitting Model
2024-02-05 01:56:51,243:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:56:51,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.
2024-02-05 01:56:51,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:51,244:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:56:51,244:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 22
2024-02-05 01:56:51,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:56:52,094:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=667, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 01:56:52,094:INFO:create_model() successfully completed......................................
2024-02-05 01:56:52,185:INFO:Initializing create_model()
2024-02-05 01:56:52,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002F2A65935E0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:56:52,185:INFO:Checking exceptions
2024-02-05 01:56:52,187:INFO:Importing libraries
2024-02-05 01:56:52,188:INFO:Copying training dataset
2024-02-05 01:56:52,195:INFO:Defining folds
2024-02-05 01:56:52,196:INFO:Declaring metric variables
2024-02-05 01:56:52,196:INFO:Importing untrained model
2024-02-05 01:56:52,196:INFO:Declaring custom model
2024-02-05 01:56:52,196:INFO:CatBoost Classifier Imported successfully
2024-02-05 01:56:52,202:INFO:Cross validation set to False
2024-02-05 01:56:52,202:INFO:Fitting Model
2024-02-05 01:56:52,293:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:56:52,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2024-02-05 01:56:52,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:56:52,294:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:56:52,294:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 22
2024-02-05 01:56:52,294:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:57:26,924:INFO:<catboost.core.CatBoostClassifier object at 0x000002F2ACEA50C0>
2024-02-05 01:57:26,924:INFO:create_model() successfully completed......................................
2024-02-05 01:57:27,020:INFO:Initializing create_model()
2024-02-05 01:57:27,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=667, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:57:27,021:INFO:Checking exceptions
2024-02-05 01:57:27,025:INFO:Importing libraries
2024-02-05 01:57:27,025:INFO:Copying training dataset
2024-02-05 01:57:27,032:INFO:Defining folds
2024-02-05 01:57:27,032:INFO:Declaring metric variables
2024-02-05 01:57:27,032:INFO:Importing untrained model
2024-02-05 01:57:27,032:INFO:Declaring custom model
2024-02-05 01:57:27,033:INFO:Random Forest Classifier Imported successfully
2024-02-05 01:57:27,044:INFO:Cross validation set to False
2024-02-05 01:57:27,044:INFO:Fitting Model
2024-02-05 01:57:27,178:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:57:27,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.
2024-02-05 01:57:27,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:57:27,179:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:57:27,179:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 22
2024-02-05 01:57:27,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:57:27,792:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=667, verbose=0, warm_start=False)
2024-02-05 01:57:27,792:INFO:create_model() successfully completed......................................
2024-02-05 01:57:27,910:INFO:Initializing create_model()
2024-02-05 01:57:27,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=667, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 01:57:27,910:INFO:Checking exceptions
2024-02-05 01:57:27,914:INFO:Importing libraries
2024-02-05 01:57:27,914:INFO:Copying training dataset
2024-02-05 01:57:27,925:INFO:Defining folds
2024-02-05 01:57:27,926:INFO:Declaring metric variables
2024-02-05 01:57:27,926:INFO:Importing untrained model
2024-02-05 01:57:27,926:INFO:Declaring custom model
2024-02-05 01:57:27,928:INFO:Extra Trees Classifier Imported successfully
2024-02-05 01:57:27,943:INFO:Cross validation set to False
2024-02-05 01:57:27,943:INFO:Fitting Model
2024-02-05 01:57:28,113:INFO:[LightGBM] [Info] Number of positive: 2556, number of negative: 2556
2024-02-05 01:57:28,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
2024-02-05 01:57:28,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 01:57:28,115:INFO:[LightGBM] [Info] Total Bins 5350
2024-02-05 01:57:28,116:INFO:[LightGBM] [Info] Number of data points in the train set: 5112, number of used features: 22
2024-02-05 01:57:28,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-05 01:57:28,596:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=667, verbose=0, warm_start=False)
2024-02-05 01:57:28,597:INFO:create_model() successfully completed......................................
2024-02-05 01:57:28,746:INFO:_master_model_container: 15
2024-02-05 01:57:28,746:INFO:_display_container: 2
2024-02-05 01:57:28,748:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=667, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=667, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x000002F2ACEA50C0>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=667, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=667, verbose=0, warm_start=False)]
2024-02-05 01:57:28,748:INFO:compare_models() successfully completed......................................
2024-02-05 01:57:28,789:INFO:Initializing tune_model()
2024-02-05 01:57:28,789:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=667, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002F2FDDEAAA0>)
2024-02-05 01:57:28,790:INFO:Checking exceptions
2024-02-05 01:57:28,816:INFO:Copying training dataset
2024-02-05 01:57:28,828:INFO:Checking base model
2024-02-05 01:57:28,828:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 01:57:28,838:INFO:Declaring metric variables
2024-02-05 01:57:28,844:INFO:Defining Hyperparameters
2024-02-05 01:57:28,978:INFO:Tuning with n_jobs=1
2024-02-05 01:57:28,978:INFO:Initializing RandomizedSearchCV
2024-02-05 02:05:15,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 02:05:15,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 02:05:15,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 02:05:15,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 02:05:16,480:INFO:PyCaret ClassificationExperiment
2024-02-05 02:05:16,480:INFO:Logging name: clf-default-name
2024-02-05 02:05:16,480:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 02:05:16,480:INFO:version 3.2.0
2024-02-05 02:05:16,480:INFO:Initializing setup()
2024-02-05 02:05:16,480:INFO:self.USI: d176
2024-02-05 02:05:16,481:INFO:self._variable_keys: {'data', '_ml_usecase', 'memory', 'n_jobs_param', 'idx', 'gpu_n_jobs_param', 'exp_id', 'fold_generator', 'target_param', 'y_train', 'fold_groups_param', 'y_test', 'log_plots_param', 'seed', 'pipeline', 'X', 'exp_name_log', 'fix_imbalance', 'USI', 'X_train', 'gpu_param', 'html_param', 'y', 'fold_shuffle_param', 'is_multiclass', '_available_plots', 'X_test', 'logging_param'}
2024-02-05 02:05:16,481:INFO:Checking environment
2024-02-05 02:05:16,481:INFO:python_version: 3.10.9
2024-02-05 02:05:16,481:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 02:05:16,481:INFO:machine: AMD64
2024-02-05 02:05:16,481:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 02:05:16,481:INFO:Memory: svmem(total=16856182784, available=10178379776, percent=39.6, used=6677803008, free=10178379776)
2024-02-05 02:05:16,481:INFO:Physical Core: 4
2024-02-05 02:05:16,481:INFO:Logical Core: 8
2024-02-05 02:05:16,481:INFO:Checking libraries
2024-02-05 02:05:16,481:INFO:System:
2024-02-05 02:05:16,482:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 02:05:16,482:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 02:05:16,482:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 02:05:16,482:INFO:PyCaret required dependencies:
2024-02-05 02:05:16,617:INFO:                 pip: 22.3.1
2024-02-05 02:05:16,617:INFO:          setuptools: 65.6.3
2024-02-05 02:05:16,617:INFO:             pycaret: 3.2.0
2024-02-05 02:05:16,617:INFO:             IPython: 8.20.0
2024-02-05 02:05:16,617:INFO:          ipywidgets: 8.0.4
2024-02-05 02:05:16,617:INFO:                tqdm: 4.64.1
2024-02-05 02:05:16,618:INFO:               numpy: 1.25.2
2024-02-05 02:05:16,618:INFO:              pandas: 1.5.3
2024-02-05 02:05:16,618:INFO:              jinja2: 3.1.3
2024-02-05 02:05:16,618:INFO:               scipy: 1.10.1
2024-02-05 02:05:16,618:INFO:              joblib: 1.3.2
2024-02-05 02:05:16,618:INFO:             sklearn: 1.2.2
2024-02-05 02:05:16,618:INFO:                pyod: 1.1.2
2024-02-05 02:05:16,618:INFO:            imblearn: 0.12.0
2024-02-05 02:05:16,618:INFO:   category_encoders: 2.6.3
2024-02-05 02:05:16,619:INFO:            lightgbm: 4.3.0
2024-02-05 02:05:16,619:INFO:               numba: 0.59.0
2024-02-05 02:05:16,619:INFO:            requests: 2.31.0
2024-02-05 02:05:16,619:INFO:          matplotlib: 3.6.0
2024-02-05 02:05:16,619:INFO:          scikitplot: 0.3.7
2024-02-05 02:05:16,619:INFO:         yellowbrick: 1.5
2024-02-05 02:05:16,619:INFO:              plotly: 5.18.0
2024-02-05 02:05:16,619:INFO:    plotly-resampler: Not installed
2024-02-05 02:05:16,619:INFO:             kaleido: 0.2.1
2024-02-05 02:05:16,619:INFO:           schemdraw: 0.15
2024-02-05 02:05:16,619:INFO:         statsmodels: 0.14.1
2024-02-05 02:05:16,619:INFO:              sktime: 0.21.1
2024-02-05 02:05:16,619:INFO:               tbats: 1.1.3
2024-02-05 02:05:16,619:INFO:            pmdarima: 2.0.4
2024-02-05 02:05:16,619:INFO:              psutil: 5.9.0
2024-02-05 02:05:16,620:INFO:          markupsafe: 2.1.3
2024-02-05 02:05:16,620:INFO:             pickle5: Not installed
2024-02-05 02:05:16,620:INFO:         cloudpickle: 3.0.0
2024-02-05 02:05:16,620:INFO:         deprecation: 2.1.0
2024-02-05 02:05:16,620:INFO:              xxhash: 3.4.1
2024-02-05 02:05:16,620:INFO:           wurlitzer: Not installed
2024-02-05 02:05:16,620:INFO:PyCaret optional dependencies:
2024-02-05 02:05:16,638:INFO:                shap: 0.44.1
2024-02-05 02:05:16,638:INFO:           interpret: Not installed
2024-02-05 02:05:16,638:INFO:                umap: Not installed
2024-02-05 02:05:16,638:INFO:     ydata_profiling: Not installed
2024-02-05 02:05:16,638:INFO:  explainerdashboard: 0.4.5
2024-02-05 02:05:16,639:INFO:             autoviz: Not installed
2024-02-05 02:05:16,639:INFO:           fairlearn: Not installed
2024-02-05 02:05:16,639:INFO:          deepchecks: Not installed
2024-02-05 02:05:16,639:INFO:             xgboost: Not installed
2024-02-05 02:05:16,639:INFO:            catboost: 1.2.2
2024-02-05 02:05:16,639:INFO:              kmodes: Not installed
2024-02-05 02:05:16,639:INFO:             mlxtend: Not installed
2024-02-05 02:05:16,639:INFO:       statsforecast: Not installed
2024-02-05 02:05:16,639:INFO:        tune_sklearn: Not installed
2024-02-05 02:05:16,639:INFO:                 ray: Not installed
2024-02-05 02:05:16,639:INFO:            hyperopt: Not installed
2024-02-05 02:05:16,639:INFO:              optuna: Not installed
2024-02-05 02:05:16,639:INFO:               skopt: Not installed
2024-02-05 02:05:16,639:INFO:              mlflow: 2.10.0
2024-02-05 02:05:16,639:INFO:              gradio: Not installed
2024-02-05 02:05:16,639:INFO:             fastapi: Not installed
2024-02-05 02:05:16,639:INFO:             uvicorn: Not installed
2024-02-05 02:05:16,639:INFO:              m2cgen: Not installed
2024-02-05 02:05:16,639:INFO:           evidently: Not installed
2024-02-05 02:05:16,639:INFO:               fugue: Not installed
2024-02-05 02:05:16,639:INFO:           streamlit: Not installed
2024-02-05 02:05:16,640:INFO:             prophet: Not installed
2024-02-05 02:05:16,640:INFO:None
2024-02-05 02:05:16,640:INFO:Set up data.
2024-02-05 02:05:16,757:INFO:Set up folding strategy.
2024-02-05 02:05:16,757:INFO:Set up train/test split.
2024-02-05 02:05:16,771:INFO:Set up index.
2024-02-05 02:05:16,772:INFO:Assigning column types.
2024-02-05 02:05:16,779:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 02:05:16,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 02:05:16,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 02:05:16,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:16,868:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,009:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 02:05:17,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 02:05:17,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,038:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,039:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 02:05:17,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 02:05:17,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,112:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,154:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 02:05:17,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,182:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,183:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 02:05:17,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,258:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,369:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:17,372:INFO:Preparing preprocessing pipeline...
2024-02-05 02:05:17,376:INFO:Set up label encoding.
2024-02-05 02:05:17,376:INFO:Set up simple imputation.
2024-02-05 02:05:17,382:INFO:Set up encoding of categorical features.
2024-02-05 02:05:17,530:INFO:Finished creating preprocessing pipeline.
2024-02-05 02:05:17,542:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'tot...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-02-05 02:05:17,543:INFO:Creating final display dataframe.
2024-02-05 02:05:17,866:INFO:Setup _display_container:                     Description             Value
0                    Session id              6328
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 22)
5        Transformed data shape        (4250, 23)
6   Transformed train set shape        (2975, 23)
7    Transformed test set shape        (1275, 23)
8              Numeric features                18
9          Categorical features                 2
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              d176
2024-02-05 02:05:17,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:17,986:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:18,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 02:05:18,073:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 02:05:18,073:INFO:setup() successfully completed in 1.6s...............
2024-02-05 02:05:18,105:INFO:Initializing compare_models()
2024-02-05 02:05:18,105:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, 'include': None, 'exclude': ['svm', 'lr', 'ridge', 'dt', 'qda'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['svm', 'lr', 'ridge', 'dt', 'qda'])
2024-02-05 02:05:18,105:INFO:Checking exceptions
2024-02-05 02:05:18,111:INFO:Preparing display monitor
2024-02-05 02:05:18,142:INFO:Initializing K Neighbors Classifier
2024-02-05 02:05:18,142:INFO:Total runtime is 0.0 minutes
2024-02-05 02:05:18,148:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:18,148:INFO:Initializing create_model()
2024-02-05 02:05:18,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:18,150:INFO:Checking exceptions
2024-02-05 02:05:18,150:INFO:Importing libraries
2024-02-05 02:05:18,150:INFO:Copying training dataset
2024-02-05 02:05:18,161:INFO:Defining folds
2024-02-05 02:05:18,161:INFO:Declaring metric variables
2024-02-05 02:05:18,165:INFO:Importing untrained model
2024-02-05 02:05:18,171:INFO:K Neighbors Classifier Imported successfully
2024-02-05 02:05:18,179:INFO:Starting cross validation
2024-02-05 02:05:18,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:24,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,259:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,353:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,590:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,593:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,599:INFO:Calculating mean and std
2024-02-05 02:05:24,600:INFO:Creating metrics dataframe
2024-02-05 02:05:24,604:INFO:Uploading results into container
2024-02-05 02:05:24,605:INFO:Uploading model into container now
2024-02-05 02:05:24,606:INFO:_master_model_container: 1
2024-02-05 02:05:24,606:INFO:_display_container: 2
2024-02-05 02:05:24,607:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-05 02:05:24,608:INFO:create_model() successfully completed......................................
2024-02-05 02:05:24,694:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:24,694:INFO:Creating metrics dataframe
2024-02-05 02:05:24,704:INFO:Initializing Naive Bayes
2024-02-05 02:05:24,705:INFO:Total runtime is 0.1093839963277181 minutes
2024-02-05 02:05:24,709:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:24,709:INFO:Initializing create_model()
2024-02-05 02:05:24,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:24,710:INFO:Checking exceptions
2024-02-05 02:05:24,710:INFO:Importing libraries
2024-02-05 02:05:24,710:INFO:Copying training dataset
2024-02-05 02:05:24,716:INFO:Defining folds
2024-02-05 02:05:24,716:INFO:Declaring metric variables
2024-02-05 02:05:24,721:INFO:Importing untrained model
2024-02-05 02:05:24,725:INFO:Naive Bayes Imported successfully
2024-02-05 02:05:24,734:INFO:Starting cross validation
2024-02-05 02:05:24,736:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:24,957:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,963:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,971:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:24,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,010:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,013:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,096:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:25,122:INFO:Calculating mean and std
2024-02-05 02:05:25,124:INFO:Creating metrics dataframe
2024-02-05 02:05:25,129:INFO:Uploading results into container
2024-02-05 02:05:25,130:INFO:Uploading model into container now
2024-02-05 02:05:25,130:INFO:_master_model_container: 2
2024-02-05 02:05:25,130:INFO:_display_container: 2
2024-02-05 02:05:25,131:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-05 02:05:25,131:INFO:create_model() successfully completed......................................
2024-02-05 02:05:25,210:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:25,210:INFO:Creating metrics dataframe
2024-02-05 02:05:25,220:INFO:Initializing Random Forest Classifier
2024-02-05 02:05:25,220:INFO:Total runtime is 0.11796855131785075 minutes
2024-02-05 02:05:25,224:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:25,224:INFO:Initializing create_model()
2024-02-05 02:05:25,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:25,224:INFO:Checking exceptions
2024-02-05 02:05:25,224:INFO:Importing libraries
2024-02-05 02:05:25,225:INFO:Copying training dataset
2024-02-05 02:05:25,231:INFO:Defining folds
2024-02-05 02:05:25,231:INFO:Declaring metric variables
2024-02-05 02:05:25,236:INFO:Importing untrained model
2024-02-05 02:05:25,240:INFO:Random Forest Classifier Imported successfully
2024-02-05 02:05:25,247:INFO:Starting cross validation
2024-02-05 02:05:25,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:26,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,612:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,665:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,749:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:26,757:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,207:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:27,227:INFO:Calculating mean and std
2024-02-05 02:05:27,229:INFO:Creating metrics dataframe
2024-02-05 02:05:27,232:INFO:Uploading results into container
2024-02-05 02:05:27,232:INFO:Uploading model into container now
2024-02-05 02:05:27,233:INFO:_master_model_container: 3
2024-02-05 02:05:27,233:INFO:_display_container: 2
2024-02-05 02:05:27,233:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:05:27,233:INFO:create_model() successfully completed......................................
2024-02-05 02:05:27,308:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:27,308:INFO:Creating metrics dataframe
2024-02-05 02:05:27,323:INFO:Initializing Ada Boost Classifier
2024-02-05 02:05:27,323:INFO:Total runtime is 0.1530150890350342 minutes
2024-02-05 02:05:27,328:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:27,329:INFO:Initializing create_model()
2024-02-05 02:05:27,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:27,329:INFO:Checking exceptions
2024-02-05 02:05:27,329:INFO:Importing libraries
2024-02-05 02:05:27,329:INFO:Copying training dataset
2024-02-05 02:05:27,339:INFO:Defining folds
2024-02-05 02:05:27,340:INFO:Declaring metric variables
2024-02-05 02:05:27,344:INFO:Importing untrained model
2024-02-05 02:05:27,350:INFO:Ada Boost Classifier Imported successfully
2024-02-05 02:05:27,360:INFO:Starting cross validation
2024-02-05 02:05:27,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:28,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,186:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,212:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,564:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:28,587:INFO:Calculating mean and std
2024-02-05 02:05:28,588:INFO:Creating metrics dataframe
2024-02-05 02:05:28,591:INFO:Uploading results into container
2024-02-05 02:05:28,592:INFO:Uploading model into container now
2024-02-05 02:05:28,592:INFO:_master_model_container: 4
2024-02-05 02:05:28,593:INFO:_display_container: 2
2024-02-05 02:05:28,593:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6328)
2024-02-05 02:05:28,593:INFO:create_model() successfully completed......................................
2024-02-05 02:05:28,669:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:28,669:INFO:Creating metrics dataframe
2024-02-05 02:05:28,680:INFO:Initializing Gradient Boosting Classifier
2024-02-05 02:05:28,680:INFO:Total runtime is 0.1756388584772746 minutes
2024-02-05 02:05:28,683:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:28,684:INFO:Initializing create_model()
2024-02-05 02:05:28,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:28,684:INFO:Checking exceptions
2024-02-05 02:05:28,684:INFO:Importing libraries
2024-02-05 02:05:28,684:INFO:Copying training dataset
2024-02-05 02:05:28,690:INFO:Defining folds
2024-02-05 02:05:28,690:INFO:Declaring metric variables
2024-02-05 02:05:28,694:INFO:Importing untrained model
2024-02-05 02:05:28,700:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 02:05:28,707:INFO:Starting cross validation
2024-02-05 02:05:28,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:30,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,436:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,451:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,460:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,529:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,538:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:30,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,584:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,602:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,625:INFO:Calculating mean and std
2024-02-05 02:05:31,627:INFO:Creating metrics dataframe
2024-02-05 02:05:31,630:INFO:Uploading results into container
2024-02-05 02:05:31,631:INFO:Uploading model into container now
2024-02-05 02:05:31,631:INFO:_master_model_container: 5
2024-02-05 02:05:31,631:INFO:_display_container: 2
2024-02-05 02:05:31,632:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 02:05:31,632:INFO:create_model() successfully completed......................................
2024-02-05 02:05:31,706:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:31,706:INFO:Creating metrics dataframe
2024-02-05 02:05:31,716:INFO:Initializing Linear Discriminant Analysis
2024-02-05 02:05:31,717:INFO:Total runtime is 0.22624263763427735 minutes
2024-02-05 02:05:31,721:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:31,721:INFO:Initializing create_model()
2024-02-05 02:05:31,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:31,721:INFO:Checking exceptions
2024-02-05 02:05:31,721:INFO:Importing libraries
2024-02-05 02:05:31,721:INFO:Copying training dataset
2024-02-05 02:05:31,727:INFO:Defining folds
2024-02-05 02:05:31,728:INFO:Declaring metric variables
2024-02-05 02:05:31,731:INFO:Importing untrained model
2024-02-05 02:05:31,735:INFO:Linear Discriminant Analysis Imported successfully
2024-02-05 02:05:31,742:INFO:Starting cross validation
2024-02-05 02:05:31,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:31,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,975:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,981:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:31,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,010:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,010:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:32,148:INFO:Calculating mean and std
2024-02-05 02:05:32,149:INFO:Creating metrics dataframe
2024-02-05 02:05:32,153:INFO:Uploading results into container
2024-02-05 02:05:32,153:INFO:Uploading model into container now
2024-02-05 02:05:32,153:INFO:_master_model_container: 6
2024-02-05 02:05:32,154:INFO:_display_container: 2
2024-02-05 02:05:32,154:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-05 02:05:32,154:INFO:create_model() successfully completed......................................
2024-02-05 02:05:32,227:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:32,228:INFO:Creating metrics dataframe
2024-02-05 02:05:32,241:INFO:Initializing Extra Trees Classifier
2024-02-05 02:05:32,241:INFO:Total runtime is 0.23498310248057047 minutes
2024-02-05 02:05:32,248:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:32,248:INFO:Initializing create_model()
2024-02-05 02:05:32,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:32,248:INFO:Checking exceptions
2024-02-05 02:05:32,248:INFO:Importing libraries
2024-02-05 02:05:32,248:INFO:Copying training dataset
2024-02-05 02:05:32,257:INFO:Defining folds
2024-02-05 02:05:32,257:INFO:Declaring metric variables
2024-02-05 02:05:32,263:INFO:Importing untrained model
2024-02-05 02:05:32,272:INFO:Extra Trees Classifier Imported successfully
2024-02-05 02:05:32,281:INFO:Starting cross validation
2024-02-05 02:05:32,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:33,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,237:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,245:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,771:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,792:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:33,812:INFO:Calculating mean and std
2024-02-05 02:05:33,813:INFO:Creating metrics dataframe
2024-02-05 02:05:33,818:INFO:Uploading results into container
2024-02-05 02:05:33,818:INFO:Uploading model into container now
2024-02-05 02:05:33,819:INFO:_master_model_container: 7
2024-02-05 02:05:33,819:INFO:_display_container: 2
2024-02-05 02:05:33,820:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:05:33,820:INFO:create_model() successfully completed......................................
2024-02-05 02:05:33,905:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:33,905:INFO:Creating metrics dataframe
2024-02-05 02:05:33,919:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 02:05:33,919:INFO:Total runtime is 0.26294287443161013 minutes
2024-02-05 02:05:33,924:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:33,925:INFO:Initializing create_model()
2024-02-05 02:05:33,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:33,925:INFO:Checking exceptions
2024-02-05 02:05:33,925:INFO:Importing libraries
2024-02-05 02:05:33,925:INFO:Copying training dataset
2024-02-05 02:05:33,932:INFO:Defining folds
2024-02-05 02:05:33,932:INFO:Declaring metric variables
2024-02-05 02:05:33,937:INFO:Importing untrained model
2024-02-05 02:05:33,942:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 02:05:33,952:INFO:Starting cross validation
2024-02-05 02:05:33,955:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:35,219:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,227:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,236:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,246:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,251:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,259:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,267:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,411:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,449:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,498:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,818:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,831:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,836:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:35,852:INFO:Calculating mean and std
2024-02-05 02:05:35,854:INFO:Creating metrics dataframe
2024-02-05 02:05:35,860:INFO:Uploading results into container
2024-02-05 02:05:35,861:INFO:Uploading model into container now
2024-02-05 02:05:35,862:INFO:_master_model_container: 8
2024-02-05 02:05:35,862:INFO:_display_container: 2
2024-02-05 02:05:35,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 02:05:35,863:INFO:create_model() successfully completed......................................
2024-02-05 02:05:35,964:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:35,964:INFO:Creating metrics dataframe
2024-02-05 02:05:35,979:INFO:Initializing CatBoost Classifier
2024-02-05 02:05:35,979:INFO:Total runtime is 0.29728403091430666 minutes
2024-02-05 02:05:35,984:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:35,984:INFO:Initializing create_model()
2024-02-05 02:05:35,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:35,984:INFO:Checking exceptions
2024-02-05 02:05:35,985:INFO:Importing libraries
2024-02-05 02:05:35,985:INFO:Copying training dataset
2024-02-05 02:05:35,992:INFO:Defining folds
2024-02-05 02:05:35,993:INFO:Declaring metric variables
2024-02-05 02:05:35,998:INFO:Importing untrained model
2024-02-05 02:05:36,005:INFO:CatBoost Classifier Imported successfully
2024-02-05 02:05:36,014:INFO:Starting cross validation
2024-02-05 02:05:36,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:52,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,481:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,523:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,731:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:52,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,866:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,871:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:57,880:INFO:Calculating mean and std
2024-02-05 02:05:57,881:INFO:Creating metrics dataframe
2024-02-05 02:05:57,886:INFO:Uploading results into container
2024-02-05 02:05:57,886:INFO:Uploading model into container now
2024-02-05 02:05:57,887:INFO:_master_model_container: 9
2024-02-05 02:05:57,887:INFO:_display_container: 2
2024-02-05 02:05:57,887:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF6AAB160>
2024-02-05 02:05:57,887:INFO:create_model() successfully completed......................................
2024-02-05 02:05:57,976:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:57,976:INFO:Creating metrics dataframe
2024-02-05 02:05:57,993:INFO:Initializing Dummy Classifier
2024-02-05 02:05:57,993:INFO:Total runtime is 0.6641904274622599 minutes
2024-02-05 02:05:57,998:INFO:SubProcess create_model() called ==================================
2024-02-05 02:05:57,999:INFO:Initializing create_model()
2024-02-05 02:05:57,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF67EE0B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:57,999:INFO:Checking exceptions
2024-02-05 02:05:57,999:INFO:Importing libraries
2024-02-05 02:05:57,999:INFO:Copying training dataset
2024-02-05 02:05:58,008:INFO:Defining folds
2024-02-05 02:05:58,009:INFO:Declaring metric variables
2024-02-05 02:05:58,014:INFO:Importing untrained model
2024-02-05 02:05:58,020:INFO:Dummy Classifier Imported successfully
2024-02-05 02:05:58,030:INFO:Starting cross validation
2024-02-05 02:05:58,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:05:58,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,331:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,455:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-05 02:05:58,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:05:58,474:INFO:Calculating mean and std
2024-02-05 02:05:58,475:INFO:Creating metrics dataframe
2024-02-05 02:05:58,480:INFO:Uploading results into container
2024-02-05 02:05:58,480:INFO:Uploading model into container now
2024-02-05 02:05:58,481:INFO:_master_model_container: 10
2024-02-05 02:05:58,481:INFO:_display_container: 2
2024-02-05 02:05:58,481:INFO:DummyClassifier(constant=None, random_state=6328, strategy='prior')
2024-02-05 02:05:58,482:INFO:create_model() successfully completed......................................
2024-02-05 02:05:58,568:INFO:SubProcess create_model() end ==================================
2024-02-05 02:05:58,568:INFO:Creating metrics dataframe
2024-02-05 02:05:58,595:INFO:Initializing create_model()
2024-02-05 02:05:58,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:58,595:INFO:Checking exceptions
2024-02-05 02:05:58,598:INFO:Importing libraries
2024-02-05 02:05:58,599:INFO:Copying training dataset
2024-02-05 02:05:58,606:INFO:Defining folds
2024-02-05 02:05:58,606:INFO:Declaring metric variables
2024-02-05 02:05:58,606:INFO:Importing untrained model
2024-02-05 02:05:58,606:INFO:Declaring custom model
2024-02-05 02:05:58,607:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 02:05:58,608:INFO:Cross validation set to False
2024-02-05 02:05:58,608:INFO:Fitting Model
2024-02-05 02:05:58,683:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:05:58,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-02-05 02:05:58,684:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:05:58,684:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:05:58,684:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:05:58,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 02:05:58,684:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 02:05:58,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 02:05:58,803:INFO:create_model() successfully completed......................................
2024-02-05 02:05:58,911:INFO:Initializing create_model()
2024-02-05 02:05:58,911:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF6AAB160>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:05:58,911:INFO:Checking exceptions
2024-02-05 02:05:58,914:INFO:Importing libraries
2024-02-05 02:05:58,914:INFO:Copying training dataset
2024-02-05 02:05:58,921:INFO:Defining folds
2024-02-05 02:05:58,921:INFO:Declaring metric variables
2024-02-05 02:05:58,922:INFO:Importing untrained model
2024-02-05 02:05:58,922:INFO:Declaring custom model
2024-02-05 02:05:58,922:INFO:CatBoost Classifier Imported successfully
2024-02-05 02:05:58,924:INFO:Cross validation set to False
2024-02-05 02:05:58,924:INFO:Fitting Model
2024-02-05 02:06:02,879:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>
2024-02-05 02:06:02,879:INFO:create_model() successfully completed......................................
2024-02-05 02:06:02,956:INFO:Initializing create_model()
2024-02-05 02:06:02,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:06:02,956:INFO:Checking exceptions
2024-02-05 02:06:02,957:INFO:Importing libraries
2024-02-05 02:06:02,957:INFO:Copying training dataset
2024-02-05 02:06:02,963:INFO:Defining folds
2024-02-05 02:06:02,964:INFO:Declaring metric variables
2024-02-05 02:06:02,964:INFO:Importing untrained model
2024-02-05 02:06:02,964:INFO:Declaring custom model
2024-02-05 02:06:02,964:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 02:06:02,966:INFO:Cross validation set to False
2024-02-05 02:06:02,966:INFO:Fitting Model
2024-02-05 02:06:03,924:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 02:06:03,924:INFO:create_model() successfully completed......................................
2024-02-05 02:06:03,995:INFO:Initializing create_model()
2024-02-05 02:06:03,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:06:03,996:INFO:Checking exceptions
2024-02-05 02:06:03,999:INFO:Importing libraries
2024-02-05 02:06:04,000:INFO:Copying training dataset
2024-02-05 02:06:04,006:INFO:Defining folds
2024-02-05 02:06:04,006:INFO:Declaring metric variables
2024-02-05 02:06:04,007:INFO:Importing untrained model
2024-02-05 02:06:04,007:INFO:Declaring custom model
2024-02-05 02:06:04,007:INFO:Random Forest Classifier Imported successfully
2024-02-05 02:06:04,008:INFO:Cross validation set to False
2024-02-05 02:06:04,008:INFO:Fitting Model
2024-02-05 02:06:04,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:06:04,286:INFO:create_model() successfully completed......................................
2024-02-05 02:06:04,358:INFO:Initializing create_model()
2024-02-05 02:06:04,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:06:04,358:INFO:Checking exceptions
2024-02-05 02:06:04,361:INFO:Importing libraries
2024-02-05 02:06:04,361:INFO:Copying training dataset
2024-02-05 02:06:04,367:INFO:Defining folds
2024-02-05 02:06:04,367:INFO:Declaring metric variables
2024-02-05 02:06:04,367:INFO:Importing untrained model
2024-02-05 02:06:04,367:INFO:Declaring custom model
2024-02-05 02:06:04,368:INFO:Extra Trees Classifier Imported successfully
2024-02-05 02:06:04,369:INFO:Cross validation set to False
2024-02-05 02:06:04,370:INFO:Fitting Model
2024-02-05 02:06:04,570:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:06:04,570:INFO:create_model() successfully completed......................................
2024-02-05 02:06:04,664:INFO:_master_model_container: 10
2024-02-05 02:06:04,664:INFO:_display_container: 2
2024-02-05 02:06:04,666:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)]
2024-02-05 02:06:04,666:INFO:compare_models() successfully completed......................................
2024-02-05 02:06:04,714:INFO:Initializing tune_model()
2024-02-05 02:06:04,715:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>)
2024-02-05 02:06:04,715:INFO:Checking exceptions
2024-02-05 02:06:04,740:INFO:Copying training dataset
2024-02-05 02:06:04,746:INFO:Checking base model
2024-02-05 02:06:04,747:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 02:06:04,752:INFO:Declaring metric variables
2024-02-05 02:06:04,756:INFO:Defining Hyperparameters
2024-02-05 02:06:04,839:INFO:Tuning with n_jobs=-1
2024-02-05 02:06:04,839:INFO:Initializing RandomizedSearchCV
2024-02-05 02:06:15,656:INFO:best_params: {'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 1e-07, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 1.0}
2024-02-05 02:06:15,657:INFO:Hyperparameter search completed
2024-02-05 02:06:15,658:INFO:SubProcess create_model() called ==================================
2024-02-05 02:06:15,658:INFO:Initializing create_model()
2024-02-05 02:06:15,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF676D030>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.5, 'reg_alpha': 1e-07, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 61, 'learning_rate': 0.15, 'feature_fraction': 0.6, 'bagging_freq': 0, 'bagging_fraction': 1.0})
2024-02-05 02:06:15,659:INFO:Checking exceptions
2024-02-05 02:06:15,659:INFO:Importing libraries
2024-02-05 02:06:15,659:INFO:Copying training dataset
2024-02-05 02:06:15,672:INFO:Defining folds
2024-02-05 02:06:15,673:INFO:Declaring metric variables
2024-02-05 02:06:15,678:INFO:Importing untrained model
2024-02-05 02:06:15,678:INFO:Declaring custom model
2024-02-05 02:06:15,685:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 02:06:15,696:INFO:Starting cross validation
2024-02-05 02:06:15,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:06:16,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,442:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,498:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,598:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:16,815:INFO:Calculating mean and std
2024-02-05 02:06:16,817:INFO:Creating metrics dataframe
2024-02-05 02:06:16,828:INFO:Finalizing model
2024-02-05 02:06:16,928:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-05 02:06:16,928:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-05 02:06:16,928:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-02-05 02:06:16,933:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-05 02:06:16,933:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-05 02:06:16,933:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2024-02-05 02:06:16,933:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:06:16,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
2024-02-05 02:06:16,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:06:16,934:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:06:16,935:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:06:16,935:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 02:06:16,935:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 02:06:16,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,998:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,998:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:16,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 02:06:17,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-05 02:06:17,031:INFO:Uploading results into container
2024-02-05 02:06:17,033:INFO:Uploading model into container now
2024-02-05 02:06:17,036:INFO:_master_model_container: 11
2024-02-05 02:06:17,036:INFO:_display_container: 2
2024-02-05 02:06:17,037:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=6328, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 02:06:17,038:INFO:create_model() successfully completed......................................
2024-02-05 02:06:17,143:INFO:SubProcess create_model() end ==================================
2024-02-05 02:06:17,143:INFO:choose_better activated
2024-02-05 02:06:17,147:INFO:SubProcess create_model() called ==================================
2024-02-05 02:06:17,148:INFO:Initializing create_model()
2024-02-05 02:06:17,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:06:17,149:INFO:Checking exceptions
2024-02-05 02:06:17,152:INFO:Importing libraries
2024-02-05 02:06:17,152:INFO:Copying training dataset
2024-02-05 02:06:17,159:INFO:Defining folds
2024-02-05 02:06:17,159:INFO:Declaring metric variables
2024-02-05 02:06:17,159:INFO:Importing untrained model
2024-02-05 02:06:17,159:INFO:Declaring custom model
2024-02-05 02:06:17,160:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 02:06:17,161:INFO:Starting cross validation
2024-02-05 02:06:17,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:06:18,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,365:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,365:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,390:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,408:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,616:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,665:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,788:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:18,795:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,055:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,070:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,078:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,094:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:06:19,111:INFO:Calculating mean and std
2024-02-05 02:06:19,112:INFO:Creating metrics dataframe
2024-02-05 02:06:19,116:INFO:Finalizing model
2024-02-05 02:06:19,241:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:06:19,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.
2024-02-05 02:06:19,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:06:19,243:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:06:19,243:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:06:19,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 02:06:19,244:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 02:06:19,393:INFO:Uploading results into container
2024-02-05 02:06:19,394:INFO:Uploading model into container now
2024-02-05 02:06:19,394:INFO:_master_model_container: 12
2024-02-05 02:06:19,394:INFO:_display_container: 3
2024-02-05 02:06:19,395:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 02:06:19,395:INFO:create_model() successfully completed......................................
2024-02-05 02:06:19,498:INFO:SubProcess create_model() end ==================================
2024-02-05 02:06:19,498:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9637
2024-02-05 02:06:19,499:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=6328, reg_alpha=1e-07, reg_lambda=0.5,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9546
2024-02-05 02:06:19,500:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-05 02:06:19,500:INFO:choose_better completed
2024-02-05 02:06:19,500:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-05 02:06:19,514:INFO:_master_model_container: 12
2024-02-05 02:06:19,514:INFO:_display_container: 2
2024-02-05 02:06:19,515:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 02:06:19,515:INFO:tune_model() successfully completed......................................
2024-02-05 02:06:19,611:INFO:Initializing tune_model()
2024-02-05 02:06:19,611:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>)
2024-02-05 02:06:19,612:INFO:Checking exceptions
2024-02-05 02:06:19,638:INFO:Copying training dataset
2024-02-05 02:06:19,645:INFO:Checking base model
2024-02-05 02:06:19,645:INFO:Base model : CatBoost Classifier
2024-02-05 02:06:19,650:INFO:Declaring metric variables
2024-02-05 02:06:19,657:INFO:Defining Hyperparameters
2024-02-05 02:06:19,769:INFO:Tuning with n_jobs=-1
2024-02-05 02:06:19,770:INFO:Initializing RandomizedSearchCV
2024-02-05 02:07:24,603:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 160, 'actual_estimator__l2_leaf_reg': 1, 'actual_estimator__eta': 0.2, 'actual_estimator__depth': 4}
2024-02-05 02:07:24,604:INFO:Hyperparameter search completed
2024-02-05 02:07:24,604:INFO:SubProcess create_model() called ==================================
2024-02-05 02:07:24,605:INFO:Initializing create_model()
2024-02-05 02:07:24,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF71DDE10>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF676D030>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 160, 'l2_leaf_reg': 1, 'eta': 0.2, 'depth': 4})
2024-02-05 02:07:24,605:INFO:Checking exceptions
2024-02-05 02:07:24,606:INFO:Importing libraries
2024-02-05 02:07:24,606:INFO:Copying training dataset
2024-02-05 02:07:24,617:INFO:Defining folds
2024-02-05 02:07:24,617:INFO:Declaring metric variables
2024-02-05 02:07:24,622:INFO:Importing untrained model
2024-02-05 02:07:24,622:INFO:Declaring custom model
2024-02-05 02:07:24,628:INFO:CatBoost Classifier Imported successfully
2024-02-05 02:07:24,637:INFO:Starting cross validation
2024-02-05 02:07:24,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:07:25,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:25,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:25,665:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,502:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,510:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,516:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,523:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,546:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,836:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:26,844:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:27,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:27,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:27,088:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:27,109:INFO:Calculating mean and std
2024-02-05 02:07:27,111:INFO:Creating metrics dataframe
2024-02-05 02:07:27,117:INFO:Finalizing model
2024-02-05 02:07:27,667:INFO:Uploading results into container
2024-02-05 02:07:27,667:INFO:Uploading model into container now
2024-02-05 02:07:27,669:INFO:_master_model_container: 13
2024-02-05 02:07:27,669:INFO:_display_container: 3
2024-02-05 02:07:27,670:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960>
2024-02-05 02:07:27,670:INFO:create_model() successfully completed......................................
2024-02-05 02:07:27,763:INFO:SubProcess create_model() end ==================================
2024-02-05 02:07:27,763:INFO:choose_better activated
2024-02-05 02:07:27,766:INFO:SubProcess create_model() called ==================================
2024-02-05 02:07:27,767:INFO:Initializing create_model()
2024-02-05 02:07:27,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:07:27,767:INFO:Checking exceptions
2024-02-05 02:07:27,769:INFO:Importing libraries
2024-02-05 02:07:27,770:INFO:Copying training dataset
2024-02-05 02:07:27,776:INFO:Defining folds
2024-02-05 02:07:27,776:INFO:Declaring metric variables
2024-02-05 02:07:27,776:INFO:Importing untrained model
2024-02-05 02:07:27,776:INFO:Declaring custom model
2024-02-05 02:07:27,777:INFO:CatBoost Classifier Imported successfully
2024-02-05 02:07:27,777:INFO:Starting cross validation
2024-02-05 02:07:27,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:07:43,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,543:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,926:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,941:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:43,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,434:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,438:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:07:48,457:INFO:Calculating mean and std
2024-02-05 02:07:48,458:INFO:Creating metrics dataframe
2024-02-05 02:07:48,461:INFO:Finalizing model
2024-02-05 02:07:52,424:INFO:Uploading results into container
2024-02-05 02:07:52,425:INFO:Uploading model into container now
2024-02-05 02:07:52,425:INFO:_master_model_container: 14
2024-02-05 02:07:52,425:INFO:_display_container: 4
2024-02-05 02:07:52,425:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF82E94E0>
2024-02-05 02:07:52,426:INFO:create_model() successfully completed......................................
2024-02-05 02:07:52,497:INFO:SubProcess create_model() end ==================================
2024-02-05 02:07:52,497:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF82E94E0> result for Accuracy is 0.9637
2024-02-05 02:07:52,497:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960> result for Accuracy is 0.964
2024-02-05 02:07:52,497:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960> is best model
2024-02-05 02:07:52,497:INFO:choose_better completed
2024-02-05 02:07:52,507:INFO:_master_model_container: 14
2024-02-05 02:07:52,507:INFO:_display_container: 3
2024-02-05 02:07:52,507:INFO:<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960>
2024-02-05 02:07:52,508:INFO:tune_model() successfully completed......................................
2024-02-05 02:07:52,576:INFO:Initializing tune_model()
2024-02-05 02:07:52,576:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>)
2024-02-05 02:07:52,576:INFO:Checking exceptions
2024-02-05 02:07:52,592:INFO:Copying training dataset
2024-02-05 02:07:52,598:INFO:Checking base model
2024-02-05 02:07:52,598:INFO:Base model : Gradient Boosting Classifier
2024-02-05 02:07:52,601:INFO:Declaring metric variables
2024-02-05 02:07:52,605:INFO:Defining Hyperparameters
2024-02-05 02:07:52,685:INFO:Tuning with n_jobs=-1
2024-02-05 02:07:52,685:INFO:Initializing RandomizedSearchCV
2024-02-05 02:08:13,395:INFO:best_params: {'actual_estimator__subsample': 0.55, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.15}
2024-02-05 02:08:13,396:INFO:Hyperparameter search completed
2024-02-05 02:08:13,396:INFO:SubProcess create_model() called ==================================
2024-02-05 02:08:13,397:INFO:Initializing create_model()
2024-02-05 02:08:13,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF673BFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.55, 'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.2, 'max_features': 'log2', 'max_depth': 11, 'learning_rate': 0.15})
2024-02-05 02:08:13,397:INFO:Checking exceptions
2024-02-05 02:08:13,397:INFO:Importing libraries
2024-02-05 02:08:13,398:INFO:Copying training dataset
2024-02-05 02:08:13,406:INFO:Defining folds
2024-02-05 02:08:13,406:INFO:Declaring metric variables
2024-02-05 02:08:13,410:INFO:Importing untrained model
2024-02-05 02:08:13,410:INFO:Declaring custom model
2024-02-05 02:08:13,415:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 02:08:13,422:INFO:Starting cross validation
2024-02-05 02:08:13,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:08:14,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,065:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,090:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,133:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,503:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:14,533:INFO:Calculating mean and std
2024-02-05 02:08:14,534:INFO:Creating metrics dataframe
2024-02-05 02:08:14,540:INFO:Finalizing model
2024-02-05 02:08:14,847:INFO:Uploading results into container
2024-02-05 02:08:14,848:INFO:Uploading model into container now
2024-02-05 02:08:14,849:INFO:_master_model_container: 15
2024-02-05 02:08:14,849:INFO:_display_container: 4
2024-02-05 02:08:14,851:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=11,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=0.55, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 02:08:14,851:INFO:create_model() successfully completed......................................
2024-02-05 02:08:14,933:INFO:SubProcess create_model() end ==================================
2024-02-05 02:08:14,933:INFO:choose_better activated
2024-02-05 02:08:14,937:INFO:SubProcess create_model() called ==================================
2024-02-05 02:08:14,937:INFO:Initializing create_model()
2024-02-05 02:08:14,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:08:14,937:INFO:Checking exceptions
2024-02-05 02:08:14,940:INFO:Importing libraries
2024-02-05 02:08:14,940:INFO:Copying training dataset
2024-02-05 02:08:14,946:INFO:Defining folds
2024-02-05 02:08:14,946:INFO:Declaring metric variables
2024-02-05 02:08:14,946:INFO:Importing untrained model
2024-02-05 02:08:14,946:INFO:Declaring custom model
2024-02-05 02:08:14,947:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 02:08:14,947:INFO:Starting cross validation
2024-02-05 02:08:14,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:08:16,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,930:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,939:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:16,955:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,220:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,229:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,236:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,237:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:17,245:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,367:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:08:18,407:INFO:Calculating mean and std
2024-02-05 02:08:18,408:INFO:Creating metrics dataframe
2024-02-05 02:08:18,410:INFO:Finalizing model
2024-02-05 02:08:19,482:INFO:Uploading results into container
2024-02-05 02:08:19,483:INFO:Uploading model into container now
2024-02-05 02:08:19,483:INFO:_master_model_container: 16
2024-02-05 02:08:19,483:INFO:_display_container: 5
2024-02-05 02:08:19,484:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 02:08:19,484:INFO:create_model() successfully completed......................................
2024-02-05 02:08:19,547:INFO:SubProcess create_model() end ==================================
2024-02-05 02:08:19,548:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9614
2024-02-05 02:08:19,548:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=11,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=3,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=0.55, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9519
2024-02-05 02:08:19,549:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-05 02:08:19,549:INFO:choose_better completed
2024-02-05 02:08:19,549:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-05 02:08:19,559:INFO:_master_model_container: 16
2024-02-05 02:08:19,559:INFO:_display_container: 4
2024-02-05 02:08:19,560:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 02:08:19,560:INFO:tune_model() successfully completed......................................
2024-02-05 02:08:19,638:INFO:Initializing tune_model()
2024-02-05 02:08:19,638:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>)
2024-02-05 02:08:19,638:INFO:Checking exceptions
2024-02-05 02:08:19,655:INFO:Copying training dataset
2024-02-05 02:08:19,661:INFO:Checking base model
2024-02-05 02:08:19,661:INFO:Base model : Random Forest Classifier
2024-02-05 02:08:19,665:INFO:Declaring metric variables
2024-02-05 02:08:19,670:INFO:Defining Hyperparameters
2024-02-05 02:08:19,759:INFO:Tuning with n_jobs=-1
2024-02-05 02:08:19,759:INFO:Initializing RandomizedSearchCV
2024-02-05 02:08:53,929:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2024-02-05 02:08:53,930:INFO:Hyperparameter search completed
2024-02-05 02:08:53,931:INFO:SubProcess create_model() called ==================================
2024-02-05 02:08:53,932:INFO:Initializing create_model()
2024-02-05 02:08:53,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF673BF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 220, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2024-02-05 02:08:53,932:INFO:Checking exceptions
2024-02-05 02:08:53,932:INFO:Importing libraries
2024-02-05 02:08:53,932:INFO:Copying training dataset
2024-02-05 02:08:53,942:INFO:Defining folds
2024-02-05 02:08:53,942:INFO:Declaring metric variables
2024-02-05 02:08:53,946:INFO:Importing untrained model
2024-02-05 02:08:53,946:INFO:Declaring custom model
2024-02-05 02:08:53,951:INFO:Random Forest Classifier Imported successfully
2024-02-05 02:08:53,959:INFO:Starting cross validation
2024-02-05 02:08:53,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:09:02,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,774:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,775:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,819:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,944:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:02,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:03,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:03,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:03,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:03,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:03,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,501:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,516:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,523:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:05,556:INFO:Calculating mean and std
2024-02-05 02:09:05,558:INFO:Creating metrics dataframe
2024-02-05 02:09:05,565:INFO:Finalizing model
2024-02-05 02:09:07,233:INFO:Uploading results into container
2024-02-05 02:09:07,235:INFO:Uploading model into container now
2024-02-05 02:09:07,237:INFO:_master_model_container: 17
2024-02-05 02:09:07,237:INFO:_display_container: 5
2024-02-05 02:09:07,239:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:07,239:INFO:create_model() successfully completed......................................
2024-02-05 02:09:07,342:INFO:SubProcess create_model() end ==================================
2024-02-05 02:09:07,343:INFO:choose_better activated
2024-02-05 02:09:07,349:INFO:SubProcess create_model() called ==================================
2024-02-05 02:09:07,350:INFO:Initializing create_model()
2024-02-05 02:09:07,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:09:07,351:INFO:Checking exceptions
2024-02-05 02:09:07,353:INFO:Importing libraries
2024-02-05 02:09:07,354:INFO:Copying training dataset
2024-02-05 02:09:07,363:INFO:Defining folds
2024-02-05 02:09:07,363:INFO:Declaring metric variables
2024-02-05 02:09:07,363:INFO:Importing untrained model
2024-02-05 02:09:07,363:INFO:Declaring custom model
2024-02-05 02:09:07,365:INFO:Random Forest Classifier Imported successfully
2024-02-05 02:09:07,366:INFO:Starting cross validation
2024-02-05 02:09:07,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:09:09,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,154:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,155:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,161:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:09,880:INFO:Calculating mean and std
2024-02-05 02:09:09,880:INFO:Creating metrics dataframe
2024-02-05 02:09:09,884:INFO:Finalizing model
2024-02-05 02:09:10,260:INFO:Uploading results into container
2024-02-05 02:09:10,261:INFO:Uploading model into container now
2024-02-05 02:09:10,261:INFO:_master_model_container: 18
2024-02-05 02:09:10,261:INFO:_display_container: 6
2024-02-05 02:09:10,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:10,262:INFO:create_model() successfully completed......................................
2024-02-05 02:09:10,331:INFO:SubProcess create_model() end ==================================
2024-02-05 02:09:10,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False) result for Accuracy is 0.955
2024-02-05 02:09:10,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False) result for Accuracy is 0.962
2024-02-05 02:09:10,333:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False) is best model
2024-02-05 02:09:10,333:INFO:choose_better completed
2024-02-05 02:09:10,343:INFO:_master_model_container: 18
2024-02-05 02:09:10,344:INFO:_display_container: 5
2024-02-05 02:09:10,344:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:10,344:INFO:tune_model() successfully completed......................................
2024-02-05 02:09:10,413:INFO:Initializing tune_model()
2024-02-05 02:09:10,413:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>)
2024-02-05 02:09:10,413:INFO:Checking exceptions
2024-02-05 02:09:10,432:INFO:Copying training dataset
2024-02-05 02:09:10,436:INFO:Checking base model
2024-02-05 02:09:10,436:INFO:Base model : Extra Trees Classifier
2024-02-05 02:09:10,440:INFO:Declaring metric variables
2024-02-05 02:09:10,446:INFO:Defining Hyperparameters
2024-02-05 02:09:10,531:INFO:Tuning with n_jobs=-1
2024-02-05 02:09:10,531:INFO:Initializing RandomizedSearchCV
2024-02-05 02:09:27,364:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2024-02-05 02:09:27,365:INFO:Hyperparameter search completed
2024-02-05 02:09:27,365:INFO:SubProcess create_model() called ==================================
2024-02-05 02:09:27,366:INFO:Initializing create_model()
2024-02-05 02:09:27,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF673BFD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 220, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2024-02-05 02:09:27,366:INFO:Checking exceptions
2024-02-05 02:09:27,366:INFO:Importing libraries
2024-02-05 02:09:27,367:INFO:Copying training dataset
2024-02-05 02:09:27,376:INFO:Defining folds
2024-02-05 02:09:27,377:INFO:Declaring metric variables
2024-02-05 02:09:27,381:INFO:Importing untrained model
2024-02-05 02:09:27,382:INFO:Declaring custom model
2024-02-05 02:09:27,386:INFO:Extra Trees Classifier Imported successfully
2024-02-05 02:09:27,395:INFO:Starting cross validation
2024-02-05 02:09:27,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:09:29,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,638:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,649:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,836:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,857:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,857:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,866:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,866:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,872:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:29,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,819:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:30,839:INFO:Calculating mean and std
2024-02-05 02:09:30,840:INFO:Creating metrics dataframe
2024-02-05 02:09:30,847:INFO:Finalizing model
2024-02-05 02:09:31,499:INFO:Uploading results into container
2024-02-05 02:09:31,501:INFO:Uploading model into container now
2024-02-05 02:09:31,502:INFO:_master_model_container: 19
2024-02-05 02:09:31,503:INFO:_display_container: 6
2024-02-05 02:09:31,504:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=8, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0, min_samples_leaf=5,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=220, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:31,504:INFO:create_model() successfully completed......................................
2024-02-05 02:09:31,592:INFO:SubProcess create_model() end ==================================
2024-02-05 02:09:31,593:INFO:choose_better activated
2024-02-05 02:09:31,597:INFO:SubProcess create_model() called ==================================
2024-02-05 02:09:31,597:INFO:Initializing create_model()
2024-02-05 02:09:31,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:09:31,598:INFO:Checking exceptions
2024-02-05 02:09:31,600:INFO:Importing libraries
2024-02-05 02:09:31,601:INFO:Copying training dataset
2024-02-05 02:09:31,608:INFO:Defining folds
2024-02-05 02:09:31,608:INFO:Declaring metric variables
2024-02-05 02:09:31,608:INFO:Importing untrained model
2024-02-05 02:09:31,608:INFO:Declaring custom model
2024-02-05 02:09:31,609:INFO:Extra Trees Classifier Imported successfully
2024-02-05 02:09:31,609:INFO:Starting cross validation
2024-02-05 02:09:31,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:09:32,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,685:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,724:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,734:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,768:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:32,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:33,327:INFO:Calculating mean and std
2024-02-05 02:09:33,327:INFO:Creating metrics dataframe
2024-02-05 02:09:33,330:INFO:Finalizing model
2024-02-05 02:09:33,597:INFO:Uploading results into container
2024-02-05 02:09:33,598:INFO:Uploading model into container now
2024-02-05 02:09:33,598:INFO:_master_model_container: 20
2024-02-05 02:09:33,599:INFO:_display_container: 7
2024-02-05 02:09:33,599:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:33,599:INFO:create_model() successfully completed......................................
2024-02-05 02:09:33,690:INFO:SubProcess create_model() end ==================================
2024-02-05 02:09:33,691:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False) result for Accuracy is 0.9301
2024-02-05 02:09:33,692:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=8, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0, min_samples_leaf=5,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=220, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False) result for Accuracy is 0.9496
2024-02-05 02:09:33,693:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=8, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0, min_samples_leaf=5,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=220, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False) is best model
2024-02-05 02:09:33,693:INFO:choose_better completed
2024-02-05 02:09:33,705:INFO:_master_model_container: 20
2024-02-05 02:09:33,706:INFO:_display_container: 6
2024-02-05 02:09:33,706:INFO:ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=8, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0, min_samples_leaf=5,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=220, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)
2024-02-05 02:09:33,706:INFO:tune_model() successfully completed......................................
2024-02-05 02:09:33,790:INFO:Initializing ensemble_model()
2024-02-05 02:09:33,790:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:09:33,790:INFO:Checking exceptions
2024-02-05 02:09:33,808:INFO:Importing libraries
2024-02-05 02:09:33,809:INFO:Copying training dataset
2024-02-05 02:09:33,809:INFO:Checking base model
2024-02-05 02:09:33,810:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 02:09:33,819:INFO:Importing untrained ensembler
2024-02-05 02:09:33,819:INFO:Ensemble method set to Bagging
2024-02-05 02:09:33,820:INFO:SubProcess create_model() called ==================================
2024-02-05 02:09:33,821:INFO:Initializing create_model()
2024-02-05 02:09:33,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=6328,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6C47D60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:09:33,821:INFO:Checking exceptions
2024-02-05 02:09:33,822:INFO:Importing libraries
2024-02-05 02:09:33,822:INFO:Copying training dataset
2024-02-05 02:09:33,832:INFO:Defining folds
2024-02-05 02:09:33,832:INFO:Declaring metric variables
2024-02-05 02:09:33,837:INFO:Importing untrained model
2024-02-05 02:09:33,837:INFO:Declaring custom model
2024-02-05 02:09:33,842:INFO:Bagging Classifier Imported successfully
2024-02-05 02:09:33,848:INFO:Starting cross validation
2024-02-05 02:09:33,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:09:41,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,709:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,741:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,777:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:41,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,112:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:42,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,421:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,427:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,530:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:09:44,545:INFO:Calculating mean and std
2024-02-05 02:09:44,547:INFO:Creating metrics dataframe
2024-02-05 02:09:44,557:INFO:Finalizing model
2024-02-05 02:09:44,662:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:44,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2024-02-05 02:09:44,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:44,664:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:44,664:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:44,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.131765 -> initscore=-1.885445
2024-02-05 02:09:44,664:INFO:[LightGBM] [Info] Start training from score -1.885445
2024-02-05 02:09:44,818:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:44,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.
2024-02-05 02:09:44,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:44,820:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:44,820:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:44,821:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135798 -> initscore=-1.850635
2024-02-05 02:09:44,821:INFO:[LightGBM] [Info] Start training from score -1.850635
2024-02-05 02:09:44,971:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:44,972:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000583 seconds.
2024-02-05 02:09:44,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:44,973:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:44,973:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:44,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.136134 -> initscore=-1.847774
2024-02-05 02:09:44,974:INFO:[LightGBM] [Info] Start training from score -1.847774
2024-02-05 02:09:45,185:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:45,185:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.
2024-02-05 02:09:45,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:45,186:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:45,186:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:45,187:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129412 -> initscore=-1.906170
2024-02-05 02:09:45,187:INFO:[LightGBM] [Info] Start training from score -1.906170
2024-02-05 02:09:45,354:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:45,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.
2024-02-05 02:09:45,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:45,355:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:45,356:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:45,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135462 -> initscore=-1.853503
2024-02-05 02:09:45,356:INFO:[LightGBM] [Info] Start training from score -1.853503
2024-02-05 02:09:45,522:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:45,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000750 seconds.
2024-02-05 02:09:45,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:45,524:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:45,524:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:45,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.148908 -> initscore=-1.743195
2024-02-05 02:09:45,525:INFO:[LightGBM] [Info] Start training from score -1.743195
2024-02-05 02:09:45,694:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:45,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-02-05 02:09:45,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-05 02:09:45,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-05 02:09:45,695:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:45,695:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:45,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140504 -> initscore=-1.811109
2024-02-05 02:09:45,696:INFO:[LightGBM] [Info] Start training from score -1.811109
2024-02-05 02:09:45,863:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:45,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.
2024-02-05 02:09:45,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:45,864:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:45,864:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:45,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.146218 -> initscore=-1.764573
2024-02-05 02:09:45,865:INFO:[LightGBM] [Info] Start training from score -1.764573
2024-02-05 02:09:46,026:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:46,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.
2024-02-05 02:09:46,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:46,028:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:46,028:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:46,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137143 -> initscore=-1.839226
2024-02-05 02:09:46,028:INFO:[LightGBM] [Info] Start training from score -1.839226
2024-02-05 02:09:46,205:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 02:09:46,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
2024-02-05 02:09:46,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 02:09:46,207:INFO:[LightGBM] [Info] Total Bins 2705
2024-02-05 02:09:46,207:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 02:09:46,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.135126 -> initscore=-1.856376
2024-02-05 02:09:46,207:INFO:[LightGBM] [Info] Start training from score -1.856376
2024-02-05 02:09:46,381:INFO:Uploading results into container
2024-02-05 02:09:46,383:INFO:Uploading model into container now
2024-02-05 02:09:46,385:INFO:_master_model_container: 21
2024-02-05 02:09:46,385:INFO:_display_container: 7
2024-02-05 02:09:46,389:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=6328,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:09:46,390:INFO:create_model() successfully completed......................................
2024-02-05 02:09:46,495:INFO:SubProcess create_model() end ==================================
2024-02-05 02:09:46,507:INFO:_master_model_container: 21
2024-02-05 02:09:46,508:INFO:_display_container: 7
2024-02-05 02:09:46,510:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=6328,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:09:46,510:INFO:ensemble_model() successfully completed......................................
2024-02-05 02:09:46,588:INFO:Initializing ensemble_model()
2024-02-05 02:09:46,588:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960>, method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:09:46,588:INFO:Checking exceptions
2024-02-05 02:09:46,610:INFO:Importing libraries
2024-02-05 02:09:46,611:INFO:Copying training dataset
2024-02-05 02:09:46,611:INFO:Checking base model
2024-02-05 02:09:46,611:INFO:Base model : CatBoost Classifier
2024-02-05 02:09:46,622:INFO:Importing untrained ensembler
2024-02-05 02:09:46,623:INFO:Ensemble method set to Bagging
2024-02-05 02:09:46,623:INFO:SubProcess create_model() called ==================================
2024-02-05 02:09:46,624:INFO:Initializing create_model()
2024-02-05 02:09:46,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF6FA9960>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6C47D60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:09:46,624:INFO:Checking exceptions
2024-02-05 02:09:46,624:INFO:Importing libraries
2024-02-05 02:09:46,624:INFO:Copying training dataset
2024-02-05 02:09:46,636:INFO:Defining folds
2024-02-05 02:09:46,636:INFO:Declaring metric variables
2024-02-05 02:09:46,643:INFO:Importing untrained model
2024-02-05 02:09:46,643:INFO:Declaring custom model
2024-02-05 02:09:46,650:INFO:Bagging Classifier Imported successfully
2024-02-05 02:09:46,662:INFO:Starting cross validation
2024-02-05 02:09:46,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:10:00,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,747:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:00,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,045:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,053:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:01,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:06,276:INFO:Calculating mean and std
2024-02-05 02:10:06,277:INFO:Creating metrics dataframe
2024-02-05 02:10:06,283:INFO:Finalizing model
2024-02-05 02:10:10,879:INFO:Uploading results into container
2024-02-05 02:10:10,881:INFO:Uploading model into container now
2024-02-05 02:10:10,882:INFO:_master_model_container: 22
2024-02-05 02:10:10,883:INFO:_display_container: 8
2024-02-05 02:10:10,884:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF6B31D50>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:10:10,884:INFO:create_model() successfully completed......................................
2024-02-05 02:10:10,992:INFO:SubProcess create_model() end ==================================
2024-02-05 02:10:11,007:INFO:_master_model_container: 22
2024-02-05 02:10:11,007:INFO:_display_container: 8
2024-02-05 02:10:11,007:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x0000022BF6B31D50>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:10:11,007:INFO:ensemble_model() successfully completed......................................
2024-02-05 02:10:11,099:INFO:Initializing ensemble_model()
2024-02-05 02:10:11,099:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:10:11,099:INFO:Checking exceptions
2024-02-05 02:10:11,119:INFO:Importing libraries
2024-02-05 02:10:11,120:INFO:Copying training dataset
2024-02-05 02:10:11,120:INFO:Checking base model
2024-02-05 02:10:11,120:INFO:Base model : Gradient Boosting Classifier
2024-02-05 02:10:11,132:INFO:Importing untrained ensembler
2024-02-05 02:10:11,132:INFO:Ensemble method set to Bagging
2024-02-05 02:10:11,132:INFO:SubProcess create_model() called ==================================
2024-02-05 02:10:11,136:INFO:Initializing create_model()
2024-02-05 02:10:11,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6328,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6A8A8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:10:11,136:INFO:Checking exceptions
2024-02-05 02:10:11,137:INFO:Importing libraries
2024-02-05 02:10:11,137:INFO:Copying training dataset
2024-02-05 02:10:11,156:INFO:Defining folds
2024-02-05 02:10:11,157:INFO:Declaring metric variables
2024-02-05 02:10:11,163:INFO:Importing untrained model
2024-02-05 02:10:11,164:INFO:Declaring custom model
2024-02-05 02:10:11,170:INFO:Bagging Classifier Imported successfully
2024-02-05 02:10:11,182:INFO:Starting cross validation
2024-02-05 02:10:11,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:10:24,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,298:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,406:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:24,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:25,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:10:31,784:INFO:Calculating mean and std
2024-02-05 02:10:31,785:INFO:Creating metrics dataframe
2024-02-05 02:10:31,791:INFO:Finalizing model
2024-02-05 02:10:38,672:INFO:Uploading results into container
2024-02-05 02:10:38,673:INFO:Uploading model into container now
2024-02-05 02:10:38,674:INFO:_master_model_container: 23
2024-02-05 02:10:38,674:INFO:_display_container: 9
2024-02-05 02:10:38,676:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6328,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:10:38,676:INFO:create_model() successfully completed......................................
2024-02-05 02:10:38,757:INFO:SubProcess create_model() end ==================================
2024-02-05 02:10:38,766:INFO:_master_model_container: 23
2024-02-05 02:10:38,766:INFO:_display_container: 9
2024-02-05 02:10:38,767:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.1,
                                                       loss='log_loss',
                                                       max_depth=3,
                                                       max_features=None,
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.0,
                                                       min_samples_leaf=1,
                                                       min_samples_split=2,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=100,
                                                       n_iter_no_change=None,
                                                       random_state=6328,
                                                       subsample=1.0,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:10:38,768:INFO:ensemble_model() successfully completed......................................
2024-02-05 02:10:38,833:INFO:Initializing ensemble_model()
2024-02-05 02:10:38,833:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=5,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:10:38,833:INFO:Checking exceptions
2024-02-05 02:10:38,849:INFO:Importing libraries
2024-02-05 02:10:38,850:INFO:Copying training dataset
2024-02-05 02:10:38,850:INFO:Checking base model
2024-02-05 02:10:38,850:INFO:Base model : Random Forest Classifier
2024-02-05 02:10:38,858:INFO:Importing untrained ensembler
2024-02-05 02:10:38,858:INFO:Ensemble method set to Bagging
2024-02-05 02:10:38,859:INFO:SubProcess create_model() called ==================================
2024-02-05 02:10:38,860:INFO:Initializing create_model()
2024-02-05 02:10:38,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced',
                                                   criterion='entropy',
                                                   max_depth=8,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=5,
                                                   min_samples_split=5,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=220, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6C47AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:10:38,860:INFO:Checking exceptions
2024-02-05 02:10:38,860:INFO:Importing libraries
2024-02-05 02:10:38,860:INFO:Copying training dataset
2024-02-05 02:10:38,866:INFO:Defining folds
2024-02-05 02:10:38,866:INFO:Declaring metric variables
2024-02-05 02:10:38,870:INFO:Importing untrained model
2024-02-05 02:10:38,870:INFO:Declaring custom model
2024-02-05 02:10:38,875:INFO:Bagging Classifier Imported successfully
2024-02-05 02:10:38,883:INFO:Starting cross validation
2024-02-05 02:10:38,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:11:40,476:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,476:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,485:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,631:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,742:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:40,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,571:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,574:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:11:57,595:INFO:Calculating mean and std
2024-02-05 02:11:57,596:INFO:Creating metrics dataframe
2024-02-05 02:11:57,601:INFO:Finalizing model
2024-02-05 02:12:07,146:INFO:Uploading results into container
2024-02-05 02:12:07,147:INFO:Uploading model into container now
2024-02-05 02:12:07,147:INFO:_master_model_container: 24
2024-02-05 02:12:07,148:INFO:_display_container: 10
2024-02-05 02:12:07,151:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced',
                                                   criterion='entropy',
                                                   max_depth=8,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=5,
                                                   min_samples_split=5,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=220, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:12:07,152:INFO:create_model() successfully completed......................................
2024-02-05 02:12:07,252:INFO:SubProcess create_model() end ==================================
2024-02-05 02:12:07,264:INFO:_master_model_container: 24
2024-02-05 02:12:07,264:INFO:_display_container: 10
2024-02-05 02:12:07,266:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RandomForestClassifier(bootstrap=True,
                                                   ccp_alpha=0.0,
                                                   class_weight='balanced',
                                                   criterion='entropy',
                                                   max_depth=8,
                                                   max_features=1.0,
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0,
                                                   min_samples_leaf=5,
                                                   min_samples_split=5,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=220, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:12:07,267:INFO:ensemble_model() successfully completed......................................
2024-02-05 02:12:07,348:INFO:Initializing ensemble_model()
2024-02-05 02:12:07,348:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=8, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0, min_samples_leaf=5,
                     min_samples_split=5, min_weight_fraction_leaf=0.0,
                     n_estimators=220, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:12:07,348:INFO:Checking exceptions
2024-02-05 02:12:07,368:INFO:Importing libraries
2024-02-05 02:12:07,368:INFO:Copying training dataset
2024-02-05 02:12:07,369:INFO:Checking base model
2024-02-05 02:12:07,370:INFO:Base model : Extra Trees Classifier
2024-02-05 02:12:07,378:INFO:Importing untrained ensembler
2024-02-05 02:12:07,378:INFO:Ensemble method set to Bagging
2024-02-05 02:12:07,378:INFO:SubProcess create_model() called ==================================
2024-02-05 02:12:07,380:INFO:Initializing create_model()
2024-02-05 02:12:07,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight='balanced',
                                                 criterion='entropy',
                                                 max_depth=8, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0,
                                                 min_samples_leaf=5,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=220, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=6328, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6FBBBB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:12:07,380:INFO:Checking exceptions
2024-02-05 02:12:07,381:INFO:Importing libraries
2024-02-05 02:12:07,381:INFO:Copying training dataset
2024-02-05 02:12:07,392:INFO:Defining folds
2024-02-05 02:12:07,392:INFO:Declaring metric variables
2024-02-05 02:12:07,399:INFO:Importing untrained model
2024-02-05 02:12:07,399:INFO:Declaring custom model
2024-02-05 02:12:07,407:INFO:Bagging Classifier Imported successfully
2024-02-05 02:12:07,415:INFO:Starting cross validation
2024-02-05 02:12:07,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:12:25,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,562:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,571:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,650:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,858:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,888:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,910:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:25,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,088:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,465:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:26,473:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,260:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:32,312:INFO:Calculating mean and std
2024-02-05 02:12:32,313:INFO:Creating metrics dataframe
2024-02-05 02:12:32,318:INFO:Finalizing model
2024-02-05 02:12:36,905:INFO:Uploading results into container
2024-02-05 02:12:36,906:INFO:Uploading model into container now
2024-02-05 02:12:36,907:INFO:_master_model_container: 25
2024-02-05 02:12:36,907:INFO:_display_container: 11
2024-02-05 02:12:36,911:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight='balanced',
                                                 criterion='entropy',
                                                 max_depth=8, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0,
                                                 min_samples_leaf=5,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=220, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=6328, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:12:36,912:INFO:create_model() successfully completed......................................
2024-02-05 02:12:37,009:INFO:SubProcess create_model() end ==================================
2024-02-05 02:12:37,023:INFO:_master_model_container: 25
2024-02-05 02:12:37,023:INFO:_display_container: 11
2024-02-05 02:12:37,025:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0,
                                                 class_weight='balanced',
                                                 criterion='entropy',
                                                 max_depth=8, max_features=1.0,
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0,
                                                 min_samples_leaf=5,
                                                 min_samples_split=5,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=220, n_jobs=-1,
                                                 oob_score=False,
                                                 random_state=6328, verbose=0,
                                                 warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6328, verbose=0,
                  warm_start=False)
2024-02-05 02:12:37,025:INFO:ensemble_model() successfully completed......................................
2024-02-05 02:12:37,108:INFO:Initializing blend_models()
2024-02-05 02:12:37,108:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:12:37,109:INFO:Checking exceptions
2024-02-05 02:12:37,129:INFO:Importing libraries
2024-02-05 02:12:37,129:INFO:Copying training dataset
2024-02-05 02:12:37,133:INFO:Getting model names
2024-02-05 02:12:37,146:INFO:SubProcess create_model() called ==================================
2024-02-05 02:12:37,157:INFO:Initializing create_model()
2024-02-05 02:12:37,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6328, reg_alpha=0.0,
                                             reg_lamb...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BF6AAB100>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:12:37,158:INFO:Checking exceptions
2024-02-05 02:12:37,158:INFO:Importing libraries
2024-02-05 02:12:37,158:INFO:Copying training dataset
2024-02-05 02:12:37,166:INFO:Defining folds
2024-02-05 02:12:37,166:INFO:Declaring metric variables
2024-02-05 02:12:37,171:INFO:Importing untrained model
2024-02-05 02:12:37,171:INFO:Declaring custom model
2024-02-05 02:12:37,177:INFO:Voting Classifier Imported successfully
2024-02-05 02:12:37,185:INFO:Starting cross validation
2024-02-05 02:12:37,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:12:56,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,656:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,679:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,771:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:12:56,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:13:03,214:INFO:Calculating mean and std
2024-02-05 02:13:03,216:INFO:Creating metrics dataframe
2024-02-05 02:13:03,226:INFO:Finalizing model
2024-02-05 02:13:08,342:INFO:Uploading results into container
2024-02-05 02:13:08,343:INFO:Uploading model into container now
2024-02-05 02:13:08,344:INFO:_master_model_container: 26
2024-02-05 02:13:08,344:INFO:_display_container: 12
2024-02-05 02:13:08,357:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6328, reg_alpha=0.0,
                                             reg_lamb...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-05 02:13:08,357:INFO:create_model() successfully completed......................................
2024-02-05 02:13:08,435:INFO:SubProcess create_model() end ==================================
2024-02-05 02:13:08,444:INFO:_master_model_container: 26
2024-02-05 02:13:08,444:INFO:_display_container: 12
2024-02-05 02:13:08,451:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6328, reg_alpha=0.0,
                                             reg_lamb...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=6328, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-05 02:13:08,451:INFO:blend_models() successfully completed......................................
2024-02-05 02:13:08,531:INFO:Initializing stack_models()
2024-02-05 02:13:08,532:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 02:13:08,532:INFO:Checking exceptions
2024-02-05 02:13:08,534:INFO:Defining meta model
2024-02-05 02:13:08,557:INFO:Getting model names
2024-02-05 02:13:08,559:INFO:[('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6328, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)), ('CatBoost Classifier', <catboost.core.CatBoostClassifier object at 0x0000022BF71DEC20>), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6328, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6328, verbose=0, warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6328, verbose=0, warm_start=False))]
2024-02-05 02:13:08,565:INFO:SubProcess create_model() called ==================================
2024-02-05 02:13:08,578:INFO:Initializing create_model()
2024-02-05 02:13:08,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BFB5BA8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:13:08,578:INFO:Checking exceptions
2024-02-05 02:13:08,578:INFO:Importing libraries
2024-02-05 02:13:08,578:INFO:Copying training dataset
2024-02-05 02:13:08,585:INFO:Defining folds
2024-02-05 02:13:08,585:INFO:Declaring metric variables
2024-02-05 02:13:08,590:INFO:Importing untrained model
2024-02-05 02:13:08,590:INFO:Declaring custom model
2024-02-05 02:13:08,596:INFO:Stacking Classifier Imported successfully
2024-02-05 02:13:08,605:INFO:Starting cross validation
2024-02-05 02:13:08,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 02:14:54,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:54,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:54,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:54,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,724:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:54,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:55,246:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:55,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:56,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:56,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:56,212:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:56,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:56,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:56,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:57,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:57,579:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:57,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:57,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:57,750:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:57,936:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:14:58,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:58,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:58,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:58,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:58,230:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:14:58,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:15:30,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-05 02:15:30,793:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 02:15:30,991:INFO:Calculating mean and std
2024-02-05 02:15:30,993:INFO:Creating metrics dataframe
2024-02-05 02:15:30,999:INFO:Finalizing model
2024-02-05 02:15:48,323:INFO:Uploading results into container
2024-02-05 02:15:48,324:INFO:Uploading model into container now
2024-02-05 02:15:48,325:INFO:_master_model_container: 27
2024-02-05 02:15:48,325:INFO:_display_container: 13
2024-02-05 02:15:48,337:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-05 02:15:48,338:INFO:create_model() successfully completed......................................
2024-02-05 02:15:48,436:INFO:SubProcess create_model() end ==================================
2024-02-05 02:15:48,447:INFO:_master_model_container: 27
2024-02-05 02:15:48,447:INFO:_display_container: 13
2024-02-05 02:15:48,454:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-05 02:15:48,455:INFO:stack_models() successfully completed......................................
2024-02-05 02:15:48,545:INFO:Initializing automl()
2024-02-05 02:15:48,545:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, optimize=Accuracy, use_holdout=False, turbo=True, return_train_score=False)
2024-02-05 02:15:48,546:INFO:Model Selection Basis : CV Results on Training set
2024-02-05 02:15:48,546:INFO:Checking model 0
2024-02-05 02:15:48,547:INFO:Checking model 1
2024-02-05 02:15:48,547:INFO:Checking model 2
2024-02-05 02:15:48,547:INFO:Checking model 3
2024-02-05 02:15:48,547:INFO:Checking model 4
2024-02-05 02:15:48,548:INFO:Checking model 5
2024-02-05 02:15:48,548:INFO:Checking model 6
2024-02-05 02:15:48,548:INFO:Checking model 7
2024-02-05 02:15:48,548:INFO:Checking model 8
2024-02-05 02:15:48,548:INFO:Checking model 9
2024-02-05 02:15:48,549:INFO:Checking model 10
2024-02-05 02:15:48,549:INFO:Checking model 11
2024-02-05 02:15:48,549:INFO:Checking model 12
2024-02-05 02:15:48,549:INFO:Checking model 13
2024-02-05 02:15:48,549:INFO:Checking model 14
2024-02-05 02:15:48,550:INFO:Checking model 15
2024-02-05 02:15:48,550:INFO:Checking model 16
2024-02-05 02:15:48,550:INFO:Checking model 17
2024-02-05 02:15:48,550:INFO:Checking model 18
2024-02-05 02:15:48,550:INFO:Checking model 19
2024-02-05 02:15:48,550:INFO:Checking model 20
2024-02-05 02:15:48,551:INFO:Checking model 21
2024-02-05 02:15:48,551:INFO:Checking model 22
2024-02-05 02:15:48,551:INFO:Checking model 23
2024-02-05 02:15:48,551:INFO:Checking model 24
2024-02-05 02:15:48,551:INFO:Checking model 25
2024-02-05 02:15:48,551:INFO:Checking model 26
2024-02-05 02:15:48,560:INFO:Initializing create_model()
2024-02-05 02:15:48,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:15:48,560:INFO:Checking exceptions
2024-02-05 02:15:48,562:INFO:Importing libraries
2024-02-05 02:15:48,562:INFO:Copying training dataset
2024-02-05 02:15:48,568:INFO:Defining folds
2024-02-05 02:15:48,569:INFO:Declaring metric variables
2024-02-05 02:15:48,569:INFO:Importing untrained model
2024-02-05 02:15:48,569:INFO:Declaring custom model
2024-02-05 02:15:48,572:INFO:Stacking Classifier Imported successfully
2024-02-05 02:15:48,573:INFO:Cross validation set to False
2024-02-05 02:15:48,573:INFO:Fitting Model
2024-02-05 02:16:05,545:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-05 02:16:05,545:INFO:create_model() successfully completed......................................
2024-02-05 02:16:05,705:INFO:StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-05 02:16:05,706:INFO:automl() successfully completed......................................
2024-02-05 02:16:05,767:INFO:Initializing finalize_model()
2024-02-05 02:16:05,767:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-05 02:16:05,778:INFO:Finalizing StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-05 02:16:05,792:INFO:Initializing create_model()
2024-02-05 02:16:05,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 02:16:05,792:INFO:Checking exceptions
2024-02-05 02:16:05,795:INFO:Importing libraries
2024-02-05 02:16:05,795:INFO:Copying training dataset
2024-02-05 02:16:05,795:INFO:Defining folds
2024-02-05 02:16:05,795:INFO:Declaring metric variables
2024-02-05 02:16:05,795:INFO:Importing untrained model
2024-02-05 02:16:05,795:INFO:Declaring custom model
2024-02-05 02:16:05,800:INFO:Stacking Classifier Imported successfully
2024-02-05 02:16:05,803:INFO:Cross validation set to False
2024-02-05 02:16:05,803:INFO:Fitting Model
2024-02-05 02:16:24,593:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                                                                      verbose=0,
                                                                      warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=6328,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-02-05 02:16:24,593:INFO:create_model() successfully completed......................................
2024-02-05 02:16:24,672:INFO:_master_model_container: 27
2024-02-05 02:16:24,672:INFO:_display_container: 12
2024-02-05 02:16:24,702:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                                                                      verbose=0,
                                                                      warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=6328,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False)
2024-02-05 02:16:24,702:INFO:finalize_model() successfully completed......................................
2024-02-05 02:16:24,842:INFO:Initializing predict_model()
2024-02-05 02:16:24,842:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=StackingClassifier(cv=5,
                   estimators=[('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_estimators=100, n_jobs=-1,
                                               num_leaves=31, objective=None,
                                               random_state=6328, reg_alpha=0.0,
                                               r...
                                                     random_state=6328,
                                                     verbose=0,
                                                     warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6328,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BF6C6F0A0>)
2024-02-05 02:16:24,843:INFO:Checking exceptions
2024-02-05 02:16:24,843:INFO:Preloading libraries
2024-02-05 02:16:24,846:INFO:Set up data.
2024-02-05 02:16:24,859:INFO:Set up index.
2024-02-05 02:23:34,568:INFO:Initializing predict_model()
2024-02-05 02:23:34,568:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BF67EE020>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                                                                      verbose=0,
                                                                      warm_start=False))],
                                    final_estimator=LogisticRegression(C=1.0,
                                                                       class_weight=None,
                                                                       dual=False,
                                                                       fit_intercept=True,
                                                                       intercept_scaling=1,
                                                                       l1_ratio=None,
                                                                       max_iter=1000,
                                                                       multi_class='auto',
                                                                       n_jobs=None,
                                                                       penalty='l2',
                                                                       random_state=6328,
                                                                       solver='lbfgs',
                                                                       tol=0.0001,
                                                                       verbose=0,
                                                                       warm_start=False),
                                    n_jobs=-1, passthrough=True,
                                    stack_method='auto', verbose=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022BD225ECB0>)
2024-02-05 02:23:34,569:INFO:Checking exceptions
2024-02-05 02:23:34,569:INFO:Preloading libraries
2024-02-05 02:23:34,573:INFO:Set up data.
2024-02-05 02:23:34,587:INFO:Set up index.
2024-02-05 11:59:48,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 11:59:48,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 11:59:48,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 11:59:48,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-05 12:02:51,132:INFO:PyCaret ClassificationExperiment
2024-02-05 12:02:51,132:INFO:Logging name: clf-default-name
2024-02-05 12:02:51,132:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-05 12:02:51,132:INFO:version 3.2.0
2024-02-05 12:02:51,133:INFO:Initializing setup()
2024-02-05 12:02:51,133:INFO:self.USI: 4f9c
2024-02-05 12:02:51,133:INFO:self._variable_keys: {'X', 'data', 'html_param', '_available_plots', 'gpu_param', 'y', 'is_multiclass', 'gpu_n_jobs_param', 'target_param', 'fold_shuffle_param', 'pipeline', 'exp_name_log', 'USI', 'n_jobs_param', 'y_test', 'fold_groups_param', 'fix_imbalance', '_ml_usecase', 'logging_param', 'y_train', 'idx', 'X_test', 'seed', 'exp_id', 'memory', 'fold_generator', 'X_train', 'log_plots_param'}
2024-02-05 12:02:51,133:INFO:Checking environment
2024-02-05 12:02:51,133:INFO:python_version: 3.10.9
2024-02-05 12:02:51,133:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-05 12:02:51,133:INFO:machine: AMD64
2024-02-05 12:02:51,133:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-05 12:02:51,133:INFO:Memory: svmem(total=16856182784, available=6642393088, percent=60.6, used=10213789696, free=6642393088)
2024-02-05 12:02:51,133:INFO:Physical Core: 4
2024-02-05 12:02:51,133:INFO:Logical Core: 8
2024-02-05 12:02:51,133:INFO:Checking libraries
2024-02-05 12:02:51,133:INFO:System:
2024-02-05 12:02:51,134:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-05 12:02:51,134:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-05 12:02:51,134:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-05 12:02:51,134:INFO:PyCaret required dependencies:
2024-02-05 12:02:51,246:INFO:                 pip: 22.3.1
2024-02-05 12:02:51,246:INFO:          setuptools: 65.6.3
2024-02-05 12:02:51,246:INFO:             pycaret: 3.2.0
2024-02-05 12:02:51,246:INFO:             IPython: 8.20.0
2024-02-05 12:02:51,247:INFO:          ipywidgets: 8.0.4
2024-02-05 12:02:51,247:INFO:                tqdm: 4.64.1
2024-02-05 12:02:51,247:INFO:               numpy: 1.25.2
2024-02-05 12:02:51,247:INFO:              pandas: 1.5.3
2024-02-05 12:02:51,247:INFO:              jinja2: 3.1.3
2024-02-05 12:02:51,247:INFO:               scipy: 1.10.1
2024-02-05 12:02:51,247:INFO:              joblib: 1.3.2
2024-02-05 12:02:51,247:INFO:             sklearn: 1.2.2
2024-02-05 12:02:51,247:INFO:                pyod: 1.1.2
2024-02-05 12:02:51,247:INFO:            imblearn: 0.12.0
2024-02-05 12:02:51,247:INFO:   category_encoders: 2.6.3
2024-02-05 12:02:51,247:INFO:            lightgbm: 4.3.0
2024-02-05 12:02:51,247:INFO:               numba: 0.59.0
2024-02-05 12:02:51,248:INFO:            requests: 2.31.0
2024-02-05 12:02:51,248:INFO:          matplotlib: 3.6.0
2024-02-05 12:02:51,248:INFO:          scikitplot: 0.3.7
2024-02-05 12:02:51,248:INFO:         yellowbrick: 1.5
2024-02-05 12:02:51,248:INFO:              plotly: 5.18.0
2024-02-05 12:02:51,248:INFO:    plotly-resampler: Not installed
2024-02-05 12:02:51,248:INFO:             kaleido: 0.2.1
2024-02-05 12:02:51,248:INFO:           schemdraw: 0.15
2024-02-05 12:02:51,248:INFO:         statsmodels: 0.14.1
2024-02-05 12:02:51,248:INFO:              sktime: 0.21.1
2024-02-05 12:02:51,248:INFO:               tbats: 1.1.3
2024-02-05 12:02:51,248:INFO:            pmdarima: 2.0.4
2024-02-05 12:02:51,249:INFO:              psutil: 5.9.0
2024-02-05 12:02:51,249:INFO:          markupsafe: 2.1.3
2024-02-05 12:02:51,249:INFO:             pickle5: Not installed
2024-02-05 12:02:51,249:INFO:         cloudpickle: 3.0.0
2024-02-05 12:02:51,249:INFO:         deprecation: 2.1.0
2024-02-05 12:02:51,249:INFO:              xxhash: 3.4.1
2024-02-05 12:02:51,249:INFO:           wurlitzer: Not installed
2024-02-05 12:02:51,249:INFO:PyCaret optional dependencies:
2024-02-05 12:02:51,267:INFO:                shap: 0.44.1
2024-02-05 12:02:51,268:INFO:           interpret: Not installed
2024-02-05 12:02:51,268:INFO:                umap: Not installed
2024-02-05 12:02:51,268:INFO:     ydata_profiling: Not installed
2024-02-05 12:02:51,268:INFO:  explainerdashboard: 0.4.5
2024-02-05 12:02:51,268:INFO:             autoviz: Not installed
2024-02-05 12:02:51,268:INFO:           fairlearn: Not installed
2024-02-05 12:02:51,268:INFO:          deepchecks: Not installed
2024-02-05 12:02:51,268:INFO:             xgboost: Not installed
2024-02-05 12:02:51,268:INFO:            catboost: 1.2.2
2024-02-05 12:02:51,268:INFO:              kmodes: Not installed
2024-02-05 12:02:51,268:INFO:             mlxtend: Not installed
2024-02-05 12:02:51,268:INFO:       statsforecast: Not installed
2024-02-05 12:02:51,268:INFO:        tune_sklearn: Not installed
2024-02-05 12:02:51,268:INFO:                 ray: Not installed
2024-02-05 12:02:51,268:INFO:            hyperopt: Not installed
2024-02-05 12:02:51,268:INFO:              optuna: Not installed
2024-02-05 12:02:51,268:INFO:               skopt: Not installed
2024-02-05 12:02:51,268:INFO:              mlflow: 2.10.0
2024-02-05 12:02:51,268:INFO:              gradio: Not installed
2024-02-05 12:02:51,268:INFO:             fastapi: Not installed
2024-02-05 12:02:51,269:INFO:             uvicorn: Not installed
2024-02-05 12:02:51,269:INFO:              m2cgen: Not installed
2024-02-05 12:02:51,269:INFO:           evidently: Not installed
2024-02-05 12:02:51,269:INFO:               fugue: Not installed
2024-02-05 12:02:51,269:INFO:           streamlit: Not installed
2024-02-05 12:02:51,269:INFO:             prophet: Not installed
2024-02-05 12:02:51,269:INFO:None
2024-02-05 12:02:51,269:INFO:Set up data.
2024-02-05 12:02:51,281:INFO:Set up folding strategy.
2024-02-05 12:02:51,282:INFO:Set up train/test split.
2024-02-05 12:02:51,291:INFO:Set up index.
2024-02-05 12:02:51,291:INFO:Assigning column types.
2024-02-05 12:02:51,296:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-05 12:02:51,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,375:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,481:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,543:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,544:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-05 12:02:51,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,617:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,660:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-05 12:02:51,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,685:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,686:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-05 12:02:51,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,756:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:51,829:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:51,831:INFO:Preparing preprocessing pipeline...
2024-02-05 12:02:51,832:INFO:Set up label encoding.
2024-02-05 12:02:51,832:INFO:Set up simple imputation.
2024-02-05 12:02:51,835:INFO:Set up encoding of categorical features.
2024-02-05 12:02:51,941:INFO:Finished creating preprocessing pipeline.
2024-02-05 12:02:51,952:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'tot...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['state'],
                                    transformer=TargetEncoder(cols=['state'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-02-05 12:02:51,952:INFO:Creating final display dataframe.
2024-02-05 12:02:52,256:INFO:Setup _display_container:                     Description             Value
0                    Session id              2310
1                        Target             churn
2                   Target type            Binary
3                Target mapping     no: 0, yes: 1
4           Original data shape        (4250, 22)
5        Transformed data shape        (4250, 23)
6   Transformed train set shape        (2975, 23)
7    Transformed test set shape        (1275, 23)
8              Numeric features                18
9          Categorical features                 2
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              4f9c
2024-02-05 12:02:52,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:52,353:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:52,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:52,432:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:52,433:INFO:setup() successfully completed in 1.31s...............
2024-02-05 12:02:54,282:INFO:gpu_param set to False
2024-02-05 12:02:54,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:54,358:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:02:54,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:02:54,430:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:03:42,861:INFO:gpu_param set to False
2024-02-05 12:03:42,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:03:42,936:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:03:43,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-05 12:03:43,010:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-05 12:04:56,853:INFO:Initializing compare_models()
2024-02-05 12:04:56,853:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, include=['gbc', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, 'include': ['gbc', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 12:04:56,854:INFO:Checking exceptions
2024-02-05 12:04:56,861:INFO:Preparing display monitor
2024-02-05 12:04:56,897:INFO:Initializing Gradient Boosting Classifier
2024-02-05 12:04:56,897:INFO:Total runtime is 0.0 minutes
2024-02-05 12:04:56,902:INFO:SubProcess create_model() called ==================================
2024-02-05 12:04:56,903:INFO:Initializing create_model()
2024-02-05 12:04:56,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BAB6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:04:56,903:INFO:Checking exceptions
2024-02-05 12:04:56,903:INFO:Importing libraries
2024-02-05 12:04:56,903:INFO:Copying training dataset
2024-02-05 12:04:56,911:INFO:Defining folds
2024-02-05 12:04:56,911:INFO:Declaring metric variables
2024-02-05 12:04:56,916:INFO:Importing untrained model
2024-02-05 12:04:56,922:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 12:04:56,935:INFO:Starting cross validation
2024-02-05 12:04:56,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:05:03,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:03,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:03,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:03,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:03,999:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,202:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,346:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,369:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,481:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,488:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:04,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,538:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,696:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:05,707:INFO:Calculating mean and std
2024-02-05 12:05:05,708:INFO:Creating metrics dataframe
2024-02-05 12:05:05,712:INFO:Uploading results into container
2024-02-05 12:05:05,713:INFO:Uploading model into container now
2024-02-05 12:05:05,713:INFO:_master_model_container: 1
2024-02-05 12:05:05,714:INFO:_display_container: 2
2024-02-05 12:05:05,714:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 12:05:05,714:INFO:create_model() successfully completed......................................
2024-02-05 12:05:05,830:INFO:SubProcess create_model() end ==================================
2024-02-05 12:05:05,830:INFO:Creating metrics dataframe
2024-02-05 12:05:05,842:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 12:05:05,842:INFO:Total runtime is 0.14908965826034545 minutes
2024-02-05 12:05:05,845:INFO:SubProcess create_model() called ==================================
2024-02-05 12:05:05,845:INFO:Initializing create_model()
2024-02-05 12:05:05,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BAB6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:05:05,845:INFO:Checking exceptions
2024-02-05 12:05:05,845:INFO:Importing libraries
2024-02-05 12:05:05,846:INFO:Copying training dataset
2024-02-05 12:05:05,852:INFO:Defining folds
2024-02-05 12:05:05,852:INFO:Declaring metric variables
2024-02-05 12:05:05,856:INFO:Importing untrained model
2024-02-05 12:05:05,861:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:05:05,870:INFO:Starting cross validation
2024-02-05 12:05:05,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:05:06,724:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,731:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,743:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,760:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,766:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,873:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,980:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,989:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:06,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,053:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,242:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:07,268:INFO:Calculating mean and std
2024-02-05 12:05:07,269:INFO:Creating metrics dataframe
2024-02-05 12:05:07,275:INFO:Uploading results into container
2024-02-05 12:05:07,276:INFO:Uploading model into container now
2024-02-05 12:05:07,277:INFO:_master_model_container: 2
2024-02-05 12:05:07,277:INFO:_display_container: 2
2024-02-05 12:05:07,278:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:05:07,278:INFO:create_model() successfully completed......................................
2024-02-05 12:05:07,411:INFO:SubProcess create_model() end ==================================
2024-02-05 12:05:07,411:INFO:Creating metrics dataframe
2024-02-05 12:05:07,422:INFO:Initializing CatBoost Classifier
2024-02-05 12:05:07,422:INFO:Total runtime is 0.17542407115300496 minutes
2024-02-05 12:05:07,425:INFO:SubProcess create_model() called ==================================
2024-02-05 12:05:07,425:INFO:Initializing create_model()
2024-02-05 12:05:07,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BAB6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:05:07,426:INFO:Checking exceptions
2024-02-05 12:05:07,426:INFO:Importing libraries
2024-02-05 12:05:07,426:INFO:Copying training dataset
2024-02-05 12:05:07,432:INFO:Defining folds
2024-02-05 12:05:07,432:INFO:Declaring metric variables
2024-02-05 12:05:07,436:INFO:Importing untrained model
2024-02-05 12:05:07,444:INFO:CatBoost Classifier Imported successfully
2024-02-05 12:05:07,453:INFO:Starting cross validation
2024-02-05 12:05:07,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:05:20,849:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:20,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:20,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,497:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,509:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,510:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,518:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,883:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:21,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,064:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,074:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,089:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,096:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:22,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,120:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:05:26,144:INFO:Calculating mean and std
2024-02-05 12:05:26,144:INFO:Creating metrics dataframe
2024-02-05 12:05:26,148:INFO:Uploading results into container
2024-02-05 12:05:26,149:INFO:Uploading model into container now
2024-02-05 12:05:26,149:INFO:_master_model_container: 3
2024-02-05 12:05:26,149:INFO:_display_container: 2
2024-02-05 12:05:26,149:INFO:<catboost.core.CatBoostClassifier object at 0x000001D58B738C70>
2024-02-05 12:05:26,149:INFO:create_model() successfully completed......................................
2024-02-05 12:05:26,253:INFO:SubProcess create_model() end ==================================
2024-02-05 12:05:26,253:INFO:Creating metrics dataframe
2024-02-05 12:05:26,274:INFO:Initializing create_model()
2024-02-05 12:05:26,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:05:26,274:INFO:Checking exceptions
2024-02-05 12:05:26,279:INFO:Importing libraries
2024-02-05 12:05:26,279:INFO:Copying training dataset
2024-02-05 12:05:26,287:INFO:Defining folds
2024-02-05 12:05:26,287:INFO:Declaring metric variables
2024-02-05 12:05:26,287:INFO:Importing untrained model
2024-02-05 12:05:26,287:INFO:Declaring custom model
2024-02-05 12:05:26,288:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:05:26,290:INFO:Cross validation set to False
2024-02-05 12:05:26,291:INFO:Fitting Model
2024-02-05 12:05:26,359:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:05:26,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-02-05 12:05:26,360:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:05:26,360:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:05:26,360:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:05:26,360:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:05:26,360:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:05:26,429:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:05:26,429:INFO:create_model() successfully completed......................................
2024-02-05 12:05:26,542:INFO:Initializing create_model()
2024-02-05 12:05:26,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D58B738C70>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:05:26,543:INFO:Checking exceptions
2024-02-05 12:05:26,545:INFO:Importing libraries
2024-02-05 12:05:26,545:INFO:Copying training dataset
2024-02-05 12:05:26,552:INFO:Defining folds
2024-02-05 12:05:26,552:INFO:Declaring metric variables
2024-02-05 12:05:26,552:INFO:Importing untrained model
2024-02-05 12:05:26,552:INFO:Declaring custom model
2024-02-05 12:05:26,553:INFO:CatBoost Classifier Imported successfully
2024-02-05 12:05:26,554:INFO:Cross validation set to False
2024-02-05 12:05:26,554:INFO:Fitting Model
2024-02-05 12:05:29,908:INFO:<catboost.core.CatBoostClassifier object at 0x000001D58BC01870>
2024-02-05 12:05:29,908:INFO:create_model() successfully completed......................................
2024-02-05 12:05:30,013:INFO:Initializing create_model()
2024-02-05 12:05:30,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:05:30,013:INFO:Checking exceptions
2024-02-05 12:05:30,018:INFO:Importing libraries
2024-02-05 12:05:30,018:INFO:Copying training dataset
2024-02-05 12:05:30,026:INFO:Defining folds
2024-02-05 12:05:30,027:INFO:Declaring metric variables
2024-02-05 12:05:30,027:INFO:Importing untrained model
2024-02-05 12:05:30,027:INFO:Declaring custom model
2024-02-05 12:05:30,028:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 12:05:30,030:INFO:Cross validation set to False
2024-02-05 12:05:30,031:INFO:Fitting Model
2024-02-05 12:05:31,114:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 12:05:31,114:INFO:create_model() successfully completed......................................
2024-02-05 12:05:31,240:INFO:_master_model_container: 3
2024-02-05 12:05:31,240:INFO:_display_container: 2
2024-02-05 12:05:31,241:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001D58BC01870>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-02-05 12:05:31,241:INFO:compare_models() successfully completed......................................
2024-02-05 12:06:59,275:INFO:Initializing automl()
2024-02-05 12:06:59,275:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, optimize=Accuracy, use_holdout=False, turbo=True, return_train_score=False)
2024-02-05 12:06:59,276:INFO:Model Selection Basis : CV Results on Training set
2024-02-05 12:06:59,276:INFO:Checking model 0
2024-02-05 12:06:59,277:INFO:Checking model 1
2024-02-05 12:06:59,277:INFO:Checking model 2
2024-02-05 12:06:59,278:INFO:Initializing create_model()
2024-02-05 12:06:59,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:06:59,278:INFO:Checking exceptions
2024-02-05 12:06:59,280:INFO:Importing libraries
2024-02-05 12:06:59,281:INFO:Copying training dataset
2024-02-05 12:06:59,287:INFO:Defining folds
2024-02-05 12:06:59,287:INFO:Declaring metric variables
2024-02-05 12:06:59,287:INFO:Importing untrained model
2024-02-05 12:06:59,287:INFO:Declaring custom model
2024-02-05 12:06:59,288:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:06:59,289:INFO:Cross validation set to False
2024-02-05 12:06:59,289:INFO:Fitting Model
2024-02-05 12:06:59,350:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:06:59,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2024-02-05 12:06:59,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:06:59,351:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:06:59,351:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:06:59,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:06:59,351:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:06:59,456:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:06:59,456:INFO:create_model() successfully completed......................................
2024-02-05 12:06:59,735:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:06:59,736:INFO:automl() successfully completed......................................
2024-02-05 12:08:22,279:INFO:Initializing compare_models()
2024-02-05 12:08:22,279:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, include=['gbc', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, 'include': ['gbc', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 12:08:22,279:INFO:Checking exceptions
2024-02-05 12:08:22,283:INFO:Preparing display monitor
2024-02-05 12:08:22,335:INFO:Initializing Gradient Boosting Classifier
2024-02-05 12:08:22,336:INFO:Total runtime is 9.147326151529948e-06 minutes
2024-02-05 12:08:22,341:INFO:SubProcess create_model() called ==================================
2024-02-05 12:08:22,343:INFO:Initializing create_model()
2024-02-05 12:08:22,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58B84FF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:22,343:INFO:Checking exceptions
2024-02-05 12:08:22,344:INFO:Importing libraries
2024-02-05 12:08:22,344:INFO:Copying training dataset
2024-02-05 12:08:22,353:INFO:Defining folds
2024-02-05 12:08:22,353:INFO:Declaring metric variables
2024-02-05 12:08:22,358:INFO:Importing untrained model
2024-02-05 12:08:22,363:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 12:08:22,373:INFO:Starting cross validation
2024-02-05 12:08:22,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:08:23,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,838:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,844:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,873:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:23,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,178:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,229:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:24,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:25,093:INFO:Calculating mean and std
2024-02-05 12:08:25,094:INFO:Creating metrics dataframe
2024-02-05 12:08:25,097:INFO:Uploading results into container
2024-02-05 12:08:25,098:INFO:Uploading model into container now
2024-02-05 12:08:25,098:INFO:_master_model_container: 4
2024-02-05 12:08:25,098:INFO:_display_container: 2
2024-02-05 12:08:25,099:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 12:08:25,099:INFO:create_model() successfully completed......................................
2024-02-05 12:08:25,212:INFO:SubProcess create_model() end ==================================
2024-02-05 12:08:25,212:INFO:Creating metrics dataframe
2024-02-05 12:08:25,221:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 12:08:25,221:INFO:Total runtime is 0.04808850685755412 minutes
2024-02-05 12:08:25,224:INFO:SubProcess create_model() called ==================================
2024-02-05 12:08:25,225:INFO:Initializing create_model()
2024-02-05 12:08:25,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58B84FF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:25,225:INFO:Checking exceptions
2024-02-05 12:08:25,225:INFO:Importing libraries
2024-02-05 12:08:25,225:INFO:Copying training dataset
2024-02-05 12:08:25,231:INFO:Defining folds
2024-02-05 12:08:25,231:INFO:Declaring metric variables
2024-02-05 12:08:25,234:INFO:Importing untrained model
2024-02-05 12:08:25,241:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:08:25,250:INFO:Starting cross validation
2024-02-05 12:08:25,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:08:26,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,041:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,064:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,179:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,392:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:26,405:INFO:Calculating mean and std
2024-02-05 12:08:26,407:INFO:Creating metrics dataframe
2024-02-05 12:08:26,412:INFO:Uploading results into container
2024-02-05 12:08:26,413:INFO:Uploading model into container now
2024-02-05 12:08:26,414:INFO:_master_model_container: 5
2024-02-05 12:08:26,414:INFO:_display_container: 2
2024-02-05 12:08:26,416:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:08:26,416:INFO:create_model() successfully completed......................................
2024-02-05 12:08:26,546:INFO:SubProcess create_model() end ==================================
2024-02-05 12:08:26,546:INFO:Creating metrics dataframe
2024-02-05 12:08:26,555:INFO:Initializing CatBoost Classifier
2024-02-05 12:08:26,556:INFO:Total runtime is 0.07033460140228272 minutes
2024-02-05 12:08:26,559:INFO:SubProcess create_model() called ==================================
2024-02-05 12:08:26,560:INFO:Initializing create_model()
2024-02-05 12:08:26,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58B84FF70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:26,560:INFO:Checking exceptions
2024-02-05 12:08:26,560:INFO:Importing libraries
2024-02-05 12:08:26,560:INFO:Copying training dataset
2024-02-05 12:08:26,567:INFO:Defining folds
2024-02-05 12:08:26,567:INFO:Declaring metric variables
2024-02-05 12:08:26,572:INFO:Importing untrained model
2024-02-05 12:08:26,579:INFO:CatBoost Classifier Imported successfully
2024-02-05 12:08:26,591:INFO:Starting cross validation
2024-02-05 12:08:26,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:08:39,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,529:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,584:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,652:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,664:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,793:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,828:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:39,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,852:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,856:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:08:44,866:INFO:Calculating mean and std
2024-02-05 12:08:44,867:INFO:Creating metrics dataframe
2024-02-05 12:08:44,870:INFO:Uploading results into container
2024-02-05 12:08:44,872:INFO:Uploading model into container now
2024-02-05 12:08:44,874:INFO:_master_model_container: 6
2024-02-05 12:08:44,874:INFO:_display_container: 2
2024-02-05 12:08:44,874:INFO:<catboost.core.CatBoostClassifier object at 0x000001D58D5DBD00>
2024-02-05 12:08:44,875:INFO:create_model() successfully completed......................................
2024-02-05 12:08:45,021:INFO:SubProcess create_model() end ==================================
2024-02-05 12:08:45,021:INFO:Creating metrics dataframe
2024-02-05 12:08:45,045:INFO:Initializing create_model()
2024-02-05 12:08:45,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:45,046:INFO:Checking exceptions
2024-02-05 12:08:45,048:INFO:Importing libraries
2024-02-05 12:08:45,048:INFO:Copying training dataset
2024-02-05 12:08:45,057:INFO:Defining folds
2024-02-05 12:08:45,057:INFO:Declaring metric variables
2024-02-05 12:08:45,058:INFO:Importing untrained model
2024-02-05 12:08:45,058:INFO:Declaring custom model
2024-02-05 12:08:45,058:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:08:45,061:INFO:Cross validation set to False
2024-02-05 12:08:45,061:INFO:Fitting Model
2024-02-05 12:08:45,123:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:08:45,124:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2024-02-05 12:08:45,124:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:08:45,124:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:08:45,124:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:08:45,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:08:45,125:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:08:45,191:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:08:45,192:INFO:create_model() successfully completed......................................
2024-02-05 12:08:45,301:INFO:Initializing create_model()
2024-02-05 12:08:45,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=<catboost.core.CatBoostClassifier object at 0x000001D58D5DBD00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:45,302:INFO:Checking exceptions
2024-02-05 12:08:45,304:INFO:Importing libraries
2024-02-05 12:08:45,304:INFO:Copying training dataset
2024-02-05 12:08:45,312:INFO:Defining folds
2024-02-05 12:08:45,313:INFO:Declaring metric variables
2024-02-05 12:08:45,313:INFO:Importing untrained model
2024-02-05 12:08:45,313:INFO:Declaring custom model
2024-02-05 12:08:45,314:INFO:CatBoost Classifier Imported successfully
2024-02-05 12:08:45,315:INFO:Cross validation set to False
2024-02-05 12:08:45,315:INFO:Fitting Model
2024-02-05 12:08:49,202:INFO:<catboost.core.CatBoostClassifier object at 0x000001D58D5DB910>
2024-02-05 12:08:49,202:INFO:create_model() successfully completed......................................
2024-02-05 12:08:49,327:INFO:Initializing create_model()
2024-02-05 12:08:49,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:08:49,327:INFO:Checking exceptions
2024-02-05 12:08:49,333:INFO:Importing libraries
2024-02-05 12:08:49,334:INFO:Copying training dataset
2024-02-05 12:08:49,345:INFO:Defining folds
2024-02-05 12:08:49,346:INFO:Declaring metric variables
2024-02-05 12:08:49,346:INFO:Importing untrained model
2024-02-05 12:08:49,346:INFO:Declaring custom model
2024-02-05 12:08:49,347:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 12:08:49,350:INFO:Cross validation set to False
2024-02-05 12:08:49,350:INFO:Fitting Model
2024-02-05 12:08:50,480:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 12:08:50,480:INFO:create_model() successfully completed......................................
2024-02-05 12:08:50,619:INFO:_master_model_container: 6
2024-02-05 12:08:50,620:INFO:_display_container: 2
2024-02-05 12:08:50,621:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001D58D5DB910>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-02-05 12:08:50,621:INFO:compare_models() successfully completed......................................
2024-02-05 12:10:52,387:INFO:Initializing tune_model()
2024-02-05 12:10:52,387:INFO:tune_model(estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000001D58D5DB910>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>)
2024-02-05 12:10:52,387:INFO:Checking exceptions
2024-02-05 12:12:01,215:INFO:Initializing compare_models()
2024-02-05 12:12:01,215:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, include=['gbc', 'lightgbm', 'catboost'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, 'include': ['gbc', 'lightgbm', 'catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-05 12:12:01,216:INFO:Checking exceptions
2024-02-05 12:12:01,219:INFO:Preparing display monitor
2024-02-05 12:12:01,271:INFO:Initializing Gradient Boosting Classifier
2024-02-05 12:12:01,271:INFO:Total runtime is 1.6578038533528645e-05 minutes
2024-02-05 12:12:01,278:INFO:SubProcess create_model() called ==================================
2024-02-05 12:12:01,278:INFO:Initializing create_model()
2024-02-05 12:12:01,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BC8A800>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:12:01,279:INFO:Checking exceptions
2024-02-05 12:12:01,280:INFO:Importing libraries
2024-02-05 12:12:01,280:INFO:Copying training dataset
2024-02-05 12:12:01,288:INFO:Defining folds
2024-02-05 12:12:01,288:INFO:Declaring metric variables
2024-02-05 12:12:01,292:INFO:Importing untrained model
2024-02-05 12:12:01,297:INFO:Gradient Boosting Classifier Imported successfully
2024-02-05 12:12:01,305:INFO:Starting cross validation
2024-02-05 12:12:01,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:12:02,750:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,757:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,763:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,829:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,839:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:02,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:03,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:03,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:03,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:04,049:INFO:Calculating mean and std
2024-02-05 12:12:04,050:INFO:Creating metrics dataframe
2024-02-05 12:12:04,053:INFO:Uploading results into container
2024-02-05 12:12:04,054:INFO:Uploading model into container now
2024-02-05 12:12:04,054:INFO:_master_model_container: 7
2024-02-05 12:12:04,054:INFO:_display_container: 2
2024-02-05 12:12:04,055:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2310, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-05 12:12:04,055:INFO:create_model() successfully completed......................................
2024-02-05 12:12:04,172:INFO:SubProcess create_model() end ==================================
2024-02-05 12:12:04,172:INFO:Creating metrics dataframe
2024-02-05 12:12:04,181:INFO:Initializing Light Gradient Boosting Machine
2024-02-05 12:12:04,181:INFO:Total runtime is 0.04851437012354533 minutes
2024-02-05 12:12:04,184:INFO:SubProcess create_model() called ==================================
2024-02-05 12:12:04,185:INFO:Initializing create_model()
2024-02-05 12:12:04,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BC8A800>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:12:04,185:INFO:Checking exceptions
2024-02-05 12:12:04,185:INFO:Importing libraries
2024-02-05 12:12:04,185:INFO:Copying training dataset
2024-02-05 12:12:04,192:INFO:Defining folds
2024-02-05 12:12:04,192:INFO:Declaring metric variables
2024-02-05 12:12:04,196:INFO:Importing untrained model
2024-02-05 12:12:04,203:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:12:04,212:INFO:Starting cross validation
2024-02-05 12:12:04,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:12:05,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,112:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,114:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,212:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,224:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,304:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,546:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:05,587:INFO:Calculating mean and std
2024-02-05 12:12:05,588:INFO:Creating metrics dataframe
2024-02-05 12:12:05,594:INFO:Uploading results into container
2024-02-05 12:12:05,594:INFO:Uploading model into container now
2024-02-05 12:12:05,596:INFO:_master_model_container: 8
2024-02-05 12:12:05,596:INFO:_display_container: 2
2024-02-05 12:12:05,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:12:05,599:INFO:create_model() successfully completed......................................
2024-02-05 12:12:05,794:INFO:SubProcess create_model() end ==================================
2024-02-05 12:12:05,795:INFO:Creating metrics dataframe
2024-02-05 12:12:05,813:INFO:Initializing CatBoost Classifier
2024-02-05 12:12:05,813:INFO:Total runtime is 0.07572053670883179 minutes
2024-02-05 12:12:05,819:INFO:SubProcess create_model() called ==================================
2024-02-05 12:12:05,819:INFO:Initializing create_model()
2024-02-05 12:12:05,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BC8A800>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:12:05,820:INFO:Checking exceptions
2024-02-05 12:12:05,820:INFO:Importing libraries
2024-02-05 12:12:05,820:INFO:Copying training dataset
2024-02-05 12:12:05,831:INFO:Defining folds
2024-02-05 12:12:05,831:INFO:Declaring metric variables
2024-02-05 12:12:05,837:INFO:Importing untrained model
2024-02-05 12:12:05,847:INFO:CatBoost Classifier Imported successfully
2024-02-05 12:12:05,865:INFO:Starting cross validation
2024-02-05 12:12:05,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:12:17,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:17,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:17,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,246:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,493:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,499:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,607:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,631:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,642:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:19,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:12:25,226:INFO:Calculating mean and std
2024-02-05 12:12:25,228:INFO:Creating metrics dataframe
2024-02-05 12:12:25,235:INFO:Uploading results into container
2024-02-05 12:12:25,236:INFO:Uploading model into container now
2024-02-05 12:12:25,237:INFO:_master_model_container: 9
2024-02-05 12:12:25,237:INFO:_display_container: 2
2024-02-05 12:12:25,238:INFO:<catboost.core.CatBoostClassifier object at 0x000001D58D5DBCA0>
2024-02-05 12:12:25,238:INFO:create_model() successfully completed......................................
2024-02-05 12:12:25,409:INFO:SubProcess create_model() end ==================================
2024-02-05 12:12:25,409:INFO:Creating metrics dataframe
2024-02-05 12:12:25,449:INFO:Initializing create_model()
2024-02-05 12:12:25,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:12:25,450:INFO:Checking exceptions
2024-02-05 12:12:25,453:INFO:Importing libraries
2024-02-05 12:12:25,455:INFO:Copying training dataset
2024-02-05 12:12:25,471:INFO:Defining folds
2024-02-05 12:12:25,471:INFO:Declaring metric variables
2024-02-05 12:12:25,472:INFO:Importing untrained model
2024-02-05 12:12:25,472:INFO:Declaring custom model
2024-02-05 12:12:25,475:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:12:25,478:INFO:Cross validation set to False
2024-02-05 12:12:25,479:INFO:Fitting Model
2024-02-05 12:12:25,660:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:12:25,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000646 seconds.
2024-02-05 12:12:25,661:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:12:25,662:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:12:25,662:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:12:25,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:12:25,662:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:12:25,760:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:12:25,760:INFO:create_model() successfully completed......................................
2024-02-05 12:12:25,909:INFO:_master_model_container: 9
2024-02-05 12:12:25,910:INFO:_display_container: 2
2024-02-05 12:12:25,912:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:12:25,912:INFO:compare_models() successfully completed......................................
2024-02-05 12:16:17,955:INFO:Initializing plot_model()
2024-02-05 12:16:17,956:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, system=True)
2024-02-05 12:16:17,956:INFO:Checking exceptions
2024-02-05 12:16:17,962:INFO:Preloading libraries
2024-02-05 12:16:17,971:INFO:Copying training dataset
2024-02-05 12:16:17,971:INFO:Plot type: auc
2024-02-05 12:16:18,407:INFO:Fitting Model
2024-02-05 12:16:18,409:INFO:Scoring test/hold-out set
2024-02-05 12:16:18,718:INFO:Visual Rendered Successfully
2024-02-05 12:16:18,842:INFO:plot_model() successfully completed......................................
2024-02-05 12:18:34,648:INFO:Initializing predict_model()
2024-02-05 12:18:34,648:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D566560>)
2024-02-05 12:18:34,648:INFO:Checking exceptions
2024-02-05 12:18:34,648:INFO:Preloading libraries
2024-02-05 12:19:09,910:INFO:Initializing predict_model()
2024-02-05 12:19:09,910:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D564B80>)
2024-02-05 12:19:09,910:INFO:Checking exceptions
2024-02-05 12:19:09,911:INFO:Preloading libraries
2024-02-05 12:19:55,157:INFO:Initializing tune_model()
2024-02-05 12:19:55,158:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>)
2024-02-05 12:19:55,159:INFO:Checking exceptions
2024-02-05 12:19:55,183:INFO:Copying training dataset
2024-02-05 12:19:55,190:INFO:Checking base model
2024-02-05 12:19:55,190:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 12:19:55,198:INFO:Declaring metric variables
2024-02-05 12:19:55,205:INFO:Defining Hyperparameters
2024-02-05 12:19:55,331:INFO:Tuning with n_jobs=-1
2024-02-05 12:19:55,332:INFO:Initializing RandomizedSearchCV
2024-02-05 12:20:12,543:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 60, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.8}
2024-02-05 12:20:12,545:INFO:Hyperparameter search completed
2024-02-05 12:20:12,545:INFO:SubProcess create_model() called ==================================
2024-02-05 12:20:12,546:INFO:Initializing create_model()
2024-02-05 12:20:12,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D5897BCD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.1, 'num_leaves': 60, 'n_estimators': 250, 'min_split_gain': 0.5, 'min_child_samples': 11, 'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.8})
2024-02-05 12:20:12,547:INFO:Checking exceptions
2024-02-05 12:20:12,547:INFO:Importing libraries
2024-02-05 12:20:12,547:INFO:Copying training dataset
2024-02-05 12:20:12,559:INFO:Defining folds
2024-02-05 12:20:12,559:INFO:Declaring metric variables
2024-02-05 12:20:12,564:INFO:Importing untrained model
2024-02-05 12:20:12,564:INFO:Declaring custom model
2024-02-05 12:20:12,571:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:20:12,582:INFO:Starting cross validation
2024-02-05 12:20:12,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:20:15,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,678:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,685:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,694:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,709:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,759:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,774:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,847:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,941:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:15,979:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,601:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,607:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,696:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:16,709:INFO:Calculating mean and std
2024-02-05 12:20:16,712:INFO:Creating metrics dataframe
2024-02-05 12:20:16,724:INFO:Finalizing model
2024-02-05 12:20:16,878:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-02-05 12:20:16,878:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-05 12:20:16,878:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-05 12:20:16,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-02-05 12:20:16,883:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-05 12:20:16,884:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-05 12:20:16,884:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:20:16,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
2024-02-05 12:20:16,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:20:16,885:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:20:16,885:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:20:16,886:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:20:16,886:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:20:16,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:16,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:20:17,502:INFO:Uploading results into container
2024-02-05 12:20:17,504:INFO:Uploading model into container now
2024-02-05 12:20:17,506:INFO:_master_model_container: 10
2024-02-05 12:20:17,509:INFO:_display_container: 3
2024-02-05 12:20:17,511:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=250, n_jobs=-1, num_leaves=60, objective=None,
               random_state=2310, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:20:17,511:INFO:create_model() successfully completed......................................
2024-02-05 12:20:17,659:INFO:SubProcess create_model() end ==================================
2024-02-05 12:20:17,659:INFO:choose_better activated
2024-02-05 12:20:17,663:INFO:SubProcess create_model() called ==================================
2024-02-05 12:20:17,664:INFO:Initializing create_model()
2024-02-05 12:20:17,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:20:17,665:INFO:Checking exceptions
2024-02-05 12:20:17,667:INFO:Importing libraries
2024-02-05 12:20:17,667:INFO:Copying training dataset
2024-02-05 12:20:17,672:INFO:Defining folds
2024-02-05 12:20:17,672:INFO:Declaring metric variables
2024-02-05 12:20:17,672:INFO:Importing untrained model
2024-02-05 12:20:17,673:INFO:Declaring custom model
2024-02-05 12:20:17,673:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:20:17,674:INFO:Starting cross validation
2024-02-05 12:20:17,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:20:18,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,651:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,847:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,862:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,874:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,979:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:18,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:20:19,251:INFO:Calculating mean and std
2024-02-05 12:20:19,252:INFO:Creating metrics dataframe
2024-02-05 12:20:19,255:INFO:Finalizing model
2024-02-05 12:20:19,362:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:20:19,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
2024-02-05 12:20:19,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:20:19,363:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:20:19,364:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:20:19,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:20:19,364:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:20:19,505:INFO:Uploading results into container
2024-02-05 12:20:19,506:INFO:Uploading model into container now
2024-02-05 12:20:19,506:INFO:_master_model_container: 11
2024-02-05 12:20:19,506:INFO:_display_container: 4
2024-02-05 12:20:19,508:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:20:19,508:INFO:create_model() successfully completed......................................
2024-02-05 12:20:19,640:INFO:SubProcess create_model() end ==================================
2024-02-05 12:20:19,640:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9661
2024-02-05 12:20:19,641:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=250, n_jobs=-1, num_leaves=60, objective=None,
               random_state=2310, reg_alpha=0.1, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9597
2024-02-05 12:20:19,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-05 12:20:19,642:INFO:choose_better completed
2024-02-05 12:20:19,642:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-05 12:20:19,651:INFO:_master_model_container: 11
2024-02-05 12:20:19,652:INFO:_display_container: 3
2024-02-05 12:20:19,652:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:20:19,652:INFO:tune_model() successfully completed......................................
2024-02-05 12:20:36,970:INFO:Initializing predict_model()
2024-02-05 12:20:36,970:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D5665F0>)
2024-02-05 12:20:36,970:INFO:Checking exceptions
2024-02-05 12:20:36,970:INFO:Preloading libraries
2024-02-05 12:22:48,459:INFO:Initializing ensemble_model()
2024-02-05 12:22:48,460:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 12:22:48,460:INFO:Checking exceptions
2024-02-05 12:22:48,483:INFO:Importing libraries
2024-02-05 12:22:48,483:INFO:Copying training dataset
2024-02-05 12:22:48,483:INFO:Checking base model
2024-02-05 12:22:48,483:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 12:22:48,495:INFO:Importing untrained ensembler
2024-02-05 12:22:48,495:INFO:Ensemble method set to Bagging
2024-02-05 12:22:48,496:INFO:SubProcess create_model() called ==================================
2024-02-05 12:22:48,498:INFO:Initializing create_model()
2024-02-05 12:22:48,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58B0EF8E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:22:48,498:INFO:Checking exceptions
2024-02-05 12:22:48,498:INFO:Importing libraries
2024-02-05 12:22:48,499:INFO:Copying training dataset
2024-02-05 12:22:48,508:INFO:Defining folds
2024-02-05 12:22:48,508:INFO:Declaring metric variables
2024-02-05 12:22:48,512:INFO:Importing untrained model
2024-02-05 12:22:48,513:INFO:Declaring custom model
2024-02-05 12:22:48,518:INFO:Bagging Classifier Imported successfully
2024-02-05 12:22:48,529:INFO:Starting cross validation
2024-02-05 12:22:48,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:22:52,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:52,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:52,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:52,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:53,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:53,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:53,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:53,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:53,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:54,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:54,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:54,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,436:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:55,501:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:56,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:57,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:57,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:57,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:22:57,356:INFO:Calculating mean and std
2024-02-05 12:22:57,358:INFO:Creating metrics dataframe
2024-02-05 12:22:57,365:INFO:Finalizing model
2024-02-05 12:22:57,460:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:57,460:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-02-05 12:22:57,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:57,461:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:57,461:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:57,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141176 -> initscore=-1.805553
2024-02-05 12:22:57,461:INFO:[LightGBM] [Info] Start training from score -1.805553
2024-02-05 12:22:57,573:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:57,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.
2024-02-05 12:22:57,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:57,573:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:57,574:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:57,574:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137479 -> initscore=-1.836388
2024-02-05 12:22:57,574:INFO:[LightGBM] [Info] Start training from score -1.836388
2024-02-05 12:22:57,684:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:57,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2024-02-05 12:22:57,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:57,685:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:57,685:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:57,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.150588 -> initscore=-1.729995
2024-02-05 12:22:57,686:INFO:[LightGBM] [Info] Start training from score -1.729995
2024-02-05 12:22:57,820:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:57,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-02-05 12:22:57,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:57,821:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:57,821:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:57,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.133109 -> initscore=-1.873743
2024-02-05 12:22:57,822:INFO:[LightGBM] [Info] Start training from score -1.873743
2024-02-05 12:22:57,949:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:57,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2024-02-05 12:22:57,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:57,950:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:57,950:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:57,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.148571 -> initscore=-1.745850
2024-02-05 12:22:57,951:INFO:[LightGBM] [Info] Start training from score -1.745850
2024-02-05 12:22:58,062:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:58,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-02-05 12:22:58,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:58,063:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:58,063:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:58,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.136807 -> initscore=-1.842069
2024-02-05 12:22:58,064:INFO:[LightGBM] [Info] Start training from score -1.842069
2024-02-05 12:22:58,187:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:58,188:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2024-02-05 12:22:58,188:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:58,188:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:58,188:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:58,189:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143193 -> initscore=-1.789017
2024-02-05 12:22:58,189:INFO:[LightGBM] [Info] Start training from score -1.789017
2024-02-05 12:22:58,301:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:58,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2024-02-05 12:22:58,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:58,302:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:58,302:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:58,303:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141849 -> initscore=-1.800019
2024-02-05 12:22:58,303:INFO:[LightGBM] [Info] Start training from score -1.800019
2024-02-05 12:22:58,413:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:58,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-02-05 12:22:58,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:58,414:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:58,414:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:58,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.136134 -> initscore=-1.847774
2024-02-05 12:22:58,415:INFO:[LightGBM] [Info] Start training from score -1.847774
2024-02-05 12:22:58,608:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:22:58,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2024-02-05 12:22:58,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:22:58,609:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:22:58,609:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:22:58,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.134790 -> initscore=-1.859255
2024-02-05 12:22:58,609:INFO:[LightGBM] [Info] Start training from score -1.859255
2024-02-05 12:22:58,719:INFO:Uploading results into container
2024-02-05 12:22:58,721:INFO:Uploading model into container now
2024-02-05 12:22:58,722:INFO:_master_model_container: 12
2024-02-05 12:22:58,723:INFO:_display_container: 5
2024-02-05 12:22:58,727:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False)
2024-02-05 12:22:58,728:INFO:create_model() successfully completed......................................
2024-02-05 12:22:58,855:INFO:SubProcess create_model() end ==================================
2024-02-05 12:22:58,863:INFO:_master_model_container: 12
2024-02-05 12:22:58,863:INFO:_display_container: 5
2024-02-05 12:22:58,865:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False)
2024-02-05 12:22:58,865:INFO:ensemble_model() successfully completed......................................
2024-02-05 12:23:12,817:INFO:Initializing predict_model()
2024-02-05 12:23:12,817:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D564700>)
2024-02-05 12:23:12,817:INFO:Checking exceptions
2024-02-05 12:23:12,818:INFO:Preloading libraries
2024-02-05 12:24:35,473:INFO:Initializing ensemble_model()
2024-02-05 12:24:35,474:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Boosting, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 12:24:35,474:INFO:Checking exceptions
2024-02-05 12:24:35,629:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:24:35,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-02-05 12:24:35,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:24:35,630:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:24:35,630:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:24:35,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:24:35,630:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:24:35,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:35,710:INFO:Importing libraries
2024-02-05 12:24:35,710:INFO:Copying training dataset
2024-02-05 12:24:35,711:INFO:Checking base model
2024-02-05 12:24:35,711:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 12:24:35,719:INFO:Importing untrained ensembler
2024-02-05 12:24:35,719:INFO:Ensemble method set to Boosting
2024-02-05 12:24:35,719:INFO:SubProcess create_model() called ==================================
2024-02-05 12:24:35,721:INFO:Initializing create_model()
2024-02-05 12:24:35,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            importance_type='split',
                                            learning_rate=0.1, max_depth=-1,
                                            min_child_samples=20,
                                            min_child_weight=0.001,
                                            min_split_gain=0.0,
                                            n_estimators=100, n_jobs=-1,
                                            num_leaves=31, objective=None,
                                            random_state=2310, reg_alpha=0.0,
                                            reg_lambda=0.0, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=2310), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58D5DB4F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:24:35,721:INFO:Checking exceptions
2024-02-05 12:24:35,721:INFO:Importing libraries
2024-02-05 12:24:35,722:INFO:Copying training dataset
2024-02-05 12:24:35,730:INFO:Defining folds
2024-02-05 12:24:35,731:INFO:Declaring metric variables
2024-02-05 12:24:35,734:INFO:Importing untrained model
2024-02-05 12:24:35,734:INFO:Declaring custom model
2024-02-05 12:24:35,740:INFO:Ada Boost Classifier Imported successfully
2024-02-05 12:24:35,755:INFO:Starting cross validation
2024-02-05 12:24:35,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:24:36,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,390:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,395:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,442:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,912:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,950:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:36,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,051:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,207:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:24:37,221:INFO:Calculating mean and std
2024-02-05 12:24:37,222:INFO:Creating metrics dataframe
2024-02-05 12:24:37,229:INFO:Finalizing model
2024-02-05 12:24:37,315:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:24:37,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2024-02-05 12:24:37,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:24:37,315:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:24:37,315:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:24:37,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140840 -> initscore=-1.808328
2024-02-05 12:24:37,316:INFO:[LightGBM] [Info] Start training from score -1.808328
2024-02-05 12:24:37,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-05 12:24:37,530:INFO:Uploading results into container
2024-02-05 12:24:37,531:INFO:Uploading model into container now
2024-02-05 12:24:37,532:INFO:_master_model_container: 13
2024-02-05 12:24:37,532:INFO:_display_container: 7
2024-02-05 12:24:37,537:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            importance_type='split',
                                            learning_rate=0.1, max_depth=-1,
                                            min_child_samples=20,
                                            min_child_weight=0.001,
                                            min_split_gain=0.0,
                                            n_estimators=100, n_jobs=-1,
                                            num_leaves=31, objective=None,
                                            random_state=2310, reg_alpha=0.0,
                                            reg_lambda=0.0, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=2310)
2024-02-05 12:24:37,537:INFO:create_model() successfully completed......................................
2024-02-05 12:24:37,667:INFO:SubProcess create_model() end ==================================
2024-02-05 12:24:37,676:INFO:_master_model_container: 13
2024-02-05 12:24:37,676:INFO:_display_container: 7
2024-02-05 12:24:37,678:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            importance_type='split',
                                            learning_rate=0.1, max_depth=-1,
                                            min_child_samples=20,
                                            min_child_weight=0.001,
                                            min_split_gain=0.0,
                                            n_estimators=100, n_jobs=-1,
                                            num_leaves=31, objective=None,
                                            random_state=2310, reg_alpha=0.0,
                                            reg_lambda=0.0, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=2310)
2024-02-05 12:24:37,678:INFO:ensemble_model() successfully completed......................................
2024-02-05 12:24:39,696:INFO:Initializing predict_model()
2024-02-05 12:24:39,696:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            importance_type='split',
                                            learning_rate=0.1, max_depth=-1,
                                            min_child_samples=20,
                                            min_child_weight=0.001,
                                            min_split_gain=0.0,
                                            n_estimators=100, n_jobs=-1,
                                            num_leaves=31, objective=None,
                                            random_state=2310, reg_alpha=0.0,
                                            reg_lambda=0.0, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=2310), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D566680>)
2024-02-05 12:24:39,696:INFO:Checking exceptions
2024-02-05 12:24:39,696:INFO:Preloading libraries
2024-02-05 12:26:16,430:INFO:Initializing ensemble_model()
2024-02-05 12:26:16,430:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-05 12:26:16,431:INFO:Checking exceptions
2024-02-05 12:26:16,456:INFO:Importing libraries
2024-02-05 12:26:16,457:INFO:Copying training dataset
2024-02-05 12:26:16,458:INFO:Checking base model
2024-02-05 12:26:16,458:INFO:Base model : Light Gradient Boosting Machine
2024-02-05 12:26:16,466:INFO:Importing untrained ensembler
2024-02-05 12:26:16,467:INFO:Ensemble method set to Bagging
2024-02-05 12:26:16,467:INFO:SubProcess create_model() called ==================================
2024-02-05 12:26:16,469:INFO:Initializing create_model()
2024-02-05 12:26:16,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D58BC015A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:26:16,469:INFO:Checking exceptions
2024-02-05 12:26:16,469:INFO:Importing libraries
2024-02-05 12:26:16,470:INFO:Copying training dataset
2024-02-05 12:26:16,476:INFO:Defining folds
2024-02-05 12:26:16,476:INFO:Declaring metric variables
2024-02-05 12:26:16,479:INFO:Importing untrained model
2024-02-05 12:26:16,479:INFO:Declaring custom model
2024-02-05 12:26:16,483:INFO:Bagging Classifier Imported successfully
2024-02-05 12:26:16,491:INFO:Starting cross validation
2024-02-05 12:26:16,494:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-05 12:26:22,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,455:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,518:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,540:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,621:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,745:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,760:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,766:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,768:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,772:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,775:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:22,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,665:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-05 12:26:24,692:INFO:Calculating mean and std
2024-02-05 12:26:24,694:INFO:Creating metrics dataframe
2024-02-05 12:26:24,703:INFO:Finalizing model
2024-02-05 12:26:24,889:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:24,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000621 seconds.
2024-02-05 12:26:24,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:24,890:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:24,893:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:24,895:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141176 -> initscore=-1.805553
2024-02-05 12:26:24,896:INFO:[LightGBM] [Info] Start training from score -1.805553
2024-02-05 12:26:25,056:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2024-02-05 12:26:25,057:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:25,057:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,057:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.137479 -> initscore=-1.836388
2024-02-05 12:26:25,058:INFO:[LightGBM] [Info] Start training from score -1.836388
2024-02-05 12:26:25,204:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2024-02-05 12:26:25,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:25,205:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,205:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.150588 -> initscore=-1.729995
2024-02-05 12:26:25,205:INFO:[LightGBM] [Info] Start training from score -1.729995
2024-02-05 12:26:25,341:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-02-05 12:26:25,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:25,342:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,342:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,342:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.133109 -> initscore=-1.873743
2024-02-05 12:26:25,342:INFO:[LightGBM] [Info] Start training from score -1.873743
2024-02-05 12:26:25,460:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2024-02-05 12:26:25,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:25,461:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,461:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,462:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.148571 -> initscore=-1.745850
2024-02-05 12:26:25,462:INFO:[LightGBM] [Info] Start training from score -1.745850
2024-02-05 12:26:25,669:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2024-02-05 12:26:25,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:25,669:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,670:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,670:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.136807 -> initscore=-1.842069
2024-02-05 12:26:25,670:INFO:[LightGBM] [Info] Start training from score -1.842069
2024-02-05 12:26:25,848:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:25,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.
2024-02-05 12:26:25,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-05 12:26:25,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-05 12:26:25,849:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:25,849:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:25,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143193 -> initscore=-1.789017
2024-02-05 12:26:25,850:INFO:[LightGBM] [Info] Start training from score -1.789017
2024-02-05 12:26:26,004:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:26,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2024-02-05 12:26:26,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:26,005:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:26,005:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:26,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141849 -> initscore=-1.800019
2024-02-05 12:26:26,006:INFO:[LightGBM] [Info] Start training from score -1.800019
2024-02-05 12:26:26,152:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:26,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2024-02-05 12:26:26,153:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:26,153:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:26,153:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:26,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.136134 -> initscore=-1.847774
2024-02-05 12:26:26,153:INFO:[LightGBM] [Info] Start training from score -1.847774
2024-02-05 12:26:26,302:INFO:[LightGBM] [Info] Number of positive: 419, number of negative: 2556
2024-02-05 12:26:26,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2024-02-05 12:26:26,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:26:26,304:INFO:[LightGBM] [Info] Total Bins 2710
2024-02-05 12:26:26,304:INFO:[LightGBM] [Info] Number of data points in the train set: 2975, number of used features: 22
2024-02-05 12:26:26,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.134790 -> initscore=-1.859255
2024-02-05 12:26:26,304:INFO:[LightGBM] [Info] Start training from score -1.859255
2024-02-05 12:26:26,475:INFO:Uploading results into container
2024-02-05 12:26:26,479:INFO:Uploading model into container now
2024-02-05 12:26:26,480:INFO:_master_model_container: 14
2024-02-05 12:26:26,480:INFO:_display_container: 9
2024-02-05 12:26:26,486:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False)
2024-02-05 12:26:26,486:INFO:create_model() successfully completed......................................
2024-02-05 12:26:26,617:INFO:SubProcess create_model() end ==================================
2024-02-05 12:26:26,629:INFO:_master_model_container: 14
2024-02-05 12:26:26,629:INFO:_display_container: 9
2024-02-05 12:26:26,632:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False)
2024-02-05 12:26:26,632:INFO:ensemble_model() successfully completed......................................
2024-02-05 12:26:29,326:INFO:Initializing predict_model()
2024-02-05 12:26:29,327:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           importance_type='split',
                                           learning_rate=0.1, max_depth=-1,
                                           min_child_samples=20,
                                           min_child_weight=0.001,
                                           min_split_gain=0.0, n_estimators=100,
                                           n_jobs=-1, num_leaves=31,
                                           objective=None, random_state=2310,
                                           reg_alpha=0.0, reg_lambda=0.0,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=2310, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D5EFE20>)
2024-02-05 12:26:29,327:INFO:Checking exceptions
2024-02-05 12:26:29,327:INFO:Preloading libraries
2024-02-05 12:28:47,530:INFO:Initializing finalize_model()
2024-02-05 12:28:47,531:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-05 12:28:47,532:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:28:47,537:INFO:Initializing create_model()
2024-02-05 12:28:47,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:28:47,537:INFO:Checking exceptions
2024-02-05 12:28:47,539:INFO:Importing libraries
2024-02-05 12:28:47,539:INFO:Copying training dataset
2024-02-05 12:28:47,539:INFO:Defining folds
2024-02-05 12:28:47,540:INFO:Declaring metric variables
2024-02-05 12:28:47,540:INFO:Importing untrained model
2024-02-05 12:28:47,540:INFO:Declaring custom model
2024-02-05 12:28:47,541:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:28:47,542:INFO:Cross validation set to False
2024-02-05 12:28:47,542:INFO:Fitting Model
2024-02-05 12:28:47,603:INFO:[LightGBM] [Info] Number of positive: 598, number of negative: 3652
2024-02-05 12:28:47,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2024-02-05 12:28:47,605:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:28:47,605:INFO:[LightGBM] [Info] Total Bins 2771
2024-02-05 12:28:47,605:INFO:[LightGBM] [Info] Number of data points in the train set: 4250, number of used features: 22
2024-02-05 12:28:47,606:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140706 -> initscore=-1.809439
2024-02-05 12:28:47,606:INFO:[LightGBM] [Info] Start training from score -1.809439
2024-02-05 12:28:47,678:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2310, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-02-05 12:28:47,678:INFO:create_model() successfully completed......................................
2024-02-05 12:28:47,792:INFO:_master_model_container: 14
2024-02-05 12:28:47,792:INFO:_display_container: 10
2024-02-05 12:28:47,801:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2310, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-02-05 12:28:47,801:INFO:finalize_model() successfully completed......................................
2024-02-05 12:28:56,844:INFO:Initializing predict_model()
2024-02-05 12:28:56,845:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D5ED900>)
2024-02-05 12:28:56,845:INFO:Checking exceptions
2024-02-05 12:28:56,845:INFO:Preloading libraries
2024-02-05 12:29:25,665:INFO:Initializing finalize_model()
2024-02-05 12:29:25,665:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-05 12:29:25,667:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-05 12:29:25,671:INFO:Initializing create_model()
2024-02-05 12:29:25,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-05 12:29:25,671:INFO:Checking exceptions
2024-02-05 12:29:25,673:INFO:Importing libraries
2024-02-05 12:29:25,673:INFO:Copying training dataset
2024-02-05 12:29:25,674:INFO:Defining folds
2024-02-05 12:29:25,674:INFO:Declaring metric variables
2024-02-05 12:29:25,674:INFO:Importing untrained model
2024-02-05 12:29:25,674:INFO:Declaring custom model
2024-02-05 12:29:25,675:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-05 12:29:25,676:INFO:Cross validation set to False
2024-02-05 12:29:25,677:INFO:Fitting Model
2024-02-05 12:29:25,739:INFO:[LightGBM] [Info] Number of positive: 598, number of negative: 3652
2024-02-05 12:29:25,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2024-02-05 12:29:25,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-05 12:29:25,739:INFO:[LightGBM] [Info] Total Bins 2771
2024-02-05 12:29:25,740:INFO:[LightGBM] [Info] Number of data points in the train set: 4250, number of used features: 22
2024-02-05 12:29:25,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140706 -> initscore=-1.809439
2024-02-05 12:29:25,740:INFO:[LightGBM] [Info] Start training from score -1.809439
2024-02-05 12:29:25,819:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2310, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-02-05 12:29:25,819:INFO:create_model() successfully completed......................................
2024-02-05 12:29:25,929:INFO:_master_model_container: 14
2024-02-05 12:29:25,929:INFO:_display_container: 11
2024-02-05 12:29:25,938:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2310, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-02-05 12:29:25,938:INFO:finalize_model() successfully completed......................................
2024-02-05 12:29:30,987:INFO:Initializing predict_model()
2024-02-05 12:29:30,987:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2310, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D564700>)
2024-02-05 12:29:30,988:INFO:Checking exceptions
2024-02-05 12:29:30,988:INFO:Preloading libraries
2024-02-05 12:29:31,305:INFO:Initializing predict_model()
2024-02-05 12:29:31,305:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D58B0F0970>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['account_length',
                                             'voice_mail_plan',
                                             'number_vmail_messages',
                                             'total_day_minutes',
                                             'total_day_calls',
                                             'total_day_charge',
                                             'total_eve_minutes',
                                             'tot...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2310, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D58D5EF400>)
2024-02-05 12:29:31,305:INFO:Checking exceptions
2024-02-05 12:29:31,305:INFO:Preloading libraries
2024-02-05 12:29:31,308:INFO:Set up data.
2024-02-05 12:29:31,316:INFO:Set up index.
2024-02-07 02:01:27,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 02:01:27,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 02:01:27,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 02:01:27,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
