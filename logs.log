2024-02-04 19:26:26,825:INFO:PyCaret ClassificationExperiment
2024-02-04 19:26:26,826:INFO:Logging name: customer-churn-prediction
2024-02-04 19:26:26,826:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 19:26:26,827:INFO:version 3.2.0
2024-02-04 19:26:26,827:INFO:Initializing setup()
2024-02-04 19:26:26,827:INFO:self.USI: 4d99
2024-02-04 19:26:26,828:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'gpu_n_jobs_param', 'fold_generator', 'data', 'X_train', 'X', 'X_test', 'memory', '_ml_usecase', 'exp_id', 'seed', 'gpu_param', 'fix_imbalance', 'pipeline', '_available_plots', 'is_multiclass', 'log_plots_param', 'n_jobs_param', 'html_param', 'y_train', 'y', 'fold_shuffle_param', 'idx', 'logging_param', 'target_param', 'y_test', 'USI'}
2024-02-04 19:26:26,828:INFO:Checking environment
2024-02-04 19:26:26,828:INFO:python_version: 3.10.9
2024-02-04 19:26:26,829:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 19:26:26,829:INFO:machine: AMD64
2024-02-04 19:26:26,829:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 19:26:26,829:INFO:Memory: svmem(total=16856182784, available=6111145984, percent=63.7, used=10745036800, free=6111145984)
2024-02-04 19:26:26,829:INFO:Physical Core: 4
2024-02-04 19:26:26,829:INFO:Logical Core: 8
2024-02-04 19:26:26,829:INFO:Checking libraries
2024-02-04 19:26:26,829:INFO:System:
2024-02-04 19:26:26,829:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 19:26:26,829:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 19:26:26,829:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 19:26:26,829:INFO:PyCaret required dependencies:
2024-02-04 19:26:27,090:INFO:                 pip: 22.3.1
2024-02-04 19:26:27,090:INFO:          setuptools: 65.6.3
2024-02-04 19:26:27,090:INFO:             pycaret: 3.2.0
2024-02-04 19:26:27,090:INFO:             IPython: 8.20.0
2024-02-04 19:26:27,090:INFO:          ipywidgets: 8.0.4
2024-02-04 19:26:27,090:INFO:                tqdm: 4.64.1
2024-02-04 19:26:27,090:INFO:               numpy: 1.25.2
2024-02-04 19:26:27,090:INFO:              pandas: 1.5.3
2024-02-04 19:26:27,090:INFO:              jinja2: 3.1.3
2024-02-04 19:26:27,090:INFO:               scipy: 1.10.1
2024-02-04 19:26:27,090:INFO:              joblib: 1.3.2
2024-02-04 19:26:27,091:INFO:             sklearn: 1.2.2
2024-02-04 19:26:27,091:INFO:                pyod: 1.1.2
2024-02-04 19:26:27,091:INFO:            imblearn: 0.12.0
2024-02-04 19:26:27,091:INFO:   category_encoders: 2.6.3
2024-02-04 19:26:27,091:INFO:            lightgbm: 4.3.0
2024-02-04 19:26:27,092:INFO:               numba: 0.59.0
2024-02-04 19:26:27,092:INFO:            requests: 2.31.0
2024-02-04 19:26:27,092:INFO:          matplotlib: 3.6.0
2024-02-04 19:26:27,092:INFO:          scikitplot: 0.3.7
2024-02-04 19:26:27,092:INFO:         yellowbrick: 1.5
2024-02-04 19:26:27,092:INFO:              plotly: 5.18.0
2024-02-04 19:26:27,093:INFO:    plotly-resampler: Not installed
2024-02-04 19:26:27,093:INFO:             kaleido: 0.2.1
2024-02-04 19:26:27,093:INFO:           schemdraw: 0.15
2024-02-04 19:26:27,093:INFO:         statsmodels: 0.14.1
2024-02-04 19:26:27,093:INFO:              sktime: 0.21.1
2024-02-04 19:26:27,093:INFO:               tbats: 1.1.3
2024-02-04 19:26:27,093:INFO:            pmdarima: 2.0.4
2024-02-04 19:26:27,093:INFO:              psutil: 5.9.0
2024-02-04 19:26:27,093:INFO:          markupsafe: 2.1.3
2024-02-04 19:26:27,093:INFO:             pickle5: Not installed
2024-02-04 19:26:27,093:INFO:         cloudpickle: 3.0.0
2024-02-04 19:26:27,093:INFO:         deprecation: 2.1.0
2024-02-04 19:26:27,093:INFO:              xxhash: 3.4.1
2024-02-04 19:26:27,093:INFO:           wurlitzer: Not installed
2024-02-04 19:26:27,093:INFO:PyCaret optional dependencies:
2024-02-04 19:26:27,132:INFO:                shap: Not installed
2024-02-04 19:26:27,132:INFO:           interpret: Not installed
2024-02-04 19:26:27,133:INFO:                umap: Not installed
2024-02-04 19:26:27,133:INFO:     ydata_profiling: Not installed
2024-02-04 19:26:27,133:INFO:  explainerdashboard: Not installed
2024-02-04 19:26:27,133:INFO:             autoviz: Not installed
2024-02-04 19:26:27,134:INFO:           fairlearn: Not installed
2024-02-04 19:26:27,134:INFO:          deepchecks: Not installed
2024-02-04 19:26:27,134:INFO:             xgboost: Not installed
2024-02-04 19:26:27,134:INFO:            catboost: 1.2.2
2024-02-04 19:26:27,134:INFO:              kmodes: Not installed
2024-02-04 19:26:27,134:INFO:             mlxtend: Not installed
2024-02-04 19:26:27,134:INFO:       statsforecast: Not installed
2024-02-04 19:26:27,134:INFO:        tune_sklearn: Not installed
2024-02-04 19:26:27,134:INFO:                 ray: Not installed
2024-02-04 19:26:27,135:INFO:            hyperopt: Not installed
2024-02-04 19:26:27,135:INFO:              optuna: Not installed
2024-02-04 19:26:27,135:INFO:               skopt: Not installed
2024-02-04 19:26:27,135:INFO:              mlflow: 2.10.0
2024-02-04 19:26:27,135:INFO:              gradio: Not installed
2024-02-04 19:26:27,135:INFO:             fastapi: Not installed
2024-02-04 19:26:27,136:INFO:             uvicorn: Not installed
2024-02-04 19:26:27,136:INFO:              m2cgen: Not installed
2024-02-04 19:26:27,136:INFO:           evidently: Not installed
2024-02-04 19:26:27,136:INFO:               fugue: Not installed
2024-02-04 19:26:27,136:INFO:           streamlit: Not installed
2024-02-04 19:26:27,136:INFO:             prophet: Not installed
2024-02-04 19:26:27,136:INFO:None
2024-02-04 19:26:27,136:INFO:Set up data.
2024-02-04 19:26:27,200:INFO:Set up folding strategy.
2024-02-04 19:26:27,201:INFO:Set up train/test split.
2024-02-04 19:26:27,238:INFO:Set up index.
2024-02-04 19:26:27,239:INFO:Assigning column types.
2024-02-04 19:26:27,250:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 19:26:27,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:26:27,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:26:27,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:27,466:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:27,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:26:27,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:26:27,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:27,751:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:27,753:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 19:26:27,857:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:26:27,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:27,924:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:28,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:26:28,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:28,085:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:28,087:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 19:26:28,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:28,495:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:28,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:28,740:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:26:28,751:INFO:Preparing preprocessing pipeline...
2024-02-04 19:26:28,756:INFO:Set up label encoding.
2024-02-04 19:26:28,757:INFO:Set up simple imputation.
2024-02-04 19:26:28,780:INFO:Set up encoding of ordinal features.
2024-02-04 19:26:28,809:INFO:Set up encoding of categorical features.
2024-02-04 19:26:28,810:INFO:Set up removing multicollinearity.
2024-02-04 19:26:28,810:INFO:Set up binning of numerical features.
2024-02-04 19:26:28,813:INFO:Set up removing outliers.
2024-02-04 19:26:28,813:INFO:Set up imbalanced handling.
2024-02-04 19:26:28,814:INFO:Set up column transformation.
2024-02-04 19:26:28,814:INFO:Set up feature normalization.
2024-02-04 19:26:28,814:INFO:Set up PCA.
2024-02-04 19:26:28,814:INFO:Set up feature selection.
2024-02-04 19:26:29,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:26:29,048:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,512:INFO:PyCaret ClassificationExperiment
2024-02-04 19:51:05,512:INFO:Logging name: customer-churn-prediction
2024-02-04 19:51:05,513:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 19:51:05,513:INFO:version 3.2.0
2024-02-04 19:51:05,513:INFO:Initializing setup()
2024-02-04 19:51:05,513:INFO:self.USI: 389a
2024-02-04 19:51:05,513:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'gpu_n_jobs_param', 'fold_generator', 'data', 'X_train', 'X', 'X_test', 'memory', '_ml_usecase', 'exp_id', 'seed', 'gpu_param', 'fix_imbalance', 'pipeline', '_available_plots', 'is_multiclass', 'log_plots_param', 'n_jobs_param', 'html_param', 'y_train', 'y', 'fold_shuffle_param', 'idx', 'logging_param', 'target_param', 'y_test', 'USI'}
2024-02-04 19:51:05,513:INFO:Checking environment
2024-02-04 19:51:05,513:INFO:python_version: 3.10.9
2024-02-04 19:51:05,513:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 19:51:05,513:INFO:machine: AMD64
2024-02-04 19:51:05,513:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 19:51:05,514:INFO:Memory: svmem(total=16856182784, available=3435974656, percent=79.6, used=13420208128, free=3435974656)
2024-02-04 19:51:05,514:INFO:Physical Core: 4
2024-02-04 19:51:05,514:INFO:Logical Core: 8
2024-02-04 19:51:05,514:INFO:Checking libraries
2024-02-04 19:51:05,514:INFO:System:
2024-02-04 19:51:05,514:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 19:51:05,514:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 19:51:05,514:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 19:51:05,514:INFO:PyCaret required dependencies:
2024-02-04 19:51:05,514:INFO:                 pip: 22.3.1
2024-02-04 19:51:05,514:INFO:          setuptools: 65.6.3
2024-02-04 19:51:05,514:INFO:             pycaret: 3.2.0
2024-02-04 19:51:05,514:INFO:             IPython: 8.20.0
2024-02-04 19:51:05,514:INFO:          ipywidgets: 8.0.4
2024-02-04 19:51:05,514:INFO:                tqdm: 4.64.1
2024-02-04 19:51:05,514:INFO:               numpy: 1.25.2
2024-02-04 19:51:05,514:INFO:              pandas: 1.5.3
2024-02-04 19:51:05,514:INFO:              jinja2: 3.1.3
2024-02-04 19:51:05,514:INFO:               scipy: 1.10.1
2024-02-04 19:51:05,514:INFO:              joblib: 1.3.2
2024-02-04 19:51:05,514:INFO:             sklearn: 1.2.2
2024-02-04 19:51:05,514:INFO:                pyod: 1.1.2
2024-02-04 19:51:05,514:INFO:            imblearn: 0.12.0
2024-02-04 19:51:05,515:INFO:   category_encoders: 2.6.3
2024-02-04 19:51:05,515:INFO:            lightgbm: 4.3.0
2024-02-04 19:51:05,515:INFO:               numba: 0.59.0
2024-02-04 19:51:05,515:INFO:            requests: 2.31.0
2024-02-04 19:51:05,515:INFO:          matplotlib: 3.6.0
2024-02-04 19:51:05,515:INFO:          scikitplot: 0.3.7
2024-02-04 19:51:05,515:INFO:         yellowbrick: 1.5
2024-02-04 19:51:05,515:INFO:              plotly: 5.18.0
2024-02-04 19:51:05,515:INFO:    plotly-resampler: Not installed
2024-02-04 19:51:05,515:INFO:             kaleido: 0.2.1
2024-02-04 19:51:05,515:INFO:           schemdraw: 0.15
2024-02-04 19:51:05,515:INFO:         statsmodels: 0.14.1
2024-02-04 19:51:05,515:INFO:              sktime: 0.21.1
2024-02-04 19:51:05,515:INFO:               tbats: 1.1.3
2024-02-04 19:51:05,515:INFO:            pmdarima: 2.0.4
2024-02-04 19:51:05,515:INFO:              psutil: 5.9.0
2024-02-04 19:51:05,515:INFO:          markupsafe: 2.1.3
2024-02-04 19:51:05,515:INFO:             pickle5: Not installed
2024-02-04 19:51:05,515:INFO:         cloudpickle: 3.0.0
2024-02-04 19:51:05,515:INFO:         deprecation: 2.1.0
2024-02-04 19:51:05,515:INFO:              xxhash: 3.4.1
2024-02-04 19:51:05,515:INFO:           wurlitzer: Not installed
2024-02-04 19:51:05,515:INFO:PyCaret optional dependencies:
2024-02-04 19:51:05,515:INFO:                shap: Not installed
2024-02-04 19:51:05,515:INFO:           interpret: Not installed
2024-02-04 19:51:05,517:INFO:                umap: Not installed
2024-02-04 19:51:05,517:INFO:     ydata_profiling: Not installed
2024-02-04 19:51:05,517:INFO:  explainerdashboard: Not installed
2024-02-04 19:51:05,517:INFO:             autoviz: Not installed
2024-02-04 19:51:05,517:INFO:           fairlearn: Not installed
2024-02-04 19:51:05,517:INFO:          deepchecks: Not installed
2024-02-04 19:51:05,517:INFO:             xgboost: Not installed
2024-02-04 19:51:05,517:INFO:            catboost: 1.2.2
2024-02-04 19:51:05,517:INFO:              kmodes: Not installed
2024-02-04 19:51:05,517:INFO:             mlxtend: Not installed
2024-02-04 19:51:05,517:INFO:       statsforecast: Not installed
2024-02-04 19:51:05,517:INFO:        tune_sklearn: Not installed
2024-02-04 19:51:05,517:INFO:                 ray: Not installed
2024-02-04 19:51:05,517:INFO:            hyperopt: Not installed
2024-02-04 19:51:05,517:INFO:              optuna: Not installed
2024-02-04 19:51:05,517:INFO:               skopt: Not installed
2024-02-04 19:51:05,517:INFO:              mlflow: 2.10.0
2024-02-04 19:51:05,517:INFO:              gradio: Not installed
2024-02-04 19:51:05,517:INFO:             fastapi: Not installed
2024-02-04 19:51:05,517:INFO:             uvicorn: Not installed
2024-02-04 19:51:05,517:INFO:              m2cgen: Not installed
2024-02-04 19:51:05,517:INFO:           evidently: Not installed
2024-02-04 19:51:05,517:INFO:               fugue: Not installed
2024-02-04 19:51:05,517:INFO:           streamlit: Not installed
2024-02-04 19:51:05,517:INFO:             prophet: Not installed
2024-02-04 19:51:05,518:INFO:None
2024-02-04 19:51:05,518:INFO:Set up data.
2024-02-04 19:51:05,541:INFO:Set up folding strategy.
2024-02-04 19:51:05,541:INFO:Set up train/test split.
2024-02-04 19:51:05,553:INFO:Set up index.
2024-02-04 19:51:05,553:INFO:Assigning column types.
2024-02-04 19:51:05,558:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 19:51:05,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,627:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,697:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,697:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 19:51:05,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,764:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,807:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:51:05,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,832:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,833:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 19:51:05,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,899:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:05,963:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:05,964:INFO:Preparing preprocessing pipeline...
2024-02-04 19:51:05,965:INFO:Set up label encoding.
2024-02-04 19:51:05,965:INFO:Set up simple imputation.
2024-02-04 19:51:05,970:INFO:Set up encoding of ordinal features.
2024-02-04 19:51:05,976:INFO:Set up encoding of categorical features.
2024-02-04 19:51:05,976:INFO:Set up removing multicollinearity.
2024-02-04 19:51:05,976:INFO:Set up binning of numerical features.
2024-02-04 19:51:05,977:INFO:Set up removing outliers.
2024-02-04 19:51:05,977:INFO:Set up imbalanced handling.
2024-02-04 19:51:05,977:INFO:Set up column transformation.
2024-02-04 19:51:05,977:INFO:Set up feature normalization.
2024-02-04 19:51:05,977:INFO:Set up PCA.
2024-02-04 19:51:05,977:INFO:Set up feature selection.
2024-02-04 19:51:06,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:06,047:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:07,678:INFO:Finished creating preprocessing pipeline.
2024-02-04 19:51:07,750:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 19:51:07,750:INFO:Creating final display dataframe.
2024-02-04 19:51:09,430:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        142
1                        Target                      Churn
2                   Target type                     Binary
3                Target mapping              No: 0, Yes: 1
4           Original data shape                 (6339, 21)
5        Transformed data shape                  (7998, 4)
6   Transformed train set shape                  (6096, 4)
7    Transformed test set shape                  (1902, 4)
8               Ignore features                          1
9              Ordinal features                          5
10             Numeric features                          1
11         Categorical features                         15
12                   Preprocess                       True
13              Imputation type                     simple
14           Numeric imputation                       mean
15       Categorical imputation                       mode
16     Maximum one-hot encoding                         25
17              Encoding method                       None
18     Remove multicollinearity                       True
19  Multicollinearity threshold                        0.9
20              Remove outliers                       True
21           Outliers threshold                       0.05
22                Fix imbalance                       True
23         Fix imbalance method                      SMOTE
24               Transformation                       True
25        Transformation method                yeo-johnson
26                    Normalize                       True
27             Normalize method                     zscore
28                          PCA                       True
29                   PCA method                     linear
30               PCA components                       None
31            Feature selection                       True
32     Feature selection method                    classic
33  Feature selection estimator                   lightgbm
34  Number of features selected                        0.2
35               Fold Generator            StratifiedKFold
36                  Fold Number                         10
37                     CPU Jobs                         -1
38                      Use GPU                      False
39               Log Experiment               MlflowLogger
40              Experiment Name  customer-churn-prediction
41                          USI                       389a
2024-02-04 19:51:09,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:09,499:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:09,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:51:09,572:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:51:09,573:INFO:Logging experiment in loggers
2024-02-04 19:51:09,775:INFO:SubProcess save_model() called ==================================
2024-02-04 19:51:09,897:INFO:Initializing save_model()
2024-02-04 19:51:09,897:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\user\AppData\Local\Temp\tmpawloh2xs\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-02-04 19:51:09,898:INFO:Adding model into prep_pipe
2024-02-04 19:51:09,898:WARNING:Only Model saved as it was a pipeline.
2024-02-04 19:51:09,954:INFO:C:\Users\user\AppData\Local\Temp\tmpawloh2xs\Transformation Pipeline.pkl saved in current working directory
2024-02-04 19:51:10,032:INFO:Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 19:51:10,033:INFO:save_model() successfully completed......................................
2024-02-04 19:51:10,138:INFO:SubProcess save_model() end ==================================
2024-02-04 19:51:10,329:INFO:setup() successfully completed in 4.07s...............
2024-02-04 19:53:01,682:INFO:PyCaret ClassificationExperiment
2024-02-04 19:53:01,682:INFO:Logging name: customer-churn-prediction
2024-02-04 19:53:01,682:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 19:53:01,682:INFO:version 3.2.0
2024-02-04 19:53:01,682:INFO:Initializing setup()
2024-02-04 19:53:01,684:INFO:self.USI: 9b0d
2024-02-04 19:53:01,684:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'gpu_n_jobs_param', 'fold_generator', 'data', 'X_train', 'X', 'X_test', 'memory', '_ml_usecase', 'exp_id', 'seed', 'gpu_param', 'fix_imbalance', 'pipeline', '_available_plots', 'is_multiclass', 'log_plots_param', 'n_jobs_param', 'html_param', 'y_train', 'y', 'fold_shuffle_param', 'idx', 'logging_param', 'target_param', 'y_test', 'USI'}
2024-02-04 19:53:01,684:INFO:Checking environment
2024-02-04 19:53:01,684:INFO:python_version: 3.10.9
2024-02-04 19:53:01,684:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 19:53:01,684:INFO:machine: AMD64
2024-02-04 19:53:01,684:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 19:53:01,685:INFO:Memory: svmem(total=16856182784, available=3480735744, percent=79.4, used=13375447040, free=3480735744)
2024-02-04 19:53:01,685:INFO:Physical Core: 4
2024-02-04 19:53:01,685:INFO:Logical Core: 8
2024-02-04 19:53:01,685:INFO:Checking libraries
2024-02-04 19:53:01,685:INFO:System:
2024-02-04 19:53:01,685:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 19:53:01,685:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 19:53:01,685:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 19:53:01,685:INFO:PyCaret required dependencies:
2024-02-04 19:53:01,685:INFO:                 pip: 22.3.1
2024-02-04 19:53:01,685:INFO:          setuptools: 65.6.3
2024-02-04 19:53:01,685:INFO:             pycaret: 3.2.0
2024-02-04 19:53:01,685:INFO:             IPython: 8.20.0
2024-02-04 19:53:01,685:INFO:          ipywidgets: 8.0.4
2024-02-04 19:53:01,685:INFO:                tqdm: 4.64.1
2024-02-04 19:53:01,686:INFO:               numpy: 1.25.2
2024-02-04 19:53:01,686:INFO:              pandas: 1.5.3
2024-02-04 19:53:01,686:INFO:              jinja2: 3.1.3
2024-02-04 19:53:01,686:INFO:               scipy: 1.10.1
2024-02-04 19:53:01,686:INFO:              joblib: 1.3.2
2024-02-04 19:53:01,686:INFO:             sklearn: 1.2.2
2024-02-04 19:53:01,686:INFO:                pyod: 1.1.2
2024-02-04 19:53:01,686:INFO:            imblearn: 0.12.0
2024-02-04 19:53:01,686:INFO:   category_encoders: 2.6.3
2024-02-04 19:53:01,686:INFO:            lightgbm: 4.3.0
2024-02-04 19:53:01,686:INFO:               numba: 0.59.0
2024-02-04 19:53:01,686:INFO:            requests: 2.31.0
2024-02-04 19:53:01,686:INFO:          matplotlib: 3.6.0
2024-02-04 19:53:01,686:INFO:          scikitplot: 0.3.7
2024-02-04 19:53:01,686:INFO:         yellowbrick: 1.5
2024-02-04 19:53:01,686:INFO:              plotly: 5.18.0
2024-02-04 19:53:01,686:INFO:    plotly-resampler: Not installed
2024-02-04 19:53:01,686:INFO:             kaleido: 0.2.1
2024-02-04 19:53:01,686:INFO:           schemdraw: 0.15
2024-02-04 19:53:01,686:INFO:         statsmodels: 0.14.1
2024-02-04 19:53:01,686:INFO:              sktime: 0.21.1
2024-02-04 19:53:01,686:INFO:               tbats: 1.1.3
2024-02-04 19:53:01,686:INFO:            pmdarima: 2.0.4
2024-02-04 19:53:01,686:INFO:              psutil: 5.9.0
2024-02-04 19:53:01,686:INFO:          markupsafe: 2.1.3
2024-02-04 19:53:01,686:INFO:             pickle5: Not installed
2024-02-04 19:53:01,687:INFO:         cloudpickle: 3.0.0
2024-02-04 19:53:01,687:INFO:         deprecation: 2.1.0
2024-02-04 19:53:01,687:INFO:              xxhash: 3.4.1
2024-02-04 19:53:01,687:INFO:           wurlitzer: Not installed
2024-02-04 19:53:01,687:INFO:PyCaret optional dependencies:
2024-02-04 19:53:01,687:INFO:                shap: Not installed
2024-02-04 19:53:01,687:INFO:           interpret: Not installed
2024-02-04 19:53:01,687:INFO:                umap: Not installed
2024-02-04 19:53:01,687:INFO:     ydata_profiling: Not installed
2024-02-04 19:53:01,687:INFO:  explainerdashboard: Not installed
2024-02-04 19:53:01,687:INFO:             autoviz: Not installed
2024-02-04 19:53:01,687:INFO:           fairlearn: Not installed
2024-02-04 19:53:01,687:INFO:          deepchecks: Not installed
2024-02-04 19:53:01,687:INFO:             xgboost: Not installed
2024-02-04 19:53:01,687:INFO:            catboost: 1.2.2
2024-02-04 19:53:01,687:INFO:              kmodes: Not installed
2024-02-04 19:53:01,687:INFO:             mlxtend: Not installed
2024-02-04 19:53:01,687:INFO:       statsforecast: Not installed
2024-02-04 19:53:01,687:INFO:        tune_sklearn: Not installed
2024-02-04 19:53:01,687:INFO:                 ray: Not installed
2024-02-04 19:53:01,687:INFO:            hyperopt: Not installed
2024-02-04 19:53:01,687:INFO:              optuna: Not installed
2024-02-04 19:53:01,687:INFO:               skopt: Not installed
2024-02-04 19:53:01,688:INFO:              mlflow: 2.10.0
2024-02-04 19:53:01,688:INFO:              gradio: Not installed
2024-02-04 19:53:01,688:INFO:             fastapi: Not installed
2024-02-04 19:53:01,688:INFO:             uvicorn: Not installed
2024-02-04 19:53:01,688:INFO:              m2cgen: Not installed
2024-02-04 19:53:01,688:INFO:           evidently: Not installed
2024-02-04 19:53:01,688:INFO:               fugue: Not installed
2024-02-04 19:53:01,688:INFO:           streamlit: Not installed
2024-02-04 19:53:01,688:INFO:             prophet: Not installed
2024-02-04 19:53:01,688:INFO:None
2024-02-04 19:53:01,688:INFO:Set up data.
2024-02-04 19:53:01,717:INFO:Set up folding strategy.
2024-02-04 19:53:01,717:INFO:Set up train/test split.
2024-02-04 19:53:01,736:INFO:Set up index.
2024-02-04 19:53:01,737:INFO:Assigning column types.
2024-02-04 19:53:01,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 19:53:01,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:53:01,808:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:53:01,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:01,844:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:01,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 19:53:01,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:53:01,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:01,930:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:01,930:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 19:53:01,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:53:02,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:02,014:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:02,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 19:53:02,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:02,086:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:02,087:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 19:53:02,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:02,159:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:02,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:02,228:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:02,230:INFO:Preparing preprocessing pipeline...
2024-02-04 19:53:02,231:INFO:Set up label encoding.
2024-02-04 19:53:02,231:INFO:Set up simple imputation.
2024-02-04 19:53:02,237:INFO:Set up encoding of ordinal features.
2024-02-04 19:53:02,243:INFO:Set up encoding of categorical features.
2024-02-04 19:53:02,243:INFO:Set up removing multicollinearity.
2024-02-04 19:53:02,243:INFO:Set up binning of numerical features.
2024-02-04 19:53:02,245:INFO:Set up removing outliers.
2024-02-04 19:53:02,245:INFO:Set up imbalanced handling.
2024-02-04 19:53:02,245:INFO:Set up column transformation.
2024-02-04 19:53:02,245:INFO:Set up feature normalization.
2024-02-04 19:53:02,245:INFO:Set up PCA.
2024-02-04 19:53:02,245:INFO:Set up feature selection.
2024-02-04 19:53:02,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:02,442:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:02,994:INFO:Finished creating preprocessing pipeline.
2024-02-04 19:53:03,062:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 19:53:03,062:INFO:Creating final display dataframe.
2024-02-04 19:53:03,956:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        142
1                        Target                      Churn
2                   Target type                     Binary
3                Target mapping              No: 0, Yes: 1
4           Original data shape                 (6339, 21)
5        Transformed data shape                  (7998, 4)
6   Transformed train set shape                  (6096, 4)
7    Transformed test set shape                  (1902, 4)
8               Ignore features                          1
9              Ordinal features                          5
10             Numeric features                          1
11         Categorical features                         15
12                   Preprocess                       True
13              Imputation type                     simple
14           Numeric imputation                       mean
15       Categorical imputation                       mode
16     Maximum one-hot encoding                         25
17              Encoding method                       None
18     Remove multicollinearity                       True
19  Multicollinearity threshold                        0.9
20              Remove outliers                       True
21           Outliers threshold                       0.05
22                Fix imbalance                       True
23         Fix imbalance method                      SMOTE
24               Transformation                       True
25        Transformation method                yeo-johnson
26                    Normalize                       True
27             Normalize method                     zscore
28                          PCA                       True
29                   PCA method                     linear
30               PCA components                       None
31            Feature selection                       True
32     Feature selection method                    classic
33  Feature selection estimator                   lightgbm
34  Number of features selected                        0.2
35               Fold Generator            StratifiedKFold
36                  Fold Number                         10
37                     CPU Jobs                         -1
38                      Use GPU                      False
39               Log Experiment               MlflowLogger
40              Experiment Name  customer-churn-prediction
41                          USI                       9b0d
2024-02-04 19:53:04,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:04,033:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:04,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 19:53:04,103:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 19:53:04,104:INFO:Logging experiment in loggers
2024-02-04 19:53:04,202:INFO:SubProcess save_model() called ==================================
2024-02-04 19:53:04,334:INFO:Initializing save_model()
2024-02-04 19:53:04,334:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\user\AppData\Local\Temp\tmpekkmsrmc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-02-04 19:53:04,334:INFO:Adding model into prep_pipe
2024-02-04 19:53:04,334:WARNING:Only Model saved as it was a pipeline.
2024-02-04 19:53:04,359:INFO:C:\Users\user\AppData\Local\Temp\tmpekkmsrmc\Transformation Pipeline.pkl saved in current working directory
2024-02-04 19:53:04,429:INFO:Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 19:53:04,430:INFO:save_model() successfully completed......................................
2024-02-04 19:53:04,532:INFO:SubProcess save_model() end ==================================
2024-02-04 19:53:04,589:INFO:setup() successfully completed in 2.43s...............
2024-02-04 19:56:51,981:INFO:Initializing get_config()
2024-02-04 19:56:51,981:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021B0648E230>, variable=None)
2024-02-04 20:02:09,605:INFO:PyCaret ClassificationExperiment
2024-02-04 20:02:09,605:INFO:Logging name: customer-churn-prediction
2024-02-04 20:02:09,605:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 20:02:09,605:INFO:version 3.2.0
2024-02-04 20:02:09,605:INFO:Initializing setup()
2024-02-04 20:02:09,605:INFO:self.USI: 4384
2024-02-04 20:02:09,606:INFO:self._variable_keys: {'y', 'seed', 'y_train', 'exp_id', 'is_multiclass', 'USI', 'X', 'n_jobs_param', 'pipeline', 'logging_param', 'target_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_train', 'gpu_param', 'fold_generator', 'memory', '_available_plots', 'log_plots_param', 'data', 'X_test', 'fold_groups_param', 'exp_name_log', 'y_test', 'fix_imbalance', '_ml_usecase', 'idx', 'html_param'}
2024-02-04 20:02:09,606:INFO:Checking environment
2024-02-04 20:02:09,606:INFO:python_version: 3.10.9
2024-02-04 20:02:09,606:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 20:02:09,606:INFO:machine: AMD64
2024-02-04 20:02:09,606:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 20:02:09,607:INFO:Memory: svmem(total=16856182784, available=4874285056, percent=71.1, used=11981897728, free=4874285056)
2024-02-04 20:02:09,607:INFO:Physical Core: 4
2024-02-04 20:02:09,607:INFO:Logical Core: 8
2024-02-04 20:02:09,607:INFO:Checking libraries
2024-02-04 20:02:09,607:INFO:System:
2024-02-04 20:02:09,607:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 20:02:09,607:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 20:02:09,607:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 20:02:09,608:INFO:PyCaret required dependencies:
2024-02-04 20:02:09,761:INFO:                 pip: 22.3.1
2024-02-04 20:02:09,761:INFO:          setuptools: 65.6.3
2024-02-04 20:02:09,761:INFO:             pycaret: 3.2.0
2024-02-04 20:02:09,761:INFO:             IPython: 8.20.0
2024-02-04 20:02:09,761:INFO:          ipywidgets: 8.0.4
2024-02-04 20:02:09,761:INFO:                tqdm: 4.64.1
2024-02-04 20:02:09,761:INFO:               numpy: 1.25.2
2024-02-04 20:02:09,761:INFO:              pandas: 1.5.3
2024-02-04 20:02:09,761:INFO:              jinja2: 3.1.3
2024-02-04 20:02:09,762:INFO:               scipy: 1.10.1
2024-02-04 20:02:09,762:INFO:              joblib: 1.3.2
2024-02-04 20:02:09,762:INFO:             sklearn: 1.2.2
2024-02-04 20:02:09,762:INFO:                pyod: 1.1.2
2024-02-04 20:02:09,762:INFO:            imblearn: 0.12.0
2024-02-04 20:02:09,762:INFO:   category_encoders: 2.6.3
2024-02-04 20:02:09,762:INFO:            lightgbm: 4.3.0
2024-02-04 20:02:09,762:INFO:               numba: 0.59.0
2024-02-04 20:02:09,762:INFO:            requests: 2.31.0
2024-02-04 20:02:09,762:INFO:          matplotlib: 3.6.0
2024-02-04 20:02:09,762:INFO:          scikitplot: 0.3.7
2024-02-04 20:02:09,762:INFO:         yellowbrick: 1.5
2024-02-04 20:02:09,762:INFO:              plotly: 5.18.0
2024-02-04 20:02:09,763:INFO:    plotly-resampler: Not installed
2024-02-04 20:02:09,763:INFO:             kaleido: 0.2.1
2024-02-04 20:02:09,763:INFO:           schemdraw: 0.15
2024-02-04 20:02:09,763:INFO:         statsmodels: 0.14.1
2024-02-04 20:02:09,763:INFO:              sktime: 0.21.1
2024-02-04 20:02:09,763:INFO:               tbats: 1.1.3
2024-02-04 20:02:09,763:INFO:            pmdarima: 2.0.4
2024-02-04 20:02:09,763:INFO:              psutil: 5.9.0
2024-02-04 20:02:09,763:INFO:          markupsafe: 2.1.3
2024-02-04 20:02:09,764:INFO:             pickle5: Not installed
2024-02-04 20:02:09,764:INFO:         cloudpickle: 3.0.0
2024-02-04 20:02:09,764:INFO:         deprecation: 2.1.0
2024-02-04 20:02:09,764:INFO:              xxhash: 3.4.1
2024-02-04 20:02:09,764:INFO:           wurlitzer: Not installed
2024-02-04 20:02:09,764:INFO:PyCaret optional dependencies:
2024-02-04 20:02:09,794:INFO:                shap: Not installed
2024-02-04 20:02:09,794:INFO:           interpret: Not installed
2024-02-04 20:02:09,794:INFO:                umap: Not installed
2024-02-04 20:02:09,794:INFO:     ydata_profiling: Not installed
2024-02-04 20:02:09,795:INFO:  explainerdashboard: Not installed
2024-02-04 20:02:09,795:INFO:             autoviz: Not installed
2024-02-04 20:02:09,795:INFO:           fairlearn: Not installed
2024-02-04 20:02:09,795:INFO:          deepchecks: Not installed
2024-02-04 20:02:09,795:INFO:             xgboost: Not installed
2024-02-04 20:02:09,795:INFO:            catboost: 1.2.2
2024-02-04 20:02:09,795:INFO:              kmodes: Not installed
2024-02-04 20:02:09,795:INFO:             mlxtend: Not installed
2024-02-04 20:02:09,795:INFO:       statsforecast: Not installed
2024-02-04 20:02:09,796:INFO:        tune_sklearn: Not installed
2024-02-04 20:02:09,796:INFO:                 ray: Not installed
2024-02-04 20:02:09,796:INFO:            hyperopt: Not installed
2024-02-04 20:02:09,796:INFO:              optuna: Not installed
2024-02-04 20:02:09,796:INFO:               skopt: Not installed
2024-02-04 20:02:09,796:INFO:              mlflow: 2.10.0
2024-02-04 20:02:09,796:INFO:              gradio: Not installed
2024-02-04 20:02:09,797:INFO:             fastapi: Not installed
2024-02-04 20:02:09,797:INFO:             uvicorn: Not installed
2024-02-04 20:02:09,797:INFO:              m2cgen: Not installed
2024-02-04 20:02:09,797:INFO:           evidently: Not installed
2024-02-04 20:02:09,797:INFO:               fugue: Not installed
2024-02-04 20:02:09,797:INFO:           streamlit: Not installed
2024-02-04 20:02:09,797:INFO:             prophet: Not installed
2024-02-04 20:02:09,797:INFO:None
2024-02-04 20:02:09,797:INFO:Set up data.
2024-02-04 20:02:09,848:INFO:Set up folding strategy.
2024-02-04 20:02:09,848:INFO:Set up train/test split.
2024-02-04 20:02:09,870:INFO:Set up index.
2024-02-04 20:02:09,871:INFO:Assigning column types.
2024-02-04 20:02:09,879:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 20:02:09,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 20:02:09,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 20:02:10,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,026:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 20:02:10,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 20:02:10,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,234:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 20:02:10,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 20:02:10,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,357:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 20:02:10,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,507:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,509:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 20:02:10,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,686:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,770:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:10,773:INFO:Preparing preprocessing pipeline...
2024-02-04 20:02:10,776:INFO:Set up label encoding.
2024-02-04 20:02:10,776:INFO:Set up simple imputation.
2024-02-04 20:02:10,790:INFO:Set up encoding of ordinal features.
2024-02-04 20:02:10,802:INFO:Set up encoding of categorical features.
2024-02-04 20:02:10,802:INFO:Set up removing multicollinearity.
2024-02-04 20:02:10,803:INFO:Set up binning of numerical features.
2024-02-04 20:02:10,804:INFO:Set up removing outliers.
2024-02-04 20:02:10,805:INFO:Set up imbalanced handling.
2024-02-04 20:02:10,805:INFO:Set up column transformation.
2024-02-04 20:02:10,805:INFO:Set up feature normalization.
2024-02-04 20:02:10,805:INFO:Set up PCA.
2024-02-04 20:02:10,805:INFO:Set up feature selection.
2024-02-04 20:02:10,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:10,960:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:12,628:INFO:Finished creating preprocessing pipeline.
2024-02-04 20:02:12,745:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 20:02:12,745:INFO:Creating final display dataframe.
2024-02-04 20:02:14,210:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        142
1                        Target                      Churn
2                   Target type                     Binary
3                Target mapping              No: 0, Yes: 1
4           Original data shape                 (6339, 21)
5        Transformed data shape                  (7998, 4)
6   Transformed train set shape                  (6096, 4)
7    Transformed test set shape                  (1902, 4)
8               Ignore features                          1
9              Ordinal features                          5
10             Numeric features                          1
11         Categorical features                         15
12                   Preprocess                       True
13              Imputation type                     simple
14           Numeric imputation                       mean
15       Categorical imputation                       mode
16     Maximum one-hot encoding                         25
17              Encoding method                       None
18     Remove multicollinearity                       True
19  Multicollinearity threshold                        0.9
20              Remove outliers                       True
21           Outliers threshold                       0.05
22                Fix imbalance                       True
23         Fix imbalance method                      SMOTE
24               Transformation                       True
25        Transformation method                yeo-johnson
26                    Normalize                       True
27             Normalize method                     zscore
28                          PCA                       True
29                   PCA method                     linear
30               PCA components                       None
31            Feature selection                       True
32     Feature selection method                    classic
33  Feature selection estimator                   lightgbm
34  Number of features selected                        0.2
35               Fold Generator            StratifiedKFold
36                  Fold Number                         10
37                     CPU Jobs                         -1
38                      Use GPU                      False
39               Log Experiment               MlflowLogger
40              Experiment Name  customer-churn-prediction
41                          USI                       4384
2024-02-04 20:02:14,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:14,350:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:14,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:02:14,469:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:02:14,471:INFO:Logging experiment in loggers
2024-02-04 20:02:14,670:INFO:SubProcess save_model() called ==================================
2024-02-04 20:02:14,855:INFO:Initializing save_model()
2024-02-04 20:02:14,855:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\user\AppData\Local\Temp\tmp1dlrgbpy\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-02-04 20:02:14,855:INFO:Adding model into prep_pipe
2024-02-04 20:02:14,855:WARNING:Only Model saved as it was a pipeline.
2024-02-04 20:02:14,890:INFO:C:\Users\user\AppData\Local\Temp\tmp1dlrgbpy\Transformation Pipeline.pkl saved in current working directory
2024-02-04 20:02:14,989:INFO:Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 20:02:14,989:INFO:save_model() successfully completed......................................
2024-02-04 20:02:15,074:INFO:SubProcess save_model() end ==================================
2024-02-04 20:02:15,154:INFO:setup() successfully completed in 4.88s...............
2024-02-04 20:02:15,184:INFO:Initializing get_config()
2024-02-04 20:02:15,185:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, variable=None)
2024-02-04 20:04:03,566:INFO:Initializing get_config()
2024-02-04 20:04:03,568:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, variable=None)
2024-02-04 20:04:15,062:INFO:Initializing get_config()
2024-02-04 20:04:15,063:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, variable=None)
2024-02-04 20:05:41,081:INFO:Initializing get_config()
2024-02-04 20:05:41,081:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, variable=None)
2024-02-04 20:12:05,669:INFO:Initializing compare_models()
2024-02-04 20:12:05,669:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, include=None, fold=5, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, 'include': None, 'exclude': ['gbc', 'catboost'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'catboost'])
2024-02-04 20:12:05,669:INFO:Checking exceptions
2024-02-04 20:12:05,683:INFO:Preparing display monitor
2024-02-04 20:12:05,725:INFO:Initializing Logistic Regression
2024-02-04 20:12:05,726:INFO:Total runtime is 1.666545867919922e-05 minutes
2024-02-04 20:12:05,733:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:05,734:INFO:Initializing create_model()
2024-02-04 20:12:05,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:05,735:INFO:Checking exceptions
2024-02-04 20:12:05,735:INFO:Importing libraries
2024-02-04 20:12:05,735:INFO:Copying training dataset
2024-02-04 20:12:05,745:INFO:Defining folds
2024-02-04 20:12:05,745:INFO:Declaring metric variables
2024-02-04 20:12:05,749:INFO:Importing untrained model
2024-02-04 20:12:05,755:INFO:Logistic Regression Imported successfully
2024-02-04 20:12:05,767:INFO:Starting cross validation
2024-02-04 20:12:05,784:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:13,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:13,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:13,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:13,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:13,236:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:15,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,395:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,397:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,412:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,493:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,498:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,548:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:15,571:INFO:Calculating mean and std
2024-02-04 20:12:15,573:INFO:Creating metrics dataframe
2024-02-04 20:12:15,581:INFO:Uploading results into container
2024-02-04 20:12:15,583:INFO:Uploading model into container now
2024-02-04 20:12:15,584:INFO:_master_model_container: 1
2024-02-04 20:12:15,584:INFO:_display_container: 2
2024-02-04 20:12:15,585:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=142, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 20:12:15,585:INFO:create_model() successfully completed......................................
2024-02-04 20:12:15,767:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:15,768:INFO:Creating metrics dataframe
2024-02-04 20:12:15,782:INFO:Initializing K Neighbors Classifier
2024-02-04 20:12:15,783:INFO:Total runtime is 0.16762453317642212 minutes
2024-02-04 20:12:15,788:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:15,789:INFO:Initializing create_model()
2024-02-04 20:12:15,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:15,789:INFO:Checking exceptions
2024-02-04 20:12:15,789:INFO:Importing libraries
2024-02-04 20:12:15,789:INFO:Copying training dataset
2024-02-04 20:12:15,800:INFO:Defining folds
2024-02-04 20:12:15,800:INFO:Declaring metric variables
2024-02-04 20:12:15,805:INFO:Importing untrained model
2024-02-04 20:12:15,814:INFO:K Neighbors Classifier Imported successfully
2024-02-04 20:12:15,830:INFO:Starting cross validation
2024-02-04 20:12:15,845:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:16,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:16,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:18,564:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:18,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:18,579:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:18,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:18,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:18,605:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:20,839:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:20,860:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:20,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:22,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,472:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,538:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:22,572:INFO:Calculating mean and std
2024-02-04 20:12:22,574:INFO:Creating metrics dataframe
2024-02-04 20:12:22,581:INFO:Uploading results into container
2024-02-04 20:12:22,583:INFO:Uploading model into container now
2024-02-04 20:12:22,584:INFO:_master_model_container: 2
2024-02-04 20:12:22,584:INFO:_display_container: 2
2024-02-04 20:12:22,585:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 20:12:22,585:INFO:create_model() successfully completed......................................
2024-02-04 20:12:22,740:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:22,740:INFO:Creating metrics dataframe
2024-02-04 20:12:22,757:INFO:Initializing Naive Bayes
2024-02-04 20:12:22,757:INFO:Total runtime is 0.28385847409566245 minutes
2024-02-04 20:12:22,763:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:22,764:INFO:Initializing create_model()
2024-02-04 20:12:22,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:22,765:INFO:Checking exceptions
2024-02-04 20:12:22,765:INFO:Importing libraries
2024-02-04 20:12:22,765:INFO:Copying training dataset
2024-02-04 20:12:22,771:INFO:Defining folds
2024-02-04 20:12:22,772:INFO:Declaring metric variables
2024-02-04 20:12:22,778:INFO:Importing untrained model
2024-02-04 20:12:22,784:INFO:Naive Bayes Imported successfully
2024-02-04 20:12:22,799:INFO:Starting cross validation
2024-02-04 20:12:22,819:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:23,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:23,752:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:23,770:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:23,790:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:23,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:25,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,740:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,749:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,795:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,810:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:25,862:INFO:Calculating mean and std
2024-02-04 20:12:25,864:INFO:Creating metrics dataframe
2024-02-04 20:12:25,868:INFO:Uploading results into container
2024-02-04 20:12:25,869:INFO:Uploading model into container now
2024-02-04 20:12:25,870:INFO:_master_model_container: 3
2024-02-04 20:12:25,870:INFO:_display_container: 2
2024-02-04 20:12:25,870:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 20:12:25,870:INFO:create_model() successfully completed......................................
2024-02-04 20:12:25,983:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:25,984:INFO:Creating metrics dataframe
2024-02-04 20:12:25,998:INFO:Initializing Decision Tree Classifier
2024-02-04 20:12:25,999:INFO:Total runtime is 0.3378944436709086 minutes
2024-02-04 20:12:26,008:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:26,009:INFO:Initializing create_model()
2024-02-04 20:12:26,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:26,009:INFO:Checking exceptions
2024-02-04 20:12:26,010:INFO:Importing libraries
2024-02-04 20:12:26,010:INFO:Copying training dataset
2024-02-04 20:12:26,028:INFO:Defining folds
2024-02-04 20:12:26,029:INFO:Declaring metric variables
2024-02-04 20:12:26,034:INFO:Importing untrained model
2024-02-04 20:12:26,043:INFO:Decision Tree Classifier Imported successfully
2024-02-04 20:12:26,060:INFO:Starting cross validation
2024-02-04 20:12:26,079:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:27,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:27,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:27,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:27,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:27,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:28,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,952:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:28,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,101:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:29,167:INFO:Calculating mean and std
2024-02-04 20:12:29,168:INFO:Creating metrics dataframe
2024-02-04 20:12:29,173:INFO:Uploading results into container
2024-02-04 20:12:29,174:INFO:Uploading model into container now
2024-02-04 20:12:29,175:INFO:_master_model_container: 4
2024-02-04 20:12:29,175:INFO:_display_container: 2
2024-02-04 20:12:29,176:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=142, splitter='best')
2024-02-04 20:12:29,177:INFO:create_model() successfully completed......................................
2024-02-04 20:12:29,328:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:29,329:INFO:Creating metrics dataframe
2024-02-04 20:12:29,350:INFO:Initializing SVM - Linear Kernel
2024-02-04 20:12:29,350:INFO:Total runtime is 0.39374717076619464 minutes
2024-02-04 20:12:29,359:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:29,360:INFO:Initializing create_model()
2024-02-04 20:12:29,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:29,360:INFO:Checking exceptions
2024-02-04 20:12:29,361:INFO:Importing libraries
2024-02-04 20:12:29,361:INFO:Copying training dataset
2024-02-04 20:12:29,370:INFO:Defining folds
2024-02-04 20:12:29,370:INFO:Declaring metric variables
2024-02-04 20:12:29,377:INFO:Importing untrained model
2024-02-04 20:12:29,385:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 20:12:29,402:INFO:Starting cross validation
2024-02-04 20:12:29,421:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:30,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:30,349:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:30,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:30,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:30,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:32,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 20:12:32,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 20:12:32,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,386:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 20:12:32,434:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,516:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 20:12:32,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,530:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 20:12:32,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,540:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:32,569:INFO:Calculating mean and std
2024-02-04 20:12:32,570:INFO:Creating metrics dataframe
2024-02-04 20:12:32,574:INFO:Uploading results into container
2024-02-04 20:12:32,575:INFO:Uploading model into container now
2024-02-04 20:12:32,576:INFO:_master_model_container: 5
2024-02-04 20:12:32,576:INFO:_display_container: 2
2024-02-04 20:12:32,577:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=142, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 20:12:32,577:INFO:create_model() successfully completed......................................
2024-02-04 20:12:32,745:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:32,746:INFO:Creating metrics dataframe
2024-02-04 20:12:32,757:INFO:Initializing Ridge Classifier
2024-02-04 20:12:32,757:INFO:Total runtime is 0.45053554773330684 minutes
2024-02-04 20:12:32,764:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:32,764:INFO:Initializing create_model()
2024-02-04 20:12:32,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:32,764:INFO:Checking exceptions
2024-02-04 20:12:32,765:INFO:Importing libraries
2024-02-04 20:12:32,765:INFO:Copying training dataset
2024-02-04 20:12:32,773:INFO:Defining folds
2024-02-04 20:12:32,773:INFO:Declaring metric variables
2024-02-04 20:12:32,780:INFO:Importing untrained model
2024-02-04 20:12:32,789:INFO:Ridge Classifier Imported successfully
2024-02-04 20:12:32,802:INFO:Starting cross validation
2024-02-04 20:12:32,820:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:33,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:33,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:33,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:33,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:33,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:35,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 20:12:35,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 20:12:35,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 20:12:35,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 20:12:35,369:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 20:12:35,392:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,406:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:35,426:INFO:Calculating mean and std
2024-02-04 20:12:35,428:INFO:Creating metrics dataframe
2024-02-04 20:12:35,433:INFO:Uploading results into container
2024-02-04 20:12:35,434:INFO:Uploading model into container now
2024-02-04 20:12:35,434:INFO:_master_model_container: 6
2024-02-04 20:12:35,434:INFO:_display_container: 2
2024-02-04 20:12:35,435:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=142, solver='auto',
                tol=0.0001)
2024-02-04 20:12:35,435:INFO:create_model() successfully completed......................................
2024-02-04 20:12:35,545:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:35,545:INFO:Creating metrics dataframe
2024-02-04 20:12:35,565:INFO:Initializing Random Forest Classifier
2024-02-04 20:12:35,566:INFO:Total runtime is 0.4973467389742533 minutes
2024-02-04 20:12:35,573:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:35,574:INFO:Initializing create_model()
2024-02-04 20:12:35,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:35,574:INFO:Checking exceptions
2024-02-04 20:12:35,574:INFO:Importing libraries
2024-02-04 20:12:35,575:INFO:Copying training dataset
2024-02-04 20:12:35,584:INFO:Defining folds
2024-02-04 20:12:35,584:INFO:Declaring metric variables
2024-02-04 20:12:35,596:INFO:Importing untrained model
2024-02-04 20:12:35,604:INFO:Random Forest Classifier Imported successfully
2024-02-04 20:12:35,617:INFO:Starting cross validation
2024-02-04 20:12:35,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:36,425:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:36,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:36,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:36,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:36,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:39,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,455:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,471:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,473:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,488:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,590:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,716:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,725:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:39,755:INFO:Calculating mean and std
2024-02-04 20:12:39,757:INFO:Creating metrics dataframe
2024-02-04 20:12:39,763:INFO:Uploading results into container
2024-02-04 20:12:39,764:INFO:Uploading model into container now
2024-02-04 20:12:39,765:INFO:_master_model_container: 7
2024-02-04 20:12:39,765:INFO:_display_container: 2
2024-02-04 20:12:39,766:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False)
2024-02-04 20:12:39,766:INFO:create_model() successfully completed......................................
2024-02-04 20:12:39,912:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:39,912:INFO:Creating metrics dataframe
2024-02-04 20:12:39,937:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 20:12:39,938:INFO:Total runtime is 0.5702208757400512 minutes
2024-02-04 20:12:39,948:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:39,949:INFO:Initializing create_model()
2024-02-04 20:12:39,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:39,951:INFO:Checking exceptions
2024-02-04 20:12:39,951:INFO:Importing libraries
2024-02-04 20:12:39,951:INFO:Copying training dataset
2024-02-04 20:12:39,966:INFO:Defining folds
2024-02-04 20:12:39,966:INFO:Declaring metric variables
2024-02-04 20:12:39,976:INFO:Importing untrained model
2024-02-04 20:12:39,983:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 20:12:39,998:INFO:Starting cross validation
2024-02-04 20:12:40,016:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:41,045:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:41,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:41,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:41,067:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:41,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:43,151:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,221:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,350:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:43,379:INFO:Calculating mean and std
2024-02-04 20:12:43,381:INFO:Creating metrics dataframe
2024-02-04 20:12:43,386:INFO:Uploading results into container
2024-02-04 20:12:43,387:INFO:Uploading model into container now
2024-02-04 20:12:43,387:INFO:_master_model_container: 8
2024-02-04 20:12:43,388:INFO:_display_container: 2
2024-02-04 20:12:43,389:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 20:12:43,389:INFO:create_model() successfully completed......................................
2024-02-04 20:12:43,535:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:43,535:INFO:Creating metrics dataframe
2024-02-04 20:12:43,555:INFO:Initializing Ada Boost Classifier
2024-02-04 20:12:43,556:INFO:Total runtime is 0.6305090943972269 minutes
2024-02-04 20:12:43,563:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:43,564:INFO:Initializing create_model()
2024-02-04 20:12:43,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:43,564:INFO:Checking exceptions
2024-02-04 20:12:43,565:INFO:Importing libraries
2024-02-04 20:12:43,565:INFO:Copying training dataset
2024-02-04 20:12:43,580:INFO:Defining folds
2024-02-04 20:12:43,580:INFO:Declaring metric variables
2024-02-04 20:12:43,589:INFO:Importing untrained model
2024-02-04 20:12:43,600:INFO:Ada Boost Classifier Imported successfully
2024-02-04 20:12:43,617:INFO:Starting cross validation
2024-02-04 20:12:43,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:44,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:44,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:44,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:44,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:44,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:47,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,259:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,465:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:47,499:INFO:Calculating mean and std
2024-02-04 20:12:47,502:INFO:Creating metrics dataframe
2024-02-04 20:12:47,508:INFO:Uploading results into container
2024-02-04 20:12:47,510:INFO:Uploading model into container now
2024-02-04 20:12:47,511:INFO:_master_model_container: 9
2024-02-04 20:12:47,511:INFO:_display_container: 2
2024-02-04 20:12:47,512:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142)
2024-02-04 20:12:47,512:INFO:create_model() successfully completed......................................
2024-02-04 20:12:47,654:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:47,654:INFO:Creating metrics dataframe
2024-02-04 20:12:47,676:INFO:Initializing Linear Discriminant Analysis
2024-02-04 20:12:47,676:INFO:Total runtime is 0.6991727828979492 minutes
2024-02-04 20:12:47,681:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:47,682:INFO:Initializing create_model()
2024-02-04 20:12:47,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:47,683:INFO:Checking exceptions
2024-02-04 20:12:47,683:INFO:Importing libraries
2024-02-04 20:12:47,683:INFO:Copying training dataset
2024-02-04 20:12:47,691:INFO:Defining folds
2024-02-04 20:12:47,691:INFO:Declaring metric variables
2024-02-04 20:12:47,696:INFO:Importing untrained model
2024-02-04 20:12:47,704:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 20:12:47,719:INFO:Starting cross validation
2024-02-04 20:12:47,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:48,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:48,570:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:48,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:48,602:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:48,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:50,413:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,438:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,484:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,497:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:50,538:INFO:Calculating mean and std
2024-02-04 20:12:50,540:INFO:Creating metrics dataframe
2024-02-04 20:12:50,545:INFO:Uploading results into container
2024-02-04 20:12:50,546:INFO:Uploading model into container now
2024-02-04 20:12:50,546:INFO:_master_model_container: 10
2024-02-04 20:12:50,547:INFO:_display_container: 2
2024-02-04 20:12:50,547:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 20:12:50,547:INFO:create_model() successfully completed......................................
2024-02-04 20:12:50,687:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:50,687:INFO:Creating metrics dataframe
2024-02-04 20:12:50,708:INFO:Initializing Extra Trees Classifier
2024-02-04 20:12:50,709:INFO:Total runtime is 0.7497273127237956 minutes
2024-02-04 20:12:50,719:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:50,719:INFO:Initializing create_model()
2024-02-04 20:12:50,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:50,720:INFO:Checking exceptions
2024-02-04 20:12:50,720:INFO:Importing libraries
2024-02-04 20:12:50,720:INFO:Copying training dataset
2024-02-04 20:12:50,733:INFO:Defining folds
2024-02-04 20:12:50,734:INFO:Declaring metric variables
2024-02-04 20:12:50,740:INFO:Importing untrained model
2024-02-04 20:12:50,747:INFO:Extra Trees Classifier Imported successfully
2024-02-04 20:12:50,758:INFO:Starting cross validation
2024-02-04 20:12:50,776:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:51,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:51,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:51,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:51,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:51,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:54,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,434:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,540:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,773:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:54,812:INFO:Calculating mean and std
2024-02-04 20:12:54,813:INFO:Creating metrics dataframe
2024-02-04 20:12:54,822:INFO:Uploading results into container
2024-02-04 20:12:54,824:INFO:Uploading model into container now
2024-02-04 20:12:54,825:INFO:_master_model_container: 11
2024-02-04 20:12:54,825:INFO:_display_container: 2
2024-02-04 20:12:54,826:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False)
2024-02-04 20:12:54,826:INFO:create_model() successfully completed......................................
2024-02-04 20:12:54,968:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:54,969:INFO:Creating metrics dataframe
2024-02-04 20:12:54,987:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 20:12:54,987:INFO:Total runtime is 0.8210353334744771 minutes
2024-02-04 20:12:54,994:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:54,994:INFO:Initializing create_model()
2024-02-04 20:12:54,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:54,995:INFO:Checking exceptions
2024-02-04 20:12:54,995:INFO:Importing libraries
2024-02-04 20:12:54,995:INFO:Copying training dataset
2024-02-04 20:12:55,005:INFO:Defining folds
2024-02-04 20:12:55,005:INFO:Declaring metric variables
2024-02-04 20:12:55,010:INFO:Importing untrained model
2024-02-04 20:12:55,018:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:12:55,034:INFO:Starting cross validation
2024-02-04 20:12:55,056:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:12:56,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:56,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:56,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:56,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:56,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:12:58,604:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,620:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,661:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,685:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:58,981:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:12:59,014:INFO:Calculating mean and std
2024-02-04 20:12:59,016:INFO:Creating metrics dataframe
2024-02-04 20:12:59,024:INFO:Uploading results into container
2024-02-04 20:12:59,026:INFO:Uploading model into container now
2024-02-04 20:12:59,028:INFO:_master_model_container: 12
2024-02-04 20:12:59,028:INFO:_display_container: 2
2024-02-04 20:12:59,029:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:12:59,029:INFO:create_model() successfully completed......................................
2024-02-04 20:12:59,180:INFO:SubProcess create_model() end ==================================
2024-02-04 20:12:59,180:INFO:Creating metrics dataframe
2024-02-04 20:12:59,199:INFO:Initializing Dummy Classifier
2024-02-04 20:12:59,199:INFO:Total runtime is 0.8912291487058004 minutes
2024-02-04 20:12:59,204:INFO:SubProcess create_model() called ==================================
2024-02-04 20:12:59,205:INFO:Initializing create_model()
2024-02-04 20:12:59,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:12:59,205:INFO:Checking exceptions
2024-02-04 20:12:59,205:INFO:Importing libraries
2024-02-04 20:12:59,205:INFO:Copying training dataset
2024-02-04 20:12:59,215:INFO:Defining folds
2024-02-04 20:12:59,215:INFO:Declaring metric variables
2024-02-04 20:12:59,220:INFO:Importing untrained model
2024-02-04 20:12:59,226:INFO:Dummy Classifier Imported successfully
2024-02-04 20:12:59,238:INFO:Starting cross validation
2024-02-04 20:12:59,268:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:13:00,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:13:00,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:13:00,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:13:00,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:13:00,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:13:02,528:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,544:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:13:02,559:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:13:02,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:13:02,620:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:13:02,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,720:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,729:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,734:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:13:02,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:13:02,753:INFO:Calculating mean and std
2024-02-04 20:13:02,755:INFO:Creating metrics dataframe
2024-02-04 20:13:02,763:INFO:Uploading results into container
2024-02-04 20:13:02,764:INFO:Uploading model into container now
2024-02-04 20:13:02,764:INFO:_master_model_container: 13
2024-02-04 20:13:02,764:INFO:_display_container: 2
2024-02-04 20:13:02,765:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 20:13:02,765:INFO:create_model() successfully completed......................................
2024-02-04 20:13:02,911:INFO:SubProcess create_model() end ==================================
2024-02-04 20:13:02,911:INFO:Creating metrics dataframe
2024-02-04 20:13:02,945:INFO:Initializing create_model()
2024-02-04 20:13:02,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:13:02,945:INFO:Checking exceptions
2024-02-04 20:13:02,948:INFO:Importing libraries
2024-02-04 20:13:02,948:INFO:Copying training dataset
2024-02-04 20:13:02,957:INFO:Defining folds
2024-02-04 20:13:02,957:INFO:Declaring metric variables
2024-02-04 20:13:02,959:INFO:Importing untrained model
2024-02-04 20:13:02,959:INFO:Declaring custom model
2024-02-04 20:13:02,962:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:13:02,981:INFO:Cross validation set to False
2024-02-04 20:13:02,982:INFO:Fitting Model
2024-02-04 20:13:04,235:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:13:04,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001094 seconds.
2024-02-04 20:13:04,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:13:04,237:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:13:04,238:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:13:04,238:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:13:04,427:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:13:04,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-02-04 20:13:04,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:13:04,428:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:13:04,428:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:13:04,428:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:13:04,482:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:13:04,482:INFO:create_model() successfully completed......................................
2024-02-04 20:13:04,616:INFO:Creating Dashboard logs
2024-02-04 20:13:04,622:INFO:Model: Light Gradient Boosting Machine
2024-02-04 20:13:04,710:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 142, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-02-04 20:13:04,965:INFO:Initializing predict_model()
2024-02-04 20:13:04,965:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599C65630>)
2024-02-04 20:13:04,965:INFO:Checking exceptions
2024-02-04 20:13:04,966:INFO:Preloading libraries
2024-02-04 20:13:06,471:INFO:Creating Dashboard logs
2024-02-04 20:13:06,475:INFO:Model: Ada Boost Classifier
2024-02-04 20:13:06,539:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 142}
2024-02-04 20:13:06,931:INFO:Creating Dashboard logs
2024-02-04 20:13:06,937:INFO:Model: Random Forest Classifier
2024-02-04 20:13:07,010:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 20:13:07,419:INFO:Creating Dashboard logs
2024-02-04 20:13:07,423:INFO:Model: Extra Trees Classifier
2024-02-04 20:13:07,501:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 20:13:07,940:INFO:Creating Dashboard logs
2024-02-04 20:13:07,945:INFO:Model: K Neighbors Classifier
2024-02-04 20:13:08,047:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-02-04 20:13:08,540:INFO:Creating Dashboard logs
2024-02-04 20:13:08,546:INFO:Model: Linear Discriminant Analysis
2024-02-04 20:13:08,629:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-02-04 20:13:09,106:INFO:Creating Dashboard logs
2024-02-04 20:13:09,113:INFO:Model: Ridge Classifier
2024-02-04 20:13:09,193:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 142, 'solver': 'auto', 'tol': 0.0001}
2024-02-04 20:13:09,690:INFO:Creating Dashboard logs
2024-02-04 20:13:09,698:INFO:Model: Logistic Regression
2024-02-04 20:13:09,784:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 142, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-02-04 20:13:10,245:INFO:Creating Dashboard logs
2024-02-04 20:13:10,249:INFO:Model: Quadratic Discriminant Analysis
2024-02-04 20:13:10,328:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-02-04 20:13:10,818:INFO:Creating Dashboard logs
2024-02-04 20:13:10,825:INFO:Model: Naive Bayes
2024-02-04 20:13:10,921:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-02-04 20:13:11,367:INFO:Creating Dashboard logs
2024-02-04 20:13:11,372:INFO:Model: Decision Tree Classifier
2024-02-04 20:13:11,450:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 142, 'splitter': 'best'}
2024-02-04 20:13:11,909:INFO:Creating Dashboard logs
2024-02-04 20:13:11,914:INFO:Model: Dummy Classifier
2024-02-04 20:13:11,996:INFO:Logged params: {'constant': None, 'random_state': 142, 'strategy': 'prior'}
2024-02-04 20:13:12,447:INFO:Creating Dashboard logs
2024-02-04 20:13:12,451:INFO:Model: SVM - Linear Kernel
2024-02-04 20:13:12,517:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 142, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-02-04 20:13:13,030:INFO:_master_model_container: 13
2024-02-04 20:13:13,030:INFO:_display_container: 2
2024-02-04 20:13:13,031:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:13:13,031:INFO:compare_models() successfully completed......................................
2024-02-04 20:15:48,601:INFO:Initializing tune_model()
2024-02-04 20:15:48,602:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>)
2024-02-04 20:15:48,602:INFO:Checking exceptions
2024-02-04 20:15:48,612:INFO:Copying training dataset
2024-02-04 20:15:48,619:INFO:Checking base model
2024-02-04 20:15:48,619:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 20:15:48,620:INFO:Declaring metric variables
2024-02-04 20:15:48,621:INFO:Defining Hyperparameters
2024-02-04 20:15:48,812:INFO:Tuning with n_jobs=-1
2024-02-04 20:15:48,812:INFO:Initializing RandomizedSearchCV
2024-02-04 20:15:50,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,217:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,222:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,252:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:50,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:52,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:52,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:52,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:52,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:53,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:54,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:54,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:54,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:54,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:54,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:57,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:57,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:57,355:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:57,401:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:57,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:57,853:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:57,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:15:58,427:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:58,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:58,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:58,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:59,125:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:15:59,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:00,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:01,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:01,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:02,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:02,259:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:02,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:02,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:02,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:03,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:03,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:03,894:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:04,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:04,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:04,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:05,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:07,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:07,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:08,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:08,944:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:09,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:09,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:09,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:10,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:11,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:11,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:11,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:12,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:12,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:12,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:13,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:13,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:13,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:14,104:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:14,371:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:14,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:14,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:14,927:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:16,631:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:17,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:17,584:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:17,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:18,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:18,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:18,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:19,473:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:19,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:20,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:20,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:21,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:21,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:21,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:21,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:21,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:22,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:22,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:23,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:24,107:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:24,325:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:24,371:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:24,588:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:24,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:24,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:25,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:25,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:27,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:27,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:27,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:28,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:28,213:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:28,233:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.9}
2024-02-04 20:16:28,233:INFO:Hyperparameter search completed
2024-02-04 20:16:28,233:INFO:SubProcess create_model() called ==================================
2024-02-04 20:16:28,235:INFO:Initializing create_model()
2024-02-04 20:16:28,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A557DC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 30, 'n_estimators': 260, 'min_split_gain': 0.6, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9})
2024-02-04 20:16:28,235:INFO:Checking exceptions
2024-02-04 20:16:28,235:INFO:Importing libraries
2024-02-04 20:16:28,235:INFO:Copying training dataset
2024-02-04 20:16:28,248:INFO:Defining folds
2024-02-04 20:16:28,249:INFO:Declaring metric variables
2024-02-04 20:16:28,250:INFO:Importing untrained model
2024-02-04 20:16:28,250:INFO:Declaring custom model
2024-02-04 20:16:28,251:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:16:28,252:INFO:Starting cross validation
2024-02-04 20:16:28,283:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:16:29,604:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:29,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:29,697:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:30,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:30,546:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:33,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:33,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:33,335:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:33,771:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:33,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:33,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,090:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:34,319:INFO:Calculating mean and std
2024-02-04 20:16:34,320:INFO:Creating metrics dataframe
2024-02-04 20:16:34,323:INFO:Finalizing model
2024-02-04 20:16:35,641:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:16:35,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001472 seconds.
2024-02-04 20:16:35,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:16:35,643:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:16:35,643:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:16:35,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:16:35,886:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:16:35,887:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:16:35,887:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:16:35,893:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:16:35,893:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:16:35,893:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:16:35,893:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:16:35,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.
2024-02-04 20:16:35,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-04 20:16:35,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-04 20:16:35,896:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:16:35,896:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:16:35,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:16:35,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:16:36,216:INFO:Uploading results into container
2024-02-04 20:16:36,218:INFO:Uploading model into container now
2024-02-04 20:16:36,218:INFO:_master_model_container: 14
2024-02-04 20:16:36,218:INFO:_display_container: 3
2024-02-04 20:16:36,219:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:16:36,219:INFO:create_model() successfully completed......................................
2024-02-04 20:16:36,356:INFO:SubProcess create_model() end ==================================
2024-02-04 20:16:36,356:INFO:choose_better activated
2024-02-04 20:16:36,356:INFO:SubProcess create_model() called ==================================
2024-02-04 20:16:36,357:INFO:Initializing create_model()
2024-02-04 20:16:36,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:16:36,357:INFO:Checking exceptions
2024-02-04 20:16:36,359:INFO:Importing libraries
2024-02-04 20:16:36,359:INFO:Copying training dataset
2024-02-04 20:16:36,369:INFO:Defining folds
2024-02-04 20:16:36,369:INFO:Declaring metric variables
2024-02-04 20:16:36,370:INFO:Importing untrained model
2024-02-04 20:16:36,370:INFO:Declaring custom model
2024-02-04 20:16:36,371:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:16:36,371:INFO:Starting cross validation
2024-02-04 20:16:36,384:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:16:37,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:37,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:37,350:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:37,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:37,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:16:40,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,179:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,325:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,392:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,562:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,590:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:16:40,623:INFO:Calculating mean and std
2024-02-04 20:16:40,624:INFO:Creating metrics dataframe
2024-02-04 20:16:40,627:INFO:Finalizing model
2024-02-04 20:16:42,016:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:16:42,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.
2024-02-04 20:16:42,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:16:42,017:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:16:42,018:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:16:42,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:16:42,252:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:16:42,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-02-04 20:16:42,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:16:42,253:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:16:42,253:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:16:42,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:16:42,340:INFO:Uploading results into container
2024-02-04 20:16:42,341:INFO:Uploading model into container now
2024-02-04 20:16:42,341:INFO:_master_model_container: 15
2024-02-04 20:16:42,341:INFO:_display_container: 4
2024-02-04 20:16:42,342:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:16:42,342:INFO:create_model() successfully completed......................................
2024-02-04 20:16:42,470:INFO:SubProcess create_model() end ==================================
2024-02-04 20:16:42,471:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6807
2024-02-04 20:16:42,471:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6923
2024-02-04 20:16:42,472:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 20:16:42,472:INFO:choose_better completed
2024-02-04 20:16:42,472:INFO:Creating Dashboard logs
2024-02-04 20:16:42,472:INFO:Model: Light Gradient Boosting Machine
2024-02-04 20:16:42,546:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.005, 'max_depth': -1, 'min_child_samples': 96, 'min_child_weight': 0.001, 'min_split_gain': 0.6, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 30, 'objective': None, 'random_state': 142, 'reg_alpha': 0.3, 'reg_lambda': 4, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9}
2024-02-04 20:16:42,810:INFO:Initializing predict_model()
2024-02-04 20:16:42,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599D4A050>)
2024-02-04 20:16:42,810:INFO:Checking exceptions
2024-02-04 20:16:42,810:INFO:Preloading libraries
2024-02-04 20:16:43,440:INFO:_master_model_container: 15
2024-02-04 20:16:43,440:INFO:_display_container: 3
2024-02-04 20:16:43,440:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:16:43,440:INFO:tune_model() successfully completed......................................
2024-02-04 20:17:16,008:INFO:Initializing plot_model()
2024-02-04 20:17:16,009:INFO:plot_model(plot=parameter, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 20:17:16,010:INFO:Checking exceptions
2024-02-04 20:17:16,020:INFO:Preloading libraries
2024-02-04 20:17:16,067:INFO:Copying training dataset
2024-02-04 20:17:16,067:INFO:Plot type: parameter
2024-02-04 20:17:16,073:INFO:Visual Rendered Successfully
2024-02-04 20:17:16,265:INFO:plot_model() successfully completed......................................
2024-02-04 20:19:39,225:INFO:Initializing ensemble_model()
2024-02-04 20:19:39,226:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=5, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 20:19:39,226:INFO:Checking exceptions
2024-02-04 20:19:39,264:INFO:Importing libraries
2024-02-04 20:19:39,264:INFO:Copying training dataset
2024-02-04 20:19:39,264:INFO:Checking base model
2024-02-04 20:19:39,265:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 20:19:39,278:INFO:Importing untrained ensembler
2024-02-04 20:19:39,279:INFO:Ensemble method set to Bagging
2024-02-04 20:19:39,279:INFO:SubProcess create_model() called ==================================
2024-02-04 20:19:39,281:INFO:Initializing create_model()
2024-02-04 20:19:39,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.005, max_depth=-1,
                                           min_child_samples=96,
                                           min_child_weight=0.001,
                                           min_split_gain=0.6, n_estimators=260,
                                           n_jobs=-1, num_leaves=30,
                                           objective=None, random_state=142,
                                           reg_alpha=0.3, reg_lambda=4,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5999200D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:19:39,283:INFO:Checking exceptions
2024-02-04 20:19:39,283:INFO:Importing libraries
2024-02-04 20:19:39,283:INFO:Copying training dataset
2024-02-04 20:19:39,292:INFO:Defining folds
2024-02-04 20:19:39,292:INFO:Declaring metric variables
2024-02-04 20:19:39,297:INFO:Importing untrained model
2024-02-04 20:19:39,297:INFO:Declaring custom model
2024-02-04 20:19:39,304:INFO:Bagging Classifier Imported successfully
2024-02-04 20:19:39,315:INFO:Starting cross validation
2024-02-04 20:19:39,356:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:19:40,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:19:40,773:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:19:40,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:19:40,999:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:19:41,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:19:57,651:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:57,681:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:57,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,240:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,322:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,562:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,607:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:19:58,649:INFO:Calculating mean and std
2024-02-04 20:19:58,653:INFO:Creating metrics dataframe
2024-02-04 20:19:58,675:INFO:Finalizing model
2024-02-04 20:20:02,005:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:02,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002383 seconds.
2024-02-04 20:20:02,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:02,008:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:20:02,009:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:20:02,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:20:02,469:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:02,469:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:02,469:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:02,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:02,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:02,475:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:02,475:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:02,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-02-04 20:20:02,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:02,476:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:02,477:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:02,477:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500164 -> initscore=0.000656
2024-02-04 20:20:02,478:INFO:[LightGBM] [Info] Start training from score 0.000656
2024-02-04 20:20:02,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,901:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:02,901:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:02,901:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:02,906:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:02,906:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:02,906:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:02,907:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:02,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.
2024-02-04 20:20:02,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:02,910:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:02,910:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:02,911:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502297 -> initscore=0.009186
2024-02-04 20:20:02,911:INFO:[LightGBM] [Info] Start training from score 0.009186
2024-02-04 20:20:02,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:02,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,314:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:03,314:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:03,314:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:03,319:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:03,320:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:03,320:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:03,320:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:03,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-02-04 20:20:03,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:03,321:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:03,321:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:03,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499344 -> initscore=-0.002625
2024-02-04 20:20:03,322:INFO:[LightGBM] [Info] Start training from score -0.002625
2024-02-04 20:20:03,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,666:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:03,667:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:03,667:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:03,672:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:03,672:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:03,672:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:03,674:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:03,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-02-04 20:20:03,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-04 20:20:03,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-04 20:20:03,675:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:03,675:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:03,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494587 -> initscore=-0.021654
2024-02-04 20:20:03,675:INFO:[LightGBM] [Info] Start training from score -0.021654
2024-02-04 20:20:03,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:03,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,095:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,095:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,095:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,100:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,100:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,101:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,101:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:04,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-02-04 20:20:04,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:04,102:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:04,102:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:04,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505741 -> initscore=0.022967
2024-02-04 20:20:04,102:INFO:[LightGBM] [Info] Start training from score 0.022967
2024-02-04 20:20:04,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,446:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,451:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,451:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,451:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:04,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-02-04 20:20:04,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:04,452:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:04,452:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:04,452:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497539 -> initscore=-0.009843
2024-02-04 20:20:04,453:INFO:[LightGBM] [Info] Start training from score -0.009843
2024-02-04 20:20:04,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,797:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,798:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,798:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:04,803:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:04,803:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:04,804:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:04,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-02-04 20:20:04,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:04,804:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:04,804:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:04,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511647 -> initscore=0.046596
2024-02-04 20:20:04,805:INFO:[LightGBM] [Info] Start training from score 0.046596
2024-02-04 20:20:04,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:04,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,170:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,170:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,170:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,174:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,175:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,175:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,175:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:05,176:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-02-04 20:20:05,176:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:05,176:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:05,176:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:05,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499016 -> initscore=-0.003937
2024-02-04 20:20:05,177:INFO:[LightGBM] [Info] Start training from score -0.003937
2024-02-04 20:20:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,522:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,522:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,527:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,527:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,527:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,528:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:05,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-02-04 20:20:05,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:05,529:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:05,529:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:05,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497867 -> initscore=-0.008530
2024-02-04 20:20:05,529:INFO:[LightGBM] [Info] Start training from score -0.008530
2024-02-04 20:20:05,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,883:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,883:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,884:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:20:05,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:20:05,890:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:20:05,890:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:20:05,891:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-02-04 20:20:05,891:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:20:05,891:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:20:05,891:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:20:05,892:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503117 -> initscore=0.012467
2024-02-04 20:20:05,892:INFO:[LightGBM] [Info] Start training from score 0.012467
2024-02-04 20:20:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:05,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:20:06,357:INFO:Uploading results into container
2024-02-04 20:20:06,360:INFO:Uploading model into container now
2024-02-04 20:20:06,365:INFO:_master_model_container: 16
2024-02-04 20:20:06,366:INFO:_display_container: 4
2024-02-04 20:20:06,372:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.005, max_depth=-1,
                                           min_child_samples=96,
                                           min_child_weight=0.001,
                                           min_split_gain=0.6, n_estimators=260,
                                           n_jobs=-1, num_leaves=30,
                                           objective=None, random_state=142,
                                           reg_alpha=0.3, reg_lambda=4,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False)
2024-02-04 20:20:06,372:INFO:create_model() successfully completed......................................
2024-02-04 20:20:06,592:INFO:SubProcess create_model() end ==================================
2024-02-04 20:20:06,593:INFO:Creating Dashboard logs
2024-02-04 20:20:06,601:INFO:Model: Bagging Classifier
2024-02-04 20:20:06,712:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.005, 'estimator__max_depth': -1, 'estimator__min_child_samples': 96, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.6, 'estimator__n_estimators': 260, 'estimator__n_jobs': -1, 'estimator__num_leaves': 30, 'estimator__objective': None, 'estimator__random_state': 142, 'estimator__reg_alpha': 0.3, 'estimator__reg_lambda': 4, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator__feature_fraction': 0.6, 'estimator__bagging_freq': 2, 'estimator__bagging_fraction': 0.9, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 20:20:07,156:INFO:Initializing predict_model()
2024-02-04 20:20:07,156:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.005, max_depth=-1,
                                           min_child_samples=96,
                                           min_child_weight=0.001,
                                           min_split_gain=0.6, n_estimators=260,
                                           n_jobs=-1, num_leaves=30,
                                           objective=None, random_state=142,
                                           reg_alpha=0.3, reg_lambda=4,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599D4A8C0>)
2024-02-04 20:20:07,156:INFO:Checking exceptions
2024-02-04 20:20:07,157:INFO:Preloading libraries
2024-02-04 20:20:08,958:INFO:_master_model_container: 16
2024-02-04 20:20:08,959:INFO:_display_container: 4
2024-02-04 20:20:08,964:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.005, max_depth=-1,
                                           min_child_samples=96,
                                           min_child_weight=0.001,
                                           min_split_gain=0.6, n_estimators=260,
                                           n_jobs=-1, num_leaves=30,
                                           objective=None, random_state=142,
                                           reg_alpha=0.3, reg_lambda=4,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False)
2024-02-04 20:20:08,965:INFO:ensemble_model() successfully completed......................................
2024-02-04 20:21:57,235:INFO:Initializing plot_model()
2024-02-04 20:21:57,236:INFO:plot_model(plot=parameter, fold=None, verbose=True, display=None, display_format=None, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.005, max_depth=-1,
                                           min_child_samples=96,
                                           min_child_weight=0.001,
                                           min_split_gain=0.6, n_estimators=260,
                                           n_jobs=-1, num_leaves=30,
                                           objective=None, random_state=142,
                                           reg_alpha=0.3, reg_lambda=4,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 20:21:57,236:INFO:Checking exceptions
2024-02-04 20:21:57,245:INFO:Preloading libraries
2024-02-04 20:21:57,595:INFO:Copying training dataset
2024-02-04 20:21:57,595:INFO:Plot type: parameter
2024-02-04 20:21:57,606:INFO:Visual Rendered Successfully
2024-02-04 20:21:57,758:INFO:plot_model() successfully completed......................................
2024-02-04 20:23:46,376:INFO:Initializing ensemble_model()
2024-02-04 20:23:46,376:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Boosting, fold=5, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 20:23:46,376:INFO:Checking exceptions
2024-02-04 20:23:46,577:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,577:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,578:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,581:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,581:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,581:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,581:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:46,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-02-04 20:23:46,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:46,582:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:46,582:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:46,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:46,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,605:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,721:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,721:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,768:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,768:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,769:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,783:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,783:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,783:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,805:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,806:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,806:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,806:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:46,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-02-04 20:23:46,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:46,807:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:46,808:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:46,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,879:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,879:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,900:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,953:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,953:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,954:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,957:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,957:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,958:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,959:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:46,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:46,986:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,986:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,986:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,994:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,994:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,994:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,998:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:46,998:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:46,998:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:46,998:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:46,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-02-04 20:23:46,999:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:46,999:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:46,999:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:46,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,114:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,114:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,121:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,122:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,123:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,127:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,127:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,128:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,134:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,134:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,134:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,140:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,141:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,141:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-02-04 20:23:47,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,141:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,141:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,146:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,154:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,164:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,164:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,166:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,166:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,169:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,169:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,171:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,201:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,214:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,239:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,240:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,240:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,240:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,241:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,242:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,242:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,242:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,243:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,244:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,244:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,244:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,245:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,245:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,246:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,246:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,247:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,247:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,247:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,248:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,250:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,250:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,250:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,257:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,257:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,258:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,261:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,261:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,261:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,261:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-02-04 20:23:47,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,262:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,262:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,264:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,264:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,274:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,274:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,356:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,356:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,356:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,357:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,357:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,358:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,359:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,360:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,361:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,365:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,365:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,365:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,366:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,367:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,372:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,372:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,372:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,378:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,378:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,378:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,381:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,381:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,381:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,382:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
2024-02-04 20:23:47,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,382:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,382:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,411:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,411:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,412:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,412:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,414:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,415:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,415:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,425:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,427:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,427:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,430:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,432:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,433:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,433:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,435:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,438:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,438:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,449:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,449:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,465:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,468:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,469:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,470:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,471:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,472:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,473:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,474:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,474:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,475:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,475:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,475:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,477:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,478:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,479:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,479:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,479:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,480:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,480:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,492:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,492:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,492:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,498:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,498:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,498:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,502:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,502:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,502:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,502:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.
2024-02-04 20:23:47,503:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,503:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,503:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,504:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,504:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,506:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,506:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,508:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,508:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,511:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,555:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,556:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,556:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,562:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,562:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,565:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,565:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,589:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,605:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,605:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,605:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,611:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,611:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,611:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,614:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,614:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,614:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,614:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,615:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.
2024-02-04 20:23:47,615:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,615:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,615:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,615:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,714:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,717:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,717:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,717:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,723:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,724:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,727:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,727:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,727:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,728:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-02-04 20:23:47,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,728:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,728:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,788:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,827:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,827:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,827:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,832:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,832:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,832:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,835:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,835:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,836:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,836:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:47,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.
2024-02-04 20:23:47,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:47,836:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:47,836:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:47,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,840:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,948:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,949:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:47,952:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:47,955:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:47,955:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:47,955:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:47,993:INFO:Importing libraries
2024-02-04 20:23:47,993:INFO:Copying training dataset
2024-02-04 20:23:47,994:INFO:Checking base model
2024-02-04 20:23:47,994:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 20:23:48,010:INFO:Importing untrained ensembler
2024-02-04 20:23:48,010:INFO:Ensemble method set to Boosting
2024-02-04 20:23:48,021:INFO:SubProcess create_model() called ==================================
2024-02-04 20:23:48,024:INFO:Initializing create_model()
2024-02-04 20:23:48,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A72C0A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:23:48,024:INFO:Checking exceptions
2024-02-04 20:23:48,025:INFO:Importing libraries
2024-02-04 20:23:48,025:INFO:Copying training dataset
2024-02-04 20:23:48,037:INFO:Defining folds
2024-02-04 20:23:48,037:INFO:Declaring metric variables
2024-02-04 20:23:48,043:INFO:Importing untrained model
2024-02-04 20:23:48,044:INFO:Declaring custom model
2024-02-04 20:23:48,052:INFO:Ada Boost Classifier Imported successfully
2024-02-04 20:23:48,066:INFO:Starting cross validation
2024-02-04 20:23:48,082:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:23:49,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:23:49,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:23:49,427:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:23:49,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:23:49,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:23:53,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,793:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:23:53,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:23:53,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,831:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:23:53,838:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,927:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:53,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:23:53,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:54,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:54,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:54,129:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 20:23:54,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:23:54,166:INFO:Calculating mean and std
2024-02-04 20:23:54,168:INFO:Creating metrics dataframe
2024-02-04 20:23:54,183:INFO:Finalizing model
2024-02-04 20:23:55,773:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:55,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.
2024-02-04 20:23:55,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:55,775:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:23:55,775:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:23:55,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,010:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,010:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,010:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,015:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,016:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,016:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,016:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.
2024-02-04 20:23:56,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,016:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,016:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,042:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,043:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,114:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,122:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,122:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,122:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,128:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,129:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,129:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,132:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,132:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,133:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,133:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-02-04 20:23:56,133:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,133:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,133:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,135:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,135:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,138:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,138:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,139:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,139:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,140:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,140:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,141:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,142:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,142:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,143:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,144:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,145:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,146:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,146:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,147:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,150:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,151:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,152:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,153:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,154:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,154:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,158:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,159:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,160:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,161:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,162:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,163:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,164:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,164:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,165:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,166:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,166:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,168:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,169:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,169:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,170:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,171:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,172:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,174:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,175:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,176:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,177:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,178:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,178:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,179:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,180:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,181:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,200:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,202:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,203:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,204:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,205:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,206:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,207:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,208:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,209:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,210:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,211:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,212:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,213:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,215:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,216:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,217:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,224:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,225:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,228:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,229:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,230:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,231:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,232:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,233:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,234:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,238:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,241:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,241:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,241:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,249:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,249:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,249:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,252:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,252:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,252:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,253:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-02-04 20:23:56,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,253:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,253:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,254:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,254:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,255:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,256:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,256:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,257:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,257:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,257:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,258:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,259:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,259:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,260:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,260:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,261:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,262:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,262:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,263:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,264:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,264:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,265:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,266:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,267:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,268:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,269:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,270:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,271:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,272:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,273:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,274:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,277:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,278:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,279:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,280:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,282:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,283:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,284:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,285:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,286:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,294:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,295:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,296:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,297:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,298:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,299:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,299:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,300:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,301:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,302:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,303:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,304:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,305:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,306:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,307:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,308:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,309:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,310:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,311:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,312:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,313:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,314:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,315:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,316:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,318:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,319:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,320:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,321:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,323:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,326:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,327:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,329:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,332:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,333:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,334:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,336:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,338:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,339:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,340:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,341:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,342:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,343:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,344:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,345:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,346:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,347:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,348:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,349:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,350:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,351:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,353:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,354:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,355:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,358:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,358:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,358:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,363:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,364:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,364:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,367:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,367:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,368:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,368:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-02-04 20:23:56,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,368:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,368:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,391:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,392:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,393:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,394:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,397:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,398:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,399:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,400:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,401:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,402:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,403:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,404:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,405:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,406:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,407:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,410:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,411:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,412:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,412:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,413:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,414:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,415:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,416:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,417:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,418:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,419:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,421:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,422:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,423:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,424:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,424:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,425:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,425:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,425:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,426:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,427:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,427:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,428:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,429:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,430:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,431:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,432:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,432:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,433:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,433:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,433:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,434:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,436:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,438:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,438:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,438:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,439:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,440:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,441:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,442:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,443:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,447:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,448:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,449:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,449:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,450:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,451:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,452:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,453:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,454:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,463:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,464:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,466:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,467:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,469:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,469:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,469:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,475:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,475:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,475:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,479:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,479:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,479:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,479:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.
2024-02-04 20:23:56,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,480:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,480:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,480:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,481:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,482:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,483:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,484:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,485:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,486:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,487:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,488:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,489:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,490:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,491:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,494:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,495:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,497:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,498:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,499:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,500:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,501:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,502:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,503:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,504:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,505:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,506:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,507:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,508:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,508:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,509:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,510:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,512:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,513:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,514:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,515:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,516:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,517:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,517:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,539:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,540:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,543:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,544:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,545:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,546:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,547:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,548:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,549:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,550:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,551:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,552:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,553:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,554:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,554:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,555:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,555:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,555:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,556:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,556:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,557:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,558:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,559:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,560:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,561:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,562:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,563:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,564:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,565:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,566:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,566:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,567:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,570:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,571:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,572:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,574:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,575:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,576:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,578:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,579:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,580:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,581:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,583:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,585:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,586:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,587:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,589:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,589:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,589:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,595:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,596:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,599:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,600:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,600:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,600:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.
2024-02-04 20:23:56,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,601:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,601:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,601:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,602:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,603:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,604:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,606:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,608:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,610:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,611:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,612:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,624:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,625:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,627:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,628:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,629:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,630:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,631:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,632:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,633:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,634:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,636:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,656:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,659:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,678:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,679:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,682:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,684:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,698:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,701:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,704:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,710:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,715:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,719:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,719:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,725:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,725:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,725:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,730:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,730:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,730:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,730:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-02-04 20:23:56,730:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,730:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,730:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,788:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,834:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,840:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,841:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,841:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,846:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,847:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,847:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,850:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,851:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,851:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,851:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2024-02-04 20:23:56,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,851:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,851:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,873:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,874:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,875:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,876:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,878:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,879:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,879:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,880:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,882:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,883:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,884:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,885:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,886:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,888:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,889:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,890:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,891:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,892:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,893:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,896:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,897:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,898:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,899:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,900:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,900:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,900:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,901:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,902:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,904:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,906:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,907:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,908:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,909:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,912:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,913:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,914:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,915:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,920:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,921:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,922:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,925:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,926:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,930:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,932:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,933:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,934:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,937:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,940:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,941:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,945:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,948:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,948:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,949:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,954:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,954:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,954:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,957:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:56,957:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:56,957:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:56,957:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:56,958:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-02-04 20:23:56,958:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:56,958:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:56,958:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:56,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:56,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,959:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,959:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,960:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,961:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,964:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,975:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,978:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,982:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,985:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,989:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,991:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,992:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,993:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,994:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,995:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,998:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,998:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:56,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:56,999:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,002:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,003:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,011:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,012:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,013:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,015:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,017:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,018:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,021:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,023:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,024:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,025:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,031:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,033:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,035:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,037:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,038:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,039:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,040:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,041:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,043:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:57,043:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:57,043:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:57,049:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:57,049:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:57,049:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:57,052:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:57,052:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:57,052:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:57,052:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:23:57,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.
2024-02-04 20:23:57,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:23:57,052:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:23:57,052:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:23:57,053:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:23:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,064:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,069:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,070:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,073:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,075:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,077:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,080:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,081:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,083:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,084:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,086:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,088:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,091:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,092:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,094:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,095:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,097:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,098:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,099:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,100:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,101:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,103:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,104:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,106:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,107:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,109:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,111:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,113:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,114:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,115:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,117:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,119:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,121:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,125:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,126:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,127:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,127:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,129:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,130:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,131:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,132:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,133:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,135:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,136:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:23:57,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-04 20:23:57,139:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:23:57,140:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:23:57,140:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:23:57,151:INFO:Uploading results into container
2024-02-04 20:23:57,152:INFO:Uploading model into container now
2024-02-04 20:23:57,153:INFO:_master_model_container: 17
2024-02-04 20:23:57,153:INFO:_display_container: 5
2024-02-04 20:23:57,157:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142)
2024-02-04 20:23:57,157:INFO:create_model() successfully completed......................................
2024-02-04 20:23:57,320:INFO:SubProcess create_model() end ==================================
2024-02-04 20:23:57,320:INFO:Creating Dashboard logs
2024-02-04 20:23:57,325:INFO:Model: Ada Boost Classifier
2024-02-04 20:23:57,411:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.005, 'estimator__max_depth': -1, 'estimator__min_child_samples': 96, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.6, 'estimator__n_estimators': 260, 'estimator__n_jobs': -1, 'estimator__num_leaves': 30, 'estimator__objective': None, 'estimator__random_state': 142, 'estimator__reg_alpha': 0.3, 'estimator__reg_lambda': 4, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator__feature_fraction': 0.6, 'estimator__bagging_freq': 2, 'estimator__bagging_fraction': 0.9, 'learning_rate': 1.0, 'n_estimators': 10, 'random_state': 142}
2024-02-04 20:23:57,664:INFO:Initializing predict_model()
2024-02-04 20:23:57,665:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599F523B0>)
2024-02-04 20:23:57,665:INFO:Checking exceptions
2024-02-04 20:23:57,665:INFO:Preloading libraries
2024-02-04 20:23:58,287:INFO:_master_model_container: 17
2024-02-04 20:23:58,287:INFO:_display_container: 5
2024-02-04 20:23:58,289:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142)
2024-02-04 20:23:58,290:INFO:ensemble_model() successfully completed......................................
2024-02-04 20:25:53,690:INFO:gpu_param set to False
2024-02-04 20:25:53,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:25:53,852:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:25:53,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 20:25:53,990:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 20:36:55,720:INFO:Initializing blend_models()
2024-02-04 20:36:55,721:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator_list=[LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142)], fold=5, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 20:36:55,721:INFO:Checking exceptions
2024-02-04 20:36:55,761:INFO:Importing libraries
2024-02-04 20:36:55,761:INFO:Copying training dataset
2024-02-04 20:36:55,768:INFO:Getting model names
2024-02-04 20:36:55,776:INFO:SubProcess create_model() called ==================================
2024-02-04 20:36:55,788:INFO:Initializing create_model()
2024-02-04 20:36:55,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A58A750A90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:36:55,789:INFO:Checking exceptions
2024-02-04 20:36:55,789:INFO:Importing libraries
2024-02-04 20:36:55,789:INFO:Copying training dataset
2024-02-04 20:36:55,801:INFO:Defining folds
2024-02-04 20:36:55,802:INFO:Declaring metric variables
2024-02-04 20:36:55,806:INFO:Importing untrained model
2024-02-04 20:36:55,808:INFO:Declaring custom model
2024-02-04 20:36:55,817:INFO:Voting Classifier Imported successfully
2024-02-04 20:36:55,834:INFO:Starting cross validation
2024-02-04 20:36:55,856:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:37:03,512:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:37:03,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:37:03,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:37:03,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:37:03,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:37:07,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,848:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,906:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,907:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:07,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:08,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:08,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:08,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:37:08,290:INFO:Calculating mean and std
2024-02-04 20:37:08,292:INFO:Creating metrics dataframe
2024-02-04 20:37:08,303:INFO:Finalizing model
2024-02-04 20:37:09,822:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:37:09,823:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.
2024-02-04 20:37:09,823:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:37:09,824:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:37:09,825:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:37:09,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:37:13,152:INFO:Uploading results into container
2024-02-04 20:37:13,154:INFO:Uploading model into container now
2024-02-04 20:37:13,157:INFO:_master_model_container: 18
2024-02-04 20:37:13,158:INFO:_display_container: 6
2024-02-04 20:37:13,176:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 20:37:13,176:INFO:create_model() successfully completed......................................
2024-02-04 20:37:13,356:INFO:SubProcess create_model() end ==================================
2024-02-04 20:37:13,356:INFO:Creating Dashboard logs
2024-02-04 20:37:13,361:INFO:Model: Voting Classifier
2024-02-04 20:37:13,458:INFO:Logged params: {'flatten_transform': True, 'n_jobs': -1, 'verbose': False, 'voting': 'soft', 'weights': None, 'Light Gradient Boosting Machine__boosting_type': 'gbdt', 'Light Gradient Boosting Machine__class_weight': None, 'Light Gradient Boosting Machine__colsample_bytree': 1.0, 'Light Gradient Boosting Machine__importance_type': 'split', 'Light Gradient Boosting Machine__learning_rate': 0.005, 'Light Gradient Boosting Machine__max_depth': -1, 'Light Gradient Boosting Machine__min_child_samples': 96, 'Light Gradient Boosting Machine__min_child_weight': 0.001, 'Light Gradient Boosting Machine__min_split_gain': 0.6, 'Light Gradient Boosting Machine__n_estimators': 260, 'Light Gradient Boosting Machine__n_jobs': -1, 'Light Gradient Boosting Machine__num_leaves': 30, 'Light Gradient Boosting Machine__objective': None, 'Light Gradient Boosting Machine__random_state': 142, 'Light Gradient Boosting Machine__reg_alpha': 0.3, 'Light Gradient Boosting Machine__reg_lambda': 4, 'Light Gradient Boosting Machine__subsample': 1.0, 'Light Gradient Boosting Machine__subsample_for_bin': 200000, 'Light Gradient Boosting Machine__subsample_freq': 0, 'Light Gradient Boosting Machine__feature_fraction': 0.6, 'Light Gradient Boosting Machine__bagging_freq': 2, 'Light Gradient Boosting Machine__bagging_fraction': 0.9, 'Ada Boost Classifier__algorithm': 'SAMME.R', 'Ada Boost Classifier__base_estimator': 'deprecated', 'Ada Boost Classifier__estimator__boosting_type': 'gbdt', 'Ada Boost Classifier__estimator__class_weight': None, 'Ada Boost Classifier__estimator__colsample_bytree': 1.0, 'Ada Boost Classifier__estimator__importance_type': 'split', 'Ada Boost Classifier__estimator__learning_rate': 0.005, 'Ada Boost Classifier__estimator__max_depth': -1, 'Ada Boost Classifier__estimator__min_child_samples': 96, 'Ada Boost Classifier__estimator__min_child_weight': 0.001, 'Ada Boost Classifier__estimator__min_split_gain': 0.6, 'Ada Boost Classifier__estimator__n_estimators': 260, 'Ada Boost Classifier__estimator__n_jobs': -1, 'Ada Boost Classifier__estimator__num_leaves': 30, 'Ada Boost Classifier__estimator__objective': None, 'Ada Boost Classifier__estimator__random_state': 142, 'Ada Boost Classifier__estimator__reg_alpha': 0.3, 'Ada Boost Classifier__estimator__reg_lambda': 4, 'Ada Boost Classifier__estimator__subsample': 1.0, 'Ada Boost Classifier__estimator__subsample_for_bin': 200000, 'Ada Boost Classifier__estimator__subsample_freq': 0, 'Ada Boost Classifier__estimator__feature_fraction': 0.6, 'Ada Boost Classifier__estimator__bagging_freq': 2, 'Ada Boost Classifier__estimator__bagging_fraction': 0.9, 'Ada Boost Classifier__learning_rate': 1.0, 'Ada Boost Classifier__n_estimators': 10, 'Ada Boost Classifier__random_state': 142}
2024-02-04 20:37:13,818:INFO:Initializing predict_model()
2024-02-04 20:37:13,819:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599FFE560>)
2024-02-04 20:37:13,819:INFO:Checking exceptions
2024-02-04 20:37:13,819:INFO:Preloading libraries
2024-02-04 20:37:14,550:INFO:_master_model_container: 18
2024-02-04 20:37:14,550:INFO:_display_container: 6
2024-02-04 20:37:14,558:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-04 20:37:14,558:INFO:blend_models() successfully completed......................................
2024-02-04 20:43:21,043:INFO:Initializing plot_model()
2024-02-04 20:43:21,044:INFO:plot_model(plot=parameter, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 20:43:21,044:INFO:Checking exceptions
2024-02-04 20:43:21,054:INFO:Preloading libraries
2024-02-04 20:43:21,081:INFO:Copying training dataset
2024-02-04 20:43:21,081:INFO:Plot type: parameter
2024-02-04 20:43:21,090:INFO:Visual Rendered Successfully
2024-02-04 20:43:21,283:INFO:plot_model() successfully completed......................................
2024-02-04 20:45:03,856:INFO:Initializing predict_model()
2024-02-04 20:45:03,856:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599FFE290>)
2024-02-04 20:45:03,856:INFO:Checking exceptions
2024-02-04 20:45:03,856:INFO:Preloading libraries
2024-02-04 20:45:52,544:INFO:Initializing predict_model()
2024-02-04 20:45:52,544:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=LGBMClassifier(bagging_fraction=0.9,
                                            bagging_freq=2,
                                            boosting_type='gbdt',
                                            class_weight=None,
                                            colsample_bytree=1.0,
                                            feature_fraction=0.6,
                                            importance_type='split',
                                            learning_rate=0.005, max_depth=-1,
                                            min_child_samples=96,
                                            min_child_weight=0.001,
                                            min_split_gain=0.6,
                                            n_estimators=260, n_jobs=-1,
                                            num_leaves=30, objective=None,
                                            random_state=142, reg_alpha=0.3,
                                            reg_lambda=4, subsample=1.0,
                                            subsample_for_bin=200000,
                                            subsample_freq=0),
                   learning_rate=1.0, n_estimators=10, random_state=142), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A59A19F9A0>)
2024-02-04 20:45:52,545:INFO:Checking exceptions
2024-02-04 20:45:52,546:INFO:Preloading libraries
2024-02-04 20:47:49,142:INFO:Initializing predict_model()
2024-02-04 20:47:49,142:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.6,
                                             importance_type='split',
                                             learning_rate=0.005, max_depth=-1,
                                             min_child_samples=96,
                                             min_child_weight=0.001,
                                             min_split_gain=0.6,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves...
                                                                          max_depth=-1,
                                                                          min_child_samples=96,
                                                                          min_child_weight=0.001,
                                                                          min_split_gain=0.6,
                                                                          n_estimators=260,
                                                                          n_jobs=-1,
                                                                          num_leaves=30,
                                                                          objective=None,
                                                                          random_state=142,
                                                                          reg_alpha=0.3,
                                                                          reg_lambda=4,
                                                                          subsample=1.0,
                                                                          subsample_for_bin=200000,
                                                                          subsample_freq=0),
                                                 learning_rate=1.0,
                                                 n_estimators=10,
                                                 random_state=142))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A599FFFE20>)
2024-02-04 20:47:49,143:INFO:Checking exceptions
2024-02-04 20:47:49,143:INFO:Preloading libraries
2024-02-04 20:51:19,081:INFO:Initializing plot_model()
2024-02-04 20:51:19,082:INFO:plot_model(plot=parameter, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 20:51:19,082:INFO:Checking exceptions
2024-02-04 20:51:19,090:INFO:Preloading libraries
2024-02-04 20:51:19,114:INFO:Copying training dataset
2024-02-04 20:51:19,114:INFO:Plot type: parameter
2024-02-04 20:51:19,120:INFO:Visual Rendered Successfully
2024-02-04 20:51:19,289:INFO:plot_model() successfully completed......................................
2024-02-04 20:51:23,079:INFO:Initializing tune_model()
2024-02-04 20:51:23,079:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>)
2024-02-04 20:51:23,080:INFO:Checking exceptions
2024-02-04 20:51:23,088:INFO:Copying training dataset
2024-02-04 20:51:23,095:INFO:Checking base model
2024-02-04 20:51:23,095:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 20:51:23,096:INFO:Declaring metric variables
2024-02-04 20:51:23,096:INFO:Defining Hyperparameters
2024-02-04 20:51:23,264:INFO:Tuning with n_jobs=-1
2024-02-04 20:51:23,264:INFO:Initializing RandomizedSearchCV
2024-02-04 20:51:32,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,571:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:32,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:33,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:36,499:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:36,510:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:36,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:37,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:37,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:37,483:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:37,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:38,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:38,581:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:38,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:39,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:39,610:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:39,778:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:39,907:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:40,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:40,777:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:43,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:43,067:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:43,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:43,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:43,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:44,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:44,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:44,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:45,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:45,408:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:45,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:46,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:46,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:46,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:48,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:48,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:48,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:49,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:49,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:49,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:49,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:50,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:50,429:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:51,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:51,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:52,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:52,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:52,965:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:53,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:53,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:53,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:54,538:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:54,608:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:55,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:55,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:56,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:56,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:57,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:57,041:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:57,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:58,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:58,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:51:58,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:51:59,331:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:00,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:01,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:01,576:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:02,449:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:02,719:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:03,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:04,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:04,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:05,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:06,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:07,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:08,463:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:09,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:09,952:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:10,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:10,361:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:11,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:11,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:11,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:12,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:12,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:13,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:15,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:15,745:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:16,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:16,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:16,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:17,763:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:17,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:18,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:18,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:19,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:19,836:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.9}
2024-02-04 20:52:19,836:INFO:Hyperparameter search completed
2024-02-04 20:52:19,836:INFO:SubProcess create_model() called ==================================
2024-02-04 20:52:19,838:INFO:Initializing create_model()
2024-02-04 20:52:19,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A5E3A904C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 30, 'n_estimators': 260, 'min_split_gain': 0.6, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9})
2024-02-04 20:52:19,838:INFO:Checking exceptions
2024-02-04 20:52:19,838:INFO:Importing libraries
2024-02-04 20:52:19,838:INFO:Copying training dataset
2024-02-04 20:52:19,852:INFO:Defining folds
2024-02-04 20:52:19,852:INFO:Declaring metric variables
2024-02-04 20:52:19,853:INFO:Importing untrained model
2024-02-04 20:52:19,854:INFO:Declaring custom model
2024-02-04 20:52:19,856:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:52:19,856:INFO:Starting cross validation
2024-02-04 20:52:19,882:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:52:21,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:21,460:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:21,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:21,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:21,612:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:25,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:25,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:25,851:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:25,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:25,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:25,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,078:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,101:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:26,159:INFO:Calculating mean and std
2024-02-04 20:52:26,161:INFO:Creating metrics dataframe
2024-02-04 20:52:26,166:INFO:Finalizing model
2024-02-04 20:52:28,633:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:52:28,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002128 seconds.
2024-02-04 20:52:28,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:52:28,637:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:52:28,638:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:52:28,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:52:29,080:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:52:29,081:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:52:29,081:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:52:29,087:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 20:52:29,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 20:52:29,087:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 20:52:29,087:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:52:29,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-02-04 20:52:29,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:52:29,087:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:52:29,088:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:52:29,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:52:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 20:52:29,497:INFO:Uploading results into container
2024-02-04 20:52:29,498:INFO:Uploading model into container now
2024-02-04 20:52:29,499:INFO:_master_model_container: 19
2024-02-04 20:52:29,499:INFO:_display_container: 10
2024-02-04 20:52:29,501:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:52:29,502:INFO:create_model() successfully completed......................................
2024-02-04 20:52:29,733:INFO:SubProcess create_model() end ==================================
2024-02-04 20:52:29,734:INFO:choose_better activated
2024-02-04 20:52:29,734:INFO:SubProcess create_model() called ==================================
2024-02-04 20:52:29,735:INFO:Initializing create_model()
2024-02-04 20:52:29,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 20:52:29,736:INFO:Checking exceptions
2024-02-04 20:52:29,739:INFO:Importing libraries
2024-02-04 20:52:29,739:INFO:Copying training dataset
2024-02-04 20:52:29,754:INFO:Defining folds
2024-02-04 20:52:29,754:INFO:Declaring metric variables
2024-02-04 20:52:29,754:INFO:Importing untrained model
2024-02-04 20:52:29,754:INFO:Declaring custom model
2024-02-04 20:52:29,756:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 20:52:29,757:INFO:Starting cross validation
2024-02-04 20:52:29,779:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 20:52:31,120:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:31,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:31,193:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:31,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 20:52:34,471:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,651:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,679:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,786:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 20:52:34,868:INFO:Calculating mean and std
2024-02-04 20:52:34,869:INFO:Creating metrics dataframe
2024-02-04 20:52:34,874:INFO:Finalizing model
2024-02-04 20:52:37,293:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:52:37,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.
2024-02-04 20:52:37,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:52:37,296:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 20:52:37,297:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 20:52:37,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:52:37,744:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 20:52:37,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-02-04 20:52:37,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 20:52:37,745:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 20:52:37,746:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 20:52:37,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 20:52:37,849:INFO:Uploading results into container
2024-02-04 20:52:37,851:INFO:Uploading model into container now
2024-02-04 20:52:37,851:INFO:_master_model_container: 20
2024-02-04 20:52:37,852:INFO:_display_container: 11
2024-02-04 20:52:37,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:52:37,853:INFO:create_model() successfully completed......................................
2024-02-04 20:52:38,081:INFO:SubProcess create_model() end ==================================
2024-02-04 20:52:38,082:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6807
2024-02-04 20:52:38,084:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6923
2024-02-04 20:52:38,085:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 20:52:38,086:INFO:choose_better completed
2024-02-04 20:52:38,086:INFO:Creating Dashboard logs
2024-02-04 20:52:38,087:INFO:Model: Light Gradient Boosting Machine
2024-02-04 20:52:38,205:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.005, 'max_depth': -1, 'min_child_samples': 96, 'min_child_weight': 0.001, 'min_split_gain': 0.6, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 30, 'objective': None, 'random_state': 142, 'reg_alpha': 0.3, 'reg_lambda': 4, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9}
2024-02-04 20:52:38,573:INFO:Initializing predict_model()
2024-02-04 20:52:38,573:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A59CB05AB0>)
2024-02-04 20:52:38,573:INFO:Checking exceptions
2024-02-04 20:52:38,573:INFO:Preloading libraries
2024-02-04 20:52:39,706:INFO:_master_model_container: 20
2024-02-04 20:52:39,707:INFO:_display_container: 10
2024-02-04 20:52:39,708:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 20:52:39,708:INFO:tune_model() successfully completed......................................
2024-02-04 21:00:16,156:INFO:Initializing plot_model()
2024-02-04 21:00:16,156:INFO:plot_model(plot=parameter, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:00:16,156:INFO:Checking exceptions
2024-02-04 21:00:16,166:INFO:Preloading libraries
2024-02-04 21:00:16,185:INFO:Copying training dataset
2024-02-04 21:00:16,185:INFO:Plot type: parameter
2024-02-04 21:00:16,193:INFO:Visual Rendered Successfully
2024-02-04 21:00:16,367:INFO:plot_model() successfully completed......................................
2024-02-04 21:00:48,616:INFO:Initializing plot_model()
2024-02-04 21:00:48,617:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:00:48,617:INFO:Checking exceptions
2024-02-04 21:00:48,631:INFO:Preloading libraries
2024-02-04 21:00:48,669:INFO:Copying training dataset
2024-02-04 21:00:48,669:INFO:Plot type: auc
2024-02-04 21:00:49,035:INFO:Fitting Model
2024-02-04 21:00:49,037:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:00:49,037:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:00:49,037:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:00:49,038:INFO:Scoring test/hold-out set
2024-02-04 21:00:49,039:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:00:49,039:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:00:49,040:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:00:49,050:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:00:49,050:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:00:49,050:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:00:49,483:INFO:Visual Rendered Successfully
2024-02-04 21:00:49,644:INFO:plot_model() successfully completed......................................
2024-02-04 21:01:35,148:INFO:Initializing plot_model()
2024-02-04 21:01:35,148:INFO:plot_model(plot=pr, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:01:35,149:INFO:Checking exceptions
2024-02-04 21:01:35,157:INFO:Preloading libraries
2024-02-04 21:01:35,180:INFO:Copying training dataset
2024-02-04 21:01:35,180:INFO:Plot type: pr
2024-02-04 21:01:35,577:INFO:Fitting Model
2024-02-04 21:01:35,580:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:01:35,580:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:01:35,580:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:01:35,581:INFO:Scoring test/hold-out set
2024-02-04 21:01:35,583:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:01:35,583:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:01:35,584:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:01:35,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:01:35,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:01:35,597:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:01:35,947:INFO:Visual Rendered Successfully
2024-02-04 21:01:36,138:INFO:plot_model() successfully completed......................................
2024-02-04 21:03:50,526:INFO:Initializing evaluate_model()
2024-02-04 21:03:50,526:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-04 21:03:50,557:INFO:Initializing plot_model()
2024-02-04 21:03:50,559:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:03:50,559:INFO:Checking exceptions
2024-02-04 21:03:50,565:INFO:Preloading libraries
2024-02-04 21:03:50,590:INFO:Copying training dataset
2024-02-04 21:03:50,590:INFO:Plot type: pipeline
2024-02-04 21:03:51,184:INFO:Visual Rendered Successfully
2024-02-04 21:03:51,363:INFO:plot_model() successfully completed......................................
2024-02-04 21:04:00,643:INFO:Initializing plot_model()
2024-02-04 21:04:00,644:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:04:00,644:INFO:Checking exceptions
2024-02-04 21:04:00,648:INFO:Preloading libraries
2024-02-04 21:04:00,671:INFO:Copying training dataset
2024-02-04 21:04:00,671:INFO:Plot type: parameter
2024-02-04 21:04:00,679:INFO:Visual Rendered Successfully
2024-02-04 21:04:00,847:INFO:plot_model() successfully completed......................................
2024-02-04 21:04:06,255:INFO:Initializing plot_model()
2024-02-04 21:04:06,255:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:04:06,255:INFO:Checking exceptions
2024-02-04 21:04:06,260:INFO:Preloading libraries
2024-02-04 21:04:06,284:INFO:Copying training dataset
2024-02-04 21:04:06,285:INFO:Plot type: auc
2024-02-04 21:04:06,634:INFO:Fitting Model
2024-02-04 21:04:06,635:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:06,635:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:06,635:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:06,636:INFO:Scoring test/hold-out set
2024-02-04 21:04:06,637:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:06,637:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:06,638:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:06,650:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:06,650:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:06,651:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:07,057:INFO:Visual Rendered Successfully
2024-02-04 21:04:07,245:INFO:plot_model() successfully completed......................................
2024-02-04 21:04:31,479:INFO:Initializing plot_model()
2024-02-04 21:04:31,479:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:04:31,479:INFO:Checking exceptions
2024-02-04 21:04:31,486:INFO:Preloading libraries
2024-02-04 21:04:31,515:INFO:Copying training dataset
2024-02-04 21:04:31,515:INFO:Plot type: pr
2024-02-04 21:04:31,865:INFO:Fitting Model
2024-02-04 21:04:31,866:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:31,866:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:31,866:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:31,867:INFO:Scoring test/hold-out set
2024-02-04 21:04:31,869:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:31,869:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:31,869:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:31,881:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:31,881:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:31,881:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:32,173:INFO:Visual Rendered Successfully
2024-02-04 21:04:32,314:INFO:plot_model() successfully completed......................................
2024-02-04 21:04:43,705:INFO:Initializing plot_model()
2024-02-04 21:04:43,705:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:04:43,705:INFO:Checking exceptions
2024-02-04 21:04:43,711:INFO:Preloading libraries
2024-02-04 21:04:43,738:INFO:Copying training dataset
2024-02-04 21:04:43,738:INFO:Plot type: ks
2024-02-04 21:04:43,738:INFO:Generating predictions / predict_proba on X_test
2024-02-04 21:04:43,854:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:04:43,854:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:04:43,854:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:04:44,190:INFO:Visual Rendered Successfully
2024-02-04 21:04:44,322:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:30,934:INFO:Initializing evaluate_model()
2024-02-04 21:05:30,934:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=AUC, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-04 21:05:37,040:INFO:Initializing evaluate_model()
2024-02-04 21:05:37,040:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-04 21:05:37,067:INFO:Initializing plot_model()
2024-02-04 21:05:37,067:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:37,067:INFO:Checking exceptions
2024-02-04 21:05:37,073:INFO:Preloading libraries
2024-02-04 21:05:37,093:INFO:Copying training dataset
2024-02-04 21:05:37,093:INFO:Plot type: pipeline
2024-02-04 21:05:37,563:INFO:Visual Rendered Successfully
2024-02-04 21:05:37,739:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:41,965:INFO:Initializing plot_model()
2024-02-04 21:05:41,965:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:41,965:INFO:Checking exceptions
2024-02-04 21:05:41,970:INFO:Preloading libraries
2024-02-04 21:05:41,994:INFO:Copying training dataset
2024-02-04 21:05:41,995:INFO:Plot type: lift
2024-02-04 21:05:41,995:INFO:Generating predictions / predict_proba on X_test
2024-02-04 21:05:42,166:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:42,166:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:42,166:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:42,460:INFO:Visual Rendered Successfully
2024-02-04 21:05:42,672:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:44,851:INFO:Initializing plot_model()
2024-02-04 21:05:44,851:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:44,851:INFO:Checking exceptions
2024-02-04 21:05:44,856:INFO:Preloading libraries
2024-02-04 21:05:44,886:INFO:Copying training dataset
2024-02-04 21:05:44,887:INFO:Plot type: auc
2024-02-04 21:05:45,252:INFO:Fitting Model
2024-02-04 21:05:45,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:45,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:45,253:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:45,254:INFO:Scoring test/hold-out set
2024-02-04 21:05:45,256:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:45,256:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:45,256:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:45,279:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:45,280:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:45,280:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:45,759:INFO:Visual Rendered Successfully
2024-02-04 21:05:45,954:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:52,286:INFO:Initializing plot_model()
2024-02-04 21:05:52,286:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:52,286:INFO:Checking exceptions
2024-02-04 21:05:52,291:INFO:Preloading libraries
2024-02-04 21:05:52,312:INFO:Copying training dataset
2024-02-04 21:05:52,312:INFO:Plot type: feature
2024-02-04 21:05:52,314:WARNING:No coef_ found. Trying feature_importances_
2024-02-04 21:05:52,755:INFO:Visual Rendered Successfully
2024-02-04 21:05:52,985:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:53,270:INFO:Initializing plot_model()
2024-02-04 21:05:53,271:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:53,271:INFO:Checking exceptions
2024-02-04 21:05:53,277:INFO:Preloading libraries
2024-02-04 21:05:53,300:INFO:Copying training dataset
2024-02-04 21:05:53,300:INFO:Plot type: pr
2024-02-04 21:05:53,679:INFO:Fitting Model
2024-02-04 21:05:53,681:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:53,681:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:53,681:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:53,683:INFO:Scoring test/hold-out set
2024-02-04 21:05:53,685:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:53,686:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:53,686:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:53,701:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:53,701:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:53,701:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:54,050:INFO:Visual Rendered Successfully
2024-02-04 21:05:54,196:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:55,828:INFO:Initializing plot_model()
2024-02-04 21:05:55,829:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:55,829:INFO:Checking exceptions
2024-02-04 21:05:55,835:INFO:Preloading libraries
2024-02-04 21:05:55,855:INFO:Copying training dataset
2024-02-04 21:05:55,855:INFO:Plot type: calibration
2024-02-04 21:05:55,884:INFO:Scoring test/hold-out set
2024-02-04 21:05:55,992:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:05:55,993:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:05:55,993:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:05:56,384:INFO:Visual Rendered Successfully
2024-02-04 21:05:56,605:INFO:plot_model() successfully completed......................................
2024-02-04 21:05:58,867:INFO:Initializing plot_model()
2024-02-04 21:05:58,867:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:05:58,868:INFO:Checking exceptions
2024-02-04 21:05:58,874:INFO:Preloading libraries
2024-02-04 21:05:58,899:INFO:Copying training dataset
2024-02-04 21:05:58,899:INFO:Plot type: manifold
2024-02-04 21:05:59,334:INFO:Fitting & Transforming Model
2024-02-04 21:06:33,675:INFO:Visual Rendered Successfully
2024-02-04 21:06:33,814:INFO:plot_model() successfully completed......................................
2024-02-04 21:06:33,895:INFO:Initializing evaluate_model()
2024-02-04 21:06:33,895:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-02-04 21:06:33,915:INFO:Initializing plot_model()
2024-02-04 21:06:33,915:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:06:33,915:INFO:Checking exceptions
2024-02-04 21:06:33,920:INFO:Preloading libraries
2024-02-04 21:06:33,937:INFO:Copying training dataset
2024-02-04 21:06:33,937:INFO:Plot type: pipeline
2024-02-04 21:06:34,458:INFO:Visual Rendered Successfully
2024-02-04 21:06:34,632:INFO:plot_model() successfully completed......................................
2024-02-04 21:06:34,653:INFO:Initializing plot_model()
2024-02-04 21:06:34,653:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:06:34,654:INFO:Checking exceptions
2024-02-04 21:06:34,659:INFO:Preloading libraries
2024-02-04 21:06:34,679:INFO:Copying training dataset
2024-02-04 21:06:34,679:INFO:Plot type: learning
2024-02-04 21:06:35,041:INFO:Fitting Model
2024-02-04 21:06:59,889:INFO:Visual Rendered Successfully
2024-02-04 21:07:00,155:INFO:plot_model() successfully completed......................................
2024-02-04 21:07:00,199:INFO:Initializing plot_model()
2024-02-04 21:07:00,199:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:07:00,201:INFO:Checking exceptions
2024-02-04 21:07:00,209:INFO:Preloading libraries
2024-02-04 21:07:00,240:INFO:Copying training dataset
2024-02-04 21:07:00,241:INFO:Plot type: parameter
2024-02-04 21:07:00,256:INFO:Visual Rendered Successfully
2024-02-04 21:07:00,521:INFO:plot_model() successfully completed......................................
2024-02-04 21:07:02,087:INFO:Initializing plot_model()
2024-02-04 21:07:02,087:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:07:02,088:INFO:Checking exceptions
2024-02-04 21:07:02,097:INFO:Preloading libraries
2024-02-04 21:07:02,134:INFO:Copying training dataset
2024-02-04 21:07:02,135:INFO:Plot type: auc
2024-02-04 21:07:02,773:INFO:Fitting Model
2024-02-04 21:07:02,775:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:07:02,776:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:07:02,776:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:07:02,777:INFO:Scoring test/hold-out set
2024-02-04 21:07:02,781:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:07:02,781:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:07:02,781:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:07:02,810:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:07:02,811:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:07:02,811:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:07:03,520:INFO:Visual Rendered Successfully
2024-02-04 21:07:03,804:INFO:plot_model() successfully completed......................................
2024-02-04 21:08:49,950:INFO:Initializing plot_model()
2024-02-04 21:08:49,950:INFO:plot_model(plot=error, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, system=True)
2024-02-04 21:08:49,956:INFO:Checking exceptions
2024-02-04 21:08:49,966:INFO:Preloading libraries
2024-02-04 21:08:50,009:INFO:Copying training dataset
2024-02-04 21:08:50,009:INFO:Plot type: error
2024-02-04 21:08:50,438:INFO:Fitting Model
2024-02-04 21:08:50,440:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:08:50,440:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:08:50,440:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:08:50,442:INFO:Scoring test/hold-out set
2024-02-04 21:08:50,443:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:08:50,443:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:08:50,443:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:08:50,456:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:08:50,456:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:08:50,456:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:08:50,732:INFO:Visual Rendered Successfully
2024-02-04 21:08:50,888:INFO:plot_model() successfully completed......................................
2024-02-04 21:09:50,168:INFO:Initializing compare_models()
2024-02-04 21:09:50,168:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, include=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A588CFB6D0>, 'include': LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-04 21:09:50,168:INFO:Checking exceptions
2024-02-04 21:11:15,607:ERROR:
'explainerdashboard' is a soft dependency and not included in the pycaret installation. Please run: `pip install explainerdashboard` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-02-04 21:14:41,615:INFO:PyCaret ClassificationExperiment
2024-02-04 21:14:41,616:INFO:Logging name: customer-churn-prediction
2024-02-04 21:14:41,616:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 21:14:41,616:INFO:version 3.2.0
2024-02-04 21:14:41,616:INFO:Initializing setup()
2024-02-04 21:14:41,616:INFO:self.USI: d8da
2024-02-04 21:14:41,616:INFO:self._variable_keys: {'X_train', 'html_param', 'USI', 'log_plots_param', 'y', 'idx', 'X_test', 'gpu_param', 'n_jobs_param', '_available_plots', '_ml_usecase', 'X', 'y_train', 'logging_param', 'is_multiclass', 'fold_shuffle_param', 'fold_generator', 'memory', 'target_param', 'exp_id', 'data', 'pipeline', 'seed', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'exp_name_log', 'fold_groups_param'}
2024-02-04 21:14:41,616:INFO:Checking environment
2024-02-04 21:14:41,616:INFO:python_version: 3.10.9
2024-02-04 21:14:41,616:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 21:14:41,616:INFO:machine: AMD64
2024-02-04 21:14:41,617:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 21:14:41,617:INFO:Memory: svmem(total=16856182784, available=7063949312, percent=58.1, used=9792233472, free=7063949312)
2024-02-04 21:14:41,617:INFO:Physical Core: 4
2024-02-04 21:14:41,617:INFO:Logical Core: 8
2024-02-04 21:14:41,617:INFO:Checking libraries
2024-02-04 21:14:41,617:INFO:System:
2024-02-04 21:14:41,617:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 21:14:41,617:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 21:14:41,617:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 21:14:41,618:INFO:PyCaret required dependencies:
2024-02-04 21:14:41,785:INFO:                 pip: 22.3.1
2024-02-04 21:14:41,785:INFO:          setuptools: 65.6.3
2024-02-04 21:14:41,785:INFO:             pycaret: 3.2.0
2024-02-04 21:14:41,785:INFO:             IPython: 8.20.0
2024-02-04 21:14:41,785:INFO:          ipywidgets: 8.0.4
2024-02-04 21:14:41,785:INFO:                tqdm: 4.64.1
2024-02-04 21:14:41,786:INFO:               numpy: 1.25.2
2024-02-04 21:14:41,786:INFO:              pandas: 1.5.3
2024-02-04 21:14:41,786:INFO:              jinja2: 3.1.3
2024-02-04 21:14:41,786:INFO:               scipy: 1.10.1
2024-02-04 21:14:41,786:INFO:              joblib: 1.3.2
2024-02-04 21:14:41,786:INFO:             sklearn: 1.2.2
2024-02-04 21:14:41,786:INFO:                pyod: 1.1.2
2024-02-04 21:14:41,786:INFO:            imblearn: 0.12.0
2024-02-04 21:14:41,786:INFO:   category_encoders: 2.6.3
2024-02-04 21:14:41,787:INFO:            lightgbm: 4.3.0
2024-02-04 21:14:41,787:INFO:               numba: 0.59.0
2024-02-04 21:14:41,787:INFO:            requests: 2.31.0
2024-02-04 21:14:41,787:INFO:          matplotlib: 3.6.0
2024-02-04 21:14:41,787:INFO:          scikitplot: 0.3.7
2024-02-04 21:14:41,787:INFO:         yellowbrick: 1.5
2024-02-04 21:14:41,787:INFO:              plotly: 5.18.0
2024-02-04 21:14:41,787:INFO:    plotly-resampler: Not installed
2024-02-04 21:14:41,787:INFO:             kaleido: 0.2.1
2024-02-04 21:14:41,787:INFO:           schemdraw: 0.15
2024-02-04 21:14:41,787:INFO:         statsmodels: 0.14.1
2024-02-04 21:14:41,787:INFO:              sktime: 0.21.1
2024-02-04 21:14:41,788:INFO:               tbats: 1.1.3
2024-02-04 21:14:41,788:INFO:            pmdarima: 2.0.4
2024-02-04 21:14:41,788:INFO:              psutil: 5.9.0
2024-02-04 21:14:41,788:INFO:          markupsafe: 2.1.3
2024-02-04 21:14:41,788:INFO:             pickle5: Not installed
2024-02-04 21:14:41,788:INFO:         cloudpickle: 3.0.0
2024-02-04 21:14:41,788:INFO:         deprecation: 2.1.0
2024-02-04 21:14:41,788:INFO:              xxhash: 3.4.1
2024-02-04 21:14:41,788:INFO:           wurlitzer: Not installed
2024-02-04 21:14:41,788:INFO:PyCaret optional dependencies:
2024-02-04 21:14:41,823:INFO:                shap: 0.44.1
2024-02-04 21:14:41,823:INFO:           interpret: Not installed
2024-02-04 21:14:41,823:INFO:                umap: Not installed
2024-02-04 21:14:41,824:INFO:     ydata_profiling: Not installed
2024-02-04 21:14:41,824:INFO:  explainerdashboard: 0.4.5
2024-02-04 21:14:41,824:INFO:             autoviz: Not installed
2024-02-04 21:14:41,824:INFO:           fairlearn: Not installed
2024-02-04 21:14:41,824:INFO:          deepchecks: Not installed
2024-02-04 21:14:41,824:INFO:             xgboost: Not installed
2024-02-04 21:14:41,824:INFO:            catboost: 1.2.2
2024-02-04 21:14:41,824:INFO:              kmodes: Not installed
2024-02-04 21:14:41,824:INFO:             mlxtend: Not installed
2024-02-04 21:14:41,825:INFO:       statsforecast: Not installed
2024-02-04 21:14:41,825:INFO:        tune_sklearn: Not installed
2024-02-04 21:14:41,825:INFO:                 ray: Not installed
2024-02-04 21:14:41,825:INFO:            hyperopt: Not installed
2024-02-04 21:14:41,825:INFO:              optuna: Not installed
2024-02-04 21:14:41,825:INFO:               skopt: Not installed
2024-02-04 21:14:41,825:INFO:              mlflow: 2.10.0
2024-02-04 21:14:41,825:INFO:              gradio: Not installed
2024-02-04 21:14:41,826:INFO:             fastapi: Not installed
2024-02-04 21:14:41,826:INFO:             uvicorn: Not installed
2024-02-04 21:14:41,826:INFO:              m2cgen: Not installed
2024-02-04 21:14:41,826:INFO:           evidently: Not installed
2024-02-04 21:14:41,826:INFO:               fugue: Not installed
2024-02-04 21:14:41,827:INFO:           streamlit: Not installed
2024-02-04 21:14:41,827:INFO:             prophet: Not installed
2024-02-04 21:14:41,827:INFO:None
2024-02-04 21:14:41,827:INFO:Set up data.
2024-02-04 21:14:41,883:INFO:Set up folding strategy.
2024-02-04 21:14:41,883:INFO:Set up train/test split.
2024-02-04 21:14:41,908:INFO:Set up index.
2024-02-04 21:14:41,908:INFO:Assigning column types.
2024-02-04 21:14:41,917:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 21:14:41,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:42,075:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:42,204:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,205:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:42,264:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:42,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 21:14:42,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:42,457:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:42,601:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 21:14:42,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:42,676:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:42,677:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 21:14:42,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:42,855:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:43,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:43,014:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:43,017:INFO:Preparing preprocessing pipeline...
2024-02-04 21:14:43,019:INFO:Set up label encoding.
2024-02-04 21:14:43,020:INFO:Set up simple imputation.
2024-02-04 21:14:43,029:INFO:Set up encoding of ordinal features.
2024-02-04 21:14:43,050:INFO:Set up encoding of categorical features.
2024-02-04 21:14:43,050:INFO:Set up removing multicollinearity.
2024-02-04 21:14:43,050:INFO:Set up binning of numerical features.
2024-02-04 21:14:43,053:INFO:Set up removing outliers.
2024-02-04 21:14:43,053:INFO:Set up imbalanced handling.
2024-02-04 21:14:43,054:INFO:Set up column transformation.
2024-02-04 21:14:43,054:INFO:Set up feature normalization.
2024-02-04 21:14:43,054:INFO:Set up PCA.
2024-02-04 21:14:43,054:INFO:Set up feature selection.
2024-02-04 21:14:43,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:43,250:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:44,799:INFO:Finished creating preprocessing pipeline.
2024-02-04 21:14:44,960:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 21:14:44,960:INFO:Creating final display dataframe.
2024-02-04 21:14:47,134:INFO:Setup _display_container:                     Description                      Value
0                    Session id                        142
1                        Target                      Churn
2                   Target type                     Binary
3                Target mapping              No: 0, Yes: 1
4           Original data shape                 (6339, 21)
5        Transformed data shape                  (7998, 4)
6   Transformed train set shape                  (6096, 4)
7    Transformed test set shape                  (1902, 4)
8               Ignore features                          1
9              Ordinal features                          5
10             Numeric features                          1
11         Categorical features                         15
12                   Preprocess                       True
13              Imputation type                     simple
14           Numeric imputation                       mean
15       Categorical imputation                       mode
16     Maximum one-hot encoding                         25
17              Encoding method                       None
18     Remove multicollinearity                       True
19  Multicollinearity threshold                        0.9
20              Remove outliers                       True
21           Outliers threshold                       0.05
22                Fix imbalance                       True
23         Fix imbalance method                      SMOTE
24               Transformation                       True
25        Transformation method                yeo-johnson
26                    Normalize                       True
27             Normalize method                     zscore
28                          PCA                       True
29                   PCA method                     linear
30               PCA components                       None
31            Feature selection                       True
32     Feature selection method                    classic
33  Feature selection estimator                   lightgbm
34  Number of features selected                        0.2
35               Fold Generator            StratifiedKFold
36                  Fold Number                         10
37                     CPU Jobs                         -1
38                      Use GPU                      False
39               Log Experiment               MlflowLogger
40              Experiment Name  customer-churn-prediction
41                          USI                       d8da
2024-02-04 21:14:47,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:47,274:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:47,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 21:14:47,422:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 21:14:47,423:INFO:Logging experiment in loggers
2024-02-04 21:14:47,604:INFO:SubProcess save_model() called ==================================
2024-02-04 21:14:47,755:INFO:Initializing save_model()
2024-02-04 21:14:47,755:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\user\AppData\Local\Temp\tmpb3oijqw6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-02-04 21:14:47,756:INFO:Adding model into prep_pipe
2024-02-04 21:14:47,756:WARNING:Only Model saved as it was a pipeline.
2024-02-04 21:14:47,785:INFO:C:\Users\user\AppData\Local\Temp\tmpb3oijqw6\Transformation Pipeline.pkl saved in current working directory
2024-02-04 21:14:47,882:INFO:Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=3,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-04 21:14:47,882:INFO:save_model() successfully completed......................................
2024-02-04 21:14:47,965:INFO:SubProcess save_model() end ==================================
2024-02-04 21:14:48,151:INFO:setup() successfully completed in 5.84s...............
2024-02-04 21:14:48,180:INFO:Initializing get_config()
2024-02-04 21:14:48,181:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, variable=None)
2024-02-04 21:14:48,196:INFO:Initializing compare_models()
2024-02-04 21:14:48,196:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, include=None, fold=5, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, 'include': None, 'exclude': ['gbc', 'catboost'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'catboost'])
2024-02-04 21:14:48,196:INFO:Checking exceptions
2024-02-04 21:14:48,207:INFO:Preparing display monitor
2024-02-04 21:14:48,249:INFO:Initializing Logistic Regression
2024-02-04 21:14:48,249:INFO:Total runtime is 0.0 minutes
2024-02-04 21:14:48,255:INFO:SubProcess create_model() called ==================================
2024-02-04 21:14:48,256:INFO:Initializing create_model()
2024-02-04 21:14:48,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:14:48,256:INFO:Checking exceptions
2024-02-04 21:14:48,256:INFO:Importing libraries
2024-02-04 21:14:48,256:INFO:Copying training dataset
2024-02-04 21:14:48,271:INFO:Defining folds
2024-02-04 21:14:48,271:INFO:Declaring metric variables
2024-02-04 21:14:48,279:INFO:Importing untrained model
2024-02-04 21:14:48,287:INFO:Logistic Regression Imported successfully
2024-02-04 21:14:48,305:INFO:Starting cross validation
2024-02-04 21:14:48,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:14:56,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:14:56,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:14:56,661:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:14:56,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:14:56,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:14:59,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,073:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,076:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,207:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,219:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:14:59,358:INFO:Calculating mean and std
2024-02-04 21:14:59,360:INFO:Creating metrics dataframe
2024-02-04 21:14:59,366:INFO:Uploading results into container
2024-02-04 21:14:59,367:INFO:Uploading model into container now
2024-02-04 21:14:59,368:INFO:_master_model_container: 1
2024-02-04 21:14:59,368:INFO:_display_container: 2
2024-02-04 21:14:59,368:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=142, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 21:14:59,368:INFO:create_model() successfully completed......................................
2024-02-04 21:14:59,470:INFO:SubProcess create_model() end ==================================
2024-02-04 21:14:59,470:INFO:Creating metrics dataframe
2024-02-04 21:14:59,490:INFO:Initializing K Neighbors Classifier
2024-02-04 21:14:59,490:INFO:Total runtime is 0.18735392888387045 minutes
2024-02-04 21:14:59,497:INFO:SubProcess create_model() called ==================================
2024-02-04 21:14:59,498:INFO:Initializing create_model()
2024-02-04 21:14:59,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:14:59,499:INFO:Checking exceptions
2024-02-04 21:14:59,499:INFO:Importing libraries
2024-02-04 21:14:59,499:INFO:Copying training dataset
2024-02-04 21:14:59,516:INFO:Defining folds
2024-02-04 21:14:59,516:INFO:Declaring metric variables
2024-02-04 21:14:59,524:INFO:Importing untrained model
2024-02-04 21:14:59,532:INFO:K Neighbors Classifier Imported successfully
2024-02-04 21:14:59,545:INFO:Starting cross validation
2024-02-04 21:14:59,568:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:01,096:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:01,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:04,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:04,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:04,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:04,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:05,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:05,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:09,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:09,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:09,601:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:11,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,337:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:12,372:INFO:Calculating mean and std
2024-02-04 21:15:12,375:INFO:Creating metrics dataframe
2024-02-04 21:15:12,385:INFO:Uploading results into container
2024-02-04 21:15:12,386:INFO:Uploading model into container now
2024-02-04 21:15:12,387:INFO:_master_model_container: 2
2024-02-04 21:15:12,387:INFO:_display_container: 2
2024-02-04 21:15:12,388:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 21:15:12,388:INFO:create_model() successfully completed......................................
2024-02-04 21:15:12,553:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:12,553:INFO:Creating metrics dataframe
2024-02-04 21:15:12,572:INFO:Initializing Naive Bayes
2024-02-04 21:15:12,572:INFO:Total runtime is 0.4053929527600606 minutes
2024-02-04 21:15:12,580:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:12,581:INFO:Initializing create_model()
2024-02-04 21:15:12,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:12,581:INFO:Checking exceptions
2024-02-04 21:15:12,581:INFO:Importing libraries
2024-02-04 21:15:12,581:INFO:Copying training dataset
2024-02-04 21:15:12,591:INFO:Defining folds
2024-02-04 21:15:12,592:INFO:Declaring metric variables
2024-02-04 21:15:12,600:INFO:Importing untrained model
2024-02-04 21:15:12,608:INFO:Naive Bayes Imported successfully
2024-02-04 21:15:12,625:INFO:Starting cross validation
2024-02-04 21:15:12,647:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:13,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:13,944:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:13,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:13,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:13,999:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:16,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,572:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:16,843:INFO:Calculating mean and std
2024-02-04 21:15:16,845:INFO:Creating metrics dataframe
2024-02-04 21:15:16,852:INFO:Uploading results into container
2024-02-04 21:15:16,853:INFO:Uploading model into container now
2024-02-04 21:15:16,853:INFO:_master_model_container: 3
2024-02-04 21:15:16,854:INFO:_display_container: 2
2024-02-04 21:15:16,855:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 21:15:16,855:INFO:create_model() successfully completed......................................
2024-02-04 21:15:17,007:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:17,007:INFO:Creating metrics dataframe
2024-02-04 21:15:17,023:INFO:Initializing Decision Tree Classifier
2024-02-04 21:15:17,023:INFO:Total runtime is 0.4795823574066162 minutes
2024-02-04 21:15:17,030:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:17,031:INFO:Initializing create_model()
2024-02-04 21:15:17,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:17,032:INFO:Checking exceptions
2024-02-04 21:15:17,032:INFO:Importing libraries
2024-02-04 21:15:17,033:INFO:Copying training dataset
2024-02-04 21:15:17,049:INFO:Defining folds
2024-02-04 21:15:17,049:INFO:Declaring metric variables
2024-02-04 21:15:17,054:INFO:Importing untrained model
2024-02-04 21:15:17,062:INFO:Decision Tree Classifier Imported successfully
2024-02-04 21:15:17,116:INFO:Starting cross validation
2024-02-04 21:15:17,144:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:18,298:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:18,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:18,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:18,371:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:18,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:21,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,297:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,476:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,485:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:21,510:INFO:Calculating mean and std
2024-02-04 21:15:21,512:INFO:Creating metrics dataframe
2024-02-04 21:15:21,517:INFO:Uploading results into container
2024-02-04 21:15:21,518:INFO:Uploading model into container now
2024-02-04 21:15:21,518:INFO:_master_model_container: 4
2024-02-04 21:15:21,518:INFO:_display_container: 2
2024-02-04 21:15:21,519:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=142, splitter='best')
2024-02-04 21:15:21,519:INFO:create_model() successfully completed......................................
2024-02-04 21:15:21,645:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:21,645:INFO:Creating metrics dataframe
2024-02-04 21:15:21,681:INFO:Initializing SVM - Linear Kernel
2024-02-04 21:15:21,682:INFO:Total runtime is 0.5572096586227417 minutes
2024-02-04 21:15:21,690:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:21,690:INFO:Initializing create_model()
2024-02-04 21:15:21,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:21,691:INFO:Checking exceptions
2024-02-04 21:15:21,691:INFO:Importing libraries
2024-02-04 21:15:21,691:INFO:Copying training dataset
2024-02-04 21:15:21,702:INFO:Defining folds
2024-02-04 21:15:21,703:INFO:Declaring metric variables
2024-02-04 21:15:21,713:INFO:Importing untrained model
2024-02-04 21:15:21,723:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 21:15:21,742:INFO:Starting cross validation
2024-02-04 21:15:21,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:23,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:23,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:23,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:23,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:23,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:25,688:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:15:25,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:15:25,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,721:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:15:25,724:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,731:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,732:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,742:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:15:25,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:15:25,840:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,855:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,870:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:25,904:INFO:Calculating mean and std
2024-02-04 21:15:25,906:INFO:Creating metrics dataframe
2024-02-04 21:15:25,914:INFO:Uploading results into container
2024-02-04 21:15:25,915:INFO:Uploading model into container now
2024-02-04 21:15:25,916:INFO:_master_model_container: 5
2024-02-04 21:15:25,917:INFO:_display_container: 2
2024-02-04 21:15:25,919:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=142, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 21:15:25,919:INFO:create_model() successfully completed......................................
2024-02-04 21:15:26,069:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:26,070:INFO:Creating metrics dataframe
2024-02-04 21:15:26,087:INFO:Initializing Ridge Classifier
2024-02-04 21:15:26,088:INFO:Total runtime is 0.6306612054506938 minutes
2024-02-04 21:15:26,094:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:26,095:INFO:Initializing create_model()
2024-02-04 21:15:26,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:26,095:INFO:Checking exceptions
2024-02-04 21:15:26,096:INFO:Importing libraries
2024-02-04 21:15:26,096:INFO:Copying training dataset
2024-02-04 21:15:26,107:INFO:Defining folds
2024-02-04 21:15:26,107:INFO:Declaring metric variables
2024-02-04 21:15:26,113:INFO:Importing untrained model
2024-02-04 21:15:26,121:INFO:Ridge Classifier Imported successfully
2024-02-04 21:15:26,135:INFO:Starting cross validation
2024-02-04 21:15:26,157:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:27,173:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:27,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:27,202:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:27,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:27,219:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:29,619:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:15:29,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:15:29,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:15:29,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:15:29,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,728:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,750:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:15:29,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:29,936:INFO:Calculating mean and std
2024-02-04 21:15:29,937:INFO:Creating metrics dataframe
2024-02-04 21:15:29,942:INFO:Uploading results into container
2024-02-04 21:15:29,943:INFO:Uploading model into container now
2024-02-04 21:15:29,943:INFO:_master_model_container: 6
2024-02-04 21:15:29,943:INFO:_display_container: 2
2024-02-04 21:15:29,944:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=142, solver='auto',
                tol=0.0001)
2024-02-04 21:15:29,944:INFO:create_model() successfully completed......................................
2024-02-04 21:15:30,045:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:30,045:INFO:Creating metrics dataframe
2024-02-04 21:15:30,070:INFO:Initializing Random Forest Classifier
2024-02-04 21:15:30,070:INFO:Total runtime is 0.6970236500104269 minutes
2024-02-04 21:15:30,078:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:30,079:INFO:Initializing create_model()
2024-02-04 21:15:30,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:30,080:INFO:Checking exceptions
2024-02-04 21:15:30,081:INFO:Importing libraries
2024-02-04 21:15:30,081:INFO:Copying training dataset
2024-02-04 21:15:30,098:INFO:Defining folds
2024-02-04 21:15:30,098:INFO:Declaring metric variables
2024-02-04 21:15:30,104:INFO:Importing untrained model
2024-02-04 21:15:30,116:INFO:Random Forest Classifier Imported successfully
2024-02-04 21:15:30,131:INFO:Starting cross validation
2024-02-04 21:15:30,153:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:31,161:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:31,170:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:31,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:31,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:31,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:34,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,661:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,679:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,849:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,955:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:34,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:35,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:35,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:35,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:35,348:INFO:Calculating mean and std
2024-02-04 21:15:35,349:INFO:Creating metrics dataframe
2024-02-04 21:15:35,356:INFO:Uploading results into container
2024-02-04 21:15:35,357:INFO:Uploading model into container now
2024-02-04 21:15:35,358:INFO:_master_model_container: 7
2024-02-04 21:15:35,358:INFO:_display_container: 2
2024-02-04 21:15:35,358:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False)
2024-02-04 21:15:35,359:INFO:create_model() successfully completed......................................
2024-02-04 21:15:35,473:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:35,474:INFO:Creating metrics dataframe
2024-02-04 21:15:35,489:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 21:15:35,489:INFO:Total runtime is 0.7873469034830729 minutes
2024-02-04 21:15:35,497:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:35,497:INFO:Initializing create_model()
2024-02-04 21:15:35,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:35,498:INFO:Checking exceptions
2024-02-04 21:15:35,498:INFO:Importing libraries
2024-02-04 21:15:35,498:INFO:Copying training dataset
2024-02-04 21:15:35,508:INFO:Defining folds
2024-02-04 21:15:35,508:INFO:Declaring metric variables
2024-02-04 21:15:35,513:INFO:Importing untrained model
2024-02-04 21:15:35,521:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 21:15:35,532:INFO:Starting cross validation
2024-02-04 21:15:35,546:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:36,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:36,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:36,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:36,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:36,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:38,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,229:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,240:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,256:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:38,335:INFO:Calculating mean and std
2024-02-04 21:15:38,337:INFO:Creating metrics dataframe
2024-02-04 21:15:38,342:INFO:Uploading results into container
2024-02-04 21:15:38,342:INFO:Uploading model into container now
2024-02-04 21:15:38,343:INFO:_master_model_container: 8
2024-02-04 21:15:38,343:INFO:_display_container: 2
2024-02-04 21:15:38,343:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 21:15:38,343:INFO:create_model() successfully completed......................................
2024-02-04 21:15:38,443:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:38,443:INFO:Creating metrics dataframe
2024-02-04 21:15:38,462:INFO:Initializing Ada Boost Classifier
2024-02-04 21:15:38,463:INFO:Total runtime is 0.8369050621986389 minutes
2024-02-04 21:15:38,468:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:38,469:INFO:Initializing create_model()
2024-02-04 21:15:38,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:38,469:INFO:Checking exceptions
2024-02-04 21:15:38,469:INFO:Importing libraries
2024-02-04 21:15:38,469:INFO:Copying training dataset
2024-02-04 21:15:38,480:INFO:Defining folds
2024-02-04 21:15:38,480:INFO:Declaring metric variables
2024-02-04 21:15:38,485:INFO:Importing untrained model
2024-02-04 21:15:38,497:INFO:Ada Boost Classifier Imported successfully
2024-02-04 21:15:38,509:INFO:Starting cross validation
2024-02-04 21:15:38,526:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:39,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:39,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:39,355:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:39,369:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:39,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:41,870:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,919:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,925:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,960:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,994:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:41,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:42,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:42,032:INFO:Calculating mean and std
2024-02-04 21:15:42,035:INFO:Creating metrics dataframe
2024-02-04 21:15:42,042:INFO:Uploading results into container
2024-02-04 21:15:42,044:INFO:Uploading model into container now
2024-02-04 21:15:42,045:INFO:_master_model_container: 9
2024-02-04 21:15:42,045:INFO:_display_container: 2
2024-02-04 21:15:42,046:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142)
2024-02-04 21:15:42,046:INFO:create_model() successfully completed......................................
2024-02-04 21:15:42,159:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:42,159:INFO:Creating metrics dataframe
2024-02-04 21:15:42,176:INFO:Initializing Linear Discriminant Analysis
2024-02-04 21:15:42,176:INFO:Total runtime is 0.8987910827000936 minutes
2024-02-04 21:15:42,184:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:42,184:INFO:Initializing create_model()
2024-02-04 21:15:42,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:42,184:INFO:Checking exceptions
2024-02-04 21:15:42,184:INFO:Importing libraries
2024-02-04 21:15:42,184:INFO:Copying training dataset
2024-02-04 21:15:42,195:INFO:Defining folds
2024-02-04 21:15:42,195:INFO:Declaring metric variables
2024-02-04 21:15:42,200:INFO:Importing untrained model
2024-02-04 21:15:42,208:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 21:15:42,224:INFO:Starting cross validation
2024-02-04 21:15:42,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:43,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:43,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:43,242:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:43,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:43,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:45,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,476:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:45,535:INFO:Calculating mean and std
2024-02-04 21:15:45,536:INFO:Creating metrics dataframe
2024-02-04 21:15:45,542:INFO:Uploading results into container
2024-02-04 21:15:45,543:INFO:Uploading model into container now
2024-02-04 21:15:45,544:INFO:_master_model_container: 10
2024-02-04 21:15:45,544:INFO:_display_container: 2
2024-02-04 21:15:45,544:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 21:15:45,544:INFO:create_model() successfully completed......................................
2024-02-04 21:15:45,664:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:45,664:INFO:Creating metrics dataframe
2024-02-04 21:15:45,682:INFO:Initializing Extra Trees Classifier
2024-02-04 21:15:45,683:INFO:Total runtime is 0.9572335640589396 minutes
2024-02-04 21:15:45,688:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:45,688:INFO:Initializing create_model()
2024-02-04 21:15:45,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:45,689:INFO:Checking exceptions
2024-02-04 21:15:45,689:INFO:Importing libraries
2024-02-04 21:15:45,689:INFO:Copying training dataset
2024-02-04 21:15:45,699:INFO:Defining folds
2024-02-04 21:15:45,699:INFO:Declaring metric variables
2024-02-04 21:15:45,704:INFO:Importing untrained model
2024-02-04 21:15:45,711:INFO:Extra Trees Classifier Imported successfully
2024-02-04 21:15:45,725:INFO:Starting cross validation
2024-02-04 21:15:45,742:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:46,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:46,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:46,686:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:46,703:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:46,720:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:49,930:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,951:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,978:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:49,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,009:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,011:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,083:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,138:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:50,163:INFO:Calculating mean and std
2024-02-04 21:15:50,164:INFO:Creating metrics dataframe
2024-02-04 21:15:50,170:INFO:Uploading results into container
2024-02-04 21:15:50,171:INFO:Uploading model into container now
2024-02-04 21:15:50,171:INFO:_master_model_container: 11
2024-02-04 21:15:50,172:INFO:_display_container: 2
2024-02-04 21:15:50,173:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False)
2024-02-04 21:15:50,173:INFO:create_model() successfully completed......................................
2024-02-04 21:15:50,289:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:50,289:INFO:Creating metrics dataframe
2024-02-04 21:15:50,308:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 21:15:50,308:INFO:Total runtime is 1.034323271115621 minutes
2024-02-04 21:15:50,313:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:50,313:INFO:Initializing create_model()
2024-02-04 21:15:50,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:50,314:INFO:Checking exceptions
2024-02-04 21:15:50,314:INFO:Importing libraries
2024-02-04 21:15:50,314:INFO:Copying training dataset
2024-02-04 21:15:50,327:INFO:Defining folds
2024-02-04 21:15:50,327:INFO:Declaring metric variables
2024-02-04 21:15:50,333:INFO:Importing untrained model
2024-02-04 21:15:50,341:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:15:50,356:INFO:Starting cross validation
2024-02-04 21:15:50,374:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:51,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:51,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:51,376:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:51,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:51,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:55,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,170:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,230:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,246:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:15:55,376:INFO:Calculating mean and std
2024-02-04 21:15:55,379:INFO:Creating metrics dataframe
2024-02-04 21:15:55,393:INFO:Uploading results into container
2024-02-04 21:15:55,396:INFO:Uploading model into container now
2024-02-04 21:15:55,411:INFO:_master_model_container: 12
2024-02-04 21:15:55,411:INFO:_display_container: 2
2024-02-04 21:15:55,413:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:15:55,413:INFO:create_model() successfully completed......................................
2024-02-04 21:15:55,628:INFO:SubProcess create_model() end ==================================
2024-02-04 21:15:55,629:INFO:Creating metrics dataframe
2024-02-04 21:15:55,681:INFO:Initializing Dummy Classifier
2024-02-04 21:15:55,681:INFO:Total runtime is 1.1238697210947672 minutes
2024-02-04 21:15:55,692:INFO:SubProcess create_model() called ==================================
2024-02-04 21:15:55,693:INFO:Initializing create_model()
2024-02-04 21:15:55,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747A70610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:15:55,694:INFO:Checking exceptions
2024-02-04 21:15:55,695:INFO:Importing libraries
2024-02-04 21:15:55,695:INFO:Copying training dataset
2024-02-04 21:15:55,717:INFO:Defining folds
2024-02-04 21:15:55,718:INFO:Declaring metric variables
2024-02-04 21:15:55,730:INFO:Importing untrained model
2024-02-04 21:15:55,743:INFO:Dummy Classifier Imported successfully
2024-02-04 21:15:55,770:INFO:Starting cross validation
2024-02-04 21:15:55,805:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:15:57,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:57,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:57,495:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:57,500:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:15:57,513:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:00,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,928:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:16:00,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:16:00,960:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:00,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:16:01,017:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:16:01,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:16:01,127:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:01,180:INFO:Calculating mean and std
2024-02-04 21:16:01,183:INFO:Creating metrics dataframe
2024-02-04 21:16:01,193:INFO:Uploading results into container
2024-02-04 21:16:01,194:INFO:Uploading model into container now
2024-02-04 21:16:01,196:INFO:_master_model_container: 13
2024-02-04 21:16:01,197:INFO:_display_container: 2
2024-02-04 21:16:01,198:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 21:16:01,198:INFO:create_model() successfully completed......................................
2024-02-04 21:16:01,389:INFO:SubProcess create_model() end ==================================
2024-02-04 21:16:01,389:INFO:Creating metrics dataframe
2024-02-04 21:16:01,487:INFO:Initializing create_model()
2024-02-04 21:16:01,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:16:01,488:INFO:Checking exceptions
2024-02-04 21:16:01,496:INFO:Importing libraries
2024-02-04 21:16:01,497:INFO:Copying training dataset
2024-02-04 21:16:01,523:INFO:Defining folds
2024-02-04 21:16:01,523:INFO:Declaring metric variables
2024-02-04 21:16:01,523:INFO:Importing untrained model
2024-02-04 21:16:01,524:INFO:Declaring custom model
2024-02-04 21:16:01,528:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:16:01,568:INFO:Cross validation set to False
2024-02-04 21:16:01,569:INFO:Fitting Model
2024-02-04 21:16:04,696:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:16:04,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.
2024-02-04 21:16:04,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:16:04,700:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:16:04,701:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:16:04,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:16:05,225:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:16:05,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-02-04 21:16:05,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:16:05,226:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:16:05,226:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:16:05,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:16:05,367:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:16:05,367:INFO:create_model() successfully completed......................................
2024-02-04 21:16:05,504:INFO:Creating Dashboard logs
2024-02-04 21:16:05,521:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:16:05,660:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 142, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-02-04 21:16:06,121:INFO:Initializing predict_model()
2024-02-04 21:16:06,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016748CD0670>)
2024-02-04 21:16:06,121:INFO:Checking exceptions
2024-02-04 21:16:06,121:INFO:Preloading libraries
2024-02-04 21:16:09,477:INFO:Creating Dashboard logs
2024-02-04 21:16:09,489:INFO:Model: Ada Boost Classifier
2024-02-04 21:16:09,620:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 142}
2024-02-04 21:16:10,205:INFO:Creating Dashboard logs
2024-02-04 21:16:10,216:INFO:Model: Random Forest Classifier
2024-02-04 21:16:10,339:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:16:10,968:INFO:Creating Dashboard logs
2024-02-04 21:16:10,977:INFO:Model: Extra Trees Classifier
2024-02-04 21:16:11,105:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:16:11,806:INFO:Creating Dashboard logs
2024-02-04 21:16:11,816:INFO:Model: K Neighbors Classifier
2024-02-04 21:16:11,947:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-02-04 21:16:12,738:INFO:Creating Dashboard logs
2024-02-04 21:16:12,749:INFO:Model: Linear Discriminant Analysis
2024-02-04 21:16:12,863:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:16:13,522:INFO:Creating Dashboard logs
2024-02-04 21:16:13,534:INFO:Model: Ridge Classifier
2024-02-04 21:16:13,657:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 142, 'solver': 'auto', 'tol': 0.0001}
2024-02-04 21:16:14,310:INFO:Creating Dashboard logs
2024-02-04 21:16:14,320:INFO:Model: Logistic Regression
2024-02-04 21:16:14,456:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 142, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-02-04 21:16:15,159:INFO:Creating Dashboard logs
2024-02-04 21:16:15,170:INFO:Model: Quadratic Discriminant Analysis
2024-02-04 21:16:15,296:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:16:15,935:INFO:Creating Dashboard logs
2024-02-04 21:16:15,947:INFO:Model: Naive Bayes
2024-02-04 21:16:16,078:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-02-04 21:16:16,737:INFO:Creating Dashboard logs
2024-02-04 21:16:16,747:INFO:Model: Decision Tree Classifier
2024-02-04 21:16:16,869:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 142, 'splitter': 'best'}
2024-02-04 21:16:17,532:INFO:Creating Dashboard logs
2024-02-04 21:16:17,541:INFO:Model: Dummy Classifier
2024-02-04 21:16:17,666:INFO:Logged params: {'constant': None, 'random_state': 142, 'strategy': 'prior'}
2024-02-04 21:16:18,246:INFO:Creating Dashboard logs
2024-02-04 21:16:18,258:INFO:Model: SVM - Linear Kernel
2024-02-04 21:16:18,394:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 142, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-02-04 21:16:19,018:INFO:_master_model_container: 13
2024-02-04 21:16:19,018:INFO:_display_container: 2
2024-02-04 21:16:19,018:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:16:19,018:INFO:compare_models() successfully completed......................................
2024-02-04 21:16:19,087:INFO:Initializing tune_model()
2024-02-04 21:16:19,088:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=False, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>)
2024-02-04 21:16:19,088:INFO:Checking exceptions
2024-02-04 21:16:19,098:INFO:Copying training dataset
2024-02-04 21:16:19,105:INFO:Checking base model
2024-02-04 21:16:19,106:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 21:16:19,106:INFO:Declaring metric variables
2024-02-04 21:16:19,107:INFO:Defining Hyperparameters
2024-02-04 21:16:19,224:INFO:Tuning with n_jobs=-1
2024-02-04 21:16:19,224:INFO:Initializing RandomizedSearchCV
2024-02-04 21:16:20,469:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,471:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:20,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:23,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:23,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:23,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:23,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:23,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:23,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:24,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:24,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:24,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:25,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:25,085:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:25,114:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:26,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:26,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:27,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:27,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:28,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:28,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:28,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:28,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:29,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:29,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:29,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:29,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:29,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:30,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:30,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:31,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:33,230:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:33,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:33,871:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:33,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:34,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:34,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:34,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:35,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:36,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:37,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:37,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:37,369:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:37,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:38,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:38,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:38,398:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:39,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:40,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:40,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:40,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:40,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:41,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:41,767:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:41,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:42,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:42,429:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:43,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:44,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:44,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:45,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:45,240:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:46,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:46,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:46,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:46,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:47,415:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:47,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:47,895:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:47,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:48,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:49,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:50,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:50,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:50,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:50,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:51,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:51,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:51,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:52,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:52,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:53,297:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:53,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:53,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:54,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:54,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:55,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:55,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:55,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:56,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:56,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:57,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:57,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:57,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:57,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:16:57,617:INFO:best_params: {'actual_estimator__reg_lambda': 4, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.9}
2024-02-04 21:16:57,617:INFO:Hyperparameter search completed
2024-02-04 21:16:57,617:INFO:SubProcess create_model() called ==================================
2024-02-04 21:16:57,619:INFO:Initializing create_model()
2024-02-04 21:16:57,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 4, 'reg_alpha': 0.3, 'num_leaves': 30, 'n_estimators': 260, 'min_split_gain': 0.6, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9})
2024-02-04 21:16:57,619:INFO:Checking exceptions
2024-02-04 21:16:57,619:INFO:Importing libraries
2024-02-04 21:16:57,619:INFO:Copying training dataset
2024-02-04 21:16:57,631:INFO:Defining folds
2024-02-04 21:16:57,631:INFO:Declaring metric variables
2024-02-04 21:16:57,631:INFO:Importing untrained model
2024-02-04 21:16:57,631:INFO:Declaring custom model
2024-02-04 21:16:57,633:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:16:57,633:INFO:Starting cross validation
2024-02-04 21:16:57,647:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:16:58,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:58,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:58,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:58,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:16:58,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:02,903:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:02,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:02,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:02,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:02,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:02,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,138:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,161:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:03,203:INFO:Calculating mean and std
2024-02-04 21:17:03,204:INFO:Creating metrics dataframe
2024-02-04 21:17:03,208:INFO:Finalizing model
2024-02-04 21:17:05,808:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:17:05,809:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001219 seconds.
2024-02-04 21:17:05,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:17:05,810:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:17:05,810:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:17:05,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:17:06,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:17:06,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:17:06,136:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:17:06,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-04 21:17:06,141:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:17:06,141:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-02-04 21:17:06,142:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:17:06,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-02-04 21:17:06,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:17:06,142:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:17:06,142:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:17:06,143:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:17:06,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:17:06,739:INFO:Uploading results into container
2024-02-04 21:17:06,740:INFO:Uploading model into container now
2024-02-04 21:17:06,741:INFO:_master_model_container: 14
2024-02-04 21:17:06,741:INFO:_display_container: 3
2024-02-04 21:17:06,742:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:17:06,742:INFO:create_model() successfully completed......................................
2024-02-04 21:17:06,857:INFO:SubProcess create_model() end ==================================
2024-02-04 21:17:06,857:INFO:choose_better activated
2024-02-04 21:17:06,857:INFO:SubProcess create_model() called ==================================
2024-02-04 21:17:06,858:INFO:Initializing create_model()
2024-02-04 21:17:06,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:17:06,858:INFO:Checking exceptions
2024-02-04 21:17:06,861:INFO:Importing libraries
2024-02-04 21:17:06,861:INFO:Copying training dataset
2024-02-04 21:17:06,872:INFO:Defining folds
2024-02-04 21:17:06,872:INFO:Declaring metric variables
2024-02-04 21:17:06,872:INFO:Importing untrained model
2024-02-04 21:17:06,872:INFO:Declaring custom model
2024-02-04 21:17:06,873:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:17:06,874:INFO:Starting cross validation
2024-02-04 21:17:06,890:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:17:08,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:08,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:08,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:08,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:08,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:17:11,910:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:11,944:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:11,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,356:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,533:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,548:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,563:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,581:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,597:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:17:12,624:INFO:Calculating mean and std
2024-02-04 21:17:12,625:INFO:Creating metrics dataframe
2024-02-04 21:17:12,628:INFO:Finalizing model
2024-02-04 21:17:14,190:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:17:14,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.
2024-02-04 21:17:14,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:17:14,192:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:17:14,192:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:17:14,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:17:14,443:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:17:14,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.
2024-02-04 21:17:14,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:17:14,444:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:17:14,444:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:17:14,444:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:17:14,532:INFO:Uploading results into container
2024-02-04 21:17:14,533:INFO:Uploading model into container now
2024-02-04 21:17:14,534:INFO:_master_model_container: 15
2024-02-04 21:17:14,534:INFO:_display_container: 4
2024-02-04 21:17:14,535:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:17:14,535:INFO:create_model() successfully completed......................................
2024-02-04 21:17:14,637:INFO:SubProcess create_model() end ==================================
2024-02-04 21:17:14,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6807
2024-02-04 21:17:14,639:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6923
2024-02-04 21:17:14,639:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 21:17:14,639:INFO:choose_better completed
2024-02-04 21:17:14,639:INFO:Creating Dashboard logs
2024-02-04 21:17:14,640:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:17:14,709:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.005, 'max_depth': -1, 'min_child_samples': 96, 'min_child_weight': 0.001, 'min_split_gain': 0.6, 'n_estimators': 260, 'n_jobs': -1, 'num_leaves': 30, 'objective': None, 'random_state': 142, 'reg_alpha': 0.3, 'reg_lambda': 4, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.9}
2024-02-04 21:17:14,955:INFO:Initializing predict_model()
2024-02-04 21:17:14,956:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016747534670>)
2024-02-04 21:17:14,956:INFO:Checking exceptions
2024-02-04 21:17:14,956:INFO:Preloading libraries
2024-02-04 21:17:15,649:INFO:_master_model_container: 15
2024-02-04 21:17:15,649:INFO:_display_container: 3
2024-02-04 21:17:15,650:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=30, objective=None,
               random_state=142, reg_alpha=0.3, reg_lambda=4, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:17:15,650:INFO:tune_model() successfully completed......................................
2024-02-04 21:20:47,055:INFO:Initializing compare_models()
2024-02-04 21:20:47,055:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-04 21:20:47,055:INFO:Checking exceptions
2024-02-04 21:20:47,061:INFO:Preparing display monitor
2024-02-04 21:20:47,105:INFO:Initializing Logistic Regression
2024-02-04 21:20:47,105:INFO:Total runtime is 0.0 minutes
2024-02-04 21:20:47,112:INFO:SubProcess create_model() called ==================================
2024-02-04 21:20:47,112:INFO:Initializing create_model()
2024-02-04 21:20:47,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:20:47,113:INFO:Checking exceptions
2024-02-04 21:20:47,113:INFO:Importing libraries
2024-02-04 21:20:47,113:INFO:Copying training dataset
2024-02-04 21:20:47,126:INFO:Defining folds
2024-02-04 21:20:47,126:INFO:Declaring metric variables
2024-02-04 21:20:47,131:INFO:Importing untrained model
2024-02-04 21:20:47,134:INFO:Logistic Regression Imported successfully
2024-02-04 21:20:47,147:INFO:Starting cross validation
2024-02-04 21:20:47,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:20:48,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,460:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,465:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,562:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,572:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:48,603:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:50,989:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:50,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,013:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,070:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,089:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,610:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,649:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:51,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:52,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:52,392:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:53,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,930:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:20:53,946:INFO:Calculating mean and std
2024-02-04 21:20:53,948:INFO:Creating metrics dataframe
2024-02-04 21:20:53,953:INFO:Uploading results into container
2024-02-04 21:20:53,955:INFO:Uploading model into container now
2024-02-04 21:20:53,956:INFO:_master_model_container: 16
2024-02-04 21:20:53,956:INFO:_display_container: 4
2024-02-04 21:20:53,957:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=142, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 21:20:53,957:INFO:create_model() successfully completed......................................
2024-02-04 21:20:54,103:INFO:SubProcess create_model() end ==================================
2024-02-04 21:20:54,103:INFO:Creating metrics dataframe
2024-02-04 21:20:54,119:INFO:Initializing K Neighbors Classifier
2024-02-04 21:20:54,119:INFO:Total runtime is 0.11688606341679891 minutes
2024-02-04 21:20:54,126:INFO:SubProcess create_model() called ==================================
2024-02-04 21:20:54,127:INFO:Initializing create_model()
2024-02-04 21:20:54,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:20:54,127:INFO:Checking exceptions
2024-02-04 21:20:54,127:INFO:Importing libraries
2024-02-04 21:20:54,128:INFO:Copying training dataset
2024-02-04 21:20:54,138:INFO:Defining folds
2024-02-04 21:20:54,138:INFO:Declaring metric variables
2024-02-04 21:20:54,144:INFO:Importing untrained model
2024-02-04 21:20:54,153:INFO:K Neighbors Classifier Imported successfully
2024-02-04 21:20:54,166:INFO:Starting cross validation
2024-02-04 21:20:54,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:20:55,563:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,778:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,907:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:55,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:20:56,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:00,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,180:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,186:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,402:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,484:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:00,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:01,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:01,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:02,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,382:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,406:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,422:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:02,432:INFO:Calculating mean and std
2024-02-04 21:21:02,434:INFO:Creating metrics dataframe
2024-02-04 21:21:02,439:INFO:Uploading results into container
2024-02-04 21:21:02,440:INFO:Uploading model into container now
2024-02-04 21:21:02,441:INFO:_master_model_container: 17
2024-02-04 21:21:02,441:INFO:_display_container: 4
2024-02-04 21:21:02,441:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 21:21:02,441:INFO:create_model() successfully completed......................................
2024-02-04 21:21:02,571:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:02,572:INFO:Creating metrics dataframe
2024-02-04 21:21:02,585:INFO:Initializing Naive Bayes
2024-02-04 21:21:02,585:INFO:Total runtime is 0.257991627852122 minutes
2024-02-04 21:21:02,593:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:02,594:INFO:Initializing create_model()
2024-02-04 21:21:02,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:02,594:INFO:Checking exceptions
2024-02-04 21:21:02,594:INFO:Importing libraries
2024-02-04 21:21:02,594:INFO:Copying training dataset
2024-02-04 21:21:02,602:INFO:Defining folds
2024-02-04 21:21:02,603:INFO:Declaring metric variables
2024-02-04 21:21:02,610:INFO:Importing untrained model
2024-02-04 21:21:02,619:INFO:Naive Bayes Imported successfully
2024-02-04 21:21:02,637:INFO:Starting cross validation
2024-02-04 21:21:02,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:03,872:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:03,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:03,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:03,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:04,041:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:04,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:04,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:04,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:08,714:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,731:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,747:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,772:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,989:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:08,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:09,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:09,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:09,423:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:09,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:09,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:10,246:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:10,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:12,798:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:12,851:INFO:Calculating mean and std
2024-02-04 21:21:12,856:INFO:Creating metrics dataframe
2024-02-04 21:21:12,869:INFO:Uploading results into container
2024-02-04 21:21:12,871:INFO:Uploading model into container now
2024-02-04 21:21:12,873:INFO:_master_model_container: 18
2024-02-04 21:21:12,873:INFO:_display_container: 4
2024-02-04 21:21:12,874:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 21:21:12,874:INFO:create_model() successfully completed......................................
2024-02-04 21:21:13,085:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:13,086:INFO:Creating metrics dataframe
2024-02-04 21:21:13,122:INFO:Initializing Decision Tree Classifier
2024-02-04 21:21:13,122:INFO:Total runtime is 0.4336171348889669 minutes
2024-02-04 21:21:13,135:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:13,136:INFO:Initializing create_model()
2024-02-04 21:21:13,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:13,137:INFO:Checking exceptions
2024-02-04 21:21:13,137:INFO:Importing libraries
2024-02-04 21:21:13,137:INFO:Copying training dataset
2024-02-04 21:21:13,163:INFO:Defining folds
2024-02-04 21:21:13,164:INFO:Declaring metric variables
2024-02-04 21:21:13,178:INFO:Importing untrained model
2024-02-04 21:21:13,193:INFO:Decision Tree Classifier Imported successfully
2024-02-04 21:21:13,222:INFO:Starting cross validation
2024-02-04 21:21:13,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:14,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:14,994:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:14,998:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:15,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:15,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:15,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:15,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:15,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:18,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,969:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,972:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:18,984:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,190:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,234:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,245:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,252:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:19,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:20,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:20,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:23,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,375:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:23,439:INFO:Calculating mean and std
2024-02-04 21:21:23,442:INFO:Creating metrics dataframe
2024-02-04 21:21:23,456:INFO:Uploading results into container
2024-02-04 21:21:23,458:INFO:Uploading model into container now
2024-02-04 21:21:23,459:INFO:_master_model_container: 19
2024-02-04 21:21:23,459:INFO:_display_container: 4
2024-02-04 21:21:23,461:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=142, splitter='best')
2024-02-04 21:21:23,461:INFO:create_model() successfully completed......................................
2024-02-04 21:21:23,662:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:23,662:INFO:Creating metrics dataframe
2024-02-04 21:21:23,698:INFO:Initializing SVM - Linear Kernel
2024-02-04 21:21:23,698:INFO:Total runtime is 0.6098784406979879 minutes
2024-02-04 21:21:23,709:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:23,710:INFO:Initializing create_model()
2024-02-04 21:21:23,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:23,711:INFO:Checking exceptions
2024-02-04 21:21:23,712:INFO:Importing libraries
2024-02-04 21:21:23,712:INFO:Copying training dataset
2024-02-04 21:21:23,732:INFO:Defining folds
2024-02-04 21:21:23,732:INFO:Declaring metric variables
2024-02-04 21:21:23,741:INFO:Importing untrained model
2024-02-04 21:21:23,756:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 21:21:23,780:INFO:Starting cross validation
2024-02-04 21:21:23,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:25,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,787:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,842:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:25,980:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:30,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,064:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,076:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,161:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,703:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,746:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:30,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:30,780:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:31,518:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:31,580:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:34,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:34,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 21:21:34,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,101:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:34,132:INFO:Calculating mean and std
2024-02-04 21:21:34,136:INFO:Creating metrics dataframe
2024-02-04 21:21:34,146:INFO:Uploading results into container
2024-02-04 21:21:34,148:INFO:Uploading model into container now
2024-02-04 21:21:34,149:INFO:_master_model_container: 20
2024-02-04 21:21:34,149:INFO:_display_container: 4
2024-02-04 21:21:34,151:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=142, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 21:21:34,151:INFO:create_model() successfully completed......................................
2024-02-04 21:21:34,318:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:34,318:INFO:Creating metrics dataframe
2024-02-04 21:21:34,349:INFO:Initializing Ridge Classifier
2024-02-04 21:21:34,349:INFO:Total runtime is 0.787396800518036 minutes
2024-02-04 21:21:34,358:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:34,359:INFO:Initializing create_model()
2024-02-04 21:21:34,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:34,360:INFO:Checking exceptions
2024-02-04 21:21:34,360:INFO:Importing libraries
2024-02-04 21:21:34,361:INFO:Copying training dataset
2024-02-04 21:21:34,374:INFO:Defining folds
2024-02-04 21:21:34,374:INFO:Declaring metric variables
2024-02-04 21:21:34,383:INFO:Importing untrained model
2024-02-04 21:21:34,395:INFO:Ridge Classifier Imported successfully
2024-02-04 21:21:34,421:INFO:Starting cross validation
2024-02-04 21:21:34,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:36,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:36,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:40,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,319:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,335:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,396:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,420:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,543:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,550:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,585:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:40,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:40,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:41,604:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,615:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:41,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:41,894:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:44,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:44,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,053:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,064:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,322:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 21:21:44,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:44,367:INFO:Calculating mean and std
2024-02-04 21:21:44,370:INFO:Creating metrics dataframe
2024-02-04 21:21:44,377:INFO:Uploading results into container
2024-02-04 21:21:44,378:INFO:Uploading model into container now
2024-02-04 21:21:44,380:INFO:_master_model_container: 21
2024-02-04 21:21:44,381:INFO:_display_container: 4
2024-02-04 21:21:44,381:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=142, solver='auto',
                tol=0.0001)
2024-02-04 21:21:44,382:INFO:create_model() successfully completed......................................
2024-02-04 21:21:44,547:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:44,548:INFO:Creating metrics dataframe
2024-02-04 21:21:44,571:INFO:Initializing Random Forest Classifier
2024-02-04 21:21:44,572:INFO:Total runtime is 0.9577750841776531 minutes
2024-02-04 21:21:44,579:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:44,580:INFO:Initializing create_model()
2024-02-04 21:21:44,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:44,581:INFO:Checking exceptions
2024-02-04 21:21:44,581:INFO:Importing libraries
2024-02-04 21:21:44,582:INFO:Copying training dataset
2024-02-04 21:21:44,597:INFO:Defining folds
2024-02-04 21:21:44,597:INFO:Declaring metric variables
2024-02-04 21:21:44,606:INFO:Importing untrained model
2024-02-04 21:21:44,617:INFO:Random Forest Classifier Imported successfully
2024-02-04 21:21:44,638:INFO:Starting cross validation
2024-02-04 21:21:44,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:45,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:45,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,468:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:46,495:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:50,371:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,397:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,501:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:50,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,237:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,440:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:51,450:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:52,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:52,405:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:52,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,470:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,475:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,488:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:21:54,498:INFO:Calculating mean and std
2024-02-04 21:21:54,500:INFO:Creating metrics dataframe
2024-02-04 21:21:54,504:INFO:Uploading results into container
2024-02-04 21:21:54,506:INFO:Uploading model into container now
2024-02-04 21:21:54,507:INFO:_master_model_container: 22
2024-02-04 21:21:54,508:INFO:_display_container: 4
2024-02-04 21:21:54,509:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False)
2024-02-04 21:21:54,509:INFO:create_model() successfully completed......................................
2024-02-04 21:21:54,649:INFO:SubProcess create_model() end ==================================
2024-02-04 21:21:54,649:INFO:Creating metrics dataframe
2024-02-04 21:21:54,672:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 21:21:54,672:INFO:Total runtime is 1.1261159658432007 minutes
2024-02-04 21:21:54,678:INFO:SubProcess create_model() called ==================================
2024-02-04 21:21:54,678:INFO:Initializing create_model()
2024-02-04 21:21:54,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:21:54,678:INFO:Checking exceptions
2024-02-04 21:21:54,679:INFO:Importing libraries
2024-02-04 21:21:54,679:INFO:Copying training dataset
2024-02-04 21:21:54,688:INFO:Defining folds
2024-02-04 21:21:54,688:INFO:Declaring metric variables
2024-02-04 21:21:54,694:INFO:Importing untrained model
2024-02-04 21:21:54,704:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 21:21:54,718:INFO:Starting cross validation
2024-02-04 21:21:54,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:21:56,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:21:56,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:00,957:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:00,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:00,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,179:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,212:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,651:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,786:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:01,851:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:02,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:02,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:04,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,734:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,743:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:04,767:INFO:Calculating mean and std
2024-02-04 21:22:04,769:INFO:Creating metrics dataframe
2024-02-04 21:22:04,774:INFO:Uploading results into container
2024-02-04 21:22:04,775:INFO:Uploading model into container now
2024-02-04 21:22:04,775:INFO:_master_model_container: 23
2024-02-04 21:22:04,775:INFO:_display_container: 4
2024-02-04 21:22:04,775:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 21:22:04,776:INFO:create_model() successfully completed......................................
2024-02-04 21:22:04,865:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:04,865:INFO:Creating metrics dataframe
2024-02-04 21:22:04,877:INFO:Initializing Ada Boost Classifier
2024-02-04 21:22:04,877:INFO:Total runtime is 1.2961897770563762 minutes
2024-02-04 21:22:04,883:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:04,883:INFO:Initializing create_model()
2024-02-04 21:22:04,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:04,883:INFO:Checking exceptions
2024-02-04 21:22:04,884:INFO:Importing libraries
2024-02-04 21:22:04,884:INFO:Copying training dataset
2024-02-04 21:22:04,896:INFO:Defining folds
2024-02-04 21:22:04,897:INFO:Declaring metric variables
2024-02-04 21:22:04,904:INFO:Importing untrained model
2024-02-04 21:22:04,914:INFO:Ada Boost Classifier Imported successfully
2024-02-04 21:22:04,932:INFO:Starting cross validation
2024-02-04 21:22:04,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:22:06,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,121:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,364:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:06,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:10,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,581:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,590:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,599:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,867:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:10,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,013:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,494:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,503:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,510:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,513:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:11,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:11,843:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,851:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:11,859:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,792:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,801:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,810:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:13,832:INFO:Calculating mean and std
2024-02-04 21:22:13,834:INFO:Creating metrics dataframe
2024-02-04 21:22:13,840:INFO:Uploading results into container
2024-02-04 21:22:13,842:INFO:Uploading model into container now
2024-02-04 21:22:13,842:INFO:_master_model_container: 24
2024-02-04 21:22:13,843:INFO:_display_container: 4
2024-02-04 21:22:13,843:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142)
2024-02-04 21:22:13,843:INFO:create_model() successfully completed......................................
2024-02-04 21:22:14,013:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:14,014:INFO:Creating metrics dataframe
2024-02-04 21:22:14,033:INFO:Initializing Gradient Boosting Classifier
2024-02-04 21:22:14,033:INFO:Total runtime is 1.448788587252299 minutes
2024-02-04 21:22:14,040:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:14,041:INFO:Initializing create_model()
2024-02-04 21:22:14,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:14,041:INFO:Checking exceptions
2024-02-04 21:22:14,041:INFO:Importing libraries
2024-02-04 21:22:14,042:INFO:Copying training dataset
2024-02-04 21:22:14,057:INFO:Defining folds
2024-02-04 21:22:14,057:INFO:Declaring metric variables
2024-02-04 21:22:14,065:INFO:Importing untrained model
2024-02-04 21:22:14,074:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 21:22:14,120:INFO:Starting cross validation
2024-02-04 21:22:14,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:22:15,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:15,827:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:15,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:16,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:16,377:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:16,682:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:16,734:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:16,815:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:22,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:22,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,283:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,574:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,598:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:23,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:24,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:24,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:24,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:24,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:26,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:26,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:26,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:27,263:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:27,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:27,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:27,306:INFO:Calculating mean and std
2024-02-04 21:22:27,308:INFO:Creating metrics dataframe
2024-02-04 21:22:27,315:INFO:Uploading results into container
2024-02-04 21:22:27,316:INFO:Uploading model into container now
2024-02-04 21:22:27,317:INFO:_master_model_container: 25
2024-02-04 21:22:27,317:INFO:_display_container: 4
2024-02-04 21:22:27,319:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=142, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 21:22:27,319:INFO:create_model() successfully completed......................................
2024-02-04 21:22:27,500:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:27,500:INFO:Creating metrics dataframe
2024-02-04 21:22:27,532:INFO:Initializing Linear Discriminant Analysis
2024-02-04 21:22:27,533:INFO:Total runtime is 1.673787518342336 minutes
2024-02-04 21:22:27,539:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:27,539:INFO:Initializing create_model()
2024-02-04 21:22:27,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:27,541:INFO:Checking exceptions
2024-02-04 21:22:27,541:INFO:Importing libraries
2024-02-04 21:22:27,542:INFO:Copying training dataset
2024-02-04 21:22:27,557:INFO:Defining folds
2024-02-04 21:22:27,559:INFO:Declaring metric variables
2024-02-04 21:22:27,566:INFO:Importing untrained model
2024-02-04 21:22:27,578:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 21:22:27,596:INFO:Starting cross validation
2024-02-04 21:22:27,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:22:28,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:28,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:28,817:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:29,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:29,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:29,275:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:29,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:29,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:32,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,092:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,104:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,256:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,267:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,381:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,391:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,422:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:32,834:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:33,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:33,429:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:35,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:35,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:35,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:35,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:35,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:35,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:36,017:INFO:Calculating mean and std
2024-02-04 21:22:36,020:INFO:Creating metrics dataframe
2024-02-04 21:22:36,032:INFO:Uploading results into container
2024-02-04 21:22:36,035:INFO:Uploading model into container now
2024-02-04 21:22:36,037:INFO:_master_model_container: 26
2024-02-04 21:22:36,037:INFO:_display_container: 4
2024-02-04 21:22:36,039:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 21:22:36,039:INFO:create_model() successfully completed......................................
2024-02-04 21:22:36,229:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:36,230:INFO:Creating metrics dataframe
2024-02-04 21:22:36,259:INFO:Initializing Extra Trees Classifier
2024-02-04 21:22:36,259:INFO:Total runtime is 1.819220228989919 minutes
2024-02-04 21:22:36,268:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:36,269:INFO:Initializing create_model()
2024-02-04 21:22:36,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:36,270:INFO:Checking exceptions
2024-02-04 21:22:36,270:INFO:Importing libraries
2024-02-04 21:22:36,270:INFO:Copying training dataset
2024-02-04 21:22:36,288:INFO:Defining folds
2024-02-04 21:22:36,288:INFO:Declaring metric variables
2024-02-04 21:22:36,299:INFO:Importing untrained model
2024-02-04 21:22:36,312:INFO:Extra Trees Classifier Imported successfully
2024-02-04 21:22:36,335:INFO:Starting cross validation
2024-02-04 21:22:36,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:22:38,024:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,213:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:38,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:43,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:43,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:43,903:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:43,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:43,931:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:43,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,074:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,111:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:44,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:45,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:45,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:48,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,501:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,516:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,527:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:48,579:INFO:Calculating mean and std
2024-02-04 21:22:48,582:INFO:Creating metrics dataframe
2024-02-04 21:22:48,594:INFO:Uploading results into container
2024-02-04 21:22:48,596:INFO:Uploading model into container now
2024-02-04 21:22:48,599:INFO:_master_model_container: 27
2024-02-04 21:22:48,599:INFO:_display_container: 4
2024-02-04 21:22:48,600:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False)
2024-02-04 21:22:48,600:INFO:create_model() successfully completed......................................
2024-02-04 21:22:48,776:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:48,777:INFO:Creating metrics dataframe
2024-02-04 21:22:48,821:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 21:22:48,822:INFO:Total runtime is 2.0286065340042114 minutes
2024-02-04 21:22:48,834:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:48,835:INFO:Initializing create_model()
2024-02-04 21:22:48,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:48,836:INFO:Checking exceptions
2024-02-04 21:22:48,836:INFO:Importing libraries
2024-02-04 21:22:48,836:INFO:Copying training dataset
2024-02-04 21:22:48,859:INFO:Defining folds
2024-02-04 21:22:48,859:INFO:Declaring metric variables
2024-02-04 21:22:48,870:INFO:Importing untrained model
2024-02-04 21:22:48,882:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:22:48,905:INFO:Starting cross validation
2024-02-04 21:22:48,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:22:50,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,561:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,572:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,596:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:50,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:55,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,213:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,229:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,259:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,581:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,602:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:55,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:56,129:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:56,138:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:56,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:56,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:56,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:22:59,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,356:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,367:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:22:59,476:INFO:Calculating mean and std
2024-02-04 21:22:59,478:INFO:Creating metrics dataframe
2024-02-04 21:22:59,486:INFO:Uploading results into container
2024-02-04 21:22:59,488:INFO:Uploading model into container now
2024-02-04 21:22:59,490:INFO:_master_model_container: 28
2024-02-04 21:22:59,490:INFO:_display_container: 4
2024-02-04 21:22:59,492:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:22:59,493:INFO:create_model() successfully completed......................................
2024-02-04 21:22:59,665:INFO:SubProcess create_model() end ==================================
2024-02-04 21:22:59,665:INFO:Creating metrics dataframe
2024-02-04 21:22:59,696:INFO:Initializing CatBoost Classifier
2024-02-04 21:22:59,697:INFO:Total runtime is 2.2098635911941527 minutes
2024-02-04 21:22:59,704:INFO:SubProcess create_model() called ==================================
2024-02-04 21:22:59,704:INFO:Initializing create_model()
2024-02-04 21:22:59,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:22:59,705:INFO:Checking exceptions
2024-02-04 21:22:59,705:INFO:Importing libraries
2024-02-04 21:22:59,705:INFO:Copying training dataset
2024-02-04 21:22:59,720:INFO:Defining folds
2024-02-04 21:22:59,721:INFO:Declaring metric variables
2024-02-04 21:22:59,727:INFO:Importing untrained model
2024-02-04 21:22:59,738:INFO:CatBoost Classifier Imported successfully
2024-02-04 21:22:59,758:INFO:Starting cross validation
2024-02-04 21:22:59,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:23:03,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:03,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:21,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:21,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:21,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:22,852:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:22,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:22,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:22,981:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:23,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,331:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,446:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,710:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:23,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,193:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:24,726:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,735:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:24,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:30,872:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:30,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:30,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:32,525:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:32,530:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:32,536:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:32,567:INFO:Calculating mean and std
2024-02-04 21:23:32,569:INFO:Creating metrics dataframe
2024-02-04 21:23:32,577:INFO:Uploading results into container
2024-02-04 21:23:32,578:INFO:Uploading model into container now
2024-02-04 21:23:32,579:INFO:_master_model_container: 29
2024-02-04 21:23:32,580:INFO:_display_container: 4
2024-02-04 21:23:32,580:INFO:<catboost.core.CatBoostClassifier object at 0x0000016748BD6DD0>
2024-02-04 21:23:32,580:INFO:create_model() successfully completed......................................
2024-02-04 21:23:32,753:INFO:SubProcess create_model() end ==================================
2024-02-04 21:23:32,754:INFO:Creating metrics dataframe
2024-02-04 21:23:32,782:INFO:Initializing Dummy Classifier
2024-02-04 21:23:32,782:INFO:Total runtime is 2.7612754940986632 minutes
2024-02-04 21:23:32,790:INFO:SubProcess create_model() called ==================================
2024-02-04 21:23:32,790:INFO:Initializing create_model()
2024-02-04 21:23:32,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016720EB2AA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:23:32,791:INFO:Checking exceptions
2024-02-04 21:23:32,791:INFO:Importing libraries
2024-02-04 21:23:32,791:INFO:Copying training dataset
2024-02-04 21:23:32,803:INFO:Defining folds
2024-02-04 21:23:32,805:INFO:Declaring metric variables
2024-02-04 21:23:32,812:INFO:Importing untrained model
2024-02-04 21:23:32,822:INFO:Dummy Classifier Imported successfully
2024-02-04 21:23:32,840:INFO:Starting cross validation
2024-02-04 21:23:32,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:23:34,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,577:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,991:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:34,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:38,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,358:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,459:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,473:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,498:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,503:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,534:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,546:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,769:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,800:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:38,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:38,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:39,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:39,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:39,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:39,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:39,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:39,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:23:40,538:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:40,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:23:40,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:23:40,577:INFO:Calculating mean and std
2024-02-04 21:23:40,578:INFO:Creating metrics dataframe
2024-02-04 21:23:40,582:INFO:Uploading results into container
2024-02-04 21:23:40,584:INFO:Uploading model into container now
2024-02-04 21:23:40,585:INFO:_master_model_container: 30
2024-02-04 21:23:40,585:INFO:_display_container: 4
2024-02-04 21:23:40,586:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 21:23:40,586:INFO:create_model() successfully completed......................................
2024-02-04 21:23:40,707:INFO:SubProcess create_model() end ==================================
2024-02-04 21:23:40,708:INFO:Creating metrics dataframe
2024-02-04 21:23:40,737:INFO:Initializing create_model()
2024-02-04 21:23:40,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=DummyClassifier(constant=None, random_state=142, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:23:40,738:INFO:Checking exceptions
2024-02-04 21:23:40,741:INFO:Importing libraries
2024-02-04 21:23:40,741:INFO:Copying training dataset
2024-02-04 21:23:40,750:INFO:Defining folds
2024-02-04 21:23:40,750:INFO:Declaring metric variables
2024-02-04 21:23:40,750:INFO:Importing untrained model
2024-02-04 21:23:40,750:INFO:Declaring custom model
2024-02-04 21:23:40,752:INFO:Dummy Classifier Imported successfully
2024-02-04 21:23:40,764:INFO:Cross validation set to False
2024-02-04 21:23:40,765:INFO:Fitting Model
2024-02-04 21:23:42,205:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:23:42,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.
2024-02-04 21:23:42,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:23:42,206:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:23:42,206:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:23:42,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:23:42,394:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 21:23:42,395:INFO:create_model() successfully completed......................................
2024-02-04 21:23:42,483:INFO:Creating Dashboard logs
2024-02-04 21:23:42,489:INFO:Model: Dummy Classifier
2024-02-04 21:23:42,581:INFO:Logged params: {'constant': None, 'random_state': 142, 'strategy': 'prior'}
2024-02-04 21:23:42,798:INFO:Initializing predict_model()
2024-02-04 21:23:42,798:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=DummyClassifier(constant=None, random_state=142, strategy='prior'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167473DE680>)
2024-02-04 21:23:42,798:INFO:Checking exceptions
2024-02-04 21:23:42,798:INFO:Preloading libraries
2024-02-04 21:23:43,473:INFO:Creating Dashboard logs
2024-02-04 21:23:43,480:INFO:Model: Quadratic Discriminant Analysis
2024-02-04 21:23:43,569:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:23:43,966:INFO:Creating Dashboard logs
2024-02-04 21:23:43,972:INFO:Model: Naive Bayes
2024-02-04 21:23:44,046:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-02-04 21:23:44,419:INFO:Creating Dashboard logs
2024-02-04 21:23:44,424:INFO:Model: Gradient Boosting Classifier
2024-02-04 21:23:44,497:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 142, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-02-04 21:23:44,946:INFO:Creating Dashboard logs
2024-02-04 21:23:44,952:INFO:Model: CatBoost Classifier
2024-02-04 21:23:45,030:WARNING:Couldn't get params for model. Exception:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\loggers\dashboard_logger.py", line 78, in log_model
    params = params.get_all_params()
  File "C:\ProgramData\miniconda3\lib\site-packages\catboost\core.py", line 3377, in get_all_params
    raise CatBoostError("There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.")
_catboost.CatBoostError: There is no trained model to use get_all_params(). Use fit() to train model. Then use this method.

2024-02-04 21:23:45,030:INFO:Logged params: {}
2024-02-04 21:23:45,440:INFO:Creating Dashboard logs
2024-02-04 21:23:45,445:INFO:Model: Ada Boost Classifier
2024-02-04 21:23:45,525:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 142}
2024-02-04 21:23:45,955:INFO:Creating Dashboard logs
2024-02-04 21:23:45,960:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:23:46,044:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 142, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-02-04 21:23:46,564:INFO:Creating Dashboard logs
2024-02-04 21:23:46,572:INFO:Model: SVM - Linear Kernel
2024-02-04 21:23:46,661:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 142, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-02-04 21:23:47,127:INFO:Creating Dashboard logs
2024-02-04 21:23:47,133:INFO:Model: Random Forest Classifier
2024-02-04 21:23:47,219:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:23:47,737:INFO:Creating Dashboard logs
2024-02-04 21:23:47,743:INFO:Model: Extra Trees Classifier
2024-02-04 21:23:47,822:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:23:48,282:INFO:Creating Dashboard logs
2024-02-04 21:23:48,287:INFO:Model: K Neighbors Classifier
2024-02-04 21:23:48,357:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-02-04 21:23:48,787:INFO:Creating Dashboard logs
2024-02-04 21:23:48,792:INFO:Model: Decision Tree Classifier
2024-02-04 21:23:48,874:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 142, 'splitter': 'best'}
2024-02-04 21:23:49,332:INFO:Creating Dashboard logs
2024-02-04 21:23:49,338:INFO:Model: Linear Discriminant Analysis
2024-02-04 21:23:49,408:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:23:49,836:INFO:Creating Dashboard logs
2024-02-04 21:23:49,842:INFO:Model: Ridge Classifier
2024-02-04 21:23:49,923:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 142, 'solver': 'auto', 'tol': 0.0001}
2024-02-04 21:23:50,372:INFO:Creating Dashboard logs
2024-02-04 21:23:50,377:INFO:Model: Logistic Regression
2024-02-04 21:23:50,447:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 142, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-02-04 21:23:50,910:INFO:_master_model_container: 30
2024-02-04 21:23:50,910:INFO:_display_container: 4
2024-02-04 21:23:50,911:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 21:23:50,911:INFO:compare_models() successfully completed......................................
2024-02-04 21:24:50,353:INFO:Initializing compare_models()
2024-02-04 21:24:50,353:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, include=None, fold=5, round=4, cross_validation=True, sort=F1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, 'include': None, 'exclude': ['gbc', 'catboost'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'catboost'])
2024-02-04 21:24:50,353:INFO:Checking exceptions
2024-02-04 21:24:50,359:INFO:Preparing display monitor
2024-02-04 21:24:50,405:INFO:Initializing Logistic Regression
2024-02-04 21:24:50,405:INFO:Total runtime is 0.0 minutes
2024-02-04 21:24:50,414:INFO:SubProcess create_model() called ==================================
2024-02-04 21:24:50,414:INFO:Initializing create_model()
2024-02-04 21:24:50,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:24:50,415:INFO:Checking exceptions
2024-02-04 21:24:50,415:INFO:Importing libraries
2024-02-04 21:24:50,415:INFO:Copying training dataset
2024-02-04 21:24:50,428:INFO:Defining folds
2024-02-04 21:24:50,428:INFO:Declaring metric variables
2024-02-04 21:24:50,436:INFO:Importing untrained model
2024-02-04 21:24:50,446:INFO:Logistic Regression Imported successfully
2024-02-04 21:24:50,459:INFO:Starting cross validation
2024-02-04 21:24:50,476:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:24:51,631:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:51,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:51,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:51,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:51,728:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:55,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,059:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,067:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,074:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,078:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,082:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,103:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,191:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,224:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:24:55,257:INFO:Calculating mean and std
2024-02-04 21:24:55,260:INFO:Creating metrics dataframe
2024-02-04 21:24:55,269:INFO:Uploading results into container
2024-02-04 21:24:55,271:INFO:Uploading model into container now
2024-02-04 21:24:55,272:INFO:_master_model_container: 31
2024-02-04 21:24:55,273:INFO:_display_container: 5
2024-02-04 21:24:55,275:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=142, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 21:24:55,275:INFO:create_model() successfully completed......................................
2024-02-04 21:24:55,465:INFO:SubProcess create_model() end ==================================
2024-02-04 21:24:55,465:INFO:Creating metrics dataframe
2024-02-04 21:24:55,485:INFO:Initializing K Neighbors Classifier
2024-02-04 21:24:55,486:INFO:Total runtime is 0.0846844752629598 minutes
2024-02-04 21:24:55,498:INFO:SubProcess create_model() called ==================================
2024-02-04 21:24:55,499:INFO:Initializing create_model()
2024-02-04 21:24:55,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:24:55,500:INFO:Checking exceptions
2024-02-04 21:24:55,500:INFO:Importing libraries
2024-02-04 21:24:55,501:INFO:Copying training dataset
2024-02-04 21:24:55,522:INFO:Defining folds
2024-02-04 21:24:55,523:INFO:Declaring metric variables
2024-02-04 21:24:55,532:INFO:Importing untrained model
2024-02-04 21:24:55,541:INFO:K Neighbors Classifier Imported successfully
2024-02-04 21:24:55,560:INFO:Starting cross validation
2024-02-04 21:24:55,589:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:24:57,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:57,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:57,151:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:57,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:24:57,173:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:00,364:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,398:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,411:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,421:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,425:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,449:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,468:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,469:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,509:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:00,532:INFO:Calculating mean and std
2024-02-04 21:25:00,535:INFO:Creating metrics dataframe
2024-02-04 21:25:00,544:INFO:Uploading results into container
2024-02-04 21:25:00,546:INFO:Uploading model into container now
2024-02-04 21:25:00,547:INFO:_master_model_container: 32
2024-02-04 21:25:00,547:INFO:_display_container: 5
2024-02-04 21:25:00,549:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 21:25:00,549:INFO:create_model() successfully completed......................................
2024-02-04 21:25:00,718:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:00,718:INFO:Creating metrics dataframe
2024-02-04 21:25:00,739:INFO:Initializing Naive Bayes
2024-02-04 21:25:00,739:INFO:Total runtime is 0.17222596406936647 minutes
2024-02-04 21:25:00,748:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:00,749:INFO:Initializing create_model()
2024-02-04 21:25:00,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:00,749:INFO:Checking exceptions
2024-02-04 21:25:00,749:INFO:Importing libraries
2024-02-04 21:25:00,749:INFO:Copying training dataset
2024-02-04 21:25:00,765:INFO:Defining folds
2024-02-04 21:25:00,765:INFO:Declaring metric variables
2024-02-04 21:25:00,774:INFO:Importing untrained model
2024-02-04 21:25:00,784:INFO:Naive Bayes Imported successfully
2024-02-04 21:25:00,804:INFO:Starting cross validation
2024-02-04 21:25:00,833:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:02,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:02,237:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:02,241:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:02,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:02,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:05,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,186:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,227:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,232:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:05,360:INFO:Calculating mean and std
2024-02-04 21:25:05,363:INFO:Creating metrics dataframe
2024-02-04 21:25:05,371:INFO:Uploading results into container
2024-02-04 21:25:05,373:INFO:Uploading model into container now
2024-02-04 21:25:05,374:INFO:_master_model_container: 33
2024-02-04 21:25:05,374:INFO:_display_container: 5
2024-02-04 21:25:05,374:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 21:25:05,375:INFO:create_model() successfully completed......................................
2024-02-04 21:25:05,544:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:05,544:INFO:Creating metrics dataframe
2024-02-04 21:25:05,569:INFO:Initializing Decision Tree Classifier
2024-02-04 21:25:05,570:INFO:Total runtime is 0.2527418494224548 minutes
2024-02-04 21:25:05,580:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:05,581:INFO:Initializing create_model()
2024-02-04 21:25:05,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:05,582:INFO:Checking exceptions
2024-02-04 21:25:05,582:INFO:Importing libraries
2024-02-04 21:25:05,582:INFO:Copying training dataset
2024-02-04 21:25:05,600:INFO:Defining folds
2024-02-04 21:25:05,601:INFO:Declaring metric variables
2024-02-04 21:25:05,613:INFO:Importing untrained model
2024-02-04 21:25:05,625:INFO:Decision Tree Classifier Imported successfully
2024-02-04 21:25:05,648:INFO:Starting cross validation
2024-02-04 21:25:05,675:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:06,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:06,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:07,006:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:07,026:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:07,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:10,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,092:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,114:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:10,241:INFO:Calculating mean and std
2024-02-04 21:25:10,243:INFO:Creating metrics dataframe
2024-02-04 21:25:10,253:INFO:Uploading results into container
2024-02-04 21:25:10,255:INFO:Uploading model into container now
2024-02-04 21:25:10,256:INFO:_master_model_container: 34
2024-02-04 21:25:10,256:INFO:_display_container: 5
2024-02-04 21:25:10,258:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=142, splitter='best')
2024-02-04 21:25:10,258:INFO:create_model() successfully completed......................................
2024-02-04 21:25:10,444:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:10,444:INFO:Creating metrics dataframe
2024-02-04 21:25:10,474:INFO:Initializing SVM - Linear Kernel
2024-02-04 21:25:10,475:INFO:Total runtime is 0.33449367682139075 minutes
2024-02-04 21:25:10,485:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:10,487:INFO:Initializing create_model()
2024-02-04 21:25:10,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:10,487:INFO:Checking exceptions
2024-02-04 21:25:10,488:INFO:Importing libraries
2024-02-04 21:25:10,488:INFO:Copying training dataset
2024-02-04 21:25:10,509:INFO:Defining folds
2024-02-04 21:25:10,509:INFO:Declaring metric variables
2024-02-04 21:25:10,520:INFO:Importing untrained model
2024-02-04 21:25:10,530:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 21:25:10,556:INFO:Starting cross validation
2024-02-04 21:25:10,588:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:12,002:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:12,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:12,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:12,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:12,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:14,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:14,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:14,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:14,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:15,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:15,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:15,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:15,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,087:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,113:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:15,140:INFO:Calculating mean and std
2024-02-04 21:25:15,143:INFO:Creating metrics dataframe
2024-02-04 21:25:15,152:INFO:Uploading results into container
2024-02-04 21:25:15,155:INFO:Uploading model into container now
2024-02-04 21:25:15,156:INFO:_master_model_container: 35
2024-02-04 21:25:15,157:INFO:_display_container: 5
2024-02-04 21:25:15,160:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=142, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 21:25:15,160:INFO:create_model() successfully completed......................................
2024-02-04 21:25:15,337:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:15,338:INFO:Creating metrics dataframe
2024-02-04 21:25:15,365:INFO:Initializing Ridge Classifier
2024-02-04 21:25:15,366:INFO:Total runtime is 0.41600914398829136 minutes
2024-02-04 21:25:15,374:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:15,376:INFO:Initializing create_model()
2024-02-04 21:25:15,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:15,377:INFO:Checking exceptions
2024-02-04 21:25:15,378:INFO:Importing libraries
2024-02-04 21:25:15,378:INFO:Copying training dataset
2024-02-04 21:25:15,397:INFO:Defining folds
2024-02-04 21:25:15,397:INFO:Declaring metric variables
2024-02-04 21:25:15,407:INFO:Importing untrained model
2024-02-04 21:25:15,419:INFO:Ridge Classifier Imported successfully
2024-02-04 21:25:15,446:INFO:Starting cross validation
2024-02-04 21:25:15,478:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:16,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:16,948:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:16,971:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:16,979:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:16,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:19,985:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:19,996:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:20,083:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,159:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:20,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:20,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 21:25:20,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,199:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:20,267:INFO:Calculating mean and std
2024-02-04 21:25:20,270:INFO:Creating metrics dataframe
2024-02-04 21:25:20,282:INFO:Uploading results into container
2024-02-04 21:25:20,283:INFO:Uploading model into container now
2024-02-04 21:25:20,285:INFO:_master_model_container: 36
2024-02-04 21:25:20,285:INFO:_display_container: 5
2024-02-04 21:25:20,286:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=142, solver='auto',
                tol=0.0001)
2024-02-04 21:25:20,286:INFO:create_model() successfully completed......................................
2024-02-04 21:25:20,492:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:20,492:INFO:Creating metrics dataframe
2024-02-04 21:25:20,531:INFO:Initializing Random Forest Classifier
2024-02-04 21:25:20,532:INFO:Total runtime is 0.5021020809809367 minutes
2024-02-04 21:25:20,541:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:20,542:INFO:Initializing create_model()
2024-02-04 21:25:20,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:20,542:INFO:Checking exceptions
2024-02-04 21:25:20,542:INFO:Importing libraries
2024-02-04 21:25:20,542:INFO:Copying training dataset
2024-02-04 21:25:20,557:INFO:Defining folds
2024-02-04 21:25:20,558:INFO:Declaring metric variables
2024-02-04 21:25:20,566:INFO:Importing untrained model
2024-02-04 21:25:20,580:INFO:Random Forest Classifier Imported successfully
2024-02-04 21:25:20,602:INFO:Starting cross validation
2024-02-04 21:25:20,630:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:22,065:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:22,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:22,083:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:22,093:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:22,094:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:26,763:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,845:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:26,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,230:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,252:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,458:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:27,519:INFO:Calculating mean and std
2024-02-04 21:25:27,522:INFO:Creating metrics dataframe
2024-02-04 21:25:27,531:INFO:Uploading results into container
2024-02-04 21:25:27,532:INFO:Uploading model into container now
2024-02-04 21:25:27,533:INFO:_master_model_container: 37
2024-02-04 21:25:27,535:INFO:_display_container: 5
2024-02-04 21:25:27,537:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False)
2024-02-04 21:25:27,537:INFO:create_model() successfully completed......................................
2024-02-04 21:25:27,712:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:27,712:INFO:Creating metrics dataframe
2024-02-04 21:25:27,744:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 21:25:27,744:INFO:Total runtime is 0.6223101854324341 minutes
2024-02-04 21:25:27,752:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:27,753:INFO:Initializing create_model()
2024-02-04 21:25:27,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:27,754:INFO:Checking exceptions
2024-02-04 21:25:27,754:INFO:Importing libraries
2024-02-04 21:25:27,755:INFO:Copying training dataset
2024-02-04 21:25:27,771:INFO:Defining folds
2024-02-04 21:25:27,772:INFO:Declaring metric variables
2024-02-04 21:25:27,784:INFO:Importing untrained model
2024-02-04 21:25:27,801:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 21:25:27,824:INFO:Starting cross validation
2024-02-04 21:25:27,859:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:29,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:29,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:29,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:29,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:29,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:32,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,335:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,349:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,363:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,364:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,386:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,408:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,499:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,516:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,537:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:32,571:INFO:Calculating mean and std
2024-02-04 21:25:32,574:INFO:Creating metrics dataframe
2024-02-04 21:25:32,584:INFO:Uploading results into container
2024-02-04 21:25:32,586:INFO:Uploading model into container now
2024-02-04 21:25:32,588:INFO:_master_model_container: 38
2024-02-04 21:25:32,588:INFO:_display_container: 5
2024-02-04 21:25:32,590:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 21:25:32,591:INFO:create_model() successfully completed......................................
2024-02-04 21:25:32,782:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:32,782:INFO:Creating metrics dataframe
2024-02-04 21:25:32,813:INFO:Initializing Ada Boost Classifier
2024-02-04 21:25:32,813:INFO:Total runtime is 0.7067989786465962 minutes
2024-02-04 21:25:32,824:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:32,825:INFO:Initializing create_model()
2024-02-04 21:25:32,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:32,826:INFO:Checking exceptions
2024-02-04 21:25:32,826:INFO:Importing libraries
2024-02-04 21:25:32,826:INFO:Copying training dataset
2024-02-04 21:25:32,842:INFO:Defining folds
2024-02-04 21:25:32,843:INFO:Declaring metric variables
2024-02-04 21:25:32,853:INFO:Importing untrained model
2024-02-04 21:25:32,863:INFO:Ada Boost Classifier Imported successfully
2024-02-04 21:25:32,894:INFO:Starting cross validation
2024-02-04 21:25:32,929:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:34,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:34,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:34,316:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:34,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:34,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:37,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:37,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,070:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,076:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,103:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:38,166:INFO:Calculating mean and std
2024-02-04 21:25:38,169:INFO:Creating metrics dataframe
2024-02-04 21:25:38,179:INFO:Uploading results into container
2024-02-04 21:25:38,180:INFO:Uploading model into container now
2024-02-04 21:25:38,181:INFO:_master_model_container: 39
2024-02-04 21:25:38,182:INFO:_display_container: 5
2024-02-04 21:25:38,183:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142)
2024-02-04 21:25:38,183:INFO:create_model() successfully completed......................................
2024-02-04 21:25:38,409:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:38,409:INFO:Creating metrics dataframe
2024-02-04 21:25:38,452:INFO:Initializing Linear Discriminant Analysis
2024-02-04 21:25:38,452:INFO:Total runtime is 0.800786813100179 minutes
2024-02-04 21:25:38,463:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:38,464:INFO:Initializing create_model()
2024-02-04 21:25:38,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:38,466:INFO:Checking exceptions
2024-02-04 21:25:38,466:INFO:Importing libraries
2024-02-04 21:25:38,466:INFO:Copying training dataset
2024-02-04 21:25:38,489:INFO:Defining folds
2024-02-04 21:25:38,490:INFO:Declaring metric variables
2024-02-04 21:25:38,500:INFO:Importing untrained model
2024-02-04 21:25:38,514:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 21:25:38,539:INFO:Starting cross validation
2024-02-04 21:25:38,575:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:39,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:40,005:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:40,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:40,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:40,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:43,029:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,052:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,249:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:43,331:INFO:Calculating mean and std
2024-02-04 21:25:43,333:INFO:Creating metrics dataframe
2024-02-04 21:25:43,344:INFO:Uploading results into container
2024-02-04 21:25:43,347:INFO:Uploading model into container now
2024-02-04 21:25:43,348:INFO:_master_model_container: 40
2024-02-04 21:25:43,349:INFO:_display_container: 5
2024-02-04 21:25:43,351:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 21:25:43,351:INFO:create_model() successfully completed......................................
2024-02-04 21:25:43,527:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:43,528:INFO:Creating metrics dataframe
2024-02-04 21:25:43,574:INFO:Initializing Extra Trees Classifier
2024-02-04 21:25:43,574:INFO:Total runtime is 0.886149775981903 minutes
2024-02-04 21:25:43,584:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:43,585:INFO:Initializing create_model()
2024-02-04 21:25:43,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:43,586:INFO:Checking exceptions
2024-02-04 21:25:43,587:INFO:Importing libraries
2024-02-04 21:25:43,587:INFO:Copying training dataset
2024-02-04 21:25:43,610:INFO:Defining folds
2024-02-04 21:25:43,611:INFO:Declaring metric variables
2024-02-04 21:25:43,626:INFO:Importing untrained model
2024-02-04 21:25:43,645:INFO:Extra Trees Classifier Imported successfully
2024-02-04 21:25:43,672:INFO:Starting cross validation
2024-02-04 21:25:43,704:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:45,168:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:45,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:45,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:45,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:45,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:49,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,481:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,504:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,513:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,607:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,653:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,758:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:49,792:INFO:Calculating mean and std
2024-02-04 21:25:49,795:INFO:Creating metrics dataframe
2024-02-04 21:25:49,805:INFO:Uploading results into container
2024-02-04 21:25:49,807:INFO:Uploading model into container now
2024-02-04 21:25:49,808:INFO:_master_model_container: 41
2024-02-04 21:25:49,808:INFO:_display_container: 5
2024-02-04 21:25:49,810:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False)
2024-02-04 21:25:49,811:INFO:create_model() successfully completed......................................
2024-02-04 21:25:49,996:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:49,997:INFO:Creating metrics dataframe
2024-02-04 21:25:50,041:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 21:25:50,041:INFO:Total runtime is 0.9939371864000955 minutes
2024-02-04 21:25:50,054:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:50,055:INFO:Initializing create_model()
2024-02-04 21:25:50,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:50,056:INFO:Checking exceptions
2024-02-04 21:25:50,056:INFO:Importing libraries
2024-02-04 21:25:50,056:INFO:Copying training dataset
2024-02-04 21:25:50,078:INFO:Defining folds
2024-02-04 21:25:50,079:INFO:Declaring metric variables
2024-02-04 21:25:50,092:INFO:Importing untrained model
2024-02-04 21:25:50,110:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:25:50,143:INFO:Starting cross validation
2024-02-04 21:25:50,172:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:51,531:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:51,594:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:51,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:51,598:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:51,603:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:55,076:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,116:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,155:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,182:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:25:55,295:INFO:Calculating mean and std
2024-02-04 21:25:55,297:INFO:Creating metrics dataframe
2024-02-04 21:25:55,305:INFO:Uploading results into container
2024-02-04 21:25:55,308:INFO:Uploading model into container now
2024-02-04 21:25:55,309:INFO:_master_model_container: 42
2024-02-04 21:25:55,309:INFO:_display_container: 5
2024-02-04 21:25:55,310:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:25:55,311:INFO:create_model() successfully completed......................................
2024-02-04 21:25:55,487:INFO:SubProcess create_model() end ==================================
2024-02-04 21:25:55,487:INFO:Creating metrics dataframe
2024-02-04 21:25:55,522:INFO:Initializing Dummy Classifier
2024-02-04 21:25:55,522:INFO:Total runtime is 1.0852860927581787 minutes
2024-02-04 21:25:55,530:INFO:SubProcess create_model() called ==================================
2024-02-04 21:25:55,531:INFO:Initializing create_model()
2024-02-04 21:25:55,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:25:55,531:INFO:Checking exceptions
2024-02-04 21:25:55,532:INFO:Importing libraries
2024-02-04 21:25:55,532:INFO:Copying training dataset
2024-02-04 21:25:55,548:INFO:Defining folds
2024-02-04 21:25:55,548:INFO:Declaring metric variables
2024-02-04 21:25:55,556:INFO:Importing untrained model
2024-02-04 21:25:55,565:INFO:Dummy Classifier Imported successfully
2024-02-04 21:25:55,591:INFO:Starting cross validation
2024-02-04 21:25:55,624:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:25:57,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:57,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:57,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:57,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:25:57,193:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:26:00,625:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,649:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:26:00,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,689:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:26:00,696:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,697:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:26:00,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,713:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,729:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:26:00,737:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,750:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 21:26:00,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:26:00,794:INFO:Calculating mean and std
2024-02-04 21:26:00,797:INFO:Creating metrics dataframe
2024-02-04 21:26:00,809:INFO:Uploading results into container
2024-02-04 21:26:00,810:INFO:Uploading model into container now
2024-02-04 21:26:00,812:INFO:_master_model_container: 43
2024-02-04 21:26:00,812:INFO:_display_container: 5
2024-02-04 21:26:00,813:INFO:DummyClassifier(constant=None, random_state=142, strategy='prior')
2024-02-04 21:26:00,813:INFO:create_model() successfully completed......................................
2024-02-04 21:26:00,990:INFO:SubProcess create_model() end ==================================
2024-02-04 21:26:00,990:INFO:Creating metrics dataframe
2024-02-04 21:26:01,048:INFO:Initializing create_model()
2024-02-04 21:26:01,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:26:01,049:INFO:Checking exceptions
2024-02-04 21:26:01,054:INFO:Importing libraries
2024-02-04 21:26:01,055:INFO:Copying training dataset
2024-02-04 21:26:01,073:INFO:Defining folds
2024-02-04 21:26:01,073:INFO:Declaring metric variables
2024-02-04 21:26:01,074:INFO:Importing untrained model
2024-02-04 21:26:01,074:INFO:Declaring custom model
2024-02-04 21:26:01,075:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:26:01,103:INFO:Cross validation set to False
2024-02-04 21:26:01,103:INFO:Fitting Model
2024-02-04 21:26:03,866:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:03,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.
2024-02-04 21:26:03,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:03,869:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:26:03,869:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:26:03,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:04,326:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:04,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-02-04 21:26:04,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:04,327:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:26:04,328:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:26:04,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:04,469:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:26:04,470:INFO:create_model() successfully completed......................................
2024-02-04 21:26:04,626:INFO:Creating Dashboard logs
2024-02-04 21:26:04,638:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:26:04,781:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 142, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-02-04 21:26:05,120:INFO:Initializing predict_model()
2024-02-04 21:26:05,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC6B00>)
2024-02-04 21:26:05,121:INFO:Checking exceptions
2024-02-04 21:26:05,121:INFO:Preloading libraries
2024-02-04 21:26:06,060:INFO:Initializing create_model()
2024-02-04 21:26:06,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:26:06,060:INFO:Checking exceptions
2024-02-04 21:26:06,065:INFO:Importing libraries
2024-02-04 21:26:06,066:INFO:Copying training dataset
2024-02-04 21:26:06,078:INFO:Defining folds
2024-02-04 21:26:06,078:INFO:Declaring metric variables
2024-02-04 21:26:06,079:INFO:Importing untrained model
2024-02-04 21:26:06,080:INFO:Declaring custom model
2024-02-04 21:26:06,081:INFO:Ada Boost Classifier Imported successfully
2024-02-04 21:26:06,104:INFO:Cross validation set to False
2024-02-04 21:26:06,104:INFO:Fitting Model
2024-02-04 21:26:08,974:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:08,976:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.
2024-02-04 21:26:08,976:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:08,976:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:26:08,977:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:26:08,978:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:10,125:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142)
2024-02-04 21:26:10,125:INFO:create_model() successfully completed......................................
2024-02-04 21:26:10,277:INFO:Creating Dashboard logs
2024-02-04 21:26:10,286:INFO:Model: Ada Boost Classifier
2024-02-04 21:26:10,426:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 142}
2024-02-04 21:26:10,780:INFO:Initializing predict_model()
2024-02-04 21:26:10,780:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC5630>)
2024-02-04 21:26:10,780:INFO:Checking exceptions
2024-02-04 21:26:10,780:INFO:Preloading libraries
2024-02-04 21:26:11,847:INFO:Initializing create_model()
2024-02-04 21:26:11,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:26:11,848:INFO:Checking exceptions
2024-02-04 21:26:11,853:INFO:Importing libraries
2024-02-04 21:26:11,853:INFO:Copying training dataset
2024-02-04 21:26:11,870:INFO:Defining folds
2024-02-04 21:26:11,870:INFO:Declaring metric variables
2024-02-04 21:26:11,871:INFO:Importing untrained model
2024-02-04 21:26:11,872:INFO:Declaring custom model
2024-02-04 21:26:11,874:INFO:Random Forest Classifier Imported successfully
2024-02-04 21:26:11,905:INFO:Cross validation set to False
2024-02-04 21:26:11,905:INFO:Fitting Model
2024-02-04 21:26:14,619:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:14,622:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002299 seconds.
2024-02-04 21:26:14,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:14,622:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:26:14,623:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:26:14,623:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:15,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False)
2024-02-04 21:26:15,740:INFO:create_model() successfully completed......................................
2024-02-04 21:26:15,875:INFO:Creating Dashboard logs
2024-02-04 21:26:15,883:INFO:Model: Random Forest Classifier
2024-02-04 21:26:16,014:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:26:16,333:INFO:Initializing predict_model()
2024-02-04 21:26:16,334:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC7BE0>)
2024-02-04 21:26:16,334:INFO:Checking exceptions
2024-02-04 21:26:16,334:INFO:Preloading libraries
2024-02-04 21:26:17,487:INFO:Initializing create_model()
2024-02-04 21:26:17,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:26:17,488:INFO:Checking exceptions
2024-02-04 21:26:17,492:INFO:Importing libraries
2024-02-04 21:26:17,493:INFO:Copying training dataset
2024-02-04 21:26:17,508:INFO:Defining folds
2024-02-04 21:26:17,508:INFO:Declaring metric variables
2024-02-04 21:26:17,509:INFO:Importing untrained model
2024-02-04 21:26:17,509:INFO:Declaring custom model
2024-02-04 21:26:17,511:INFO:Extra Trees Classifier Imported successfully
2024-02-04 21:26:17,545:INFO:Cross validation set to False
2024-02-04 21:26:17,545:INFO:Fitting Model
2024-02-04 21:26:20,155:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:20,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.
2024-02-04 21:26:20,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:20,158:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:26:20,159:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:26:20,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:21,117:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False)
2024-02-04 21:26:21,117:INFO:create_model() successfully completed......................................
2024-02-04 21:26:21,266:INFO:Creating Dashboard logs
2024-02-04 21:26:21,276:INFO:Model: Extra Trees Classifier
2024-02-04 21:26:21,408:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:26:21,791:INFO:Initializing predict_model()
2024-02-04 21:26:21,792:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC7C70>)
2024-02-04 21:26:21,792:INFO:Checking exceptions
2024-02-04 21:26:21,792:INFO:Preloading libraries
2024-02-04 21:26:23,154:INFO:Initializing create_model()
2024-02-04 21:26:23,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:26:23,156:INFO:Checking exceptions
2024-02-04 21:26:23,161:INFO:Importing libraries
2024-02-04 21:26:23,161:INFO:Copying training dataset
2024-02-04 21:26:23,180:INFO:Defining folds
2024-02-04 21:26:23,180:INFO:Declaring metric variables
2024-02-04 21:26:23,181:INFO:Importing untrained model
2024-02-04 21:26:23,181:INFO:Declaring custom model
2024-02-04 21:26:23,182:INFO:K Neighbors Classifier Imported successfully
2024-02-04 21:26:23,217:INFO:Cross validation set to False
2024-02-04 21:26:23,217:INFO:Fitting Model
2024-02-04 21:26:26,390:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:26:26,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.
2024-02-04 21:26:26,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:26:26,393:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:26:26,394:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:26:26,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:26:26,834:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 21:26:26,834:INFO:create_model() successfully completed......................................
2024-02-04 21:26:27,004:INFO:Creating Dashboard logs
2024-02-04 21:26:27,017:INFO:Model: K Neighbors Classifier
2024-02-04 21:26:27,153:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2024-02-04 21:26:27,410:INFO:Initializing predict_model()
2024-02-04 21:26:27,410:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC7F40>)
2024-02-04 21:26:27,410:INFO:Checking exceptions
2024-02-04 21:26:27,411:INFO:Preloading libraries
2024-02-04 21:26:28,219:INFO:Creating Dashboard logs
2024-02-04 21:26:28,245:INFO:Model: Linear Discriminant Analysis
2024-02-04 21:26:28,351:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:26:29,106:INFO:Creating Dashboard logs
2024-02-04 21:26:29,115:INFO:Model: Ridge Classifier
2024-02-04 21:26:29,220:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 142, 'solver': 'auto', 'tol': 0.0001}
2024-02-04 21:26:30,160:INFO:Creating Dashboard logs
2024-02-04 21:26:30,166:INFO:Model: Logistic Regression
2024-02-04 21:26:30,261:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 142, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-02-04 21:26:30,746:INFO:Creating Dashboard logs
2024-02-04 21:26:30,750:INFO:Model: Quadratic Discriminant Analysis
2024-02-04 21:26:30,845:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2024-02-04 21:26:31,362:INFO:Creating Dashboard logs
2024-02-04 21:26:31,370:INFO:Model: Naive Bayes
2024-02-04 21:26:31,466:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-02-04 21:26:32,022:INFO:Creating Dashboard logs
2024-02-04 21:26:32,027:INFO:Model: Decision Tree Classifier
2024-02-04 21:26:32,107:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 142, 'splitter': 'best'}
2024-02-04 21:26:32,581:INFO:Creating Dashboard logs
2024-02-04 21:26:32,586:INFO:Model: Dummy Classifier
2024-02-04 21:26:32,656:INFO:Logged params: {'constant': None, 'random_state': 142, 'strategy': 'prior'}
2024-02-04 21:26:33,136:INFO:Creating Dashboard logs
2024-02-04 21:26:33,140:INFO:Model: SVM - Linear Kernel
2024-02-04 21:26:33,210:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 142, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2024-02-04 21:26:33,876:INFO:_master_model_container: 43
2024-02-04 21:26:33,877:INFO:_display_container: 5
2024-02-04 21:26:33,881:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=142), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=142, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=142, verbose=0, warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')]
2024-02-04 21:26:33,881:INFO:compare_models() successfully completed......................................
2024-02-04 21:30:45,343:INFO:Initializing create_model()
2024-02-04 21:30:45,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:30:45,344:INFO:Checking exceptions
2024-02-04 21:30:45,377:INFO:Importing libraries
2024-02-04 21:30:45,377:INFO:Copying training dataset
2024-02-04 21:30:45,389:INFO:Defining folds
2024-02-04 21:30:45,389:INFO:Declaring metric variables
2024-02-04 21:30:45,396:INFO:Importing untrained model
2024-02-04 21:30:45,403:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:30:45,414:INFO:Starting cross validation
2024-02-04 21:30:45,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:30:46,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:46,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:46,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:46,852:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:46,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:47,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:47,104:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:47,156:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:49,498:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,508:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,524:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,530:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,539:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,967:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:49,977:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:50,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:50,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:30:52,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:30:52,184:INFO:Calculating mean and std
2024-02-04 21:30:52,187:INFO:Creating metrics dataframe
2024-02-04 21:30:52,196:INFO:Finalizing model
2024-02-04 21:30:53,743:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:30:53,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001058 seconds.
2024-02-04 21:30:53,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:30:53,745:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:30:53,745:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:30:53,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:30:54,036:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:30:54,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-02-04 21:30:54,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:30:54,037:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:30:54,037:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:30:54,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:30:54,131:INFO:Creating Dashboard logs
2024-02-04 21:30:54,136:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:30:54,204:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 142, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2024-02-04 21:30:54,471:INFO:Initializing predict_model()
2024-02-04 21:30:54,471:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167590045E0>)
2024-02-04 21:30:54,471:INFO:Checking exceptions
2024-02-04 21:30:54,472:INFO:Preloading libraries
2024-02-04 21:30:55,129:INFO:Uploading results into container
2024-02-04 21:30:55,130:INFO:Uploading model into container now
2024-02-04 21:30:55,155:INFO:_master_model_container: 44
2024-02-04 21:30:55,155:INFO:_display_container: 5
2024-02-04 21:30:55,156:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:30:55,156:INFO:create_model() successfully completed......................................
2024-02-04 21:33:23,542:INFO:Initializing tune_model()
2024-02-04 21:33:23,543:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>)
2024-02-04 21:33:23,544:INFO:Checking exceptions
2024-02-04 21:33:23,567:INFO:Copying training dataset
2024-02-04 21:33:23,574:INFO:Checking base model
2024-02-04 21:33:23,574:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 21:33:23,579:INFO:Declaring metric variables
2024-02-04 21:33:23,584:INFO:Defining Hyperparameters
2024-02-04 21:33:23,713:INFO:Tuning with n_jobs=-1
2024-02-04 21:33:23,714:INFO:Initializing RandomizedSearchCV
2024-02-04 21:33:25,018:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,107:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,411:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,503:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:25,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,155:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,170:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,304:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:29,556:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:32,180:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:33,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:33,425:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:33,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:33,591:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:35,659:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:35,753:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:37,015:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:39,097:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:39,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:40,407:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:40,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:41,989:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:43,793:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:43,830:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:44,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:45,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:45,988:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:46,102:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:49,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:49,089:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:49,768:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:50,408:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:50,487:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:53,788:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:54,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:55,125:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:55,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:56,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:57,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:57,592:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:33:57,961:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:00,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:01,194:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:01,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:01,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:02,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:03,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:03,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:04,383:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:05,919:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:06,830:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:07,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:07,439:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:07,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:08,635:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:09,840:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:10,177:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:11,474:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:12,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:12,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:12,255:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:12,741:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:14,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:15,781:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:15,839:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:17,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:18,413:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:18,595:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:18,720:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:21,030:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:21,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:22,021:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:22,743:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:23,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:24,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:25,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:26,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:28,650:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:29,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:29,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:29,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:30,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:31,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:31,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:32,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:34,236:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:34,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:34,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:34,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:36,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:37,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:38,669:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:41,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:41,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:43,047:INFO:best_params: {'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 200, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_split_gain': 0.8, 'actual_estimator__min_child_samples': 36, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.9}
2024-02-04 21:34:43,048:INFO:Hyperparameter search completed
2024-02-04 21:34:43,049:INFO:SubProcess create_model() called ==================================
2024-02-04 21:34:43,050:INFO:Initializing create_model()
2024-02-04 21:34:43,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016747976200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1, 'reg_alpha': 4, 'num_leaves': 200, 'n_estimators': 140, 'min_split_gain': 0.8, 'min_child_samples': 36, 'learning_rate': 0.0005, 'feature_fraction': 1.0, 'bagging_freq': 5, 'bagging_fraction': 0.9})
2024-02-04 21:34:43,050:INFO:Checking exceptions
2024-02-04 21:34:43,050:INFO:Importing libraries
2024-02-04 21:34:43,051:INFO:Copying training dataset
2024-02-04 21:34:43,065:INFO:Defining folds
2024-02-04 21:34:43,065:INFO:Declaring metric variables
2024-02-04 21:34:43,072:INFO:Importing untrained model
2024-02-04 21:34:43,072:INFO:Declaring custom model
2024-02-04 21:34:43,080:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:34:43,097:INFO:Starting cross validation
2024-02-04 21:34:43,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:34:44,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,298:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,358:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:44,364:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:48,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,649:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,841:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,850:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:48,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,579:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,699:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:49,703:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:49,726:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,736:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:49,747:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,340:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,350:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,359:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,369:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:51,394:INFO:Calculating mean and std
2024-02-04 21:34:51,396:INFO:Creating metrics dataframe
2024-02-04 21:34:51,405:INFO:Finalizing model
2024-02-04 21:34:53,202:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:34:53,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001218 seconds.
2024-02-04 21:34:53,204:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:34:53,204:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:34:53,205:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:34:53,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:34:53,421:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:34:53,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:34:53,421:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:34:53,426:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:34:53,426:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:34:53,426:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:34:53,426:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:34:53,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.
2024-02-04 21:34:53,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:34:53,427:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:34:53,427:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:34:53,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:34:53,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:34:53,567:INFO:Uploading results into container
2024-02-04 21:34:53,568:INFO:Uploading model into container now
2024-02-04 21:34:53,569:INFO:_master_model_container: 45
2024-02-04 21:34:53,569:INFO:_display_container: 5
2024-02-04 21:34:53,570:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:34:53,570:INFO:create_model() successfully completed......................................
2024-02-04 21:34:53,705:INFO:SubProcess create_model() end ==================================
2024-02-04 21:34:53,705:INFO:choose_better activated
2024-02-04 21:34:53,710:INFO:SubProcess create_model() called ==================================
2024-02-04 21:34:53,711:INFO:Initializing create_model()
2024-02-04 21:34:53,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:34:53,711:INFO:Checking exceptions
2024-02-04 21:34:53,712:INFO:Importing libraries
2024-02-04 21:34:53,713:INFO:Copying training dataset
2024-02-04 21:34:53,720:INFO:Defining folds
2024-02-04 21:34:53,720:INFO:Declaring metric variables
2024-02-04 21:34:53,720:INFO:Importing untrained model
2024-02-04 21:34:53,720:INFO:Declaring custom model
2024-02-04 21:34:53,721:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 21:34:53,722:INFO:Starting cross validation
2024-02-04 21:34:53,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:34:54,938:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:54,947:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:54,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:54,958:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:55,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:55,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:55,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:55,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:58,739:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,761:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,765:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,775:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,877:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,928:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,950:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,970:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,982:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:58,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,000:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,012:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,022:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,166:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,176:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,188:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,229:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:34:59,609:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:34:59,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:35:01,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,149:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:35:01,179:INFO:Calculating mean and std
2024-02-04 21:35:01,179:INFO:Creating metrics dataframe
2024-02-04 21:35:01,182:INFO:Finalizing model
2024-02-04 21:35:02,400:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:35:02,402:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000979 seconds.
2024-02-04 21:35:02,402:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:35:02,402:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:35:02,403:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:35:02,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:35:02,677:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:35:02,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
2024-02-04 21:35:02,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:35:02,677:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:35:02,677:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:35:02,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:35:02,776:INFO:Uploading results into container
2024-02-04 21:35:02,777:INFO:Uploading model into container now
2024-02-04 21:35:02,778:INFO:_master_model_container: 46
2024-02-04 21:35:02,778:INFO:_display_container: 6
2024-02-04 21:35:02,779:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:35:02,779:INFO:create_model() successfully completed......................................
2024-02-04 21:35:02,892:INFO:SubProcess create_model() end ==================================
2024-02-04 21:35:02,893:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=142, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6933
2024-02-04 21:35:02,893:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7002
2024-02-04 21:35:02,894:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-04 21:35:02,894:INFO:choose_better completed
2024-02-04 21:35:02,894:INFO:Creating Dashboard logs
2024-02-04 21:35:02,899:INFO:Model: Light Gradient Boosting Machine
2024-02-04 21:35:02,980:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0005, 'max_depth': -1, 'min_child_samples': 36, 'min_child_weight': 0.001, 'min_split_gain': 0.8, 'n_estimators': 140, 'n_jobs': -1, 'num_leaves': 200, 'objective': None, 'random_state': 142, 'reg_alpha': 4, 'reg_lambda': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 1.0, 'bagging_freq': 5, 'bagging_fraction': 0.9}
2024-02-04 21:35:03,230:INFO:Initializing predict_model()
2024-02-04 21:35:03,230:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167590C84C0>)
2024-02-04 21:35:03,230:INFO:Checking exceptions
2024-02-04 21:35:03,230:INFO:Preloading libraries
2024-02-04 21:35:03,837:INFO:_master_model_container: 46
2024-02-04 21:35:03,837:INFO:_display_container: 5
2024-02-04 21:35:03,838:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 21:35:03,839:INFO:tune_model() successfully completed......................................
2024-02-04 21:38:22,751:INFO:Initializing plot_model()
2024-02-04 21:38:22,752:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, system=True)
2024-02-04 21:38:22,752:INFO:Checking exceptions
2024-02-04 21:38:22,758:INFO:Preloading libraries
2024-02-04 21:38:22,766:INFO:Copying training dataset
2024-02-04 21:38:22,766:INFO:Plot type: auc
2024-02-04 21:38:23,077:INFO:Fitting Model
2024-02-04 21:38:23,079:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:38:23,079:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:38:23,079:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:38:23,080:INFO:Scoring test/hold-out set
2024-02-04 21:38:23,082:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:38:23,082:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:38:23,082:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:38:23,087:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:38:23,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:38:23,087:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:38:23,448:INFO:Visual Rendered Successfully
2024-02-04 21:38:23,565:INFO:plot_model() successfully completed......................................
2024-02-04 21:39:41,677:INFO:Initializing ensemble_model()
2024-02-04 21:39:41,677:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001, min_split_gain=0.8,
               n_estimators=140, n_jobs=-1, num_leaves=200, objective=None,
               random_state=142, reg_alpha=4, reg_lambda=1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 21:39:41,678:INFO:Checking exceptions
2024-02-04 21:39:41,702:INFO:Importing libraries
2024-02-04 21:39:41,702:INFO:Copying training dataset
2024-02-04 21:39:41,702:INFO:Checking base model
2024-02-04 21:39:41,703:INFO:Base model : Light Gradient Boosting Machine
2024-02-04 21:39:41,710:INFO:Importing untrained ensembler
2024-02-04 21:39:41,711:INFO:Ensemble method set to Bagging
2024-02-04 21:39:41,711:INFO:SubProcess create_model() called ==================================
2024-02-04 21:39:41,713:INFO:Initializing create_model()
2024-02-04 21:39:41,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016748BD5C30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:39:41,713:INFO:Checking exceptions
2024-02-04 21:39:41,713:INFO:Importing libraries
2024-02-04 21:39:41,713:INFO:Copying training dataset
2024-02-04 21:39:41,720:INFO:Defining folds
2024-02-04 21:39:41,720:INFO:Declaring metric variables
2024-02-04 21:39:41,724:INFO:Importing untrained model
2024-02-04 21:39:41,724:INFO:Declaring custom model
2024-02-04 21:39:41,730:INFO:Bagging Classifier Imported successfully
2024-02-04 21:39:41,743:INFO:Starting cross validation
2024-02-04 21:39:41,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 21:39:42,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:42,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:42,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:42,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:42,973:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:42,983:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:43,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:43,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:52,915:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:52,923:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:52,933:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:53,776:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:55,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:55,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:55,438:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:56,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2024-02-04 21:39:56,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:56,703:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:56,712:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:57,568:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:57,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:57,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,062:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,813:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:58,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,232:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,254:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,593:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,603:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:39:59,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,123:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,415:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,434:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 21:40:02,458:INFO:Calculating mean and std
2024-02-04 21:40:02,463:INFO:Creating metrics dataframe
2024-02-04 21:40:02,483:INFO:Finalizing model
2024-02-04 21:40:05,034:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:05,035:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.
2024-02-04 21:40:05,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:05,035:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:40:05,035:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 34
2024-02-04 21:40:05,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:40:05,290:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,291:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,291:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,295:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,295:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,295:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,295:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:05,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-02-04 21:40:05,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:05,296:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:05,296:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:05,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500164 -> initscore=0.000656
2024-02-04 21:40:05,297:INFO:[LightGBM] [Info] Start training from score 0.000656
2024-02-04 21:40:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,594:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,594:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,594:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,598:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,598:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,598:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,598:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:05,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-02-04 21:40:05,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:05,599:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:05,599:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:05,599:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502297 -> initscore=0.009186
2024-02-04 21:40:05,600:INFO:[LightGBM] [Info] Start training from score 0.009186
2024-02-04 21:40:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,900:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,901:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,901:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,906:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:05,906:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:05,906:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:05,906:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:05,907:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-02-04 21:40:05,907:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:05,907:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:05,907:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:05,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499344 -> initscore=-0.002625
2024-02-04 21:40:05,909:INFO:[LightGBM] [Info] Start training from score -0.002625
2024-02-04 21:40:05,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:05,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,278:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,278:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,278:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,284:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,284:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,285:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,285:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:06,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-02-04 21:40:06,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:06,286:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:06,286:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:06,287:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494587 -> initscore=-0.021654
2024-02-04 21:40:06,287:INFO:[LightGBM] [Info] Start training from score -0.021654
2024-02-04 21:40:06,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,632:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,633:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,633:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,640:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,640:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,641:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,641:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:06,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-02-04 21:40:06,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:06,641:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:06,642:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:06,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505741 -> initscore=0.022967
2024-02-04 21:40:06,642:INFO:[LightGBM] [Info] Start training from score 0.022967
2024-02-04 21:40:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,949:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,949:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,950:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,954:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:06,955:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:06,955:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:06,955:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:06,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-02-04 21:40:06,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:06,956:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:06,956:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:06,957:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497539 -> initscore=-0.009843
2024-02-04 21:40:06,957:INFO:[LightGBM] [Info] Start training from score -0.009843
2024-02-04 21:40:06,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:06,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,273:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:07,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:07,273:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:07,278:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:07,278:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:07,279:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:07,279:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:07,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-02-04 21:40:07,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:07,279:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:07,279:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:07,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511647 -> initscore=0.046596
2024-02-04 21:40:07,280:INFO:[LightGBM] [Info] Start training from score 0.046596
2024-02-04 21:40:07,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,812:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:07,812:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:07,812:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:07,815:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:07,815:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:07,816:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:07,816:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:07,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2024-02-04 21:40:07,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:07,817:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:07,817:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:07,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499016 -> initscore=-0.003937
2024-02-04 21:40:07,817:INFO:[LightGBM] [Info] Start training from score -0.003937
2024-02-04 21:40:07,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:07,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,299:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:08,300:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:08,300:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:08,304:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:08,304:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:08,304:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:08,304:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:08,305:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-02-04 21:40:08,305:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:08,305:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:08,305:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:08,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497867 -> initscore=-0.008530
2024-02-04 21:40:08,305:INFO:[LightGBM] [Info] Start training from score -0.008530
2024-02-04 21:40:08,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,609:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:08,609:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:08,609:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:08,614:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:40:08,614:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:40:08,614:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:40:08,615:INFO:[LightGBM] [Info] Number of positive: 3048, number of negative: 3048
2024-02-04 21:40:08,615:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-02-04 21:40:08,615:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:40:08,615:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:40:08,615:INFO:[LightGBM] [Info] Number of data points in the train set: 6096, number of used features: 3
2024-02-04 21:40:08,616:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503117 -> initscore=0.012467
2024-02-04 21:40:08,616:INFO:[LightGBM] [Info] Start training from score 0.012467
2024-02-04 21:40:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:40:08,851:INFO:Uploading results into container
2024-02-04 21:40:08,853:INFO:Uploading model into container now
2024-02-04 21:40:08,855:INFO:_master_model_container: 47
2024-02-04 21:40:08,856:INFO:_display_container: 5
2024-02-04 21:40:08,858:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False)
2024-02-04 21:40:08,859:INFO:create_model() successfully completed......................................
2024-02-04 21:40:09,072:INFO:SubProcess create_model() end ==================================
2024-02-04 21:40:09,073:INFO:Creating Dashboard logs
2024-02-04 21:40:09,079:INFO:Model: Bagging Classifier
2024-02-04 21:40:09,197:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.0005, 'estimator__max_depth': -1, 'estimator__min_child_samples': 36, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.8, 'estimator__n_estimators': 140, 'estimator__n_jobs': -1, 'estimator__num_leaves': 200, 'estimator__objective': None, 'estimator__random_state': 142, 'estimator__reg_alpha': 4, 'estimator__reg_lambda': 1, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator__feature_fraction': 1.0, 'estimator__bagging_freq': 5, 'estimator__bagging_fraction': 0.9, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:40:09,691:INFO:Initializing predict_model()
2024-02-04 21:40:09,691:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167590C4160>)
2024-02-04 21:40:09,691:INFO:Checking exceptions
2024-02-04 21:40:09,691:INFO:Preloading libraries
2024-02-04 21:40:10,556:INFO:_master_model_container: 47
2024-02-04 21:40:10,557:INFO:_display_container: 5
2024-02-04 21:40:10,559:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False)
2024-02-04 21:40:10,559:INFO:ensemble_model() successfully completed......................................
2024-02-04 21:43:34,924:INFO:Initializing predict_model()
2024-02-04 21:43:34,924:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016758FC60E0>)
2024-02-04 21:43:34,925:INFO:Checking exceptions
2024-02-04 21:43:34,925:INFO:Preloading libraries
2024-02-04 21:43:34,927:INFO:Set up data.
2024-02-04 21:43:34,944:INFO:Set up index.
2024-02-04 21:44:21,575:INFO:Initializing predict_model()
2024-02-04 21:44:21,576:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016763DE0EE0>)
2024-02-04 21:44:21,576:INFO:Checking exceptions
2024-02-04 21:44:21,576:INFO:Preloading libraries
2024-02-04 21:44:21,578:INFO:Set up data.
2024-02-04 21:44:21,594:INFO:Set up index.
2024-02-04 21:46:27,127:INFO:Initializing predict_model()
2024-02-04 21:46:27,127:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001676256E710>)
2024-02-04 21:46:27,127:INFO:Checking exceptions
2024-02-04 21:46:27,128:INFO:Preloading libraries
2024-02-04 21:46:27,132:INFO:Set up data.
2024-02-04 21:46:27,146:INFO:Set up index.
2024-02-04 21:46:43,228:INFO:Initializing predict_model()
2024-02-04 21:46:43,228:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001676256EDD0>)
2024-02-04 21:46:43,228:INFO:Checking exceptions
2024-02-04 21:46:43,228:INFO:Preloading libraries
2024-02-04 21:46:43,233:INFO:Set up data.
2024-02-04 21:46:43,252:INFO:Set up index.
2024-02-04 21:47:55,837:INFO:Initializing finalize_model()
2024-02-04 21:47:55,838:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 21:47:55,843:INFO:Finalizing BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False)
2024-02-04 21:47:55,853:INFO:Initializing create_model()
2024-02-04 21:47:55,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=5,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=1.0,
                                           importance_type='split',
                                           learning_rate=0.0005, max_depth=-1,
                                           min_child_samples=36,
                                           min_child_weight=0.001,
                                           min_split_gain=0.8, n_estimators=140,
                                           n_jobs=-1, num_leaves=200,
                                           objective=None, random_state=142,
                                           reg_alpha=4, reg_lambda=1,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=142, verbose=0,
                  warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 21:47:55,854:INFO:Checking exceptions
2024-02-04 21:47:55,857:INFO:Importing libraries
2024-02-04 21:47:55,857:INFO:Copying training dataset
2024-02-04 21:47:55,857:INFO:Defining folds
2024-02-04 21:47:55,858:INFO:Declaring metric variables
2024-02-04 21:47:55,858:INFO:Importing untrained model
2024-02-04 21:47:55,859:INFO:Declaring custom model
2024-02-04 21:47:55,860:INFO:Bagging Classifier Imported successfully
2024-02-04 21:47:55,890:INFO:Cross validation set to False
2024-02-04 21:47:55,890:INFO:Fitting Model
2024-02-04 21:47:57,681:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:57,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.
2024-02-04 21:47:57,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:57,683:INFO:[LightGBM] [Info] Total Bins 8670
2024-02-04 21:47:57,683:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 34
2024-02-04 21:47:57,683:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:47:57,923:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:57,923:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:57,923:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:57,927:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:57,927:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:57,928:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:57,928:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:57,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-02-04 21:47:57,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:57,928:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:57,928:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:57,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495517 -> initscore=-0.017932
2024-02-04 21:47:57,929:INFO:[LightGBM] [Info] Start training from score -0.017932
2024-02-04 21:47:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:57,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,201:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,201:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,201:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,226:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,226:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,226:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,226:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:58,227:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-02-04 21:47:58,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:58,227:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:58,227:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:58,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505517 -> initscore=0.022070
2024-02-04 21:47:58,228:INFO:[LightGBM] [Info] Start training from score 0.022070
2024-02-04 21:47:58,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,495:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,495:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,495:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,499:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,499:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,499:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:58,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-02-04 21:47:58,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:58,500:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:58,500:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:58,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494483 -> initscore=-0.022070
2024-02-04 21:47:58,500:INFO:[LightGBM] [Info] Start training from score -0.022070
2024-02-04 21:47:58,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,777:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,778:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,778:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,782:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:58,782:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:58,782:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:58,782:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:58,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-02-04 21:47:58,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:58,783:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:58,783:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:58,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501724 -> initscore=0.006897
2024-02-04 21:47:58,783:INFO:[LightGBM] [Info] Start training from score 0.006897
2024-02-04 21:47:58,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:58,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,140:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,140:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,140:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,144:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,144:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,144:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,144:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:59,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-02-04 21:47:59,145:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:59,145:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:59,146:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:59,146:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498391 -> initscore=-0.006437
2024-02-04 21:47:59,146:INFO:[LightGBM] [Info] Start training from score -0.006437
2024-02-04 21:47:59,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,408:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,408:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,408:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,412:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,412:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,412:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,412:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:59,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.
2024-02-04 21:47:59,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:59,413:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:59,413:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:59,413:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502874 -> initscore=0.011494
2024-02-04 21:47:59,413:INFO:[LightGBM] [Info] Start training from score 0.011494
2024-02-04 21:47:59,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,689:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,689:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,690:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,694:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,694:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,694:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,694:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:59,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-02-04 21:47:59,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:59,695:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:59,695:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:59,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504253 -> initscore=0.017012
2024-02-04 21:47:59,695:INFO:[LightGBM] [Info] Start training from score 0.017012
2024-02-04 21:47:59,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,957:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,957:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,957:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,960:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:47:59,960:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:47:59,960:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:47:59,960:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:47:59,960:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-02-04 21:47:59,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:47:59,961:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:47:59,961:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:47:59,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506782 -> initscore=0.027128
2024-02-04 21:47:59,961:INFO:[LightGBM] [Info] Start training from score 0.027128
2024-02-04 21:47:59,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:47:59,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,153:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:48:00,153:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:48:00,153:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:48:00,156:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:48:00,156:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:48:00,156:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:48:00,156:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:48:00,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.
2024-02-04 21:48:00,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:48:00,157:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:48:00,157:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:48:00,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491609 -> initscore=-0.033566
2024-02-04 21:48:00,157:INFO:[LightGBM] [Info] Start training from score -0.033566
2024-02-04 21:48:00,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,335:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:48:00,335:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:48:00,335:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:48:00,338:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2024-02-04 21:48:00,338:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-04 21:48:00,339:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-04 21:48:00,339:INFO:[LightGBM] [Info] Number of positive: 4350, number of negative: 4350
2024-02-04 21:48:00,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.
2024-02-04 21:48:00,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-04 21:48:00,339:INFO:[LightGBM] [Info] Total Bins 765
2024-02-04 21:48:00,339:INFO:[LightGBM] [Info] Number of data points in the train set: 8700, number of used features: 3
2024-02-04 21:48:00,339:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-04 21:48:00,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-04 21:48:00,619:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                                                            min_child_samples=36,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.8,
                                                            n_estimators=140,
                                                            n_jobs=-1,
                                                            num_leaves=200,
                                                            objective=None,
                                                            random_state=142,
                                                            reg_alpha=4,
                                                            reg_lambda=1,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=142, verbose=0,
                                   warm_start=False))],
         verbose=False)
2024-02-04 21:48:00,619:INFO:create_model() successfully completed......................................
2024-02-04 21:48:00,759:INFO:Creating Dashboard logs
2024-02-04 21:48:00,760:INFO:Model: Bagging Classifier
2024-02-04 21:48:00,823:INFO:Logged params: {'base_estimator': 'deprecated', 'bootstrap': True, 'bootstrap_features': False, 'estimator__boosting_type': 'gbdt', 'estimator__class_weight': None, 'estimator__colsample_bytree': 1.0, 'estimator__importance_type': 'split', 'estimator__learning_rate': 0.0005, 'estimator__max_depth': -1, 'estimator__min_child_samples': 36, 'estimator__min_child_weight': 0.001, 'estimator__min_split_gain': 0.8, 'estimator__n_estimators': 140, 'estimator__n_jobs': -1, 'estimator__num_leaves': 200, 'estimator__objective': None, 'estimator__random_state': 142, 'estimator__reg_alpha': 4, 'estimator__reg_lambda': 1, 'estimator__subsample': 1.0, 'estimator__subsample_for_bin': 200000, 'estimator__subsample_freq': 0, 'estimator__feature_fraction': 1.0, 'estimator__bagging_freq': 5, 'estimator__bagging_fraction': 0.9, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 142, 'verbose': 0, 'warm_start': False}
2024-02-04 21:48:01,240:INFO:_master_model_container: 47
2024-02-04 21:48:01,240:INFO:_display_container: 7
2024-02-04 21:48:01,311:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                                                            min_child_samples=36,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.8,
                                                            n_estimators=140,
                                                            n_jobs=-1,
                                                            num_leaves=200,
                                                            objective=None,
                                                            random_state=142,
                                                            reg_alpha=4,
                                                            reg_lambda=1,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=142, verbose=0,
                                   warm_start=False))],
         verbose=False)
2024-02-04 21:48:01,311:INFO:finalize_model() successfully completed......................................
2024-02-04 21:48:03,488:INFO:Initializing predict_model()
2024-02-04 21:48:03,488:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016747A71600>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=['SeniorCitizen'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strate...
                                                            min_child_samples=36,
                                                            min_child_weight=0.001,
                                                            min_split_gain=0.8,
                                                            n_estimators=140,
                                                            n_jobs=-1,
                                                            num_leaves=200,
                                                            objective=None,
                                                            random_state=142,
                                                            reg_alpha=4,
                                                            reg_lambda=1,
                                                            subsample=1.0,
                                                            subsample_for_bin=200000,
                                                            subsample_freq=0),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=142, verbose=0,
                                   warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001676256ECB0>)
2024-02-04 21:48:03,488:INFO:Checking exceptions
2024-02-04 21:48:03,489:INFO:Preloading libraries
2024-02-04 21:48:03,491:INFO:Set up data.
2024-02-04 21:48:03,505:INFO:Set up index.
2024-02-04 22:15:38,852:INFO:PyCaret ClassificationExperiment
2024-02-04 22:15:38,852:INFO:Logging name: clf-default-name
2024-02-04 22:15:38,852:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-04 22:15:38,852:INFO:version 3.2.0
2024-02-04 22:15:38,852:INFO:Initializing setup()
2024-02-04 22:15:38,853:INFO:self.USI: 27c5
2024-02-04 22:15:38,853:INFO:self._variable_keys: {'USI', 'fold_generator', 'data', 'is_multiclass', '_ml_usecase', 'X_train', 'seed', '_available_plots', 'y_train', 'exp_name_log', 'pipeline', 'fold_groups_param', 'y_test', 'gpu_param', 'logging_param', 'memory', 'X_test', 'html_param', 'fix_imbalance', 'exp_id', 'gpu_n_jobs_param', 'X', 'idx', 'target_param', 'n_jobs_param', 'log_plots_param', 'fold_shuffle_param', 'y'}
2024-02-04 22:15:38,853:INFO:Checking environment
2024-02-04 22:15:38,853:INFO:python_version: 3.10.9
2024-02-04 22:15:38,853:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-04 22:15:38,853:INFO:machine: AMD64
2024-02-04 22:15:38,853:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-04 22:15:38,853:INFO:Memory: svmem(total=16856182784, available=10026266624, percent=40.5, used=6829916160, free=10026266624)
2024-02-04 22:15:38,853:INFO:Physical Core: 4
2024-02-04 22:15:38,853:INFO:Logical Core: 8
2024-02-04 22:15:38,853:INFO:Checking libraries
2024-02-04 22:15:38,853:INFO:System:
2024-02-04 22:15:38,853:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-04 22:15:38,853:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-04 22:15:38,853:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-04 22:15:38,853:INFO:PyCaret required dependencies:
2024-02-04 22:15:39,050:INFO:                 pip: 22.3.1
2024-02-04 22:15:39,050:INFO:          setuptools: 65.6.3
2024-02-04 22:15:39,050:INFO:             pycaret: 3.2.0
2024-02-04 22:15:39,050:INFO:             IPython: 8.20.0
2024-02-04 22:15:39,050:INFO:          ipywidgets: 8.0.4
2024-02-04 22:15:39,051:INFO:                tqdm: 4.64.1
2024-02-04 22:15:39,051:INFO:               numpy: 1.25.2
2024-02-04 22:15:39,051:INFO:              pandas: 1.5.3
2024-02-04 22:15:39,051:INFO:              jinja2: 3.1.3
2024-02-04 22:15:39,051:INFO:               scipy: 1.10.1
2024-02-04 22:15:39,051:INFO:              joblib: 1.3.2
2024-02-04 22:15:39,051:INFO:             sklearn: 1.2.2
2024-02-04 22:15:39,051:INFO:                pyod: 1.1.2
2024-02-04 22:15:39,051:INFO:            imblearn: 0.12.0
2024-02-04 22:15:39,051:INFO:   category_encoders: 2.6.3
2024-02-04 22:15:39,051:INFO:            lightgbm: 4.3.0
2024-02-04 22:15:39,051:INFO:               numba: 0.59.0
2024-02-04 22:15:39,051:INFO:            requests: 2.31.0
2024-02-04 22:15:39,051:INFO:          matplotlib: 3.6.0
2024-02-04 22:15:39,051:INFO:          scikitplot: 0.3.7
2024-02-04 22:15:39,051:INFO:         yellowbrick: 1.5
2024-02-04 22:15:39,051:INFO:              plotly: 5.18.0
2024-02-04 22:15:39,051:INFO:    plotly-resampler: Not installed
2024-02-04 22:15:39,051:INFO:             kaleido: 0.2.1
2024-02-04 22:15:39,051:INFO:           schemdraw: 0.15
2024-02-04 22:15:39,051:INFO:         statsmodels: 0.14.1
2024-02-04 22:15:39,051:INFO:              sktime: 0.21.1
2024-02-04 22:15:39,051:INFO:               tbats: 1.1.3
2024-02-04 22:15:39,051:INFO:            pmdarima: 2.0.4
2024-02-04 22:15:39,051:INFO:              psutil: 5.9.0
2024-02-04 22:15:39,051:INFO:          markupsafe: 2.1.3
2024-02-04 22:15:39,051:INFO:             pickle5: Not installed
2024-02-04 22:15:39,051:INFO:         cloudpickle: 3.0.0
2024-02-04 22:15:39,051:INFO:         deprecation: 2.1.0
2024-02-04 22:15:39,052:INFO:              xxhash: 3.4.1
2024-02-04 22:15:39,052:INFO:           wurlitzer: Not installed
2024-02-04 22:15:39,052:INFO:PyCaret optional dependencies:
2024-02-04 22:15:39,063:INFO:                shap: 0.44.1
2024-02-04 22:15:39,063:INFO:           interpret: Not installed
2024-02-04 22:15:39,063:INFO:                umap: Not installed
2024-02-04 22:15:39,063:INFO:     ydata_profiling: Not installed
2024-02-04 22:15:39,063:INFO:  explainerdashboard: 0.4.5
2024-02-04 22:15:39,063:INFO:             autoviz: Not installed
2024-02-04 22:15:39,063:INFO:           fairlearn: Not installed
2024-02-04 22:15:39,063:INFO:          deepchecks: Not installed
2024-02-04 22:15:39,063:INFO:             xgboost: Not installed
2024-02-04 22:15:39,063:INFO:            catboost: 1.2.2
2024-02-04 22:15:39,063:INFO:              kmodes: Not installed
2024-02-04 22:15:39,063:INFO:             mlxtend: Not installed
2024-02-04 22:15:39,063:INFO:       statsforecast: Not installed
2024-02-04 22:15:39,063:INFO:        tune_sklearn: Not installed
2024-02-04 22:15:39,063:INFO:                 ray: Not installed
2024-02-04 22:15:39,063:INFO:            hyperopt: Not installed
2024-02-04 22:15:39,063:INFO:              optuna: Not installed
2024-02-04 22:15:39,063:INFO:               skopt: Not installed
2024-02-04 22:15:39,063:INFO:              mlflow: 2.10.0
2024-02-04 22:15:39,063:INFO:              gradio: Not installed
2024-02-04 22:15:39,063:INFO:             fastapi: Not installed
2024-02-04 22:15:39,063:INFO:             uvicorn: Not installed
2024-02-04 22:15:39,064:INFO:              m2cgen: Not installed
2024-02-04 22:15:39,064:INFO:           evidently: Not installed
2024-02-04 22:15:39,064:INFO:               fugue: Not installed
2024-02-04 22:15:39,064:INFO:           streamlit: Not installed
2024-02-04 22:15:39,064:INFO:             prophet: Not installed
2024-02-04 22:15:39,064:INFO:None
2024-02-04 22:15:39,064:INFO:Set up data.
2024-02-04 22:15:39,084:INFO:Set up folding strategy.
2024-02-04 22:15:39,085:INFO:Set up train/test split.
2024-02-04 22:15:39,097:INFO:Set up index.
2024-02-04 22:15:39,098:INFO:Assigning column types.
2024-02-04 22:15:39,101:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-04 22:15:39,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,175:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,321:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,353:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,353:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-04 22:15:39,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,434:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-04 22:15:39,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,507:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,508:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-04 22:15:39,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,583:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:39,657:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:39,673:INFO:Preparing preprocessing pipeline...
2024-02-04 22:15:39,675:INFO:Set up label encoding.
2024-02-04 22:15:39,675:INFO:Set up simple imputation.
2024-02-04 22:15:39,682:INFO:Set up encoding of ordinal features.
2024-02-04 22:15:39,689:INFO:Set up encoding of categorical features.
2024-02-04 22:15:40,017:INFO:Finished creating preprocessing pipeline.
2024-02-04 22:15:40,072:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SeniorCitizen', 'tenure',
                                             'MonthlyCharges', 'TotalCharges'],
                                    transformer=SimpleImputer(add_indicator=Fal...
                                             'Contract', 'PaymentMethod'],
                                    transformer=OneHotEncoder(cols=['MultipleLines',
                                                                    'InternetService',
                                                                    'OnlineSecurity',
                                                                    'OnlineBackup',
                                                                    'DeviceProtection',
                                                                    'TechSupport',
                                                                    'StreamingTV',
                                                                    'StreamingMovies',
                                                                    'Contract',
                                                                    'PaymentMethod'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-02-04 22:15:40,072:INFO:Creating final display dataframe.
2024-02-04 22:15:40,690:INFO:Setup _display_container:                     Description             Value
0                    Session id               517
1                        Target             Churn
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape        (6339, 21)
5        Transformed data shape        (6339, 41)
6   Transformed train set shape        (4437, 41)
7    Transformed test set shape        (1902, 41)
8               Ignore features                 1
9              Ordinal features                 5
10             Numeric features                 4
11         Categorical features                15
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              27c5
2024-02-04 22:15:40,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:40,796:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:40,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-04 22:15:40,869:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-04 22:15:40,870:INFO:setup() successfully completed in 2.03s...............
2024-02-04 22:15:40,884:INFO:Initializing compare_models()
2024-02-04 22:15:40,884:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-04 22:15:40,884:INFO:Checking exceptions
2024-02-04 22:15:40,889:INFO:Preparing display monitor
2024-02-04 22:15:40,924:INFO:Initializing Logistic Regression
2024-02-04 22:15:40,924:INFO:Total runtime is 0.0 minutes
2024-02-04 22:15:40,931:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:40,932:INFO:Initializing create_model()
2024-02-04 22:15:40,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:40,933:INFO:Checking exceptions
2024-02-04 22:15:40,933:INFO:Importing libraries
2024-02-04 22:15:40,934:INFO:Copying training dataset
2024-02-04 22:15:40,944:INFO:Defining folds
2024-02-04 22:15:40,944:INFO:Declaring metric variables
2024-02-04 22:15:40,949:INFO:Importing untrained model
2024-02-04 22:15:40,952:INFO:Logistic Regression Imported successfully
2024-02-04 22:15:40,958:INFO:Starting cross validation
2024-02-04 22:15:40,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:50,821:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:50,834:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:50,854:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:50,865:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:50,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:50,894:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,036:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,161:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,165:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,180:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,240:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,936:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,939:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,955:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:51,966:INFO:Calculating mean and std
2024-02-04 22:15:51,969:INFO:Creating metrics dataframe
2024-02-04 22:15:51,977:INFO:Uploading results into container
2024-02-04 22:15:51,978:INFO:Uploading model into container now
2024-02-04 22:15:51,979:INFO:_master_model_container: 1
2024-02-04 22:15:51,979:INFO:_display_container: 2
2024-02-04 22:15:51,980:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:15:51,981:INFO:create_model() successfully completed......................................
2024-02-04 22:15:52,105:INFO:SubProcess create_model() end ==================================
2024-02-04 22:15:52,105:INFO:Creating metrics dataframe
2024-02-04 22:15:52,117:INFO:Initializing K Neighbors Classifier
2024-02-04 22:15:52,117:INFO:Total runtime is 0.18653871218363444 minutes
2024-02-04 22:15:52,122:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:52,122:INFO:Initializing create_model()
2024-02-04 22:15:52,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:52,123:INFO:Checking exceptions
2024-02-04 22:15:52,123:INFO:Importing libraries
2024-02-04 22:15:52,123:INFO:Copying training dataset
2024-02-04 22:15:52,133:INFO:Defining folds
2024-02-04 22:15:52,133:INFO:Declaring metric variables
2024-02-04 22:15:52,139:INFO:Importing untrained model
2024-02-04 22:15:52,148:INFO:K Neighbors Classifier Imported successfully
2024-02-04 22:15:52,160:INFO:Starting cross validation
2024-02-04 22:15:52,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:53,417:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,428:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,438:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,496:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,507:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,511:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,519:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,523:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,535:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,542:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,547:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,553:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,554:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,564:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,564:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,565:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:53,577:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,019:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,025:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,034:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,043:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:54,060:INFO:Calculating mean and std
2024-02-04 22:15:54,061:INFO:Creating metrics dataframe
2024-02-04 22:15:54,066:INFO:Uploading results into container
2024-02-04 22:15:54,067:INFO:Uploading model into container now
2024-02-04 22:15:54,067:INFO:_master_model_container: 2
2024-02-04 22:15:54,067:INFO:_display_container: 2
2024-02-04 22:15:54,068:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-04 22:15:54,069:INFO:create_model() successfully completed......................................
2024-02-04 22:15:54,163:INFO:SubProcess create_model() end ==================================
2024-02-04 22:15:54,163:INFO:Creating metrics dataframe
2024-02-04 22:15:54,177:INFO:Initializing Naive Bayes
2024-02-04 22:15:54,178:INFO:Total runtime is 0.22090014616648357 minutes
2024-02-04 22:15:54,183:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:54,184:INFO:Initializing create_model()
2024-02-04 22:15:54,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:54,185:INFO:Checking exceptions
2024-02-04 22:15:54,185:INFO:Importing libraries
2024-02-04 22:15:54,185:INFO:Copying training dataset
2024-02-04 22:15:54,194:INFO:Defining folds
2024-02-04 22:15:54,195:INFO:Declaring metric variables
2024-02-04 22:15:54,200:INFO:Importing untrained model
2024-02-04 22:15:54,209:INFO:Naive Bayes Imported successfully
2024-02-04 22:15:54,222:INFO:Starting cross validation
2024-02-04 22:15:54,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:55,023:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,038:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,047:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,048:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,188:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,228:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,243:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,623:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,624:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,630:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,634:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:55,643:INFO:Calculating mean and std
2024-02-04 22:15:55,644:INFO:Creating metrics dataframe
2024-02-04 22:15:55,649:INFO:Uploading results into container
2024-02-04 22:15:55,650:INFO:Uploading model into container now
2024-02-04 22:15:55,650:INFO:_master_model_container: 3
2024-02-04 22:15:55,650:INFO:_display_container: 2
2024-02-04 22:15:55,651:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-04 22:15:55,651:INFO:create_model() successfully completed......................................
2024-02-04 22:15:55,738:INFO:SubProcess create_model() end ==================================
2024-02-04 22:15:55,739:INFO:Creating metrics dataframe
2024-02-04 22:15:55,752:INFO:Initializing Decision Tree Classifier
2024-02-04 22:15:55,752:INFO:Total runtime is 0.24712655146916707 minutes
2024-02-04 22:15:55,756:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:55,756:INFO:Initializing create_model()
2024-02-04 22:15:55,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:55,756:INFO:Checking exceptions
2024-02-04 22:15:55,757:INFO:Importing libraries
2024-02-04 22:15:55,757:INFO:Copying training dataset
2024-02-04 22:15:55,764:INFO:Defining folds
2024-02-04 22:15:55,765:INFO:Declaring metric variables
2024-02-04 22:15:55,770:INFO:Importing untrained model
2024-02-04 22:15:55,778:INFO:Decision Tree Classifier Imported successfully
2024-02-04 22:15:55,786:INFO:Starting cross validation
2024-02-04 22:15:55,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:56,641:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,652:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,659:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,664:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,705:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,782:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,803:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,846:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,858:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,870:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,885:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,898:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:56,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:57,277:INFO:Calculating mean and std
2024-02-04 22:15:57,278:INFO:Creating metrics dataframe
2024-02-04 22:15:57,282:INFO:Uploading results into container
2024-02-04 22:15:57,283:INFO:Uploading model into container now
2024-02-04 22:15:57,283:INFO:_master_model_container: 4
2024-02-04 22:15:57,283:INFO:_display_container: 2
2024-02-04 22:15:57,284:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=517, splitter='best')
2024-02-04 22:15:57,284:INFO:create_model() successfully completed......................................
2024-02-04 22:15:57,370:INFO:SubProcess create_model() end ==================================
2024-02-04 22:15:57,370:INFO:Creating metrics dataframe
2024-02-04 22:15:57,382:INFO:Initializing SVM - Linear Kernel
2024-02-04 22:15:57,382:INFO:Total runtime is 0.2742922902107239 minutes
2024-02-04 22:15:57,385:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:57,386:INFO:Initializing create_model()
2024-02-04 22:15:57,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:57,386:INFO:Checking exceptions
2024-02-04 22:15:57,386:INFO:Importing libraries
2024-02-04 22:15:57,386:INFO:Copying training dataset
2024-02-04 22:15:57,393:INFO:Defining folds
2024-02-04 22:15:57,393:INFO:Declaring metric variables
2024-02-04 22:15:57,396:INFO:Importing untrained model
2024-02-04 22:15:57,401:INFO:SVM - Linear Kernel Imported successfully
2024-02-04 22:15:57,410:INFO:Starting cross validation
2024-02-04 22:15:57,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:58,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,270:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,272:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,297:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,304:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,307:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,314:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,326:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,711:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,713:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,718:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-04 22:15:58,729:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,738:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:58,756:INFO:Calculating mean and std
2024-02-04 22:15:58,757:INFO:Creating metrics dataframe
2024-02-04 22:15:58,761:INFO:Uploading results into container
2024-02-04 22:15:58,761:INFO:Uploading model into container now
2024-02-04 22:15:58,761:INFO:_master_model_container: 5
2024-02-04 22:15:58,761:INFO:_display_container: 2
2024-02-04 22:15:58,762:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=517, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-04 22:15:58,762:INFO:create_model() successfully completed......................................
2024-02-04 22:15:58,842:INFO:SubProcess create_model() end ==================================
2024-02-04 22:15:58,844:INFO:Creating metrics dataframe
2024-02-04 22:15:58,854:INFO:Initializing Ridge Classifier
2024-02-04 22:15:58,854:INFO:Total runtime is 0.298820424079895 minutes
2024-02-04 22:15:58,858:INFO:SubProcess create_model() called ==================================
2024-02-04 22:15:58,858:INFO:Initializing create_model()
2024-02-04 22:15:58,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:15:58,858:INFO:Checking exceptions
2024-02-04 22:15:58,858:INFO:Importing libraries
2024-02-04 22:15:58,858:INFO:Copying training dataset
2024-02-04 22:15:58,865:INFO:Defining folds
2024-02-04 22:15:58,865:INFO:Declaring metric variables
2024-02-04 22:15:58,869:INFO:Importing untrained model
2024-02-04 22:15:58,874:INFO:Ridge Classifier Imported successfully
2024-02-04 22:15:58,883:INFO:Starting cross validation
2024-02-04 22:15:58,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:15:59,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,616:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,617:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,618:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,629:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,637:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,639:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,640:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,658:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:15:59,659:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,665:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:15:59,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,039:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-04 22:16:00,041:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,051:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,051:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:00,067:INFO:Calculating mean and std
2024-02-04 22:16:00,068:INFO:Creating metrics dataframe
2024-02-04 22:16:00,072:INFO:Uploading results into container
2024-02-04 22:16:00,072:INFO:Uploading model into container now
2024-02-04 22:16:00,073:INFO:_master_model_container: 6
2024-02-04 22:16:00,073:INFO:_display_container: 2
2024-02-04 22:16:00,073:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)
2024-02-04 22:16:00,073:INFO:create_model() successfully completed......................................
2024-02-04 22:16:00,143:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:00,144:INFO:Creating metrics dataframe
2024-02-04 22:16:00,158:INFO:Initializing Random Forest Classifier
2024-02-04 22:16:00,159:INFO:Total runtime is 0.320579449335734 minutes
2024-02-04 22:16:00,163:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:00,163:INFO:Initializing create_model()
2024-02-04 22:16:00,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:00,164:INFO:Checking exceptions
2024-02-04 22:16:00,164:INFO:Importing libraries
2024-02-04 22:16:00,164:INFO:Copying training dataset
2024-02-04 22:16:00,171:INFO:Defining folds
2024-02-04 22:16:00,171:INFO:Declaring metric variables
2024-02-04 22:16:00,176:INFO:Importing untrained model
2024-02-04 22:16:00,183:INFO:Random Forest Classifier Imported successfully
2024-02-04 22:16:00,191:INFO:Starting cross validation
2024-02-04 22:16:00,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:02,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,262:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,273:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,291:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,335:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,350:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,354:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,365:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,470:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,476:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,478:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:02,493:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,294:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:03,316:INFO:Calculating mean and std
2024-02-04 22:16:03,317:INFO:Creating metrics dataframe
2024-02-04 22:16:03,322:INFO:Uploading results into container
2024-02-04 22:16:03,323:INFO:Uploading model into container now
2024-02-04 22:16:03,323:INFO:_master_model_container: 7
2024-02-04 22:16:03,323:INFO:_display_container: 2
2024-02-04 22:16:03,324:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=517, verbose=0, warm_start=False)
2024-02-04 22:16:03,324:INFO:create_model() successfully completed......................................
2024-02-04 22:16:03,415:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:03,415:INFO:Creating metrics dataframe
2024-02-04 22:16:03,429:INFO:Initializing Quadratic Discriminant Analysis
2024-02-04 22:16:03,429:INFO:Total runtime is 0.3750845710436503 minutes
2024-02-04 22:16:03,434:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:03,435:INFO:Initializing create_model()
2024-02-04 22:16:03,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:03,435:INFO:Checking exceptions
2024-02-04 22:16:03,435:INFO:Importing libraries
2024-02-04 22:16:03,436:INFO:Copying training dataset
2024-02-04 22:16:03,443:INFO:Defining folds
2024-02-04 22:16:03,443:INFO:Declaring metric variables
2024-02-04 22:16:03,447:INFO:Importing untrained model
2024-02-04 22:16:03,455:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-04 22:16:03,465:INFO:Starting cross validation
2024-02-04 22:16:03,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:04,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,076:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,091:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,297:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,334:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,348:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,374:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,388:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,395:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,417:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,426:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,696:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-02-04 22:16:04,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,809:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,814:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,820:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:04,841:INFO:Calculating mean and std
2024-02-04 22:16:04,842:INFO:Creating metrics dataframe
2024-02-04 22:16:04,848:INFO:Uploading results into container
2024-02-04 22:16:04,849:INFO:Uploading model into container now
2024-02-04 22:16:04,850:INFO:_master_model_container: 8
2024-02-04 22:16:04,850:INFO:_display_container: 2
2024-02-04 22:16:04,851:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-04 22:16:04,851:INFO:create_model() successfully completed......................................
2024-02-04 22:16:04,929:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:04,930:INFO:Creating metrics dataframe
2024-02-04 22:16:04,946:INFO:Initializing Ada Boost Classifier
2024-02-04 22:16:04,946:INFO:Total runtime is 0.40036038160324094 minutes
2024-02-04 22:16:04,952:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:04,952:INFO:Initializing create_model()
2024-02-04 22:16:04,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:04,953:INFO:Checking exceptions
2024-02-04 22:16:04,953:INFO:Importing libraries
2024-02-04 22:16:04,953:INFO:Copying training dataset
2024-02-04 22:16:04,961:INFO:Defining folds
2024-02-04 22:16:04,962:INFO:Declaring metric variables
2024-02-04 22:16:04,968:INFO:Importing untrained model
2024-02-04 22:16:04,975:INFO:Ada Boost Classifier Imported successfully
2024-02-04 22:16:04,985:INFO:Starting cross validation
2024-02-04 22:16:04,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:06,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,422:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,422:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,433:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,442:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,470:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,482:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,494:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,625:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,625:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,626:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,635:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,638:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,646:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:06,647:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,268:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,277:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,282:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:07,301:INFO:Calculating mean and std
2024-02-04 22:16:07,302:INFO:Creating metrics dataframe
2024-02-04 22:16:07,307:INFO:Uploading results into container
2024-02-04 22:16:07,308:INFO:Uploading model into container now
2024-02-04 22:16:07,308:INFO:_master_model_container: 9
2024-02-04 22:16:07,309:INFO:_display_container: 2
2024-02-04 22:16:07,309:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517)
2024-02-04 22:16:07,309:INFO:create_model() successfully completed......................................
2024-02-04 22:16:07,393:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:07,393:INFO:Creating metrics dataframe
2024-02-04 22:16:07,406:INFO:Initializing Gradient Boosting Classifier
2024-02-04 22:16:07,407:INFO:Total runtime is 0.4413581053415934 minutes
2024-02-04 22:16:07,410:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:07,411:INFO:Initializing create_model()
2024-02-04 22:16:07,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:07,411:INFO:Checking exceptions
2024-02-04 22:16:07,411:INFO:Importing libraries
2024-02-04 22:16:07,411:INFO:Copying training dataset
2024-02-04 22:16:07,418:INFO:Defining folds
2024-02-04 22:16:07,418:INFO:Declaring metric variables
2024-02-04 22:16:07,423:INFO:Importing untrained model
2024-02-04 22:16:07,428:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:16:07,436:INFO:Starting cross validation
2024-02-04 22:16:07,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:09,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,733:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,744:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,754:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,772:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,783:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,833:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,843:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,855:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,888:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:09,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,242:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,248:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,274:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,279:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,284:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:11,306:INFO:Calculating mean and std
2024-02-04 22:16:11,307:INFO:Creating metrics dataframe
2024-02-04 22:16:11,312:INFO:Uploading results into container
2024-02-04 22:16:11,313:INFO:Uploading model into container now
2024-02-04 22:16:11,313:INFO:_master_model_container: 10
2024-02-04 22:16:11,313:INFO:_display_container: 2
2024-02-04 22:16:11,314:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:16:11,314:INFO:create_model() successfully completed......................................
2024-02-04 22:16:11,399:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:11,399:INFO:Creating metrics dataframe
2024-02-04 22:16:11,415:INFO:Initializing Linear Discriminant Analysis
2024-02-04 22:16:11,415:INFO:Total runtime is 0.5081818342208863 minutes
2024-02-04 22:16:11,421:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:11,421:INFO:Initializing create_model()
2024-02-04 22:16:11,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:11,422:INFO:Checking exceptions
2024-02-04 22:16:11,422:INFO:Importing libraries
2024-02-04 22:16:11,422:INFO:Copying training dataset
2024-02-04 22:16:11,429:INFO:Defining folds
2024-02-04 22:16:11,430:INFO:Declaring metric variables
2024-02-04 22:16:11,435:INFO:Importing untrained model
2024-02-04 22:16:11,440:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 22:16:11,449:INFO:Starting cross validation
2024-02-04 22:16:11,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:12,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,276:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,288:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,292:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,298:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,310:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,338:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,351:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,378:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,748:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,754:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,757:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,759:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,763:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,768:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:12,780:INFO:Calculating mean and std
2024-02-04 22:16:12,781:INFO:Creating metrics dataframe
2024-02-04 22:16:12,786:INFO:Uploading results into container
2024-02-04 22:16:12,786:INFO:Uploading model into container now
2024-02-04 22:16:12,787:INFO:_master_model_container: 11
2024-02-04 22:16:12,787:INFO:_display_container: 2
2024-02-04 22:16:12,788:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:16:12,788:INFO:create_model() successfully completed......................................
2024-02-04 22:16:12,874:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:12,874:INFO:Creating metrics dataframe
2024-02-04 22:16:12,888:INFO:Initializing Extra Trees Classifier
2024-02-04 22:16:12,889:INFO:Total runtime is 0.5327423095703125 minutes
2024-02-04 22:16:12,892:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:12,893:INFO:Initializing create_model()
2024-02-04 22:16:12,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:12,893:INFO:Checking exceptions
2024-02-04 22:16:12,893:INFO:Importing libraries
2024-02-04 22:16:12,894:INFO:Copying training dataset
2024-02-04 22:16:12,901:INFO:Defining folds
2024-02-04 22:16:12,901:INFO:Declaring metric variables
2024-02-04 22:16:12,905:INFO:Importing untrained model
2024-02-04 22:16:12,912:INFO:Extra Trees Classifier Imported successfully
2024-02-04 22:16:12,927:INFO:Starting cross validation
2024-02-04 22:16:12,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:14,920:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,931:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,942:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,959:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,976:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,980:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,987:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:14,990:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,007:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,105:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,117:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,129:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,903:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:15,917:INFO:Calculating mean and std
2024-02-04 22:16:15,918:INFO:Creating metrics dataframe
2024-02-04 22:16:15,922:INFO:Uploading results into container
2024-02-04 22:16:15,923:INFO:Uploading model into container now
2024-02-04 22:16:15,923:INFO:_master_model_container: 12
2024-02-04 22:16:15,923:INFO:_display_container: 2
2024-02-04 22:16:15,924:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=517, verbose=0, warm_start=False)
2024-02-04 22:16:15,924:INFO:create_model() successfully completed......................................
2024-02-04 22:16:15,997:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:15,997:INFO:Creating metrics dataframe
2024-02-04 22:16:16,011:INFO:Initializing Light Gradient Boosting Machine
2024-02-04 22:16:16,011:INFO:Total runtime is 0.5847766757011414 minutes
2024-02-04 22:16:16,017:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:16,018:INFO:Initializing create_model()
2024-02-04 22:16:16,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:16,018:INFO:Checking exceptions
2024-02-04 22:16:16,018:INFO:Importing libraries
2024-02-04 22:16:16,018:INFO:Copying training dataset
2024-02-04 22:16:16,027:INFO:Defining folds
2024-02-04 22:16:16,027:INFO:Declaring metric variables
2024-02-04 22:16:16,030:INFO:Importing untrained model
2024-02-04 22:16:16,036:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-04 22:16:16,044:INFO:Starting cross validation
2024-02-04 22:16:16,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:17,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,336:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,343:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,347:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,370:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,379:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,495:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,505:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,687:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,698:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,707:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,726:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,888:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,906:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:17,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,209:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,223:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,226:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:18,248:INFO:Calculating mean and std
2024-02-04 22:16:18,249:INFO:Creating metrics dataframe
2024-02-04 22:16:18,256:INFO:Uploading results into container
2024-02-04 22:16:18,257:INFO:Uploading model into container now
2024-02-04 22:16:18,258:INFO:_master_model_container: 13
2024-02-04 22:16:18,258:INFO:_display_container: 2
2024-02-04 22:16:18,259:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=517, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-04 22:16:18,260:INFO:create_model() successfully completed......................................
2024-02-04 22:16:18,360:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:18,361:INFO:Creating metrics dataframe
2024-02-04 22:16:18,376:INFO:Initializing CatBoost Classifier
2024-02-04 22:16:18,376:INFO:Total runtime is 0.6241966128349306 minutes
2024-02-04 22:16:18,380:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:18,381:INFO:Initializing create_model()
2024-02-04 22:16:18,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:18,381:INFO:Checking exceptions
2024-02-04 22:16:18,381:INFO:Importing libraries
2024-02-04 22:16:18,381:INFO:Copying training dataset
2024-02-04 22:16:18,388:INFO:Defining folds
2024-02-04 22:16:18,388:INFO:Declaring metric variables
2024-02-04 22:16:18,393:INFO:Importing untrained model
2024-02-04 22:16:18,399:INFO:CatBoost Classifier Imported successfully
2024-02-04 22:16:18,408:INFO:Starting cross validation
2024-02-04 22:16:18,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:32,875:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:32,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:32,896:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,115:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,421:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,483:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,494:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,563:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,606:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,616:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,627:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,870:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,881:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:33,891:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:38,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:38,816:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:38,826:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:39,049:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:39,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:39,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:39,076:INFO:Calculating mean and std
2024-02-04 22:16:39,078:INFO:Creating metrics dataframe
2024-02-04 22:16:39,082:INFO:Uploading results into container
2024-02-04 22:16:39,082:INFO:Uploading model into container now
2024-02-04 22:16:39,083:INFO:_master_model_container: 14
2024-02-04 22:16:39,083:INFO:_display_container: 2
2024-02-04 22:16:39,083:INFO:<catboost.core.CatBoostClassifier object at 0x000001C7BC5A3040>
2024-02-04 22:16:39,084:INFO:create_model() successfully completed......................................
2024-02-04 22:16:39,169:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:39,170:INFO:Creating metrics dataframe
2024-02-04 22:16:39,187:INFO:Initializing Dummy Classifier
2024-02-04 22:16:39,187:INFO:Total runtime is 0.9710508704185488 minutes
2024-02-04 22:16:39,191:INFO:SubProcess create_model() called ==================================
2024-02-04 22:16:39,192:INFO:Initializing create_model()
2024-02-04 22:16:39,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC336200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:39,192:INFO:Checking exceptions
2024-02-04 22:16:39,192:INFO:Importing libraries
2024-02-04 22:16:39,192:INFO:Copying training dataset
2024-02-04 22:16:39,204:INFO:Defining folds
2024-02-04 22:16:39,204:INFO:Declaring metric variables
2024-02-04 22:16:39,208:INFO:Importing untrained model
2024-02-04 22:16:39,215:INFO:Dummy Classifier Imported successfully
2024-02-04 22:16:39,225:INFO:Starting cross validation
2024-02-04 22:16:39,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:16:40,001:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,014:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,020:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,027:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,028:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,035:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,046:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,077:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,088:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,101:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,112:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,118:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,136:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,143:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,558:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,583:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,586:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-04 22:16:40,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:16:40,610:INFO:Calculating mean and std
2024-02-04 22:16:40,611:INFO:Creating metrics dataframe
2024-02-04 22:16:40,616:INFO:Uploading results into container
2024-02-04 22:16:40,616:INFO:Uploading model into container now
2024-02-04 22:16:40,617:INFO:_master_model_container: 15
2024-02-04 22:16:40,617:INFO:_display_container: 2
2024-02-04 22:16:40,617:INFO:DummyClassifier(constant=None, random_state=517, strategy='prior')
2024-02-04 22:16:40,617:INFO:create_model() successfully completed......................................
2024-02-04 22:16:40,704:INFO:SubProcess create_model() end ==================================
2024-02-04 22:16:40,704:INFO:Creating metrics dataframe
2024-02-04 22:16:40,735:INFO:Initializing create_model()
2024-02-04 22:16:40,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:40,735:INFO:Checking exceptions
2024-02-04 22:16:40,738:INFO:Importing libraries
2024-02-04 22:16:40,738:INFO:Copying training dataset
2024-02-04 22:16:40,746:INFO:Defining folds
2024-02-04 22:16:40,746:INFO:Declaring metric variables
2024-02-04 22:16:40,746:INFO:Importing untrained model
2024-02-04 22:16:40,746:INFO:Declaring custom model
2024-02-04 22:16:40,747:INFO:Ada Boost Classifier Imported successfully
2024-02-04 22:16:40,749:INFO:Cross validation set to False
2024-02-04 22:16:40,750:INFO:Fitting Model
2024-02-04 22:16:41,249:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517)
2024-02-04 22:16:41,250:INFO:create_model() successfully completed......................................
2024-02-04 22:16:41,325:INFO:Initializing create_model()
2024-02-04 22:16:41,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:41,325:INFO:Checking exceptions
2024-02-04 22:16:41,328:INFO:Importing libraries
2024-02-04 22:16:41,329:INFO:Copying training dataset
2024-02-04 22:16:41,335:INFO:Defining folds
2024-02-04 22:16:41,335:INFO:Declaring metric variables
2024-02-04 22:16:41,336:INFO:Importing untrained model
2024-02-04 22:16:41,336:INFO:Declaring custom model
2024-02-04 22:16:41,336:INFO:Logistic Regression Imported successfully
2024-02-04 22:16:41,338:INFO:Cross validation set to False
2024-02-04 22:16:41,338:INFO:Fitting Model
2024-02-04 22:16:41,605:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:16:41,605:INFO:create_model() successfully completed......................................
2024-02-04 22:16:41,678:INFO:Initializing create_model()
2024-02-04 22:16:41,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:41,679:INFO:Checking exceptions
2024-02-04 22:16:41,681:INFO:Importing libraries
2024-02-04 22:16:41,681:INFO:Copying training dataset
2024-02-04 22:16:41,687:INFO:Defining folds
2024-02-04 22:16:41,688:INFO:Declaring metric variables
2024-02-04 22:16:41,688:INFO:Importing untrained model
2024-02-04 22:16:41,688:INFO:Declaring custom model
2024-02-04 22:16:41,688:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 22:16:41,691:INFO:Cross validation set to False
2024-02-04 22:16:41,691:INFO:Fitting Model
2024-02-04 22:16:41,898:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:16:41,898:INFO:create_model() successfully completed......................................
2024-02-04 22:16:41,973:INFO:Initializing create_model()
2024-02-04 22:16:41,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:41,973:INFO:Checking exceptions
2024-02-04 22:16:41,974:INFO:Importing libraries
2024-02-04 22:16:41,974:INFO:Copying training dataset
2024-02-04 22:16:41,982:INFO:Defining folds
2024-02-04 22:16:41,982:INFO:Declaring metric variables
2024-02-04 22:16:41,982:INFO:Importing untrained model
2024-02-04 22:16:41,982:INFO:Declaring custom model
2024-02-04 22:16:41,983:INFO:Ridge Classifier Imported successfully
2024-02-04 22:16:41,985:INFO:Cross validation set to False
2024-02-04 22:16:41,985:INFO:Fitting Model
2024-02-04 22:16:42,188:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)
2024-02-04 22:16:42,189:INFO:create_model() successfully completed......................................
2024-02-04 22:16:42,261:INFO:Initializing create_model()
2024-02-04 22:16:42,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:16:42,262:INFO:Checking exceptions
2024-02-04 22:16:42,266:INFO:Importing libraries
2024-02-04 22:16:42,266:INFO:Copying training dataset
2024-02-04 22:16:42,272:INFO:Defining folds
2024-02-04 22:16:42,272:INFO:Declaring metric variables
2024-02-04 22:16:42,272:INFO:Importing untrained model
2024-02-04 22:16:42,272:INFO:Declaring custom model
2024-02-04 22:16:42,273:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:16:42,277:INFO:Cross validation set to False
2024-02-04 22:16:42,277:INFO:Fitting Model
2024-02-04 22:16:43,213:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:16:43,214:INFO:create_model() successfully completed......................................
2024-02-04 22:16:43,313:INFO:_master_model_container: 15
2024-02-04 22:16:43,313:INFO:_display_container: 2
2024-02-04 22:16:43,314:INFO:[AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-02-04 22:16:43,314:INFO:compare_models() successfully completed......................................
2024-02-04 22:16:43,326:INFO:Initializing tune_model()
2024-02-04 22:16:43,326:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>)
2024-02-04 22:16:43,326:INFO:Checking exceptions
2024-02-04 22:16:43,348:INFO:Copying training dataset
2024-02-04 22:16:43,353:INFO:Checking base model
2024-02-04 22:16:43,353:INFO:Base model : Ada Boost Classifier
2024-02-04 22:16:43,358:INFO:Declaring metric variables
2024-02-04 22:16:43,364:INFO:Defining Hyperparameters
2024-02-04 22:16:43,448:INFO:Tuning with n_jobs=-1
2024-02-04 22:16:43,448:INFO:Initializing RandomizedSearchCV
2024-02-04 22:17:15,589:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__algorithm': 'SAMME.R'}
2024-02-04 22:17:15,591:INFO:Hyperparameter search completed
2024-02-04 22:17:15,591:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:15,592:INFO:Initializing create_model()
2024-02-04 22:17:15,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC335540>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'learning_rate': 0.15, 'algorithm': 'SAMME.R'})
2024-02-04 22:17:15,592:INFO:Checking exceptions
2024-02-04 22:17:15,593:INFO:Importing libraries
2024-02-04 22:17:15,594:INFO:Copying training dataset
2024-02-04 22:17:15,608:INFO:Defining folds
2024-02-04 22:17:15,608:INFO:Declaring metric variables
2024-02-04 22:17:15,616:INFO:Importing untrained model
2024-02-04 22:17:15,617:INFO:Declaring custom model
2024-02-04 22:17:15,624:INFO:Ada Boost Classifier Imported successfully
2024-02-04 22:17:15,636:INFO:Starting cross validation
2024-02-04 22:17:15,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:17,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,597:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,608:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,644:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:17,654:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,109:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,160:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,173:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,183:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,195:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,206:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:18,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,204:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,205:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,211:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,216:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:19,236:INFO:Calculating mean and std
2024-02-04 22:17:19,238:INFO:Creating metrics dataframe
2024-02-04 22:17:19,244:INFO:Finalizing model
2024-02-04 22:17:20,205:INFO:Uploading results into container
2024-02-04 22:17:20,207:INFO:Uploading model into container now
2024-02-04 22:17:20,208:INFO:_master_model_container: 16
2024-02-04 22:17:20,208:INFO:_display_container: 3
2024-02-04 22:17:20,209:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.15, n_estimators=100,
                   random_state=517)
2024-02-04 22:17:20,209:INFO:create_model() successfully completed......................................
2024-02-04 22:17:20,296:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:20,296:INFO:choose_better activated
2024-02-04 22:17:20,300:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:20,301:INFO:Initializing create_model()
2024-02-04 22:17:20,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:17:20,301:INFO:Checking exceptions
2024-02-04 22:17:20,303:INFO:Importing libraries
2024-02-04 22:17:20,303:INFO:Copying training dataset
2024-02-04 22:17:20,309:INFO:Defining folds
2024-02-04 22:17:20,309:INFO:Declaring metric variables
2024-02-04 22:17:20,309:INFO:Importing untrained model
2024-02-04 22:17:20,310:INFO:Declaring custom model
2024-02-04 22:17:20,310:INFO:Ada Boost Classifier Imported successfully
2024-02-04 22:17:20,310:INFO:Starting cross validation
2024-02-04 22:17:20,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:21,806:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,818:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,830:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,837:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,849:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,861:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,874:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,886:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,887:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,902:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,929:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,931:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,941:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,945:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,950:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,953:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,956:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:21,968:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,637:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,643:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,648:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,650:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,661:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:22,673:INFO:Calculating mean and std
2024-02-04 22:17:22,674:INFO:Creating metrics dataframe
2024-02-04 22:17:22,676:INFO:Finalizing model
2024-02-04 22:17:23,157:INFO:Uploading results into container
2024-02-04 22:17:23,157:INFO:Uploading model into container now
2024-02-04 22:17:23,158:INFO:_master_model_container: 17
2024-02-04 22:17:23,158:INFO:_display_container: 4
2024-02-04 22:17:23,158:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517)
2024-02-04 22:17:23,158:INFO:create_model() successfully completed......................................
2024-02-04 22:17:23,223:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:23,224:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517) result for Accuracy is 0.8012
2024-02-04 22:17:23,225:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.15, n_estimators=100,
                   random_state=517) result for Accuracy is 0.7996
2024-02-04 22:17:23,225:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517) is best model
2024-02-04 22:17:23,225:INFO:choose_better completed
2024-02-04 22:17:23,225:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 22:17:23,235:INFO:_master_model_container: 17
2024-02-04 22:17:23,235:INFO:_display_container: 3
2024-02-04 22:17:23,235:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517)
2024-02-04 22:17:23,235:INFO:tune_model() successfully completed......................................
2024-02-04 22:17:23,314:INFO:Initializing tune_model()
2024-02-04 22:17:23,314:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>)
2024-02-04 22:17:23,314:INFO:Checking exceptions
2024-02-04 22:17:23,333:INFO:Copying training dataset
2024-02-04 22:17:23,338:INFO:Checking base model
2024-02-04 22:17:23,338:INFO:Base model : Logistic Regression
2024-02-04 22:17:23,342:INFO:Declaring metric variables
2024-02-04 22:17:23,346:INFO:Defining Hyperparameters
2024-02-04 22:17:23,438:INFO:Tuning with n_jobs=-1
2024-02-04 22:17:23,438:INFO:Initializing RandomizedSearchCV
2024-02-04 22:17:36,005:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.465000000000001}
2024-02-04 22:17:36,005:INFO:Hyperparameter search completed
2024-02-04 22:17:36,006:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:36,007:INFO:Initializing create_model()
2024-02-04 22:17:36,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC335540>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.465000000000001})
2024-02-04 22:17:36,007:INFO:Checking exceptions
2024-02-04 22:17:36,007:INFO:Importing libraries
2024-02-04 22:17:36,007:INFO:Copying training dataset
2024-02-04 22:17:36,018:INFO:Defining folds
2024-02-04 22:17:36,019:INFO:Declaring metric variables
2024-02-04 22:17:36,023:INFO:Importing untrained model
2024-02-04 22:17:36,023:INFO:Declaring custom model
2024-02-04 22:17:36,029:INFO:Logistic Regression Imported successfully
2024-02-04 22:17:36,038:INFO:Starting cross validation
2024-02-04 22:17:36,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:37,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,081:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,094:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,124:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,126:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,135:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,137:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,141:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,146:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,148:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,218:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,231:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,632:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,637:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,642:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,672:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,677:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:37,698:INFO:Calculating mean and std
2024-02-04 22:17:37,699:INFO:Creating metrics dataframe
2024-02-04 22:17:37,705:INFO:Finalizing model
2024-02-04 22:17:38,032:INFO:Uploading results into container
2024-02-04 22:17:38,034:INFO:Uploading model into container now
2024-02-04 22:17:38,035:INFO:_master_model_container: 18
2024-02-04 22:17:38,035:INFO:_display_container: 4
2024-02-04 22:17:38,036:INFO:LogisticRegression(C=5.465000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:17:38,036:INFO:create_model() successfully completed......................................
2024-02-04 22:17:38,124:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:38,124:INFO:choose_better activated
2024-02-04 22:17:38,128:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:38,128:INFO:Initializing create_model()
2024-02-04 22:17:38,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:17:38,128:INFO:Checking exceptions
2024-02-04 22:17:38,131:INFO:Importing libraries
2024-02-04 22:17:38,131:INFO:Copying training dataset
2024-02-04 22:17:38,137:INFO:Defining folds
2024-02-04 22:17:38,138:INFO:Declaring metric variables
2024-02-04 22:17:38,138:INFO:Importing untrained model
2024-02-04 22:17:38,138:INFO:Declaring custom model
2024-02-04 22:17:38,139:INFO:Logistic Regression Imported successfully
2024-02-04 22:17:38,139:INFO:Starting cross validation
2024-02-04 22:17:38,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:39,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,057:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,068:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,071:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,079:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,083:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,094:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,096:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,099:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,110:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,154:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,164:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,184:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,608:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,614:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,620:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,633:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:39,647:INFO:Calculating mean and std
2024-02-04 22:17:39,648:INFO:Creating metrics dataframe
2024-02-04 22:17:39,650:INFO:Finalizing model
2024-02-04 22:17:39,986:INFO:Uploading results into container
2024-02-04 22:17:39,986:INFO:Uploading model into container now
2024-02-04 22:17:39,987:INFO:_master_model_container: 19
2024-02-04 22:17:39,987:INFO:_display_container: 5
2024-02-04 22:17:39,987:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:17:39,987:INFO:create_model() successfully completed......................................
2024-02-04 22:17:40,062:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:40,063:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8005
2024-02-04 22:17:40,063:INFO:LogisticRegression(C=5.465000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8012
2024-02-04 22:17:40,064:INFO:LogisticRegression(C=5.465000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-02-04 22:17:40,064:INFO:choose_better completed
2024-02-04 22:17:40,074:INFO:_master_model_container: 19
2024-02-04 22:17:40,074:INFO:_display_container: 4
2024-02-04 22:17:40,074:INFO:LogisticRegression(C=5.465000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-04 22:17:40,075:INFO:tune_model() successfully completed......................................
2024-02-04 22:17:40,144:INFO:Initializing tune_model()
2024-02-04 22:17:40,144:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>)
2024-02-04 22:17:40,144:INFO:Checking exceptions
2024-02-04 22:17:40,162:INFO:Copying training dataset
2024-02-04 22:17:40,167:INFO:Checking base model
2024-02-04 22:17:40,168:INFO:Base model : Linear Discriminant Analysis
2024-02-04 22:17:40,173:INFO:Declaring metric variables
2024-02-04 22:17:40,177:INFO:Defining Hyperparameters
2024-02-04 22:17:40,276:INFO:Tuning with n_jobs=-1
2024-02-04 22:17:40,276:INFO:Initializing RandomizedSearchCV
2024-02-04 22:17:51,294:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2024-02-04 22:17:51,295:INFO:Hyperparameter search completed
2024-02-04 22:17:51,295:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:51,296:INFO:Initializing create_model()
2024-02-04 22:17:51,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BD84BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2024-02-04 22:17:51,297:INFO:Checking exceptions
2024-02-04 22:17:51,297:INFO:Importing libraries
2024-02-04 22:17:51,297:INFO:Copying training dataset
2024-02-04 22:17:51,314:INFO:Defining folds
2024-02-04 22:17:51,314:INFO:Declaring metric variables
2024-02-04 22:17:51,321:INFO:Importing untrained model
2024-02-04 22:17:51,321:INFO:Declaring custom model
2024-02-04 22:17:51,329:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 22:17:51,341:INFO:Starting cross validation
2024-02-04 22:17:51,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:52,198:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,210:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,223:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,227:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,232:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,238:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,240:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,244:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,253:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,265:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,266:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,278:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,287:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,299:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,302:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,309:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,756:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,762:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,779:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,784:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,789:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:52,808:INFO:Calculating mean and std
2024-02-04 22:17:52,810:INFO:Creating metrics dataframe
2024-02-04 22:17:52,816:INFO:Finalizing model
2024-02-04 22:17:53,122:INFO:Uploading results into container
2024-02-04 22:17:53,123:INFO:Uploading model into container now
2024-02-04 22:17:53,124:INFO:_master_model_container: 20
2024-02-04 22:17:53,125:INFO:_display_container: 5
2024-02-04 22:17:53,125:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:17:53,126:INFO:create_model() successfully completed......................................
2024-02-04 22:17:53,221:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:53,221:INFO:choose_better activated
2024-02-04 22:17:53,225:INFO:SubProcess create_model() called ==================================
2024-02-04 22:17:53,226:INFO:Initializing create_model()
2024-02-04 22:17:53,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:17:53,226:INFO:Checking exceptions
2024-02-04 22:17:53,228:INFO:Importing libraries
2024-02-04 22:17:53,229:INFO:Copying training dataset
2024-02-04 22:17:53,237:INFO:Defining folds
2024-02-04 22:17:53,237:INFO:Declaring metric variables
2024-02-04 22:17:53,238:INFO:Importing untrained model
2024-02-04 22:17:53,238:INFO:Declaring custom model
2024-02-04 22:17:53,238:INFO:Linear Discriminant Analysis Imported successfully
2024-02-04 22:17:53,239:INFO:Starting cross validation
2024-02-04 22:17:53,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:17:54,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,074:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,078:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,098:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,108:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,119:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,132:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,152:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,162:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,187:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,221:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,234:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,235:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,245:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,247:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,257:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,655:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,666:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,680:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,685:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:17:54,707:INFO:Calculating mean and std
2024-02-04 22:17:54,708:INFO:Creating metrics dataframe
2024-02-04 22:17:54,710:INFO:Finalizing model
2024-02-04 22:17:54,945:INFO:Uploading results into container
2024-02-04 22:17:54,945:INFO:Uploading model into container now
2024-02-04 22:17:54,946:INFO:_master_model_container: 21
2024-02-04 22:17:54,946:INFO:_display_container: 6
2024-02-04 22:17:54,946:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:17:54,946:INFO:create_model() successfully completed......................................
2024-02-04 22:17:55,013:INFO:SubProcess create_model() end ==================================
2024-02-04 22:17:55,014:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for Accuracy is 0.7956
2024-02-04 22:17:55,014:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for Accuracy is 0.7936
2024-02-04 22:17:55,014:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2024-02-04 22:17:55,014:INFO:choose_better completed
2024-02-04 22:17:55,014:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-04 22:17:55,025:INFO:_master_model_container: 21
2024-02-04 22:17:55,025:INFO:_display_container: 5
2024-02-04 22:17:55,026:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-04 22:17:55,026:INFO:tune_model() successfully completed......................................
2024-02-04 22:17:55,102:INFO:Initializing tune_model()
2024-02-04 22:17:55,103:INFO:tune_model(estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>)
2024-02-04 22:17:55,103:INFO:Checking exceptions
2024-02-04 22:17:55,119:INFO:Copying training dataset
2024-02-04 22:17:55,124:INFO:Checking base model
2024-02-04 22:17:55,124:INFO:Base model : Ridge Classifier
2024-02-04 22:17:55,129:INFO:Declaring metric variables
2024-02-04 22:17:55,133:INFO:Defining Hyperparameters
2024-02-04 22:17:55,227:INFO:Tuning with n_jobs=-1
2024-02-04 22:17:55,228:INFO:Initializing RandomizedSearchCV
2024-02-04 22:18:05,570:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 9.53}
2024-02-04 22:18:05,571:INFO:Hyperparameter search completed
2024-02-04 22:18:05,572:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:05,573:INFO:Initializing create_model()
2024-02-04 22:18:05,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC579AE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 9.53})
2024-02-04 22:18:05,573:INFO:Checking exceptions
2024-02-04 22:18:05,573:INFO:Importing libraries
2024-02-04 22:18:05,574:INFO:Copying training dataset
2024-02-04 22:18:05,586:INFO:Defining folds
2024-02-04 22:18:05,586:INFO:Declaring metric variables
2024-02-04 22:18:05,590:INFO:Importing untrained model
2024-02-04 22:18:05,591:INFO:Declaring custom model
2024-02-04 22:18:05,595:INFO:Ridge Classifier Imported successfully
2024-02-04 22:18:05,604:INFO:Starting cross validation
2024-02-04 22:18:05,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:18:06,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,400:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,412:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,422:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,424:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,448:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,451:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,468:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,478:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,514:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,515:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,521:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,526:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,532:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,545:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,552:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,557:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,557:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,567:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,578:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,921:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,927:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:06,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,935:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,940:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:06,964:INFO:Calculating mean and std
2024-02-04 22:18:06,965:INFO:Creating metrics dataframe
2024-02-04 22:18:06,972:INFO:Finalizing model
2024-02-04 22:18:07,237:INFO:Uploading results into container
2024-02-04 22:18:07,238:INFO:Uploading model into container now
2024-02-04 22:18:07,239:INFO:_master_model_container: 22
2024-02-04 22:18:07,239:INFO:_display_container: 6
2024-02-04 22:18:07,240:INFO:RidgeClassifier(alpha=9.53, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)
2024-02-04 22:18:07,240:INFO:create_model() successfully completed......................................
2024-02-04 22:18:07,326:INFO:SubProcess create_model() end ==================================
2024-02-04 22:18:07,326:INFO:choose_better activated
2024-02-04 22:18:07,329:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:07,330:INFO:Initializing create_model()
2024-02-04 22:18:07,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:18:07,330:INFO:Checking exceptions
2024-02-04 22:18:07,332:INFO:Importing libraries
2024-02-04 22:18:07,332:INFO:Copying training dataset
2024-02-04 22:18:07,338:INFO:Defining folds
2024-02-04 22:18:07,338:INFO:Declaring metric variables
2024-02-04 22:18:07,338:INFO:Importing untrained model
2024-02-04 22:18:07,338:INFO:Declaring custom model
2024-02-04 22:18:07,338:INFO:Ridge Classifier Imported successfully
2024-02-04 22:18:07,338:INFO:Starting cross validation
2024-02-04 22:18:07,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:18:08,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,145:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,172:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,178:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,179:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,185:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,189:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,196:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,197:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,203:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,208:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,214:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,221:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,227:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,233:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,239:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,250:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,271:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,313:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,324:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,691:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,701:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: '_predict_proba_lr'?

  warnings.warn(

2024-02-04 22:18:08,709:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,720:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:08,739:INFO:Calculating mean and std
2024-02-04 22:18:08,740:INFO:Creating metrics dataframe
2024-02-04 22:18:08,742:INFO:Finalizing model
2024-02-04 22:18:08,988:INFO:Uploading results into container
2024-02-04 22:18:08,989:INFO:Uploading model into container now
2024-02-04 22:18:08,989:INFO:_master_model_container: 23
2024-02-04 22:18:08,989:INFO:_display_container: 7
2024-02-04 22:18:08,989:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)
2024-02-04 22:18:08,990:INFO:create_model() successfully completed......................................
2024-02-04 22:18:09,060:INFO:SubProcess create_model() end ==================================
2024-02-04 22:18:09,061:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001) result for Accuracy is 0.7976
2024-02-04 22:18:09,061:INFO:RidgeClassifier(alpha=9.53, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001) result for Accuracy is 0.7983
2024-02-04 22:18:09,062:INFO:RidgeClassifier(alpha=9.53, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001) is best model
2024-02-04 22:18:09,062:INFO:choose_better completed
2024-02-04 22:18:09,072:INFO:_master_model_container: 23
2024-02-04 22:18:09,072:INFO:_display_container: 6
2024-02-04 22:18:09,072:INFO:RidgeClassifier(alpha=9.53, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)
2024-02-04 22:18:09,072:INFO:tune_model() successfully completed......................................
2024-02-04 22:18:09,152:INFO:Initializing tune_model()
2024-02-04 22:18:09,152:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>)
2024-02-04 22:18:09,152:INFO:Checking exceptions
2024-02-04 22:18:09,172:INFO:Copying training dataset
2024-02-04 22:18:09,178:INFO:Checking base model
2024-02-04 22:18:09,178:INFO:Base model : Gradient Boosting Classifier
2024-02-04 22:18:09,182:INFO:Declaring metric variables
2024-02-04 22:18:09,188:INFO:Defining Hyperparameters
2024-02-04 22:18:09,290:INFO:Tuning with n_jobs=-1
2024-02-04 22:18:09,290:INFO:Initializing RandomizedSearchCV
2024-02-04 22:18:39,997:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 1, 'actual_estimator__learning_rate': 0.2}
2024-02-04 22:18:39,998:INFO:Hyperparameter search completed
2024-02-04 22:18:39,998:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:39,999:INFO:Initializing create_model()
2024-02-04 22:18:39,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BDA58760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 150, 'min_samples_split': 7, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.005, 'max_features': 'log2', 'max_depth': 1, 'learning_rate': 0.2})
2024-02-04 22:18:39,999:INFO:Checking exceptions
2024-02-04 22:18:39,999:INFO:Importing libraries
2024-02-04 22:18:40,000:INFO:Copying training dataset
2024-02-04 22:18:40,009:INFO:Defining folds
2024-02-04 22:18:40,009:INFO:Declaring metric variables
2024-02-04 22:18:40,014:INFO:Importing untrained model
2024-02-04 22:18:40,014:INFO:Declaring custom model
2024-02-04 22:18:40,019:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:18:40,027:INFO:Starting cross validation
2024-02-04 22:18:40,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:18:41,315:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,327:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,339:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,346:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,357:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,360:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,368:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,393:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,403:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,414:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,415:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,417:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,425:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,429:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,443:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,455:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:41,472:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,033:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,037:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,042:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,054:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,063:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:42,075:INFO:Calculating mean and std
2024-02-04 22:18:42,076:INFO:Creating metrics dataframe
2024-02-04 22:18:42,082:INFO:Finalizing model
2024-02-04 22:18:42,527:INFO:Uploading results into container
2024-02-04 22:18:42,528:INFO:Uploading model into container now
2024-02-04 22:18:42,529:INFO:_master_model_container: 24
2024-02-04 22:18:42,529:INFO:_display_container: 7
2024-02-04 22:18:42,530:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=1,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=2,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=150, n_iter_no_change=None,
                           random_state=517, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:18:42,530:INFO:create_model() successfully completed......................................
2024-02-04 22:18:42,608:INFO:SubProcess create_model() end ==================================
2024-02-04 22:18:42,608:INFO:choose_better activated
2024-02-04 22:18:42,612:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:42,613:INFO:Initializing create_model()
2024-02-04 22:18:42,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:18:42,613:INFO:Checking exceptions
2024-02-04 22:18:42,614:INFO:Importing libraries
2024-02-04 22:18:42,615:INFO:Copying training dataset
2024-02-04 22:18:42,619:INFO:Defining folds
2024-02-04 22:18:42,619:INFO:Declaring metric variables
2024-02-04 22:18:42,620:INFO:Importing untrained model
2024-02-04 22:18:42,620:INFO:Declaring custom model
2024-02-04 22:18:42,620:INFO:Gradient Boosting Classifier Imported successfully
2024-02-04 22:18:42,621:INFO:Starting cross validation
2024-02-04 22:18:42,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:18:44,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,882:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,893:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,904:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,910:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,927:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,932:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:44,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,031:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,040:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,066:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,073:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,075:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,084:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,086:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:45,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,300:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,323:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:46,336:INFO:Calculating mean and std
2024-02-04 22:18:46,336:INFO:Creating metrics dataframe
2024-02-04 22:18:46,339:INFO:Finalizing model
2024-02-04 22:18:47,470:INFO:Uploading results into container
2024-02-04 22:18:47,470:INFO:Uploading model into container now
2024-02-04 22:18:47,471:INFO:_master_model_container: 25
2024-02-04 22:18:47,471:INFO:_display_container: 8
2024-02-04 22:18:47,472:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:18:47,472:INFO:create_model() successfully completed......................................
2024-02-04 22:18:47,551:INFO:SubProcess create_model() end ==================================
2024-02-04 22:18:47,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7963
2024-02-04 22:18:47,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=1,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=2,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=150, n_iter_no_change=None,
                           random_state=517, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8012
2024-02-04 22:18:47,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=1,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=2,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=150, n_iter_no_change=None,
                           random_state=517, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-04 22:18:47,553:INFO:choose_better completed
2024-02-04 22:18:47,562:INFO:_master_model_container: 25
2024-02-04 22:18:47,562:INFO:_display_container: 7
2024-02-04 22:18:47,562:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=1,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=2,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=150, n_iter_no_change=None,
                           random_state=517, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-04 22:18:47,562:INFO:tune_model() successfully completed......................................
2024-02-04 22:18:47,651:INFO:Initializing ensemble_model()
2024-02-04 22:18:47,651:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:18:47,651:INFO:Checking exceptions
2024-02-04 22:18:47,671:INFO:Importing libraries
2024-02-04 22:18:47,671:INFO:Copying training dataset
2024-02-04 22:18:47,671:INFO:Checking base model
2024-02-04 22:18:47,672:INFO:Base model : Ada Boost Classifier
2024-02-04 22:18:47,679:INFO:Importing untrained ensembler
2024-02-04 22:18:47,679:INFO:Ensemble method set to Bagging
2024-02-04 22:18:47,680:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:47,682:INFO:Initializing create_model()
2024-02-04 22:18:47,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=AdaBoostClassifier(algorithm='SAMME.R',
                                               base_estimator='deprecated',
                                               estimator=None,
                                               learning_rate=1.0,
                                               n_estimators=50,
                                               random_state=517),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BB0D3F70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:18:47,682:INFO:Checking exceptions
2024-02-04 22:18:47,683:INFO:Importing libraries
2024-02-04 22:18:47,683:INFO:Copying training dataset
2024-02-04 22:18:47,693:INFO:Defining folds
2024-02-04 22:18:47,693:INFO:Declaring metric variables
2024-02-04 22:18:47,699:INFO:Importing untrained model
2024-02-04 22:18:47,699:INFO:Declaring custom model
2024-02-04 22:18:47,706:INFO:Bagging Classifier Imported successfully
2024-02-04 22:18:47,715:INFO:Starting cross validation
2024-02-04 22:18:47,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:18:53,600:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,605:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,611:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,616:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,622:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,645:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,656:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,693:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,704:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,715:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,868:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,878:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,889:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,890:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,892:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,899:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,900:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,908:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,924:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,934:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:53,946:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,884:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,897:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,901:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,905:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:18:56,925:INFO:Calculating mean and std
2024-02-04 22:18:56,926:INFO:Creating metrics dataframe
2024-02-04 22:18:56,931:INFO:Finalizing model
2024-02-04 22:18:59,018:INFO:Uploading results into container
2024-02-04 22:18:59,019:INFO:Uploading model into container now
2024-02-04 22:18:59,020:INFO:_master_model_container: 26
2024-02-04 22:18:59,020:INFO:_display_container: 8
2024-02-04 22:18:59,021:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=AdaBoostClassifier(algorithm='SAMME.R',
                                               base_estimator='deprecated',
                                               estimator=None,
                                               learning_rate=1.0,
                                               n_estimators=50,
                                               random_state=517),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:18:59,021:INFO:create_model() successfully completed......................................
2024-02-04 22:18:59,096:INFO:SubProcess create_model() end ==================================
2024-02-04 22:18:59,106:INFO:_master_model_container: 26
2024-02-04 22:18:59,106:INFO:_display_container: 8
2024-02-04 22:18:59,107:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=AdaBoostClassifier(algorithm='SAMME.R',
                                               base_estimator='deprecated',
                                               estimator=None,
                                               learning_rate=1.0,
                                               n_estimators=50,
                                               random_state=517),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:18:59,107:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:18:59,183:INFO:Initializing ensemble_model()
2024-02-04 22:18:59,183:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LogisticRegression(C=5.465000000000001, class_weight={}, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:18:59,183:INFO:Checking exceptions
2024-02-04 22:18:59,203:INFO:Importing libraries
2024-02-04 22:18:59,203:INFO:Copying training dataset
2024-02-04 22:18:59,203:INFO:Checking base model
2024-02-04 22:18:59,204:INFO:Base model : Logistic Regression
2024-02-04 22:18:59,212:INFO:Importing untrained ensembler
2024-02-04 22:18:59,212:INFO:Ensemble method set to Bagging
2024-02-04 22:18:59,212:INFO:SubProcess create_model() called ==================================
2024-02-04 22:18:59,213:INFO:Initializing create_model()
2024-02-04 22:18:59,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LogisticRegression(C=5.465000000000001,
                                               class_weight={}, dual=False,
                                               fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=517,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BD84BDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:18:59,213:INFO:Checking exceptions
2024-02-04 22:18:59,214:INFO:Importing libraries
2024-02-04 22:18:59,214:INFO:Copying training dataset
2024-02-04 22:18:59,222:INFO:Defining folds
2024-02-04 22:18:59,223:INFO:Declaring metric variables
2024-02-04 22:18:59,228:INFO:Importing untrained model
2024-02-04 22:18:59,228:INFO:Declaring custom model
2024-02-04 22:18:59,235:INFO:Bagging Classifier Imported successfully
2024-02-04 22:18:59,244:INFO:Starting cross validation
2024-02-04 22:18:59,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:01,175:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,188:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,201:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,321:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,332:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,333:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,345:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,402:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,409:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,418:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,469:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,472:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,481:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,549:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,559:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,569:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,671:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,678:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:01,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,480:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,486:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,541:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,546:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,551:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:02,566:INFO:Calculating mean and std
2024-02-04 22:19:02,567:INFO:Creating metrics dataframe
2024-02-04 22:19:02,574:INFO:Finalizing model
2024-02-04 22:19:03,622:INFO:Uploading results into container
2024-02-04 22:19:03,623:INFO:Uploading model into container now
2024-02-04 22:19:03,624:INFO:_master_model_container: 27
2024-02-04 22:19:03,625:INFO:_display_container: 9
2024-02-04 22:19:03,627:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LogisticRegression(C=5.465000000000001,
                                               class_weight={}, dual=False,
                                               fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=517,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:03,628:INFO:create_model() successfully completed......................................
2024-02-04 22:19:03,717:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:03,730:INFO:_master_model_container: 27
2024-02-04 22:19:03,730:INFO:_display_container: 9
2024-02-04 22:19:03,731:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LogisticRegression(C=5.465000000000001,
                                               class_weight={}, dual=False,
                                               fit_intercept=True,
                                               intercept_scaling=1,
                                               l1_ratio=None, max_iter=1000,
                                               multi_class='auto', n_jobs=None,
                                               penalty='l2', random_state=517,
                                               solver='lbfgs', tol=0.0001,
                                               verbose=0, warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:03,732:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:19:03,817:INFO:Initializing ensemble_model()
2024-02-04 22:19:03,817:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:19:03,817:INFO:Checking exceptions
2024-02-04 22:19:03,839:INFO:Importing libraries
2024-02-04 22:19:03,839:INFO:Copying training dataset
2024-02-04 22:19:03,839:INFO:Checking base model
2024-02-04 22:19:03,840:INFO:Base model : Linear Discriminant Analysis
2024-02-04 22:19:03,849:INFO:Importing untrained ensembler
2024-02-04 22:19:03,849:INFO:Ensemble method set to Bagging
2024-02-04 22:19:03,849:INFO:SubProcess create_model() called ==================================
2024-02-04 22:19:03,851:INFO:Initializing create_model()
2024-02-04 22:19:03,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                       n_components=None,
                                                       priors=None,
                                                       shrinkage=None,
                                                       solver='svd',
                                                       store_covariance=False,
                                                       tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BDB903D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:03,852:INFO:Checking exceptions
2024-02-04 22:19:03,852:INFO:Importing libraries
2024-02-04 22:19:03,852:INFO:Copying training dataset
2024-02-04 22:19:03,865:INFO:Defining folds
2024-02-04 22:19:03,865:INFO:Declaring metric variables
2024-02-04 22:19:03,872:INFO:Importing untrained model
2024-02-04 22:19:03,872:INFO:Declaring custom model
2024-02-04 22:19:03,879:INFO:Bagging Classifier Imported successfully
2024-02-04 22:19:03,890:INFO:Starting cross validation
2024-02-04 22:19:03,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:04,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,004:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,016:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,032:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,044:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,056:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,058:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,061:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,069:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,072:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,080:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,122:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,128:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,131:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,133:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,136:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,139:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,142:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,144:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,153:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,696:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,717:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,727:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:05,750:INFO:Calculating mean and std
2024-02-04 22:19:05,751:INFO:Creating metrics dataframe
2024-02-04 22:19:05,758:INFO:Finalizing model
2024-02-04 22:19:06,167:INFO:Uploading results into container
2024-02-04 22:19:06,168:INFO:Uploading model into container now
2024-02-04 22:19:06,168:INFO:_master_model_container: 28
2024-02-04 22:19:06,169:INFO:_display_container: 10
2024-02-04 22:19:06,170:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                       n_components=None,
                                                       priors=None,
                                                       shrinkage=None,
                                                       solver='svd',
                                                       store_covariance=False,
                                                       tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:06,170:INFO:create_model() successfully completed......................................
2024-02-04 22:19:06,256:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:06,266:INFO:_master_model_container: 28
2024-02-04 22:19:06,266:INFO:_display_container: 10
2024-02-04 22:19:06,267:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                       n_components=None,
                                                       priors=None,
                                                       shrinkage=None,
                                                       solver='svd',
                                                       store_covariance=False,
                                                       tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:06,267:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:19:06,342:INFO:Initializing ensemble_model()
2024-02-04 22:19:06,342:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=RidgeClassifier(alpha=9.53, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:19:06,342:INFO:Checking exceptions
2024-02-04 22:19:06,361:INFO:Importing libraries
2024-02-04 22:19:06,361:INFO:Copying training dataset
2024-02-04 22:19:06,361:INFO:Checking base model
2024-02-04 22:19:06,361:INFO:Base model : Ridge Classifier
2024-02-04 22:19:06,371:INFO:Importing untrained ensembler
2024-02-04 22:19:06,371:INFO:Ensemble method set to Bagging
2024-02-04 22:19:06,372:INFO:SubProcess create_model() called ==================================
2024-02-04 22:19:06,373:INFO:Initializing create_model()
2024-02-04 22:19:06,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RidgeClassifier(alpha=9.53, class_weight=None,
                                            copy_X=True, fit_intercept=False,
                                            max_iter=None, positive=False,
                                            random_state=517, solver='auto',
                                            tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BB0D33D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:06,374:INFO:Checking exceptions
2024-02-04 22:19:06,374:INFO:Importing libraries
2024-02-04 22:19:06,374:INFO:Copying training dataset
2024-02-04 22:19:06,381:INFO:Defining folds
2024-02-04 22:19:06,382:INFO:Declaring metric variables
2024-02-04 22:19:06,387:INFO:Importing untrained model
2024-02-04 22:19:06,387:INFO:Declaring custom model
2024-02-04 22:19:06,396:INFO:Bagging Classifier Imported successfully
2024-02-04 22:19:06,407:INFO:Starting cross validation
2024-02-04 22:19:06,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:07,289:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,295:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,301:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,306:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,311:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,317:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,329:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,352:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,412:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,425:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,430:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,437:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,441:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,451:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,467:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,479:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,489:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,937:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,949:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,953:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,960:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,965:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:07,987:INFO:Calculating mean and std
2024-02-04 22:19:07,988:INFO:Creating metrics dataframe
2024-02-04 22:19:07,995:INFO:Finalizing model
2024-02-04 22:19:08,301:INFO:Uploading results into container
2024-02-04 22:19:08,302:INFO:Uploading model into container now
2024-02-04 22:19:08,303:INFO:_master_model_container: 29
2024-02-04 22:19:08,303:INFO:_display_container: 11
2024-02-04 22:19:08,306:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RidgeClassifier(alpha=9.53, class_weight=None,
                                            copy_X=True, fit_intercept=False,
                                            max_iter=None, positive=False,
                                            random_state=517, solver='auto',
                                            tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:08,306:INFO:create_model() successfully completed......................................
2024-02-04 22:19:08,387:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:08,397:INFO:_master_model_container: 29
2024-02-04 22:19:08,397:INFO:_display_container: 11
2024-02-04 22:19:08,400:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=RidgeClassifier(alpha=9.53, class_weight=None,
                                            copy_X=True, fit_intercept=False,
                                            max_iter=None, positive=False,
                                            random_state=517, solver='auto',
                                            tol=0.0001),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:08,400:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:19:08,474:INFO:Initializing ensemble_model()
2024-02-04 22:19:08,474:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=1,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.005, min_samples_leaf=2,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=150, n_iter_no_change=None,
                           random_state=517, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:19:08,474:INFO:Checking exceptions
2024-02-04 22:19:08,491:INFO:Importing libraries
2024-02-04 22:19:08,491:INFO:Copying training dataset
2024-02-04 22:19:08,491:INFO:Checking base model
2024-02-04 22:19:08,492:INFO:Base model : Gradient Boosting Classifier
2024-02-04 22:19:08,501:INFO:Importing untrained ensembler
2024-02-04 22:19:08,501:INFO:Ensemble method set to Bagging
2024-02-04 22:19:08,501:INFO:SubProcess create_model() called ==================================
2024-02-04 22:19:08,503:INFO:Initializing create_model()
2024-02-04 22:19:08,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC1A2260>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:08,503:INFO:Checking exceptions
2024-02-04 22:19:08,503:INFO:Importing libraries
2024-02-04 22:19:08,503:INFO:Copying training dataset
2024-02-04 22:19:08,511:INFO:Defining folds
2024-02-04 22:19:08,511:INFO:Declaring metric variables
2024-02-04 22:19:08,517:INFO:Importing untrained model
2024-02-04 22:19:08,517:INFO:Declaring custom model
2024-02-04 22:19:08,526:INFO:Bagging Classifier Imported successfully
2024-02-04 22:19:08,534:INFO:Starting cross validation
2024-02-04 22:19:08,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:14,361:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,373:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,387:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,399:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,406:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,410:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,417:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,492:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,506:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,779:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,791:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,796:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,802:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,807:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,811:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,823:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,832:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,851:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,858:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:14,864:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,150:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,154:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,163:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,167:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,171:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:17,184:INFO:Calculating mean and std
2024-02-04 22:19:17,185:INFO:Creating metrics dataframe
2024-02-04 22:19:17,190:INFO:Finalizing model
2024-02-04 22:19:19,455:INFO:Uploading results into container
2024-02-04 22:19:19,456:INFO:Uploading model into container now
2024-02-04 22:19:19,457:INFO:_master_model_container: 30
2024-02-04 22:19:19,457:INFO:_display_container: 12
2024-02-04 22:19:19,459:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:19,459:INFO:create_model() successfully completed......................................
2024-02-04 22:19:19,537:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:19,546:INFO:_master_model_container: 30
2024-02-04 22:19:19,546:INFO:_display_container: 12
2024-02-04 22:19:19,547:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:19,547:INFO:ensemble_model() successfully completed......................................
2024-02-04 22:19:19,630:INFO:Initializing blend_models()
2024-02-04 22:19:19,631:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator_list=[AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:19:19,631:INFO:Checking exceptions
2024-02-04 22:19:19,631:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2024-02-04 22:19:19,650:INFO:Importing libraries
2024-02-04 22:19:19,650:INFO:Copying training dataset
2024-02-04 22:19:19,656:INFO:Getting model names
2024-02-04 22:19:19,660:INFO:SubProcess create_model() called ==================================
2024-02-04 22:19:19,669:INFO:Initializing create_model()
2024-02-04 22:19:19,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BC335D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:19,670:INFO:Checking exceptions
2024-02-04 22:19:19,670:INFO:Importing libraries
2024-02-04 22:19:19,671:INFO:Copying training dataset
2024-02-04 22:19:19,678:INFO:Defining folds
2024-02-04 22:19:19,678:INFO:Declaring metric variables
2024-02-04 22:19:19,682:INFO:Importing untrained model
2024-02-04 22:19:19,683:INFO:Declaring custom model
2024-02-04 22:19:19,689:INFO:Voting Classifier Imported successfully
2024-02-04 22:19:19,697:INFO:Starting cross validation
2024-02-04 22:19:19,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:22,130:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,134:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,147:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,157:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,308:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,312:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,320:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,328:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,384:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,392:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,402:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,435:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,444:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,573:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,575:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,582:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,587:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,799:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,804:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,805:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,808:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:22,818:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,825:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,831:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,835:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,838:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:22,846:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:23,995:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:23,997:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,003:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,083:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:19:24,085:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,090:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,095:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:24,111:INFO:Calculating mean and std
2024-02-04 22:19:24,112:INFO:Creating metrics dataframe
2024-02-04 22:19:24,118:INFO:Finalizing model
2024-02-04 22:19:25,495:INFO:Uploading results into container
2024-02-04 22:19:25,496:INFO:Uploading model into container now
2024-02-04 22:19:25,497:INFO:_master_model_container: 31
2024-02-04 22:19:25,497:INFO:_display_container: 13
2024-02-04 22:19:25,504:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-02-04 22:19:25,504:INFO:create_model() successfully completed......................................
2024-02-04 22:19:25,584:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:25,594:INFO:_master_model_container: 31
2024-02-04 22:19:25,595:INFO:_display_container: 13
2024-02-04 22:19:25,600:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-02-04 22:19:25,600:INFO:blend_models() successfully completed......................................
2024-02-04 22:19:25,696:INFO:Initializing stack_models()
2024-02-04 22:19:25,696:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator_list=[AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=False, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:19:25,696:INFO:Checking exceptions
2024-02-04 22:19:25,699:INFO:Defining meta model
2024-02-04 22:19:25,720:INFO:Getting model names
2024-02-04 22:19:25,721:INFO:[('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)), ('Linear Discriminant Analysis', LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)), ('Ridge Classifier', RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False))]
2024-02-04 22:19:25,731:INFO:SubProcess create_model() called ==================================
2024-02-04 22:19:25,742:INFO:Initializing create_model()
2024-02-04 22:19:25,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Ada Boost Classifier',
                                AdaBoostClassifier(algorithm='SAMME.R',
                                                   base_estimator='deprecated',
                                                   estimator=None,
                                                   learning_rate=1.0,
                                                   n_estimators=50,
                                                   random_state=517)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='a...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=517,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7BD84BAC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:25,742:INFO:Checking exceptions
2024-02-04 22:19:25,742:INFO:Importing libraries
2024-02-04 22:19:25,742:INFO:Copying training dataset
2024-02-04 22:19:25,750:INFO:Defining folds
2024-02-04 22:19:25,751:INFO:Declaring metric variables
2024-02-04 22:19:25,754:INFO:Importing untrained model
2024-02-04 22:19:25,754:INFO:Declaring custom model
2024-02-04 22:19:25,762:INFO:Stacking Classifier Imported successfully
2024-02-04 22:19:25,770:INFO:Starting cross validation
2024-02-04 22:19:25,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:19:39,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,466:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,477:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,605:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,617:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,628:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,673:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,684:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:39,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,318:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,341:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,344:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,355:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,366:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,372:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,385:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,396:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,442:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,452:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,463:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,656:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:40,670:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,513:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,520:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,589:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,593:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,597:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:19:45,604:INFO:Calculating mean and std
2024-02-04 22:19:45,605:INFO:Creating metrics dataframe
2024-02-04 22:19:45,610:INFO:Finalizing model
2024-02-04 22:19:48,794:INFO:Uploading results into container
2024-02-04 22:19:48,795:INFO:Uploading model into container now
2024-02-04 22:19:48,796:INFO:_master_model_container: 32
2024-02-04 22:19:48,797:INFO:_display_container: 14
2024-02-04 22:19:48,807:INFO:StackingClassifier(cv=5,
                   estimators=[('Ada Boost Classifier',
                                AdaBoostClassifier(algorithm='SAMME.R',
                                                   base_estimator='deprecated',
                                                   estimator=None,
                                                   learning_rate=1.0,
                                                   n_estimators=50,
                                                   random_state=517)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='a...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=517,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 22:19:48,807:INFO:create_model() successfully completed......................................
2024-02-04 22:19:48,890:INFO:SubProcess create_model() end ==================================
2024-02-04 22:19:48,901:INFO:_master_model_container: 32
2024-02-04 22:19:48,901:INFO:_display_container: 14
2024-02-04 22:19:48,908:INFO:StackingClassifier(cv=5,
                   estimators=[('Ada Boost Classifier',
                                AdaBoostClassifier(algorithm='SAMME.R',
                                                   base_estimator='deprecated',
                                                   estimator=None,
                                                   learning_rate=1.0,
                                                   n_estimators=50,
                                                   random_state=517)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='a...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=517,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-04 22:19:48,909:INFO:stack_models() successfully completed......................................
2024-02-04 22:19:48,998:INFO:Initializing automl()
2024-02-04 22:19:48,999:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, optimize=AUC, use_holdout=False, turbo=True, return_train_score=False)
2024-02-04 22:19:48,999:INFO:Model Selection Basis : CV Results on Training set
2024-02-04 22:19:48,999:INFO:Checking model 0
2024-02-04 22:19:48,999:INFO:Checking model 1
2024-02-04 22:19:48,999:INFO:Checking model 2
2024-02-04 22:19:49,000:INFO:Checking model 3
2024-02-04 22:19:49,000:INFO:Checking model 4
2024-02-04 22:19:49,000:INFO:Checking model 5
2024-02-04 22:19:49,000:INFO:Checking model 6
2024-02-04 22:19:49,000:INFO:Checking model 7
2024-02-04 22:19:49,001:INFO:Checking model 8
2024-02-04 22:19:49,001:INFO:Checking model 9
2024-02-04 22:19:49,001:INFO:Checking model 10
2024-02-04 22:19:49,001:INFO:Checking model 11
2024-02-04 22:19:49,002:INFO:Checking model 12
2024-02-04 22:19:49,002:INFO:Checking model 13
2024-02-04 22:19:49,002:INFO:Checking model 14
2024-02-04 22:19:49,002:INFO:Checking model 15
2024-02-04 22:19:49,002:INFO:Checking model 16
2024-02-04 22:19:49,002:INFO:Checking model 17
2024-02-04 22:19:49,002:INFO:Checking model 18
2024-02-04 22:19:49,003:INFO:Checking model 19
2024-02-04 22:19:49,003:INFO:Checking model 20
2024-02-04 22:19:49,003:INFO:Checking model 21
2024-02-04 22:19:49,003:INFO:Checking model 22
2024-02-04 22:19:49,003:INFO:Checking model 23
2024-02-04 22:19:49,003:INFO:Checking model 24
2024-02-04 22:19:49,004:INFO:Checking model 25
2024-02-04 22:19:49,004:INFO:Checking model 26
2024-02-04 22:19:49,004:INFO:Checking model 27
2024-02-04 22:19:49,004:INFO:Checking model 28
2024-02-04 22:19:49,004:INFO:Checking model 29
2024-02-04 22:19:49,004:INFO:Checking model 30
2024-02-04 22:19:49,005:INFO:Checking model 31
2024-02-04 22:19:49,006:INFO:Initializing create_model()
2024-02-04 22:19:49,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:19:49,006:INFO:Checking exceptions
2024-02-04 22:19:49,008:INFO:Importing libraries
2024-02-04 22:19:49,008:INFO:Copying training dataset
2024-02-04 22:19:49,015:INFO:Defining folds
2024-02-04 22:19:49,015:INFO:Declaring metric variables
2024-02-04 22:19:49,015:INFO:Importing untrained model
2024-02-04 22:19:49,015:INFO:Declaring custom model
2024-02-04 22:19:49,016:INFO:Bagging Classifier Imported successfully
2024-02-04 22:19:49,018:INFO:Cross validation set to False
2024-02-04 22:19:49,019:INFO:Fitting Model
2024-02-04 22:19:51,603:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:51,603:INFO:create_model() successfully completed......................................
2024-02-04 22:19:51,763:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:19:51,763:INFO:automl() successfully completed......................................
2024-02-04 22:34:16,267:INFO:Initializing finalize_model()
2024-02-04 22:34:16,267:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-04 22:34:16,270:INFO:Finalizing BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False)
2024-02-04 22:34:16,276:INFO:Initializing create_model()
2024-02-04 22:34:16,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=GradientBoostingClassifier(ccp_alpha=0.0,
                                                       criterion='friedman_mse',
                                                       init=None,
                                                       learning_rate=0.2,
                                                       loss='log_loss',
                                                       max_depth=1,
                                                       max_features='log2',
                                                       max_leaf_nodes=None,
                                                       min_impurity_decrease=0.005,
                                                       min_samples_leaf=2,
                                                       min_samples_split=7,
                                                       min_weight_fraction_leaf=0.0,
                                                       n_estimators=150,
                                                       n_iter_no_change=None,
                                                       random_state=517,
                                                       subsample=0.85,
                                                       tol=0.0001,
                                                       validation_fraction=0.1,
                                                       verbose=0,
                                                       warm_start=False),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=517, verbose=0,
                  warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:34:16,276:INFO:Checking exceptions
2024-02-04 22:34:16,279:INFO:Importing libraries
2024-02-04 22:34:16,279:INFO:Copying training dataset
2024-02-04 22:34:16,279:INFO:Defining folds
2024-02-04 22:34:16,280:INFO:Declaring metric variables
2024-02-04 22:34:16,280:INFO:Importing untrained model
2024-02-04 22:34:16,280:INFO:Declaring custom model
2024-02-04 22:34:16,281:INFO:Bagging Classifier Imported successfully
2024-02-04 22:34:16,283:INFO:Cross validation set to False
2024-02-04 22:34:16,283:INFO:Fitting Model
2024-02-04 22:34:20,030:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SeniorCitizen', 'tenure',
                                             'MonthlyCharges', 'TotalCharges'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty...
                                                                        min_impurity_decrease=0.005,
                                                                        min_samples_leaf=2,
                                                                        min_samples_split=7,
                                                                        min_weight_fraction_leaf=0.0,
                                                                        n_estimators=150,
                                                                        n_iter_no_change=None,
                                                                        random_state=517,
                                                                        subsample=0.85,
                                                                        tol=0.0001,
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=517, verbose=0,
                                   warm_start=False))],
         verbose=False)
2024-02-04 22:34:20,030:INFO:create_model() successfully completed......................................
2024-02-04 22:34:20,140:INFO:_master_model_container: 32
2024-02-04 22:34:20,140:INFO:_display_container: 13
2024-02-04 22:34:20,218:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SeniorCitizen', 'tenure',
                                             'MonthlyCharges', 'TotalCharges'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty...
                                                                        min_impurity_decrease=0.005,
                                                                        min_samples_leaf=2,
                                                                        min_samples_split=7,
                                                                        min_weight_fraction_leaf=0.0,
                                                                        n_estimators=150,
                                                                        n_iter_no_change=None,
                                                                        random_state=517,
                                                                        subsample=0.85,
                                                                        tol=0.0001,
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=517, verbose=0,
                                   warm_start=False))],
         verbose=False)
2024-02-04 22:34:20,218:INFO:finalize_model() successfully completed......................................
2024-02-04 22:36:42,389:INFO:Initializing predict_model()
2024-02-04 22:36:42,389:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SeniorCitizen', 'tenure',
                                             'MonthlyCharges', 'TotalCharges'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty...
                                                                        min_impurity_decrease=0.005,
                                                                        min_samples_leaf=2,
                                                                        min_samples_split=7,
                                                                        min_weight_fraction_leaf=0.0,
                                                                        n_estimators=150,
                                                                        n_iter_no_change=None,
                                                                        random_state=517,
                                                                        subsample=0.85,
                                                                        tol=0.0001,
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=517, verbose=0,
                                   warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C7BD9971C0>)
2024-02-04 22:36:42,389:INFO:Checking exceptions
2024-02-04 22:36:42,389:INFO:Preloading libraries
2024-02-04 22:36:42,391:INFO:Set up data.
2024-02-04 22:36:42,405:INFO:Set up index.
2024-02-04 22:37:02,842:INFO:Initializing predict_model()
2024-02-04 22:37:02,842:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['SeniorCitizen', 'tenure',
                                             'MonthlyCharges', 'TotalCharges'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty...
                                                                        min_impurity_decrease=0.005,
                                                                        min_samples_leaf=2,
                                                                        min_samples_split=7,
                                                                        min_weight_fraction_leaf=0.0,
                                                                        n_estimators=150,
                                                                        n_iter_no_change=None,
                                                                        random_state=517,
                                                                        subsample=0.85,
                                                                        tol=0.0001,
                                                                        validation_fraction=0.1,
                                                                        verbose=0,
                                                                        warm_start=False),
                                   max_features=1.0, max_samples=1.0,
                                   n_estimators=10, n_jobs=None,
                                   oob_score=False, random_state=517, verbose=0,
                                   warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C7BC563130>)
2024-02-04 22:37:02,842:INFO:Checking exceptions
2024-02-04 22:37:02,842:INFO:Preloading libraries
2024-02-04 22:37:02,845:INFO:Set up data.
2024-02-04 22:37:02,866:INFO:Set up index.
2024-02-04 22:40:13,244:INFO:Initializing blend_models()
2024-02-04 22:40:13,244:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator_list=[AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=517), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=517, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=517, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-04 22:40:13,244:INFO:Checking exceptions
2024-02-04 22:40:13,245:INFO:Estimator RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=517, solver='auto',
                tol=0.0001) doesn't support probabilities, falling back to 'hard'.
2024-02-04 22:40:13,271:INFO:Importing libraries
2024-02-04 22:40:13,272:INFO:Copying training dataset
2024-02-04 22:40:13,277:INFO:Getting model names
2024-02-04 22:40:13,284:INFO:SubProcess create_model() called ==================================
2024-02-04 22:40:13,293:INFO:Initializing create_model()
2024-02-04 22:40:13,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C7BC3359C0>, estimator=VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C7B925CFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-04 22:40:13,293:INFO:Checking exceptions
2024-02-04 22:40:13,293:INFO:Importing libraries
2024-02-04 22:40:13,293:INFO:Copying training dataset
2024-02-04 22:40:13,300:INFO:Defining folds
2024-02-04 22:40:13,300:INFO:Declaring metric variables
2024-02-04 22:40:13,306:INFO:Importing untrained model
2024-02-04 22:40:13,306:INFO:Declaring custom model
2024-02-04 22:40:13,313:INFO:Voting Classifier Imported successfully
2024-02-04 22:40:13,322:INFO:Starting cross validation
2024-02-04 22:40:13,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-04 22:40:24,261:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,281:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,296:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,304:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,371:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,394:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,401:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,404:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,416:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,431:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,436:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,447:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,454:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,456:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,461:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,464:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,652:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,657:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,663:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,668:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,685:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,695:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,702:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,751:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:24,756:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,764:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:24,771:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,445:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:25,449:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,453:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,911:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:25,913:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,918:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,922:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,964:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\ensemble\_voting.py", line 383, in _check_voting
    raise AttributeError(
AttributeError: predict_proba is not available when voting='hard'

  warnings.warn(

2024-02-04 22:40:25,966:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,971:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,974:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Yes') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-02-04 22:40:25,994:INFO:Calculating mean and std
2024-02-04 22:40:25,995:INFO:Creating metrics dataframe
2024-02-04 22:40:26,000:INFO:Finalizing model
2024-02-04 22:40:27,126:INFO:Uploading results into container
2024-02-04 22:40:27,127:INFO:Uploading model into container now
2024-02-04 22:40:27,128:INFO:_master_model_container: 33
2024-02-04 22:40:27,128:INFO:_display_container: 13
2024-02-04 22:40:27,135:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-02-04 22:40:27,135:INFO:create_model() successfully completed......................................
2024-02-04 22:40:27,247:INFO:SubProcess create_model() end ==================================
2024-02-04 22:40:27,257:INFO:_master_model_container: 33
2024-02-04 22:40:27,257:INFO:_display_container: 13
2024-02-04 22:40:27,262:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=1.0,
                                                 n_estimators=50,
                                                 random_state=517)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=517,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-02-04 22:40:27,262:INFO:blend_models() successfully completed......................................
