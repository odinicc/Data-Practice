2024-02-07 22:35:56,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:35:56,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:35:56,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:35:56,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:43:19,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:43:19,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:43:19,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 22:43:19,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 23:33:48,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 23:33:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 23:33:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-07 23:33:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:21:32,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:21:32,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:21:32,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:21:32,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:45:53,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:45:53,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:45:53,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:45:53,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-08 01:48:01,529:INFO:PyCaret ClassificationExperiment
2024-02-08 01:48:01,529:INFO:Logging name: clf-default-name
2024-02-08 01:48:01,529:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-08 01:48:01,529:INFO:version 3.2.0
2024-02-08 01:48:01,529:INFO:Initializing setup()
2024-02-08 01:48:01,529:INFO:self.USI: 727f
2024-02-08 01:48:01,529:INFO:self._variable_keys: {'seed', 'y_test', 'is_multiclass', 'exp_name_log', 'gpu_param', 'fold_groups_param', 'target_param', 'data', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'memory', 'logging_param', 'fold_generator', 'pipeline', 'X_test', 'n_jobs_param', 'y', 'fold_shuffle_param', 'USI', 'y_train', 'html_param', 'log_plots_param', 'X', '_ml_usecase', 'fix_imbalance', 'idx', 'X_train'}
2024-02-08 01:48:01,529:INFO:Checking environment
2024-02-08 01:48:01,529:INFO:python_version: 3.10.9
2024-02-08 01:48:01,530:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-08 01:48:01,530:INFO:machine: AMD64
2024-02-08 01:48:01,530:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-08 01:48:01,530:INFO:Memory: svmem(total=16856182784, available=3750866944, percent=77.7, used=13105315840, free=3750866944)
2024-02-08 01:48:01,530:INFO:Physical Core: 4
2024-02-08 01:48:01,530:INFO:Logical Core: 8
2024-02-08 01:48:01,530:INFO:Checking libraries
2024-02-08 01:48:01,530:INFO:System:
2024-02-08 01:48:01,530:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-08 01:48:01,530:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-08 01:48:01,530:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-08 01:48:01,530:INFO:PyCaret required dependencies:
2024-02-08 01:48:01,684:INFO:                 pip: 22.3.1
2024-02-08 01:48:01,684:INFO:          setuptools: 65.6.3
2024-02-08 01:48:01,684:INFO:             pycaret: 3.2.0
2024-02-08 01:48:01,684:INFO:             IPython: 8.20.0
2024-02-08 01:48:01,684:INFO:          ipywidgets: 8.0.4
2024-02-08 01:48:01,684:INFO:                tqdm: 4.64.1
2024-02-08 01:48:01,684:INFO:               numpy: 1.25.2
2024-02-08 01:48:01,684:INFO:              pandas: 1.5.3
2024-02-08 01:48:01,685:INFO:              jinja2: 3.1.3
2024-02-08 01:48:01,685:INFO:               scipy: 1.10.1
2024-02-08 01:48:01,685:INFO:              joblib: 1.3.2
2024-02-08 01:48:01,685:INFO:             sklearn: 1.2.2
2024-02-08 01:48:01,685:INFO:                pyod: 1.1.2
2024-02-08 01:48:01,685:INFO:            imblearn: 0.12.0
2024-02-08 01:48:01,685:INFO:   category_encoders: 2.6.3
2024-02-08 01:48:01,685:INFO:            lightgbm: 4.3.0
2024-02-08 01:48:01,685:INFO:               numba: 0.59.0
2024-02-08 01:48:01,685:INFO:            requests: 2.31.0
2024-02-08 01:48:01,685:INFO:          matplotlib: 3.6.0
2024-02-08 01:48:01,685:INFO:          scikitplot: 0.3.7
2024-02-08 01:48:01,685:INFO:         yellowbrick: 1.5
2024-02-08 01:48:01,685:INFO:              plotly: 5.18.0
2024-02-08 01:48:01,685:INFO:    plotly-resampler: Not installed
2024-02-08 01:48:01,685:INFO:             kaleido: 0.2.1
2024-02-08 01:48:01,685:INFO:           schemdraw: 0.15
2024-02-08 01:48:01,685:INFO:         statsmodels: 0.14.1
2024-02-08 01:48:01,685:INFO:              sktime: 0.21.1
2024-02-08 01:48:01,685:INFO:               tbats: 1.1.3
2024-02-08 01:48:01,685:INFO:            pmdarima: 2.0.4
2024-02-08 01:48:01,685:INFO:              psutil: 5.9.0
2024-02-08 01:48:01,685:INFO:          markupsafe: 2.1.3
2024-02-08 01:48:01,685:INFO:             pickle5: Not installed
2024-02-08 01:48:01,686:INFO:         cloudpickle: 3.0.0
2024-02-08 01:48:01,686:INFO:         deprecation: 2.1.0
2024-02-08 01:48:01,686:INFO:              xxhash: 3.4.1
2024-02-08 01:48:01,686:INFO:           wurlitzer: Not installed
2024-02-08 01:48:01,686:INFO:PyCaret optional dependencies:
2024-02-08 01:48:01,702:INFO:                shap: 0.44.1
2024-02-08 01:48:01,703:INFO:           interpret: Not installed
2024-02-08 01:48:01,703:INFO:                umap: Not installed
2024-02-08 01:48:01,703:INFO:     ydata_profiling: Not installed
2024-02-08 01:48:01,703:INFO:  explainerdashboard: 0.4.5
2024-02-08 01:48:01,703:INFO:             autoviz: Not installed
2024-02-08 01:48:01,703:INFO:           fairlearn: Not installed
2024-02-08 01:48:01,703:INFO:          deepchecks: Not installed
2024-02-08 01:48:01,703:INFO:             xgboost: Not installed
2024-02-08 01:48:01,703:INFO:            catboost: 1.2.2
2024-02-08 01:48:01,703:INFO:              kmodes: Not installed
2024-02-08 01:48:01,703:INFO:             mlxtend: Not installed
2024-02-08 01:48:01,703:INFO:       statsforecast: Not installed
2024-02-08 01:48:01,703:INFO:        tune_sklearn: Not installed
2024-02-08 01:48:01,703:INFO:                 ray: Not installed
2024-02-08 01:48:01,703:INFO:            hyperopt: Not installed
2024-02-08 01:48:01,703:INFO:              optuna: Not installed
2024-02-08 01:48:01,703:INFO:               skopt: Not installed
2024-02-08 01:48:01,703:INFO:              mlflow: 2.10.0
2024-02-08 01:48:01,704:INFO:              gradio: Not installed
2024-02-08 01:48:01,704:INFO:             fastapi: Not installed
2024-02-08 01:48:01,704:INFO:             uvicorn: Not installed
2024-02-08 01:48:01,704:INFO:              m2cgen: Not installed
2024-02-08 01:48:01,704:INFO:           evidently: Not installed
2024-02-08 01:48:01,704:INFO:               fugue: Not installed
2024-02-08 01:48:01,704:INFO:           streamlit: Not installed
2024-02-08 01:48:01,704:INFO:             prophet: Not installed
2024-02-08 01:48:01,704:INFO:None
2024-02-08 01:48:01,704:INFO:Set up data.
2024-02-08 01:48:01,936:INFO:Set up folding strategy.
2024-02-08 01:48:01,936:INFO:Set up train/test split.
2024-02-08 01:48:02,099:INFO:Set up index.
2024-02-08 01:48:02,107:INFO:Assigning column types.
2024-02-08 01:48:02,285:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-08 01:48:02,349:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,353:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:02,390:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:02,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,616:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:02,650:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:02,651:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-08 01:48:02,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:02,731:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:02,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:48:02,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:02,821:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:02,821:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-08 01:48:02,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:02,909:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:03,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:03,000:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:03,006:INFO:Preparing preprocessing pipeline...
2024-02-08 01:48:03,023:INFO:Set up simple imputation.
2024-02-08 01:48:03,023:INFO:Set up imbalanced handling.
2024-02-08 01:48:03,477:INFO:Finished creating preprocessing pipeline.
2024-02-08 01:48:03,485:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_i...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2024-02-08 01:48:03,485:INFO:Creating final display dataframe.
2024-02-08 01:48:05,820:INFO:Setup _display_container:                     Description              Value
0                    Session id               1466
1                        Target  churn_probability
2                   Target type             Binary
3           Original data shape       (69999, 129)
4        Transformed data shape      (109014, 129)
5   Transformed train set shape       (88014, 129)
6    Transformed test set shape       (21000, 129)
7              Numeric features                128
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12                Fix imbalance               True
13         Fix imbalance method              SMOTE
14               Fold Generator    StratifiedKFold
15                  Fold Number                 10
16                     CPU Jobs                 -1
17                      Use GPU              False
18               Log Experiment              False
19              Experiment Name   clf-default-name
20                          USI               727f
2024-02-08 01:48:05,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:05,942:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:06,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:48:06,053:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:48:06,054:INFO:setup() successfully completed in 4.57s...............
2024-02-08 01:50:01,973:INFO:PyCaret ClassificationExperiment
2024-02-08 01:50:01,973:INFO:Logging name: clf-default-name
2024-02-08 01:50:01,973:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-08 01:50:01,973:INFO:version 3.2.0
2024-02-08 01:50:01,973:INFO:Initializing setup()
2024-02-08 01:50:01,973:INFO:self.USI: e8f0
2024-02-08 01:50:01,973:INFO:self._variable_keys: {'seed', 'y_test', 'is_multiclass', 'exp_name_log', 'gpu_param', 'fold_groups_param', 'target_param', 'data', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'memory', 'logging_param', 'fold_generator', 'pipeline', 'X_test', 'n_jobs_param', 'y', 'fold_shuffle_param', 'USI', 'y_train', 'html_param', 'log_plots_param', 'X', '_ml_usecase', 'fix_imbalance', 'idx', 'X_train'}
2024-02-08 01:50:01,973:INFO:Checking environment
2024-02-08 01:50:01,974:INFO:python_version: 3.10.9
2024-02-08 01:50:01,974:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-08 01:50:01,974:INFO:machine: AMD64
2024-02-08 01:50:01,974:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-08 01:50:01,974:INFO:Memory: svmem(total=16856182784, available=4107190272, percent=75.6, used=12748992512, free=4107190272)
2024-02-08 01:50:01,974:INFO:Physical Core: 4
2024-02-08 01:50:01,974:INFO:Logical Core: 8
2024-02-08 01:50:01,974:INFO:Checking libraries
2024-02-08 01:50:01,974:INFO:System:
2024-02-08 01:50:01,974:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-08 01:50:01,975:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-08 01:50:01,975:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-08 01:50:01,975:INFO:PyCaret required dependencies:
2024-02-08 01:50:01,975:INFO:                 pip: 22.3.1
2024-02-08 01:50:01,975:INFO:          setuptools: 65.6.3
2024-02-08 01:50:01,975:INFO:             pycaret: 3.2.0
2024-02-08 01:50:01,975:INFO:             IPython: 8.20.0
2024-02-08 01:50:01,975:INFO:          ipywidgets: 8.0.4
2024-02-08 01:50:01,975:INFO:                tqdm: 4.64.1
2024-02-08 01:50:01,975:INFO:               numpy: 1.25.2
2024-02-08 01:50:01,975:INFO:              pandas: 1.5.3
2024-02-08 01:50:01,975:INFO:              jinja2: 3.1.3
2024-02-08 01:50:01,975:INFO:               scipy: 1.10.1
2024-02-08 01:50:01,975:INFO:              joblib: 1.3.2
2024-02-08 01:50:01,975:INFO:             sklearn: 1.2.2
2024-02-08 01:50:01,975:INFO:                pyod: 1.1.2
2024-02-08 01:50:01,975:INFO:            imblearn: 0.12.0
2024-02-08 01:50:01,975:INFO:   category_encoders: 2.6.3
2024-02-08 01:50:01,975:INFO:            lightgbm: 4.3.0
2024-02-08 01:50:01,975:INFO:               numba: 0.59.0
2024-02-08 01:50:01,975:INFO:            requests: 2.31.0
2024-02-08 01:50:01,975:INFO:          matplotlib: 3.6.0
2024-02-08 01:50:01,975:INFO:          scikitplot: 0.3.7
2024-02-08 01:50:01,975:INFO:         yellowbrick: 1.5
2024-02-08 01:50:01,975:INFO:              plotly: 5.18.0
2024-02-08 01:50:01,975:INFO:    plotly-resampler: Not installed
2024-02-08 01:50:01,975:INFO:             kaleido: 0.2.1
2024-02-08 01:50:01,975:INFO:           schemdraw: 0.15
2024-02-08 01:50:01,975:INFO:         statsmodels: 0.14.1
2024-02-08 01:50:01,976:INFO:              sktime: 0.21.1
2024-02-08 01:50:01,976:INFO:               tbats: 1.1.3
2024-02-08 01:50:01,976:INFO:            pmdarima: 2.0.4
2024-02-08 01:50:01,976:INFO:              psutil: 5.9.0
2024-02-08 01:50:01,976:INFO:          markupsafe: 2.1.3
2024-02-08 01:50:01,976:INFO:             pickle5: Not installed
2024-02-08 01:50:01,976:INFO:         cloudpickle: 3.0.0
2024-02-08 01:50:01,976:INFO:         deprecation: 2.1.0
2024-02-08 01:50:01,976:INFO:              xxhash: 3.4.1
2024-02-08 01:50:01,976:INFO:           wurlitzer: Not installed
2024-02-08 01:50:01,976:INFO:PyCaret optional dependencies:
2024-02-08 01:50:01,976:INFO:                shap: 0.44.1
2024-02-08 01:50:01,976:INFO:           interpret: Not installed
2024-02-08 01:50:01,976:INFO:                umap: Not installed
2024-02-08 01:50:01,976:INFO:     ydata_profiling: Not installed
2024-02-08 01:50:01,976:INFO:  explainerdashboard: 0.4.5
2024-02-08 01:50:01,976:INFO:             autoviz: Not installed
2024-02-08 01:50:01,976:INFO:           fairlearn: Not installed
2024-02-08 01:50:01,976:INFO:          deepchecks: Not installed
2024-02-08 01:50:01,976:INFO:             xgboost: Not installed
2024-02-08 01:50:01,976:INFO:            catboost: 1.2.2
2024-02-08 01:50:01,977:INFO:              kmodes: Not installed
2024-02-08 01:50:01,977:INFO:             mlxtend: Not installed
2024-02-08 01:50:01,977:INFO:       statsforecast: Not installed
2024-02-08 01:50:01,977:INFO:        tune_sklearn: Not installed
2024-02-08 01:50:01,977:INFO:                 ray: Not installed
2024-02-08 01:50:01,977:INFO:            hyperopt: Not installed
2024-02-08 01:50:01,977:INFO:              optuna: Not installed
2024-02-08 01:50:01,977:INFO:               skopt: Not installed
2024-02-08 01:50:01,977:INFO:              mlflow: 2.10.0
2024-02-08 01:50:01,977:INFO:              gradio: Not installed
2024-02-08 01:50:01,977:INFO:             fastapi: Not installed
2024-02-08 01:50:01,977:INFO:             uvicorn: Not installed
2024-02-08 01:50:01,977:INFO:              m2cgen: Not installed
2024-02-08 01:50:01,977:INFO:           evidently: Not installed
2024-02-08 01:50:01,977:INFO:               fugue: Not installed
2024-02-08 01:50:01,977:INFO:           streamlit: Not installed
2024-02-08 01:50:01,977:INFO:             prophet: Not installed
2024-02-08 01:50:01,977:INFO:None
2024-02-08 01:50:01,977:INFO:Set up data.
2024-02-08 01:50:02,170:INFO:Set up folding strategy.
2024-02-08 01:50:02,170:INFO:Set up train/test split.
2024-02-08 01:50:02,304:INFO:Set up index.
2024-02-08 01:50:02,311:INFO:Assigning column types.
2024-02-08 01:50:02,423:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-08 01:50:02,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,508:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,602:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,603:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-08 01:50:02,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,687:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:50:02,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,788:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,789:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-08 01:50:02,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,861:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:02,958:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:02,960:INFO:Preparing preprocessing pipeline...
2024-02-08 01:50:02,973:INFO:Set up simple imputation.
2024-02-08 01:50:02,974:INFO:Set up imbalanced handling.
2024-02-08 01:50:02,974:INFO:Set up feature selection.
2024-02-08 01:50:03,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:03,059:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:07,244:INFO:Finished creating preprocessing pipeline.
2024-02-08 01:50:07,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_i...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-08 01:50:07,263:INFO:Creating final display dataframe.
2024-02-08 01:50:08,785:INFO:Setup _display_container:                     Description              Value
0                    Session id                689
1                        Target  churn_probability
2                   Target type             Binary
3           Original data shape       (69999, 129)
4        Transformed data shape       (109014, 26)
5   Transformed train set shape        (88014, 26)
6    Transformed test set shape        (21000, 26)
7              Numeric features                128
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12                Fix imbalance               True
13         Fix imbalance method              SMOTE
14            Feature selection               True
15     Feature selection method            classic
16  Feature selection estimator           lightgbm
17  Number of features selected                0.2
18               Fold Generator    StratifiedKFold
19                  Fold Number                 10
20                     CPU Jobs                 -1
21                      Use GPU              False
22               Log Experiment              False
23              Experiment Name   clf-default-name
24                          USI               e8f0
2024-02-08 01:50:08,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:08,873:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:08,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:50:08,944:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:50:08,944:INFO:setup() successfully completed in 7.0s...............
2024-02-08 01:50:59,762:INFO:PyCaret ClassificationExperiment
2024-02-08 01:50:59,762:INFO:Logging name: clf-default-name
2024-02-08 01:50:59,762:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-08 01:50:59,762:INFO:version 3.2.0
2024-02-08 01:50:59,763:INFO:Initializing setup()
2024-02-08 01:50:59,763:INFO:self.USI: e2a0
2024-02-08 01:50:59,763:INFO:self._variable_keys: {'seed', 'y_test', 'is_multiclass', 'exp_name_log', 'gpu_param', 'fold_groups_param', 'target_param', 'data', '_available_plots', 'exp_id', 'gpu_n_jobs_param', 'memory', 'logging_param', 'fold_generator', 'pipeline', 'X_test', 'n_jobs_param', 'y', 'fold_shuffle_param', 'USI', 'y_train', 'html_param', 'log_plots_param', 'X', '_ml_usecase', 'fix_imbalance', 'idx', 'X_train'}
2024-02-08 01:50:59,763:INFO:Checking environment
2024-02-08 01:50:59,763:INFO:python_version: 3.10.9
2024-02-08 01:50:59,763:INFO:python_build: ('main', 'Jan 11 2023 15:15:40')
2024-02-08 01:50:59,763:INFO:machine: AMD64
2024-02-08 01:50:59,763:INFO:platform: Windows-10-10.0.19045-SP0
2024-02-08 01:50:59,763:INFO:Memory: svmem(total=16856182784, available=4023656448, percent=76.1, used=12832526336, free=4023656448)
2024-02-08 01:50:59,763:INFO:Physical Core: 4
2024-02-08 01:50:59,763:INFO:Logical Core: 8
2024-02-08 01:50:59,763:INFO:Checking libraries
2024-02-08 01:50:59,763:INFO:System:
2024-02-08 01:50:59,764:INFO:    python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
2024-02-08 01:50:59,764:INFO:executable: C:\ProgramData\miniconda3\python.exe
2024-02-08 01:50:59,764:INFO:   machine: Windows-10-10.0.19045-SP0
2024-02-08 01:50:59,764:INFO:PyCaret required dependencies:
2024-02-08 01:50:59,764:INFO:                 pip: 22.3.1
2024-02-08 01:50:59,764:INFO:          setuptools: 65.6.3
2024-02-08 01:50:59,764:INFO:             pycaret: 3.2.0
2024-02-08 01:50:59,764:INFO:             IPython: 8.20.0
2024-02-08 01:50:59,764:INFO:          ipywidgets: 8.0.4
2024-02-08 01:50:59,764:INFO:                tqdm: 4.64.1
2024-02-08 01:50:59,764:INFO:               numpy: 1.25.2
2024-02-08 01:50:59,764:INFO:              pandas: 1.5.3
2024-02-08 01:50:59,764:INFO:              jinja2: 3.1.3
2024-02-08 01:50:59,764:INFO:               scipy: 1.10.1
2024-02-08 01:50:59,764:INFO:              joblib: 1.3.2
2024-02-08 01:50:59,764:INFO:             sklearn: 1.2.2
2024-02-08 01:50:59,764:INFO:                pyod: 1.1.2
2024-02-08 01:50:59,764:INFO:            imblearn: 0.12.0
2024-02-08 01:50:59,764:INFO:   category_encoders: 2.6.3
2024-02-08 01:50:59,765:INFO:            lightgbm: 4.3.0
2024-02-08 01:50:59,765:INFO:               numba: 0.59.0
2024-02-08 01:50:59,765:INFO:            requests: 2.31.0
2024-02-08 01:50:59,765:INFO:          matplotlib: 3.6.0
2024-02-08 01:50:59,765:INFO:          scikitplot: 0.3.7
2024-02-08 01:50:59,765:INFO:         yellowbrick: 1.5
2024-02-08 01:50:59,765:INFO:              plotly: 5.18.0
2024-02-08 01:50:59,765:INFO:    plotly-resampler: Not installed
2024-02-08 01:50:59,765:INFO:             kaleido: 0.2.1
2024-02-08 01:50:59,765:INFO:           schemdraw: 0.15
2024-02-08 01:50:59,765:INFO:         statsmodels: 0.14.1
2024-02-08 01:50:59,765:INFO:              sktime: 0.21.1
2024-02-08 01:50:59,765:INFO:               tbats: 1.1.3
2024-02-08 01:50:59,765:INFO:            pmdarima: 2.0.4
2024-02-08 01:50:59,765:INFO:              psutil: 5.9.0
2024-02-08 01:50:59,765:INFO:          markupsafe: 2.1.3
2024-02-08 01:50:59,765:INFO:             pickle5: Not installed
2024-02-08 01:50:59,765:INFO:         cloudpickle: 3.0.0
2024-02-08 01:50:59,765:INFO:         deprecation: 2.1.0
2024-02-08 01:50:59,765:INFO:              xxhash: 3.4.1
2024-02-08 01:50:59,765:INFO:           wurlitzer: Not installed
2024-02-08 01:50:59,765:INFO:PyCaret optional dependencies:
2024-02-08 01:50:59,765:INFO:                shap: 0.44.1
2024-02-08 01:50:59,765:INFO:           interpret: Not installed
2024-02-08 01:50:59,766:INFO:                umap: Not installed
2024-02-08 01:50:59,766:INFO:     ydata_profiling: Not installed
2024-02-08 01:50:59,766:INFO:  explainerdashboard: 0.4.5
2024-02-08 01:50:59,766:INFO:             autoviz: Not installed
2024-02-08 01:50:59,766:INFO:           fairlearn: Not installed
2024-02-08 01:50:59,766:INFO:          deepchecks: Not installed
2024-02-08 01:50:59,766:INFO:             xgboost: Not installed
2024-02-08 01:50:59,766:INFO:            catboost: 1.2.2
2024-02-08 01:50:59,766:INFO:              kmodes: Not installed
2024-02-08 01:50:59,766:INFO:             mlxtend: Not installed
2024-02-08 01:50:59,766:INFO:       statsforecast: Not installed
2024-02-08 01:50:59,766:INFO:        tune_sklearn: Not installed
2024-02-08 01:50:59,766:INFO:                 ray: Not installed
2024-02-08 01:50:59,766:INFO:            hyperopt: Not installed
2024-02-08 01:50:59,766:INFO:              optuna: Not installed
2024-02-08 01:50:59,766:INFO:               skopt: Not installed
2024-02-08 01:50:59,766:INFO:              mlflow: 2.10.0
2024-02-08 01:50:59,766:INFO:              gradio: Not installed
2024-02-08 01:50:59,766:INFO:             fastapi: Not installed
2024-02-08 01:50:59,766:INFO:             uvicorn: Not installed
2024-02-08 01:50:59,766:INFO:              m2cgen: Not installed
2024-02-08 01:50:59,766:INFO:           evidently: Not installed
2024-02-08 01:50:59,766:INFO:               fugue: Not installed
2024-02-08 01:50:59,766:INFO:           streamlit: Not installed
2024-02-08 01:50:59,766:INFO:             prophet: Not installed
2024-02-08 01:50:59,766:INFO:None
2024-02-08 01:50:59,767:INFO:Set up data.
2024-02-08 01:50:59,973:INFO:Set up folding strategy.
2024-02-08 01:50:59,973:INFO:Set up train/test split.
2024-02-08 01:51:00,195:INFO:Set up index.
2024-02-08 01:51:00,203:INFO:Assigning column types.
2024-02-08 01:51:00,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-08 01:51:00,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,379:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,414:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,458:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,487:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,487:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-08 01:51:00,539:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,572:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-08 01:51:00,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,657:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,658:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-08 01:51:00,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,751:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,845:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:00,847:INFO:Preparing preprocessing pipeline...
2024-02-08 01:51:00,861:INFO:Set up simple imputation.
2024-02-08 01:51:00,861:INFO:Set up removing multicollinearity.
2024-02-08 01:51:00,861:INFO:Set up imbalanced handling.
2024-02-08 01:51:00,861:INFO:Set up feature selection.
2024-02-08 01:51:00,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:00,939:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:06,616:INFO:Finished creating preprocessing pipeline.
2024-02-08 01:51:06,631:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_i...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-02-08 01:51:06,631:INFO:Creating final display dataframe.
2024-02-08 01:51:08,105:INFO:Setup _display_container:                     Description              Value
0                    Session id               6300
1                        Target  churn_probability
2                   Target type             Binary
3           Original data shape       (69999, 129)
4        Transformed data shape       (109014, 26)
5   Transformed train set shape        (88014, 26)
6    Transformed test set shape        (21000, 26)
7              Numeric features                128
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12     Remove multicollinearity               True
13  Multicollinearity threshold                0.9
14                Fix imbalance               True
15         Fix imbalance method              SMOTE
16            Feature selection               True
17     Feature selection method            classic
18  Feature selection estimator           lightgbm
19  Number of features selected                0.2
20               Fold Generator    StratifiedKFold
21                  Fold Number                 10
22                     CPU Jobs                 -1
23                      Use GPU              False
24               Log Experiment              False
25              Experiment Name   clf-default-name
26                          USI               e2a0
2024-02-08 01:51:08,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:08,206:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:08,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-02-08 01:51:08,294:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-08 01:51:08,295:INFO:setup() successfully completed in 8.57s...............
2024-02-08 01:53:29,045:INFO:Initializing compare_models()
2024-02-08 01:53:29,045:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accurancy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accurancy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-08 01:53:29,045:INFO:Checking exceptions
2024-02-08 01:54:01,823:INFO:Initializing compare_models()
2024-02-08 01:54:01,824:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-08 01:54:01,824:INFO:Checking exceptions
2024-02-08 01:54:01,899:INFO:Preparing display monitor
2024-02-08 01:54:01,934:INFO:Initializing Logistic Regression
2024-02-08 01:54:01,934:INFO:Total runtime is 0.0 minutes
2024-02-08 01:54:01,939:INFO:SubProcess create_model() called ==================================
2024-02-08 01:54:01,940:INFO:Initializing create_model()
2024-02-08 01:54:01,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:54:01,940:INFO:Checking exceptions
2024-02-08 01:54:01,940:INFO:Importing libraries
2024-02-08 01:54:01,940:INFO:Copying training dataset
2024-02-08 01:54:02,057:INFO:Defining folds
2024-02-08 01:54:02,057:INFO:Declaring metric variables
2024-02-08 01:54:02,061:INFO:Importing untrained model
2024-02-08 01:54:02,065:INFO:Logistic Regression Imported successfully
2024-02-08 01:54:02,074:INFO:Starting cross validation
2024-02-08 01:54:02,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:54:42,879:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:43,612:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:43,917:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:44,566:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:55,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:56,560:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:54:58,636:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:55:00,555:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:55:09,490:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:55:09,822:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 01:55:10,014:INFO:Calculating mean and std
2024-02-08 01:55:10,016:INFO:Creating metrics dataframe
2024-02-08 01:55:10,027:INFO:Uploading results into container
2024-02-08 01:55:10,029:INFO:Uploading model into container now
2024-02-08 01:55:10,034:INFO:_master_model_container: 1
2024-02-08 01:55:10,034:INFO:_display_container: 2
2024-02-08 01:55:10,036:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6300, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-08 01:55:10,036:INFO:create_model() successfully completed......................................
2024-02-08 01:55:10,282:INFO:SubProcess create_model() end ==================================
2024-02-08 01:55:10,283:INFO:Creating metrics dataframe
2024-02-08 01:55:10,296:INFO:Initializing K Neighbors Classifier
2024-02-08 01:55:10,296:INFO:Total runtime is 1.1393545349438985 minutes
2024-02-08 01:55:10,300:INFO:SubProcess create_model() called ==================================
2024-02-08 01:55:10,301:INFO:Initializing create_model()
2024-02-08 01:55:10,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:55:10,301:INFO:Checking exceptions
2024-02-08 01:55:10,301:INFO:Importing libraries
2024-02-08 01:55:10,302:INFO:Copying training dataset
2024-02-08 01:55:10,429:INFO:Defining folds
2024-02-08 01:55:10,429:INFO:Declaring metric variables
2024-02-08 01:55:10,433:INFO:Importing untrained model
2024-02-08 01:55:10,438:INFO:K Neighbors Classifier Imported successfully
2024-02-08 01:55:10,448:INFO:Starting cross validation
2024-02-08 01:55:10,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:56:08,164:INFO:Calculating mean and std
2024-02-08 01:56:08,167:INFO:Creating metrics dataframe
2024-02-08 01:56:08,179:INFO:Uploading results into container
2024-02-08 01:56:08,181:INFO:Uploading model into container now
2024-02-08 01:56:08,182:INFO:_master_model_container: 2
2024-02-08 01:56:08,182:INFO:_display_container: 2
2024-02-08 01:56:08,183:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-08 01:56:08,183:INFO:create_model() successfully completed......................................
2024-02-08 01:56:08,339:INFO:SubProcess create_model() end ==================================
2024-02-08 01:56:08,340:INFO:Creating metrics dataframe
2024-02-08 01:56:08,351:INFO:Initializing Naive Bayes
2024-02-08 01:56:08,351:INFO:Total runtime is 2.1069378018379212 minutes
2024-02-08 01:56:08,356:INFO:SubProcess create_model() called ==================================
2024-02-08 01:56:08,357:INFO:Initializing create_model()
2024-02-08 01:56:08,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:56:08,358:INFO:Checking exceptions
2024-02-08 01:56:08,358:INFO:Importing libraries
2024-02-08 01:56:08,358:INFO:Copying training dataset
2024-02-08 01:56:08,463:INFO:Defining folds
2024-02-08 01:56:08,464:INFO:Declaring metric variables
2024-02-08 01:56:08,475:INFO:Importing untrained model
2024-02-08 01:56:08,484:INFO:Naive Bayes Imported successfully
2024-02-08 01:56:08,493:INFO:Starting cross validation
2024-02-08 01:56:08,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:56:40,491:INFO:Calculating mean and std
2024-02-08 01:56:40,494:INFO:Creating metrics dataframe
2024-02-08 01:56:40,504:INFO:Uploading results into container
2024-02-08 01:56:40,506:INFO:Uploading model into container now
2024-02-08 01:56:40,507:INFO:_master_model_container: 3
2024-02-08 01:56:40,507:INFO:_display_container: 2
2024-02-08 01:56:40,509:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-08 01:56:40,509:INFO:create_model() successfully completed......................................
2024-02-08 01:56:40,641:INFO:SubProcess create_model() end ==================================
2024-02-08 01:56:40,642:INFO:Creating metrics dataframe
2024-02-08 01:56:40,652:INFO:Initializing Decision Tree Classifier
2024-02-08 01:56:40,652:INFO:Total runtime is 2.6452887574831645 minutes
2024-02-08 01:56:40,656:INFO:SubProcess create_model() called ==================================
2024-02-08 01:56:40,656:INFO:Initializing create_model()
2024-02-08 01:56:40,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:56:40,656:INFO:Checking exceptions
2024-02-08 01:56:40,656:INFO:Importing libraries
2024-02-08 01:56:40,656:INFO:Copying training dataset
2024-02-08 01:56:40,744:INFO:Defining folds
2024-02-08 01:56:40,744:INFO:Declaring metric variables
2024-02-08 01:56:40,750:INFO:Importing untrained model
2024-02-08 01:56:40,758:INFO:Decision Tree Classifier Imported successfully
2024-02-08 01:56:40,771:INFO:Starting cross validation
2024-02-08 01:56:40,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:57:19,150:INFO:Calculating mean and std
2024-02-08 01:57:19,151:INFO:Creating metrics dataframe
2024-02-08 01:57:19,157:INFO:Uploading results into container
2024-02-08 01:57:19,158:INFO:Uploading model into container now
2024-02-08 01:57:19,159:INFO:_master_model_container: 4
2024-02-08 01:57:19,159:INFO:_display_container: 2
2024-02-08 01:57:19,160:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6300, splitter='best')
2024-02-08 01:57:19,160:INFO:create_model() successfully completed......................................
2024-02-08 01:57:19,334:INFO:SubProcess create_model() end ==================================
2024-02-08 01:57:19,334:INFO:Creating metrics dataframe
2024-02-08 01:57:19,348:INFO:Initializing SVM - Linear Kernel
2024-02-08 01:57:19,348:INFO:Total runtime is 3.2902221202850344 minutes
2024-02-08 01:57:19,356:INFO:SubProcess create_model() called ==================================
2024-02-08 01:57:19,357:INFO:Initializing create_model()
2024-02-08 01:57:19,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:57:19,357:INFO:Checking exceptions
2024-02-08 01:57:19,357:INFO:Importing libraries
2024-02-08 01:57:19,358:INFO:Copying training dataset
2024-02-08 01:57:19,498:INFO:Defining folds
2024-02-08 01:57:19,498:INFO:Declaring metric variables
2024-02-08 01:57:19,505:INFO:Importing untrained model
2024-02-08 01:57:19,512:INFO:SVM - Linear Kernel Imported successfully
2024-02-08 01:57:19,526:INFO:Starting cross validation
2024-02-08 01:57:19,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:57:50,432:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:50,709:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:55,178:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:55,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:55,785:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:56,169:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:56,604:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:57:56,792:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:58:06,484:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:58:07,303:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 01:58:07,434:INFO:Calculating mean and std
2024-02-08 01:58:07,438:INFO:Creating metrics dataframe
2024-02-08 01:58:07,447:INFO:Uploading results into container
2024-02-08 01:58:07,448:INFO:Uploading model into container now
2024-02-08 01:58:07,449:INFO:_master_model_container: 5
2024-02-08 01:58:07,449:INFO:_display_container: 2
2024-02-08 01:58:07,450:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6300, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-08 01:58:07,451:INFO:create_model() successfully completed......................................
2024-02-08 01:58:07,636:INFO:SubProcess create_model() end ==================================
2024-02-08 01:58:07,636:INFO:Creating metrics dataframe
2024-02-08 01:58:07,653:INFO:Initializing Ridge Classifier
2024-02-08 01:58:07,654:INFO:Total runtime is 4.095330123106638 minutes
2024-02-08 01:58:07,661:INFO:SubProcess create_model() called ==================================
2024-02-08 01:58:07,662:INFO:Initializing create_model()
2024-02-08 01:58:07,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:58:07,662:INFO:Checking exceptions
2024-02-08 01:58:07,662:INFO:Importing libraries
2024-02-08 01:58:07,662:INFO:Copying training dataset
2024-02-08 01:58:07,797:INFO:Defining folds
2024-02-08 01:58:07,798:INFO:Declaring metric variables
2024-02-08 01:58:07,805:INFO:Importing untrained model
2024-02-08 01:58:07,812:INFO:Ridge Classifier Imported successfully
2024-02-08 01:58:07,827:INFO:Starting cross validation
2024-02-08 01:58:07,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 01:58:29,667:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:29,954:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:32,943:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:33,286:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:33,502:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:33,660:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:33,755:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:33,880:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:39,635:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:39,824:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 01:58:39,971:INFO:Calculating mean and std
2024-02-08 01:58:39,974:INFO:Creating metrics dataframe
2024-02-08 01:58:39,984:INFO:Uploading results into container
2024-02-08 01:58:39,986:INFO:Uploading model into container now
2024-02-08 01:58:39,987:INFO:_master_model_container: 6
2024-02-08 01:58:39,987:INFO:_display_container: 2
2024-02-08 01:58:39,989:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6300, solver='auto',
                tol=0.0001)
2024-02-08 01:58:39,989:INFO:create_model() successfully completed......................................
2024-02-08 01:58:40,130:INFO:SubProcess create_model() end ==================================
2024-02-08 01:58:40,130:INFO:Creating metrics dataframe
2024-02-08 01:58:40,152:INFO:Initializing Random Forest Classifier
2024-02-08 01:58:40,152:INFO:Total runtime is 4.636962274710337 minutes
2024-02-08 01:58:40,156:INFO:SubProcess create_model() called ==================================
2024-02-08 01:58:40,156:INFO:Initializing create_model()
2024-02-08 01:58:40,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 01:58:40,157:INFO:Checking exceptions
2024-02-08 01:58:40,157:INFO:Importing libraries
2024-02-08 01:58:40,157:INFO:Copying training dataset
2024-02-08 01:58:40,258:INFO:Defining folds
2024-02-08 01:58:40,258:INFO:Declaring metric variables
2024-02-08 01:58:40,262:INFO:Importing untrained model
2024-02-08 01:58:40,274:INFO:Random Forest Classifier Imported successfully
2024-02-08 01:58:40,291:INFO:Starting cross validation
2024-02-08 01:58:40,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:00:39,448:INFO:Calculating mean and std
2024-02-08 02:00:39,449:INFO:Creating metrics dataframe
2024-02-08 02:00:39,455:INFO:Uploading results into container
2024-02-08 02:00:39,457:INFO:Uploading model into container now
2024-02-08 02:00:39,459:INFO:_master_model_container: 7
2024-02-08 02:00:39,459:INFO:_display_container: 2
2024-02-08 02:00:39,461:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:00:39,461:INFO:create_model() successfully completed......................................
2024-02-08 02:00:39,691:INFO:SubProcess create_model() end ==================================
2024-02-08 02:00:39,691:INFO:Creating metrics dataframe
2024-02-08 02:00:39,712:INFO:Initializing Quadratic Discriminant Analysis
2024-02-08 02:00:39,713:INFO:Total runtime is 6.629642323652902 minutes
2024-02-08 02:00:39,719:INFO:SubProcess create_model() called ==================================
2024-02-08 02:00:39,720:INFO:Initializing create_model()
2024-02-08 02:00:39,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:00:39,720:INFO:Checking exceptions
2024-02-08 02:00:39,720:INFO:Importing libraries
2024-02-08 02:00:39,720:INFO:Copying training dataset
2024-02-08 02:00:39,882:INFO:Defining folds
2024-02-08 02:00:39,882:INFO:Declaring metric variables
2024-02-08 02:00:39,890:INFO:Importing untrained model
2024-02-08 02:00:39,898:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-08 02:00:39,913:INFO:Starting cross validation
2024-02-08 02:00:39,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:01:14,092:INFO:Calculating mean and std
2024-02-08 02:01:14,095:INFO:Creating metrics dataframe
2024-02-08 02:01:14,105:INFO:Uploading results into container
2024-02-08 02:01:14,107:INFO:Uploading model into container now
2024-02-08 02:01:14,109:INFO:_master_model_container: 8
2024-02-08 02:01:14,109:INFO:_display_container: 2
2024-02-08 02:01:14,111:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-08 02:01:14,111:INFO:create_model() successfully completed......................................
2024-02-08 02:01:14,265:INFO:SubProcess create_model() end ==================================
2024-02-08 02:01:14,265:INFO:Creating metrics dataframe
2024-02-08 02:01:14,288:INFO:Initializing Ada Boost Classifier
2024-02-08 02:01:14,289:INFO:Total runtime is 7.205918296178181 minutes
2024-02-08 02:01:14,292:INFO:SubProcess create_model() called ==================================
2024-02-08 02:01:14,293:INFO:Initializing create_model()
2024-02-08 02:01:14,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:01:14,293:INFO:Checking exceptions
2024-02-08 02:01:14,293:INFO:Importing libraries
2024-02-08 02:01:14,293:INFO:Copying training dataset
2024-02-08 02:01:14,386:INFO:Defining folds
2024-02-08 02:01:14,386:INFO:Declaring metric variables
2024-02-08 02:01:14,391:INFO:Importing untrained model
2024-02-08 02:01:14,407:INFO:Ada Boost Classifier Imported successfully
2024-02-08 02:01:14,420:INFO:Starting cross validation
2024-02-08 02:01:14,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:02:27,496:INFO:Calculating mean and std
2024-02-08 02:02:27,499:INFO:Creating metrics dataframe
2024-02-08 02:02:27,509:INFO:Uploading results into container
2024-02-08 02:02:27,511:INFO:Uploading model into container now
2024-02-08 02:02:27,513:INFO:_master_model_container: 9
2024-02-08 02:02:27,513:INFO:_display_container: 2
2024-02-08 02:02:27,515:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6300)
2024-02-08 02:02:27,516:INFO:create_model() successfully completed......................................
2024-02-08 02:02:27,672:INFO:SubProcess create_model() end ==================================
2024-02-08 02:02:27,672:INFO:Creating metrics dataframe
2024-02-08 02:02:27,684:INFO:Initializing Gradient Boosting Classifier
2024-02-08 02:02:27,684:INFO:Total runtime is 8.429156816005706 minutes
2024-02-08 02:02:27,688:INFO:SubProcess create_model() called ==================================
2024-02-08 02:02:27,689:INFO:Initializing create_model()
2024-02-08 02:02:27,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:02:27,689:INFO:Checking exceptions
2024-02-08 02:02:27,689:INFO:Importing libraries
2024-02-08 02:02:27,690:INFO:Copying training dataset
2024-02-08 02:02:27,791:INFO:Defining folds
2024-02-08 02:02:27,792:INFO:Declaring metric variables
2024-02-08 02:02:27,796:INFO:Importing untrained model
2024-02-08 02:02:27,805:INFO:Gradient Boosting Classifier Imported successfully
2024-02-08 02:02:27,813:INFO:Starting cross validation
2024-02-08 02:02:27,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:06:07,769:INFO:Calculating mean and std
2024-02-08 02:06:07,773:INFO:Creating metrics dataframe
2024-02-08 02:06:07,783:INFO:Uploading results into container
2024-02-08 02:06:07,785:INFO:Uploading model into container now
2024-02-08 02:06:07,785:INFO:_master_model_container: 10
2024-02-08 02:06:07,786:INFO:_display_container: 2
2024-02-08 02:06:07,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-08 02:06:07,787:INFO:create_model() successfully completed......................................
2024-02-08 02:06:07,976:INFO:SubProcess create_model() end ==================================
2024-02-08 02:06:07,977:INFO:Creating metrics dataframe
2024-02-08 02:06:07,997:INFO:Initializing Linear Discriminant Analysis
2024-02-08 02:06:07,997:INFO:Total runtime is 12.101041110356649 minutes
2024-02-08 02:06:08,002:INFO:SubProcess create_model() called ==================================
2024-02-08 02:06:08,003:INFO:Initializing create_model()
2024-02-08 02:06:08,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:06:08,003:INFO:Checking exceptions
2024-02-08 02:06:08,003:INFO:Importing libraries
2024-02-08 02:06:08,003:INFO:Copying training dataset
2024-02-08 02:06:08,139:INFO:Defining folds
2024-02-08 02:06:08,139:INFO:Declaring metric variables
2024-02-08 02:06:08,144:INFO:Importing untrained model
2024-02-08 02:06:08,152:INFO:Linear Discriminant Analysis Imported successfully
2024-02-08 02:06:08,161:INFO:Starting cross validation
2024-02-08 02:06:08,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:06:40,572:INFO:Calculating mean and std
2024-02-08 02:06:40,575:INFO:Creating metrics dataframe
2024-02-08 02:06:40,584:INFO:Uploading results into container
2024-02-08 02:06:40,588:INFO:Uploading model into container now
2024-02-08 02:06:40,588:INFO:_master_model_container: 11
2024-02-08 02:06:40,590:INFO:_display_container: 2
2024-02-08 02:06:40,590:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-08 02:06:40,590:INFO:create_model() successfully completed......................................
2024-02-08 02:06:40,763:INFO:SubProcess create_model() end ==================================
2024-02-08 02:06:40,763:INFO:Creating metrics dataframe
2024-02-08 02:06:40,781:INFO:Initializing Extra Trees Classifier
2024-02-08 02:06:40,782:INFO:Total runtime is 12.647458040714264 minutes
2024-02-08 02:06:40,788:INFO:SubProcess create_model() called ==================================
2024-02-08 02:06:40,789:INFO:Initializing create_model()
2024-02-08 02:06:40,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:06:40,789:INFO:Checking exceptions
2024-02-08 02:06:40,790:INFO:Importing libraries
2024-02-08 02:06:40,790:INFO:Copying training dataset
2024-02-08 02:06:40,969:INFO:Defining folds
2024-02-08 02:06:40,969:INFO:Declaring metric variables
2024-02-08 02:06:40,977:INFO:Importing untrained model
2024-02-08 02:06:40,985:INFO:Extra Trees Classifier Imported successfully
2024-02-08 02:06:40,997:INFO:Starting cross validation
2024-02-08 02:06:41,013:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:07:48,590:INFO:Calculating mean and std
2024-02-08 02:07:48,593:INFO:Creating metrics dataframe
2024-02-08 02:07:48,603:INFO:Uploading results into container
2024-02-08 02:07:48,605:INFO:Uploading model into container now
2024-02-08 02:07:48,605:INFO:_master_model_container: 12
2024-02-08 02:07:48,606:INFO:_display_container: 2
2024-02-08 02:07:48,607:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:07:48,608:INFO:create_model() successfully completed......................................
2024-02-08 02:07:48,817:INFO:SubProcess create_model() end ==================================
2024-02-08 02:07:48,818:INFO:Creating metrics dataframe
2024-02-08 02:07:48,852:INFO:Initializing Light Gradient Boosting Machine
2024-02-08 02:07:48,852:INFO:Total runtime is 13.781957828998566 minutes
2024-02-08 02:07:48,860:INFO:SubProcess create_model() called ==================================
2024-02-08 02:07:48,861:INFO:Initializing create_model()
2024-02-08 02:07:48,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:07:48,861:INFO:Checking exceptions
2024-02-08 02:07:48,862:INFO:Importing libraries
2024-02-08 02:07:48,862:INFO:Copying training dataset
2024-02-08 02:07:49,038:INFO:Defining folds
2024-02-08 02:07:49,038:INFO:Declaring metric variables
2024-02-08 02:07:49,044:INFO:Importing untrained model
2024-02-08 02:07:49,055:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 02:07:49,066:INFO:Starting cross validation
2024-02-08 02:07:49,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:08:30,402:INFO:Calculating mean and std
2024-02-08 02:08:30,404:INFO:Creating metrics dataframe
2024-02-08 02:08:30,413:INFO:Uploading results into container
2024-02-08 02:08:30,414:INFO:Uploading model into container now
2024-02-08 02:08:30,415:INFO:_master_model_container: 13
2024-02-08 02:08:30,416:INFO:_display_container: 2
2024-02-08 02:08:30,417:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 02:08:30,418:INFO:create_model() successfully completed......................................
2024-02-08 02:08:30,622:INFO:SubProcess create_model() end ==================================
2024-02-08 02:08:30,622:INFO:Creating metrics dataframe
2024-02-08 02:08:30,643:INFO:Initializing CatBoost Classifier
2024-02-08 02:08:30,643:INFO:Total runtime is 14.478477700551352 minutes
2024-02-08 02:08:30,649:INFO:SubProcess create_model() called ==================================
2024-02-08 02:08:30,650:INFO:Initializing create_model()
2024-02-08 02:08:30,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:08:30,650:INFO:Checking exceptions
2024-02-08 02:08:30,651:INFO:Importing libraries
2024-02-08 02:08:30,651:INFO:Copying training dataset
2024-02-08 02:08:30,822:INFO:Defining folds
2024-02-08 02:08:30,822:INFO:Declaring metric variables
2024-02-08 02:08:30,830:INFO:Importing untrained model
2024-02-08 02:08:30,837:INFO:CatBoost Classifier Imported successfully
2024-02-08 02:08:30,852:INFO:Starting cross validation
2024-02-08 02:08:30,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:11:09,952:INFO:Calculating mean and std
2024-02-08 02:11:09,954:INFO:Creating metrics dataframe
2024-02-08 02:11:09,961:INFO:Uploading results into container
2024-02-08 02:11:09,963:INFO:Uploading model into container now
2024-02-08 02:11:09,964:INFO:_master_model_container: 14
2024-02-08 02:11:09,964:INFO:_display_container: 2
2024-02-08 02:11:09,964:INFO:<catboost.core.CatBoostClassifier object at 0x0000023698F21D80>
2024-02-08 02:11:09,964:INFO:create_model() successfully completed......................................
2024-02-08 02:11:10,160:INFO:SubProcess create_model() end ==================================
2024-02-08 02:11:10,161:INFO:Creating metrics dataframe
2024-02-08 02:11:10,194:INFO:Initializing Dummy Classifier
2024-02-08 02:11:10,195:INFO:Total runtime is 17.137672372659047 minutes
2024-02-08 02:11:10,203:INFO:SubProcess create_model() called ==================================
2024-02-08 02:11:10,204:INFO:Initializing create_model()
2024-02-08 02:11:10,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27ABD60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:11:10,204:INFO:Checking exceptions
2024-02-08 02:11:10,204:INFO:Importing libraries
2024-02-08 02:11:10,204:INFO:Copying training dataset
2024-02-08 02:11:10,395:INFO:Defining folds
2024-02-08 02:11:10,395:INFO:Declaring metric variables
2024-02-08 02:11:10,401:INFO:Importing untrained model
2024-02-08 02:11:10,409:INFO:Dummy Classifier Imported successfully
2024-02-08 02:11:10,425:INFO:Starting cross validation
2024-02-08 02:11:10,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:11:32,986:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:33,008:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:33,664:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:33,708:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:33,993:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:36,112:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:36,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:36,192:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:42,794:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:42,876:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:11:43,010:INFO:Calculating mean and std
2024-02-08 02:11:43,012:INFO:Creating metrics dataframe
2024-02-08 02:11:43,021:INFO:Uploading results into container
2024-02-08 02:11:43,022:INFO:Uploading model into container now
2024-02-08 02:11:43,022:INFO:_master_model_container: 15
2024-02-08 02:11:43,022:INFO:_display_container: 2
2024-02-08 02:11:43,023:INFO:DummyClassifier(constant=None, random_state=6300, strategy='prior')
2024-02-08 02:11:43,023:INFO:create_model() successfully completed......................................
2024-02-08 02:11:43,216:INFO:SubProcess create_model() end ==================================
2024-02-08 02:11:43,217:INFO:Creating metrics dataframe
2024-02-08 02:11:43,263:INFO:Initializing create_model()
2024-02-08 02:11:43,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:11:43,263:INFO:Checking exceptions
2024-02-08 02:11:43,267:INFO:Importing libraries
2024-02-08 02:11:43,267:INFO:Copying training dataset
2024-02-08 02:11:43,430:INFO:Defining folds
2024-02-08 02:11:43,430:INFO:Declaring metric variables
2024-02-08 02:11:43,430:INFO:Importing untrained model
2024-02-08 02:11:43,430:INFO:Declaring custom model
2024-02-08 02:11:43,431:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 02:11:43,448:INFO:Cross validation set to False
2024-02-08 02:11:43,449:INFO:Fitting Model
2024-02-08 02:11:48,263:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:11:48,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089323 seconds.
2024-02-08 02:11:48,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:11:48,383:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:11:48,386:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:11:48,388:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:11:51,047:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:11:51,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009886 seconds.
2024-02-08 02:11:51,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:11:51,060:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 02:11:51,061:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 02:11:51,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:11:51,533:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 02:11:51,533:INFO:create_model() successfully completed......................................
2024-02-08 02:11:51,731:INFO:Initializing create_model()
2024-02-08 02:11:51,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:11:51,732:INFO:Checking exceptions
2024-02-08 02:11:51,735:INFO:Importing libraries
2024-02-08 02:11:51,738:INFO:Copying training dataset
2024-02-08 02:11:51,891:INFO:Defining folds
2024-02-08 02:11:51,891:INFO:Declaring metric variables
2024-02-08 02:11:51,892:INFO:Importing untrained model
2024-02-08 02:11:51,892:INFO:Declaring custom model
2024-02-08 02:11:51,893:INFO:Extra Trees Classifier Imported successfully
2024-02-08 02:11:51,904:INFO:Cross validation set to False
2024-02-08 02:11:51,904:INFO:Fitting Model
2024-02-08 02:11:55,383:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:11:55,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069595 seconds.
2024-02-08 02:11:55,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:11:55,476:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:11:55,478:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:11:55,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:12:02,581:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:12:02,581:INFO:create_model() successfully completed......................................
2024-02-08 02:12:02,739:INFO:Initializing create_model()
2024-02-08 02:12:02,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:12:02,739:INFO:Checking exceptions
2024-02-08 02:12:02,743:INFO:Importing libraries
2024-02-08 02:12:02,744:INFO:Copying training dataset
2024-02-08 02:12:02,899:INFO:Defining folds
2024-02-08 02:12:02,899:INFO:Declaring metric variables
2024-02-08 02:12:02,899:INFO:Importing untrained model
2024-02-08 02:12:02,899:INFO:Declaring custom model
2024-02-08 02:12:02,900:INFO:Random Forest Classifier Imported successfully
2024-02-08 02:12:02,911:INFO:Cross validation set to False
2024-02-08 02:12:02,912:INFO:Fitting Model
2024-02-08 02:12:06,097:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:12:06,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071349 seconds.
2024-02-08 02:12:06,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:12:06,192:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:12:06,195:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:12:06,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:12:18,708:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:12:18,708:INFO:create_model() successfully completed......................................
2024-02-08 02:12:18,916:INFO:Initializing create_model()
2024-02-08 02:12:18,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:12:18,917:INFO:Checking exceptions
2024-02-08 02:12:18,921:INFO:Importing libraries
2024-02-08 02:12:18,921:INFO:Copying training dataset
2024-02-08 02:12:19,092:INFO:Defining folds
2024-02-08 02:12:19,093:INFO:Declaring metric variables
2024-02-08 02:12:19,093:INFO:Importing untrained model
2024-02-08 02:12:19,093:INFO:Declaring custom model
2024-02-08 02:12:19,094:INFO:Gradient Boosting Classifier Imported successfully
2024-02-08 02:12:19,109:INFO:Cross validation set to False
2024-02-08 02:12:19,109:INFO:Fitting Model
2024-02-08 02:12:22,954:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:12:23,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065020 seconds.
2024-02-08 02:12:23,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:12:23,044:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:12:23,046:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:12:23,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:13:22,064:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-08 02:13:22,064:INFO:create_model() successfully completed......................................
2024-02-08 02:13:22,211:INFO:Initializing create_model()
2024-02-08 02:13:22,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6300), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:13:22,212:INFO:Checking exceptions
2024-02-08 02:13:22,213:INFO:Importing libraries
2024-02-08 02:13:22,213:INFO:Copying training dataset
2024-02-08 02:13:22,353:INFO:Defining folds
2024-02-08 02:13:22,353:INFO:Declaring metric variables
2024-02-08 02:13:22,353:INFO:Importing untrained model
2024-02-08 02:13:22,353:INFO:Declaring custom model
2024-02-08 02:13:22,354:INFO:Ada Boost Classifier Imported successfully
2024-02-08 02:13:22,364:INFO:Cross validation set to False
2024-02-08 02:13:22,364:INFO:Fitting Model
2024-02-08 02:13:25,776:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:13:25,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021644 seconds.
2024-02-08 02:13:25,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 02:13:25,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 02:13:25,849:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:13:25,851:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:13:25,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:13:37,916:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6300)
2024-02-08 02:13:37,916:INFO:create_model() successfully completed......................................
2024-02-08 02:13:38,072:INFO:_master_model_container: 15
2024-02-08 02:13:38,072:INFO:_display_container: 2
2024-02-08 02:13:38,073:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6300)]
2024-02-08 02:13:38,073:INFO:compare_models() successfully completed......................................
2024-02-08 02:26:55,471:INFO:Initializing compare_models()
2024-02-08 02:26:55,471:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-08 02:26:55,472:INFO:Checking exceptions
2024-02-08 02:26:55,514:INFO:Preparing display monitor
2024-02-08 02:26:55,547:INFO:Initializing Logistic Regression
2024-02-08 02:26:55,547:INFO:Total runtime is 0.0 minutes
2024-02-08 02:26:55,553:INFO:SubProcess create_model() called ==================================
2024-02-08 02:26:55,553:INFO:Initializing create_model()
2024-02-08 02:26:55,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:26:55,554:INFO:Checking exceptions
2024-02-08 02:26:55,554:INFO:Importing libraries
2024-02-08 02:26:55,554:INFO:Copying training dataset
2024-02-08 02:26:55,673:INFO:Defining folds
2024-02-08 02:26:55,673:INFO:Declaring metric variables
2024-02-08 02:26:55,679:INFO:Importing untrained model
2024-02-08 02:26:55,684:INFO:Logistic Regression Imported successfully
2024-02-08 02:26:55,692:INFO:Starting cross validation
2024-02-08 02:26:55,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:27:36,706:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:38,200:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:38,342:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:40,050:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:40,225:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:40,258:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:41,637:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:51,362:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:56,100:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:56,106:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 02:27:56,284:INFO:Calculating mean and std
2024-02-08 02:27:56,286:INFO:Creating metrics dataframe
2024-02-08 02:27:56,292:INFO:Uploading results into container
2024-02-08 02:27:56,293:INFO:Uploading model into container now
2024-02-08 02:27:56,293:INFO:_master_model_container: 16
2024-02-08 02:27:56,294:INFO:_display_container: 2
2024-02-08 02:27:56,294:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6300, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-08 02:27:56,295:INFO:create_model() successfully completed......................................
2024-02-08 02:27:56,470:INFO:SubProcess create_model() end ==================================
2024-02-08 02:27:56,471:INFO:Creating metrics dataframe
2024-02-08 02:27:56,482:INFO:Initializing K Neighbors Classifier
2024-02-08 02:27:56,482:INFO:Total runtime is 1.0155830224355062 minutes
2024-02-08 02:27:56,487:INFO:SubProcess create_model() called ==================================
2024-02-08 02:27:56,487:INFO:Initializing create_model()
2024-02-08 02:27:56,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:27:56,488:INFO:Checking exceptions
2024-02-08 02:27:56,488:INFO:Importing libraries
2024-02-08 02:27:56,488:INFO:Copying training dataset
2024-02-08 02:27:56,603:INFO:Defining folds
2024-02-08 02:27:56,603:INFO:Declaring metric variables
2024-02-08 02:27:56,608:INFO:Importing untrained model
2024-02-08 02:27:56,614:INFO:K Neighbors Classifier Imported successfully
2024-02-08 02:27:56,621:INFO:Starting cross validation
2024-02-08 02:27:56,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:28:46,389:INFO:Calculating mean and std
2024-02-08 02:28:46,392:INFO:Creating metrics dataframe
2024-02-08 02:28:46,400:INFO:Uploading results into container
2024-02-08 02:28:46,401:INFO:Uploading model into container now
2024-02-08 02:28:46,401:INFO:_master_model_container: 17
2024-02-08 02:28:46,401:INFO:_display_container: 2
2024-02-08 02:28:46,402:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-08 02:28:46,402:INFO:create_model() successfully completed......................................
2024-02-08 02:28:46,524:INFO:SubProcess create_model() end ==================================
2024-02-08 02:28:46,524:INFO:Creating metrics dataframe
2024-02-08 02:28:46,535:INFO:Initializing Naive Bayes
2024-02-08 02:28:46,535:INFO:Total runtime is 1.8498025576273602 minutes
2024-02-08 02:28:46,540:INFO:SubProcess create_model() called ==================================
2024-02-08 02:28:46,540:INFO:Initializing create_model()
2024-02-08 02:28:46,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:28:46,540:INFO:Checking exceptions
2024-02-08 02:28:46,540:INFO:Importing libraries
2024-02-08 02:28:46,540:INFO:Copying training dataset
2024-02-08 02:28:46,631:INFO:Defining folds
2024-02-08 02:28:46,632:INFO:Declaring metric variables
2024-02-08 02:28:46,637:INFO:Importing untrained model
2024-02-08 02:28:46,643:INFO:Naive Bayes Imported successfully
2024-02-08 02:28:46,653:INFO:Starting cross validation
2024-02-08 02:28:46,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:29:18,508:INFO:Calculating mean and std
2024-02-08 02:29:18,511:INFO:Creating metrics dataframe
2024-02-08 02:29:18,522:INFO:Uploading results into container
2024-02-08 02:29:18,523:INFO:Uploading model into container now
2024-02-08 02:29:18,525:INFO:_master_model_container: 18
2024-02-08 02:29:18,525:INFO:_display_container: 2
2024-02-08 02:29:18,526:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-08 02:29:18,526:INFO:create_model() successfully completed......................................
2024-02-08 02:29:18,665:INFO:SubProcess create_model() end ==================================
2024-02-08 02:29:18,665:INFO:Creating metrics dataframe
2024-02-08 02:29:18,677:INFO:Initializing Decision Tree Classifier
2024-02-08 02:29:18,677:INFO:Total runtime is 2.385511040687561 minutes
2024-02-08 02:29:18,682:INFO:SubProcess create_model() called ==================================
2024-02-08 02:29:18,683:INFO:Initializing create_model()
2024-02-08 02:29:18,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:29:18,683:INFO:Checking exceptions
2024-02-08 02:29:18,683:INFO:Importing libraries
2024-02-08 02:29:18,683:INFO:Copying training dataset
2024-02-08 02:29:18,765:INFO:Defining folds
2024-02-08 02:29:18,765:INFO:Declaring metric variables
2024-02-08 02:29:18,771:INFO:Importing untrained model
2024-02-08 02:29:18,776:INFO:Decision Tree Classifier Imported successfully
2024-02-08 02:29:18,784:INFO:Starting cross validation
2024-02-08 02:29:18,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:29:55,199:INFO:Calculating mean and std
2024-02-08 02:29:55,202:INFO:Creating metrics dataframe
2024-02-08 02:29:55,207:INFO:Uploading results into container
2024-02-08 02:29:55,208:INFO:Uploading model into container now
2024-02-08 02:29:55,209:INFO:_master_model_container: 19
2024-02-08 02:29:55,209:INFO:_display_container: 2
2024-02-08 02:29:55,209:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6300, splitter='best')
2024-02-08 02:29:55,209:INFO:create_model() successfully completed......................................
2024-02-08 02:29:55,335:INFO:SubProcess create_model() end ==================================
2024-02-08 02:29:55,336:INFO:Creating metrics dataframe
2024-02-08 02:29:55,348:INFO:Initializing SVM - Linear Kernel
2024-02-08 02:29:55,348:INFO:Total runtime is 2.996685802936554 minutes
2024-02-08 02:29:55,353:INFO:SubProcess create_model() called ==================================
2024-02-08 02:29:55,354:INFO:Initializing create_model()
2024-02-08 02:29:55,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:29:55,355:INFO:Checking exceptions
2024-02-08 02:29:55,355:INFO:Importing libraries
2024-02-08 02:29:55,355:INFO:Copying training dataset
2024-02-08 02:29:55,443:INFO:Defining folds
2024-02-08 02:29:55,444:INFO:Declaring metric variables
2024-02-08 02:29:55,449:INFO:Importing untrained model
2024-02-08 02:29:55,454:INFO:SVM - Linear Kernel Imported successfully
2024-02-08 02:29:55,461:INFO:Starting cross validation
2024-02-08 02:29:55,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:30:26,491:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:26,992:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:27,181:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:28,692:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:29,488:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:30,215:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:31,256:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:34,690:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:38,700:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:40,280:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-08 02:30:40,405:INFO:Calculating mean and std
2024-02-08 02:30:40,407:INFO:Creating metrics dataframe
2024-02-08 02:30:40,413:INFO:Uploading results into container
2024-02-08 02:30:40,414:INFO:Uploading model into container now
2024-02-08 02:30:40,415:INFO:_master_model_container: 20
2024-02-08 02:30:40,415:INFO:_display_container: 2
2024-02-08 02:30:40,416:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6300, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-08 02:30:40,416:INFO:create_model() successfully completed......................................
2024-02-08 02:30:40,583:INFO:SubProcess create_model() end ==================================
2024-02-08 02:30:40,583:INFO:Creating metrics dataframe
2024-02-08 02:30:40,596:INFO:Initializing Ridge Classifier
2024-02-08 02:30:40,597:INFO:Total runtime is 3.7508379300435384 minutes
2024-02-08 02:30:40,602:INFO:SubProcess create_model() called ==================================
2024-02-08 02:30:40,603:INFO:Initializing create_model()
2024-02-08 02:30:40,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:30:40,603:INFO:Checking exceptions
2024-02-08 02:30:40,603:INFO:Importing libraries
2024-02-08 02:30:40,603:INFO:Copying training dataset
2024-02-08 02:30:40,723:INFO:Defining folds
2024-02-08 02:30:40,723:INFO:Declaring metric variables
2024-02-08 02:30:40,728:INFO:Importing untrained model
2024-02-08 02:30:40,735:INFO:Ridge Classifier Imported successfully
2024-02-08 02:30:40,744:INFO:Starting cross validation
2024-02-08 02:30:40,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:31:04,683:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:04,741:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:04,853:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:04,916:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:05,269:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:05,797:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:06,577:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:06,674:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:13,613:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:13,812:WARNING:C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\ProgramData\miniconda3\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-08 02:31:13,953:INFO:Calculating mean and std
2024-02-08 02:31:13,954:INFO:Creating metrics dataframe
2024-02-08 02:31:13,959:INFO:Uploading results into container
2024-02-08 02:31:13,960:INFO:Uploading model into container now
2024-02-08 02:31:13,961:INFO:_master_model_container: 21
2024-02-08 02:31:13,961:INFO:_display_container: 2
2024-02-08 02:31:13,961:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6300, solver='auto',
                tol=0.0001)
2024-02-08 02:31:13,962:INFO:create_model() successfully completed......................................
2024-02-08 02:31:14,091:INFO:SubProcess create_model() end ==================================
2024-02-08 02:31:14,091:INFO:Creating metrics dataframe
2024-02-08 02:31:14,101:INFO:Initializing Random Forest Classifier
2024-02-08 02:31:14,102:INFO:Total runtime is 4.309262867768606 minutes
2024-02-08 02:31:14,106:INFO:SubProcess create_model() called ==================================
2024-02-08 02:31:14,106:INFO:Initializing create_model()
2024-02-08 02:31:14,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:31:14,106:INFO:Checking exceptions
2024-02-08 02:31:14,107:INFO:Importing libraries
2024-02-08 02:31:14,107:INFO:Copying training dataset
2024-02-08 02:31:14,186:INFO:Defining folds
2024-02-08 02:31:14,186:INFO:Declaring metric variables
2024-02-08 02:31:14,190:INFO:Importing untrained model
2024-02-08 02:31:14,198:INFO:Random Forest Classifier Imported successfully
2024-02-08 02:31:14,207:INFO:Starting cross validation
2024-02-08 02:31:14,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:33:10,554:INFO:Calculating mean and std
2024-02-08 02:33:10,556:INFO:Creating metrics dataframe
2024-02-08 02:33:10,560:INFO:Uploading results into container
2024-02-08 02:33:10,561:INFO:Uploading model into container now
2024-02-08 02:33:10,562:INFO:_master_model_container: 22
2024-02-08 02:33:10,562:INFO:_display_container: 2
2024-02-08 02:33:10,563:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:33:10,563:INFO:create_model() successfully completed......................................
2024-02-08 02:33:10,723:INFO:SubProcess create_model() end ==================================
2024-02-08 02:33:10,724:INFO:Creating metrics dataframe
2024-02-08 02:33:10,738:INFO:Initializing Quadratic Discriminant Analysis
2024-02-08 02:33:10,738:INFO:Total runtime is 6.253186639149984 minutes
2024-02-08 02:33:10,742:INFO:SubProcess create_model() called ==================================
2024-02-08 02:33:10,742:INFO:Initializing create_model()
2024-02-08 02:33:10,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:33:10,742:INFO:Checking exceptions
2024-02-08 02:33:10,742:INFO:Importing libraries
2024-02-08 02:33:10,743:INFO:Copying training dataset
2024-02-08 02:33:10,844:INFO:Defining folds
2024-02-08 02:33:10,844:INFO:Declaring metric variables
2024-02-08 02:33:10,848:INFO:Importing untrained model
2024-02-08 02:33:10,856:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-08 02:33:10,868:INFO:Starting cross validation
2024-02-08 02:33:10,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:33:45,285:INFO:Calculating mean and std
2024-02-08 02:33:45,287:INFO:Creating metrics dataframe
2024-02-08 02:33:45,292:INFO:Uploading results into container
2024-02-08 02:33:45,293:INFO:Uploading model into container now
2024-02-08 02:33:45,293:INFO:_master_model_container: 23
2024-02-08 02:33:45,294:INFO:_display_container: 2
2024-02-08 02:33:45,294:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-08 02:33:45,294:INFO:create_model() successfully completed......................................
2024-02-08 02:33:45,425:INFO:SubProcess create_model() end ==================================
2024-02-08 02:33:45,425:INFO:Creating metrics dataframe
2024-02-08 02:33:45,447:INFO:Initializing Ada Boost Classifier
2024-02-08 02:33:45,448:INFO:Total runtime is 6.831691896915436 minutes
2024-02-08 02:33:45,452:INFO:SubProcess create_model() called ==================================
2024-02-08 02:33:45,452:INFO:Initializing create_model()
2024-02-08 02:33:45,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:33:45,452:INFO:Checking exceptions
2024-02-08 02:33:45,453:INFO:Importing libraries
2024-02-08 02:33:45,453:INFO:Copying training dataset
2024-02-08 02:33:45,566:INFO:Defining folds
2024-02-08 02:33:45,566:INFO:Declaring metric variables
2024-02-08 02:33:45,570:INFO:Importing untrained model
2024-02-08 02:33:45,577:INFO:Ada Boost Classifier Imported successfully
2024-02-08 02:33:45,587:INFO:Starting cross validation
2024-02-08 02:33:45,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:34:54,344:INFO:Calculating mean and std
2024-02-08 02:34:54,347:INFO:Creating metrics dataframe
2024-02-08 02:34:54,353:INFO:Uploading results into container
2024-02-08 02:34:54,354:INFO:Uploading model into container now
2024-02-08 02:34:54,354:INFO:_master_model_container: 24
2024-02-08 02:34:54,355:INFO:_display_container: 2
2024-02-08 02:34:54,355:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6300)
2024-02-08 02:34:54,356:INFO:create_model() successfully completed......................................
2024-02-08 02:34:54,521:INFO:SubProcess create_model() end ==================================
2024-02-08 02:34:54,522:INFO:Creating metrics dataframe
2024-02-08 02:34:54,536:INFO:Initializing Gradient Boosting Classifier
2024-02-08 02:34:54,536:INFO:Total runtime is 7.983156907558442 minutes
2024-02-08 02:34:54,541:INFO:SubProcess create_model() called ==================================
2024-02-08 02:34:54,541:INFO:Initializing create_model()
2024-02-08 02:34:54,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:34:54,541:INFO:Checking exceptions
2024-02-08 02:34:54,541:INFO:Importing libraries
2024-02-08 02:34:54,542:INFO:Copying training dataset
2024-02-08 02:34:54,654:INFO:Defining folds
2024-02-08 02:34:54,654:INFO:Declaring metric variables
2024-02-08 02:34:54,658:INFO:Importing untrained model
2024-02-08 02:34:54,667:INFO:Gradient Boosting Classifier Imported successfully
2024-02-08 02:34:54,680:INFO:Starting cross validation
2024-02-08 02:34:54,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:38:13,524:INFO:Calculating mean and std
2024-02-08 02:38:13,525:INFO:Creating metrics dataframe
2024-02-08 02:38:13,530:INFO:Uploading results into container
2024-02-08 02:38:13,531:INFO:Uploading model into container now
2024-02-08 02:38:13,531:INFO:_master_model_container: 25
2024-02-08 02:38:13,531:INFO:_display_container: 2
2024-02-08 02:38:13,532:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-08 02:38:13,532:INFO:create_model() successfully completed......................................
2024-02-08 02:38:13,679:INFO:SubProcess create_model() end ==================================
2024-02-08 02:38:13,679:INFO:Creating metrics dataframe
2024-02-08 02:38:13,697:INFO:Initializing Linear Discriminant Analysis
2024-02-08 02:38:13,697:INFO:Total runtime is 11.302500132719675 minutes
2024-02-08 02:38:13,703:INFO:SubProcess create_model() called ==================================
2024-02-08 02:38:13,704:INFO:Initializing create_model()
2024-02-08 02:38:13,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:38:13,705:INFO:Checking exceptions
2024-02-08 02:38:13,705:INFO:Importing libraries
2024-02-08 02:38:13,705:INFO:Copying training dataset
2024-02-08 02:38:13,824:INFO:Defining folds
2024-02-08 02:38:13,825:INFO:Declaring metric variables
2024-02-08 02:38:13,829:INFO:Importing untrained model
2024-02-08 02:38:13,836:INFO:Linear Discriminant Analysis Imported successfully
2024-02-08 02:38:13,846:INFO:Starting cross validation
2024-02-08 02:38:13,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:38:45,596:INFO:Calculating mean and std
2024-02-08 02:38:45,597:INFO:Creating metrics dataframe
2024-02-08 02:38:45,603:INFO:Uploading results into container
2024-02-08 02:38:45,604:INFO:Uploading model into container now
2024-02-08 02:38:45,604:INFO:_master_model_container: 26
2024-02-08 02:38:45,604:INFO:_display_container: 2
2024-02-08 02:38:45,605:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-08 02:38:45,605:INFO:create_model() successfully completed......................................
2024-02-08 02:38:45,737:INFO:SubProcess create_model() end ==================================
2024-02-08 02:38:45,737:INFO:Creating metrics dataframe
2024-02-08 02:38:45,751:INFO:Initializing Extra Trees Classifier
2024-02-08 02:38:45,751:INFO:Total runtime is 11.836739285786946 minutes
2024-02-08 02:38:45,755:INFO:SubProcess create_model() called ==================================
2024-02-08 02:38:45,755:INFO:Initializing create_model()
2024-02-08 02:38:45,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:38:45,755:INFO:Checking exceptions
2024-02-08 02:38:45,756:INFO:Importing libraries
2024-02-08 02:38:45,756:INFO:Copying training dataset
2024-02-08 02:38:45,867:INFO:Defining folds
2024-02-08 02:38:45,867:INFO:Declaring metric variables
2024-02-08 02:38:45,871:INFO:Importing untrained model
2024-02-08 02:38:45,877:INFO:Extra Trees Classifier Imported successfully
2024-02-08 02:38:45,886:INFO:Starting cross validation
2024-02-08 02:38:45,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:39:52,761:INFO:Calculating mean and std
2024-02-08 02:39:52,763:INFO:Creating metrics dataframe
2024-02-08 02:39:52,769:INFO:Uploading results into container
2024-02-08 02:39:52,770:INFO:Uploading model into container now
2024-02-08 02:39:52,770:INFO:_master_model_container: 27
2024-02-08 02:39:52,770:INFO:_display_container: 2
2024-02-08 02:39:52,771:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:39:52,771:INFO:create_model() successfully completed......................................
2024-02-08 02:39:52,916:INFO:SubProcess create_model() end ==================================
2024-02-08 02:39:52,916:INFO:Creating metrics dataframe
2024-02-08 02:39:52,931:INFO:Initializing Light Gradient Boosting Machine
2024-02-08 02:39:52,931:INFO:Total runtime is 12.956408309936522 minutes
2024-02-08 02:39:52,936:INFO:SubProcess create_model() called ==================================
2024-02-08 02:39:52,936:INFO:Initializing create_model()
2024-02-08 02:39:52,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:39:52,936:INFO:Checking exceptions
2024-02-08 02:39:52,936:INFO:Importing libraries
2024-02-08 02:39:52,937:INFO:Copying training dataset
2024-02-08 02:39:53,057:INFO:Defining folds
2024-02-08 02:39:53,057:INFO:Declaring metric variables
2024-02-08 02:39:53,062:INFO:Importing untrained model
2024-02-08 02:39:53,068:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 02:39:53,078:INFO:Starting cross validation
2024-02-08 02:39:53,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:40:32,523:INFO:Calculating mean and std
2024-02-08 02:40:32,525:INFO:Creating metrics dataframe
2024-02-08 02:40:32,529:INFO:Uploading results into container
2024-02-08 02:40:32,530:INFO:Uploading model into container now
2024-02-08 02:40:32,530:INFO:_master_model_container: 28
2024-02-08 02:40:32,531:INFO:_display_container: 2
2024-02-08 02:40:32,531:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 02:40:32,531:INFO:create_model() successfully completed......................................
2024-02-08 02:40:32,676:INFO:SubProcess create_model() end ==================================
2024-02-08 02:40:32,676:INFO:Creating metrics dataframe
2024-02-08 02:40:32,697:INFO:Initializing CatBoost Classifier
2024-02-08 02:40:32,697:INFO:Total runtime is 13.619181064764657 minutes
2024-02-08 02:40:32,704:INFO:SubProcess create_model() called ==================================
2024-02-08 02:40:32,704:INFO:Initializing create_model()
2024-02-08 02:40:32,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:40:32,704:INFO:Checking exceptions
2024-02-08 02:40:32,704:INFO:Importing libraries
2024-02-08 02:40:32,705:INFO:Copying training dataset
2024-02-08 02:40:32,827:INFO:Defining folds
2024-02-08 02:40:32,827:INFO:Declaring metric variables
2024-02-08 02:40:32,832:INFO:Importing untrained model
2024-02-08 02:40:32,838:INFO:CatBoost Classifier Imported successfully
2024-02-08 02:40:32,848:INFO:Starting cross validation
2024-02-08 02:40:32,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:43:19,175:INFO:Calculating mean and std
2024-02-08 02:43:19,177:INFO:Creating metrics dataframe
2024-02-08 02:43:19,181:INFO:Uploading results into container
2024-02-08 02:43:19,182:INFO:Uploading model into container now
2024-02-08 02:43:19,183:INFO:_master_model_container: 29
2024-02-08 02:43:19,183:INFO:_display_container: 2
2024-02-08 02:43:19,183:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A89A980>
2024-02-08 02:43:19,183:INFO:create_model() successfully completed......................................
2024-02-08 02:43:19,326:INFO:SubProcess create_model() end ==================================
2024-02-08 02:43:19,327:INFO:Creating metrics dataframe
2024-02-08 02:43:19,340:INFO:Initializing Dummy Classifier
2024-02-08 02:43:19,340:INFO:Total runtime is 16.396550365289052 minutes
2024-02-08 02:43:19,345:INFO:SubProcess create_model() called ==================================
2024-02-08 02:43:19,345:INFO:Initializing create_model()
2024-02-08 02:43:19,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E20F4CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:43:19,345:INFO:Checking exceptions
2024-02-08 02:43:19,345:INFO:Importing libraries
2024-02-08 02:43:19,346:INFO:Copying training dataset
2024-02-08 02:43:19,461:INFO:Defining folds
2024-02-08 02:43:19,461:INFO:Declaring metric variables
2024-02-08 02:43:19,467:INFO:Importing untrained model
2024-02-08 02:43:19,475:INFO:Dummy Classifier Imported successfully
2024-02-08 02:43:19,483:INFO:Starting cross validation
2024-02-08 02:43:19,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 02:43:42,457:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:42,730:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:43,174:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:43,293:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:43,662:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:46,060:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:46,380:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:46,517:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:52,389:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:52,522:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-08 02:43:52,650:INFO:Calculating mean and std
2024-02-08 02:43:52,652:INFO:Creating metrics dataframe
2024-02-08 02:43:52,662:INFO:Uploading results into container
2024-02-08 02:43:52,663:INFO:Uploading model into container now
2024-02-08 02:43:52,664:INFO:_master_model_container: 30
2024-02-08 02:43:52,665:INFO:_display_container: 2
2024-02-08 02:43:52,665:INFO:DummyClassifier(constant=None, random_state=6300, strategy='prior')
2024-02-08 02:43:52,665:INFO:create_model() successfully completed......................................
2024-02-08 02:43:52,798:INFO:SubProcess create_model() end ==================================
2024-02-08 02:43:52,798:INFO:Creating metrics dataframe
2024-02-08 02:43:52,824:INFO:Initializing create_model()
2024-02-08 02:43:52,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A89A980>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:43:52,824:INFO:Checking exceptions
2024-02-08 02:43:52,826:INFO:Importing libraries
2024-02-08 02:43:52,827:INFO:Copying training dataset
2024-02-08 02:43:52,919:INFO:Defining folds
2024-02-08 02:43:52,919:INFO:Declaring metric variables
2024-02-08 02:43:52,919:INFO:Importing untrained model
2024-02-08 02:43:52,919:INFO:Declaring custom model
2024-02-08 02:43:52,920:INFO:CatBoost Classifier Imported successfully
2024-02-08 02:43:52,929:INFO:Cross validation set to False
2024-02-08 02:43:52,929:INFO:Fitting Model
2024-02-08 02:43:55,931:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:43:55,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017389 seconds.
2024-02-08 02:43:55,989:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 02:43:55,989:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 02:43:55,989:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:43:55,991:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:43:55,992:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:44:18,092:INFO:<catboost.core.CatBoostClassifier object at 0x0000023698F22110>
2024-02-08 02:44:18,092:INFO:create_model() successfully completed......................................
2024-02-08 02:44:18,248:INFO:Initializing create_model()
2024-02-08 02:44:18,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:44:18,248:INFO:Checking exceptions
2024-02-08 02:44:18,251:INFO:Importing libraries
2024-02-08 02:44:18,251:INFO:Copying training dataset
2024-02-08 02:44:18,377:INFO:Defining folds
2024-02-08 02:44:18,377:INFO:Declaring metric variables
2024-02-08 02:44:18,378:INFO:Importing untrained model
2024-02-08 02:44:18,378:INFO:Declaring custom model
2024-02-08 02:44:18,379:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 02:44:18,391:INFO:Cross validation set to False
2024-02-08 02:44:18,391:INFO:Fitting Model
2024-02-08 02:44:21,699:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:44:21,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073440 seconds.
2024-02-08 02:44:21,793:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:44:21,796:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:44:21,798:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:44:21,799:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:44:24,049:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:44:24,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003652 seconds.
2024-02-08 02:44:24,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 02:44:24,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 02:44:24,063:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 02:44:24,063:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 02:44:24,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:44:24,600:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 02:44:24,600:INFO:create_model() successfully completed......................................
2024-02-08 02:44:24,776:INFO:Initializing create_model()
2024-02-08 02:44:24,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:44:24,776:INFO:Checking exceptions
2024-02-08 02:44:24,780:INFO:Importing libraries
2024-02-08 02:44:24,780:INFO:Copying training dataset
2024-02-08 02:44:24,894:INFO:Defining folds
2024-02-08 02:44:24,895:INFO:Declaring metric variables
2024-02-08 02:44:24,895:INFO:Importing untrained model
2024-02-08 02:44:24,895:INFO:Declaring custom model
2024-02-08 02:44:24,896:INFO:Extra Trees Classifier Imported successfully
2024-02-08 02:44:24,904:INFO:Cross validation set to False
2024-02-08 02:44:24,904:INFO:Fitting Model
2024-02-08 02:44:28,627:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:44:28,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079275 seconds.
2024-02-08 02:44:28,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:44:28,729:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:44:28,730:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:44:28,731:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:44:35,090:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:44:35,090:INFO:create_model() successfully completed......................................
2024-02-08 02:44:35,229:INFO:Initializing create_model()
2024-02-08 02:44:35,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:44:35,230:INFO:Checking exceptions
2024-02-08 02:44:35,231:INFO:Importing libraries
2024-02-08 02:44:35,232:INFO:Copying training dataset
2024-02-08 02:44:35,338:INFO:Defining folds
2024-02-08 02:44:35,338:INFO:Declaring metric variables
2024-02-08 02:44:35,339:INFO:Importing untrained model
2024-02-08 02:44:35,339:INFO:Declaring custom model
2024-02-08 02:44:35,339:INFO:Random Forest Classifier Imported successfully
2024-02-08 02:44:35,348:INFO:Cross validation set to False
2024-02-08 02:44:35,348:INFO:Fitting Model
2024-02-08 02:44:38,577:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:44:38,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073432 seconds.
2024-02-08 02:44:38,667:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:44:38,669:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:44:38,671:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:44:38,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:44:52,044:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2024-02-08 02:44:52,044:INFO:create_model() successfully completed......................................
2024-02-08 02:44:52,185:INFO:Initializing create_model()
2024-02-08 02:44:52,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 02:44:52,186:INFO:Checking exceptions
2024-02-08 02:44:52,188:INFO:Importing libraries
2024-02-08 02:44:52,188:INFO:Copying training dataset
2024-02-08 02:44:52,298:INFO:Defining folds
2024-02-08 02:44:52,298:INFO:Declaring metric variables
2024-02-08 02:44:52,298:INFO:Importing untrained model
2024-02-08 02:44:52,298:INFO:Declaring custom model
2024-02-08 02:44:52,299:INFO:Gradient Boosting Classifier Imported successfully
2024-02-08 02:44:52,307:INFO:Cross validation set to False
2024-02-08 02:44:52,307:INFO:Fitting Model
2024-02-08 02:44:55,316:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 02:44:55,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053763 seconds.
2024-02-08 02:44:55,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 02:44:55,384:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 02:44:55,385:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 02:44:55,386:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 02:45:53,469:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-08 02:45:53,469:INFO:create_model() successfully completed......................................
2024-02-08 02:45:53,678:INFO:_master_model_container: 30
2024-02-08 02:45:53,678:INFO:_display_container: 2
2024-02-08 02:45:53,680:INFO:[<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-02-08 02:45:53,680:INFO:compare_models() successfully completed......................................
2024-02-08 02:45:53,763:INFO:Initializing tune_model()
2024-02-08 02:45:53,764:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>)
2024-02-08 02:45:53,764:INFO:Checking exceptions
2024-02-08 02:45:53,838:INFO:Copying training dataset
2024-02-08 02:45:53,924:INFO:Checking base model
2024-02-08 02:45:53,924:INFO:Base model : CatBoost Classifier
2024-02-08 02:45:53,929:INFO:Declaring metric variables
2024-02-08 02:45:53,934:INFO:Defining Hyperparameters
2024-02-08 02:45:54,116:INFO:Tuning with n_jobs=-1
2024-02-08 02:45:54,116:INFO:Initializing RandomizedSearchCV
2024-02-08 03:10:25,871:INFO:best_params: {'actual_estimator__random_strength': 0.3, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 10, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 11}
2024-02-08 03:10:25,872:INFO:Hyperparameter search completed
2024-02-08 03:10:25,872:INFO:SubProcess create_model() called ==================================
2024-02-08 03:10:25,873:INFO:Initializing create_model()
2024-02-08 03:10:25,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8BC0A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E2BFF3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.3, 'n_estimators': 280, 'l2_leaf_reg': 10, 'eta': 0.1, 'depth': 11})
2024-02-08 03:10:25,873:INFO:Checking exceptions
2024-02-08 03:10:25,873:INFO:Importing libraries
2024-02-08 03:10:25,873:INFO:Copying training dataset
2024-02-08 03:10:25,979:INFO:Defining folds
2024-02-08 03:10:25,980:INFO:Declaring metric variables
2024-02-08 03:10:25,984:INFO:Importing untrained model
2024-02-08 03:10:25,984:INFO:Declaring custom model
2024-02-08 03:10:25,989:INFO:CatBoost Classifier Imported successfully
2024-02-08 03:10:25,996:INFO:Starting cross validation
2024-02-08 03:10:26,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:16:50,467:INFO:Calculating mean and std
2024-02-08 03:16:50,469:INFO:Creating metrics dataframe
2024-02-08 03:16:50,476:INFO:Finalizing model
2024-02-08 03:16:53,511:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:16:53,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057377 seconds.
2024-02-08 03:16:53,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 03:16:53,585:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:16:53,586:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:16:53,586:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:17:46,205:INFO:Uploading results into container
2024-02-08 03:17:46,207:INFO:Uploading model into container now
2024-02-08 03:17:46,207:INFO:_master_model_container: 31
2024-02-08 03:17:46,208:INFO:_display_container: 2
2024-02-08 03:17:46,208:INFO:<catboost.core.CatBoostClassifier object at 0x0000023698F8DC60>
2024-02-08 03:17:46,208:INFO:create_model() successfully completed......................................
2024-02-08 03:17:46,368:INFO:SubProcess create_model() end ==================================
2024-02-08 03:17:46,368:INFO:choose_better activated
2024-02-08 03:17:46,372:INFO:SubProcess create_model() called ==================================
2024-02-08 03:17:46,372:INFO:Initializing create_model()
2024-02-08 03:17:46,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 03:17:46,372:INFO:Checking exceptions
2024-02-08 03:17:46,374:INFO:Importing libraries
2024-02-08 03:17:46,374:INFO:Copying training dataset
2024-02-08 03:17:46,489:INFO:Defining folds
2024-02-08 03:17:46,490:INFO:Declaring metric variables
2024-02-08 03:17:46,490:INFO:Importing untrained model
2024-02-08 03:17:46,490:INFO:Declaring custom model
2024-02-08 03:17:46,490:INFO:CatBoost Classifier Imported successfully
2024-02-08 03:17:46,491:INFO:Starting cross validation
2024-02-08 03:17:46,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:20:33,399:INFO:Calculating mean and std
2024-02-08 03:20:33,399:INFO:Creating metrics dataframe
2024-02-08 03:20:33,402:INFO:Finalizing model
2024-02-08 03:20:36,983:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:20:37,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030307 seconds.
2024-02-08 03:20:37,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 03:20:37,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 03:20:37,073:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:20:37,074:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:20:37,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:20:58,848:INFO:Uploading results into container
2024-02-08 03:20:58,850:INFO:Uploading model into container now
2024-02-08 03:20:58,850:INFO:_master_model_container: 32
2024-02-08 03:20:58,850:INFO:_display_container: 3
2024-02-08 03:20:58,850:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8352A0>
2024-02-08 03:20:58,850:INFO:create_model() successfully completed......................................
2024-02-08 03:20:58,997:INFO:SubProcess create_model() end ==================================
2024-02-08 03:20:58,997:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8352A0> result for Accuracy is 0.9408
2024-02-08 03:20:58,998:INFO:<catboost.core.CatBoostClassifier object at 0x0000023698F8DC60> result for Accuracy is 0.9387
2024-02-08 03:20:58,998:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8352A0> is best model
2024-02-08 03:20:58,998:INFO:choose_better completed
2024-02-08 03:20:58,998:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-08 03:20:59,011:INFO:_master_model_container: 32
2024-02-08 03:20:59,011:INFO:_display_container: 2
2024-02-08 03:20:59,011:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8352A0>
2024-02-08 03:20:59,011:INFO:tune_model() successfully completed......................................
2024-02-08 03:20:59,183:INFO:Initializing tune_model()
2024-02-08 03:20:59,183:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>)
2024-02-08 03:20:59,183:INFO:Checking exceptions
2024-02-08 03:20:59,246:INFO:Copying training dataset
2024-02-08 03:20:59,334:INFO:Checking base model
2024-02-08 03:20:59,334:INFO:Base model : Light Gradient Boosting Machine
2024-02-08 03:20:59,338:INFO:Declaring metric variables
2024-02-08 03:20:59,342:INFO:Defining Hyperparameters
2024-02-08 03:20:59,505:INFO:Tuning with n_jobs=-1
2024-02-08 03:20:59,506:INFO:Initializing RandomizedSearchCV
2024-02-08 03:29:01,833:INFO:best_params: {'actual_estimator__reg_lambda': 0.3, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 170, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.8}
2024-02-08 03:29:01,834:INFO:Hyperparameter search completed
2024-02-08 03:29:01,835:INFO:SubProcess create_model() called ==================================
2024-02-08 03:29:01,836:INFO:Initializing create_model()
2024-02-08 03:29:01,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023698F22200>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.3, 'reg_alpha': 0.7, 'num_leaves': 8, 'n_estimators': 170, 'min_split_gain': 0.4, 'min_child_samples': 21, 'learning_rate': 0.3, 'feature_fraction': 0.6, 'bagging_freq': 6, 'bagging_fraction': 0.8})
2024-02-08 03:29:01,836:INFO:Checking exceptions
2024-02-08 03:29:01,836:INFO:Importing libraries
2024-02-08 03:29:01,836:INFO:Copying training dataset
2024-02-08 03:29:01,975:INFO:Defining folds
2024-02-08 03:29:01,976:INFO:Declaring metric variables
2024-02-08 03:29:01,980:INFO:Importing untrained model
2024-02-08 03:29:01,980:INFO:Declaring custom model
2024-02-08 03:29:01,985:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 03:29:01,993:INFO:Starting cross validation
2024-02-08 03:29:02,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:29:39,471:INFO:Calculating mean and std
2024-02-08 03:29:39,473:INFO:Creating metrics dataframe
2024-02-08 03:29:39,480:INFO:Finalizing model
2024-02-08 03:29:43,190:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:29:43,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030921 seconds.
2024-02-08 03:29:43,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 03:29:43,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 03:29:43,286:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:29:43,286:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:29:43,287:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:29:45,892:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 03:29:45,892:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 03:29:45,892:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 03:29:45,979:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 03:29:45,979:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 03:29:45,979:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 03:29:45,979:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:29:45,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.
2024-02-08 03:29:45,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 03:29:45,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 03:29:45,994:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 03:29:45,995:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 03:29:45,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:29:46,677:INFO:Uploading results into container
2024-02-08 03:29:46,678:INFO:Uploading model into container now
2024-02-08 03:29:46,679:INFO:_master_model_container: 33
2024-02-08 03:29:46,680:INFO:_display_container: 3
2024-02-08 03:29:46,682:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 03:29:46,683:INFO:create_model() successfully completed......................................
2024-02-08 03:29:46,848:INFO:SubProcess create_model() end ==================================
2024-02-08 03:29:46,848:INFO:choose_better activated
2024-02-08 03:29:46,852:INFO:SubProcess create_model() called ==================================
2024-02-08 03:29:46,853:INFO:Initializing create_model()
2024-02-08 03:29:46,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 03:29:46,853:INFO:Checking exceptions
2024-02-08 03:29:46,855:INFO:Importing libraries
2024-02-08 03:29:46,855:INFO:Copying training dataset
2024-02-08 03:29:46,961:INFO:Defining folds
2024-02-08 03:29:46,961:INFO:Declaring metric variables
2024-02-08 03:29:46,961:INFO:Importing untrained model
2024-02-08 03:29:46,961:INFO:Declaring custom model
2024-02-08 03:29:46,962:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 03:29:46,962:INFO:Starting cross validation
2024-02-08 03:29:46,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:30:27,095:INFO:Calculating mean and std
2024-02-08 03:30:27,096:INFO:Creating metrics dataframe
2024-02-08 03:30:27,098:INFO:Finalizing model
2024-02-08 03:30:30,754:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:30:30,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074865 seconds.
2024-02-08 03:30:30,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 03:30:30,850:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:30:30,851:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:30:30,852:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:30:33,624:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:30:33,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003687 seconds.
2024-02-08 03:30:33,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 03:30:33,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 03:30:33,636:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 03:30:33,636:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 03:30:33,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:30:34,155:INFO:Uploading results into container
2024-02-08 03:30:34,155:INFO:Uploading model into container now
2024-02-08 03:30:34,156:INFO:_master_model_container: 34
2024-02-08 03:30:34,156:INFO:_display_container: 4
2024-02-08 03:30:34,157:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 03:30:34,157:INFO:create_model() successfully completed......................................
2024-02-08 03:30:34,311:INFO:SubProcess create_model() end ==================================
2024-02-08 03:30:34,312:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9376
2024-02-08 03:30:34,312:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9388
2024-02-08 03:30:34,313:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-08 03:30:34,313:INFO:choose_better completed
2024-02-08 03:30:34,324:INFO:_master_model_container: 34
2024-02-08 03:30:34,324:INFO:_display_container: 3
2024-02-08 03:30:34,324:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 03:30:34,324:INFO:tune_model() successfully completed......................................
2024-02-08 03:30:34,499:INFO:Initializing ensemble_model()
2024-02-08 03:30:34,500:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8352A0>, method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-08 03:30:34,500:INFO:Checking exceptions
2024-02-08 03:30:34,561:INFO:Importing libraries
2024-02-08 03:30:34,561:INFO:Copying training dataset
2024-02-08 03:30:34,561:INFO:Checking base model
2024-02-08 03:30:34,561:INFO:Base model : CatBoost Classifier
2024-02-08 03:30:34,569:INFO:Importing untrained ensembler
2024-02-08 03:30:34,569:INFO:Ensemble method set to Bagging
2024-02-08 03:30:34,569:INFO:SubProcess create_model() called ==================================
2024-02-08 03:30:34,570:INFO:Initializing create_model()
2024-02-08 03:30:34,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8352A0>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27B2EC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 03:30:34,570:INFO:Checking exceptions
2024-02-08 03:30:34,570:INFO:Importing libraries
2024-02-08 03:30:34,571:INFO:Copying training dataset
2024-02-08 03:30:34,664:INFO:Defining folds
2024-02-08 03:30:34,664:INFO:Declaring metric variables
2024-02-08 03:30:34,668:INFO:Importing untrained model
2024-02-08 03:30:34,668:INFO:Declaring custom model
2024-02-08 03:30:34,672:INFO:Bagging Classifier Imported successfully
2024-02-08 03:30:34,680:INFO:Starting cross validation
2024-02-08 03:30:34,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:52:45,868:INFO:Calculating mean and std
2024-02-08 03:52:45,871:INFO:Creating metrics dataframe
2024-02-08 03:52:45,880:INFO:Finalizing model
2024-02-08 03:52:49,003:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:52:49,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060653 seconds.
2024-02-08 03:52:49,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 03:52:49,084:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:52:49,084:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:52:49,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:55:57,891:INFO:Uploading results into container
2024-02-08 03:55:57,892:INFO:Uploading model into container now
2024-02-08 03:55:57,893:INFO:_master_model_container: 35
2024-02-08 03:55:57,894:INFO:_display_container: 3
2024-02-08 03:55:57,894:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000002369A894340>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False)
2024-02-08 03:55:57,895:INFO:create_model() successfully completed......................................
2024-02-08 03:55:58,031:INFO:SubProcess create_model() end ==================================
2024-02-08 03:55:58,032:INFO:choose_better activated
2024-02-08 03:55:58,035:INFO:SubProcess create_model() called ==================================
2024-02-08 03:55:58,036:INFO:Initializing create_model()
2024-02-08 03:55:58,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8352A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 03:55:58,036:INFO:Checking exceptions
2024-02-08 03:55:58,038:INFO:Importing libraries
2024-02-08 03:55:58,038:INFO:Copying training dataset
2024-02-08 03:55:58,151:INFO:Defining folds
2024-02-08 03:55:58,151:INFO:Declaring metric variables
2024-02-08 03:55:58,151:INFO:Importing untrained model
2024-02-08 03:55:58,151:INFO:Declaring custom model
2024-02-08 03:55:58,151:INFO:CatBoost Classifier Imported successfully
2024-02-08 03:55:58,152:INFO:Starting cross validation
2024-02-08 03:55:58,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 03:58:53,890:INFO:Calculating mean and std
2024-02-08 03:58:53,891:INFO:Creating metrics dataframe
2024-02-08 03:58:53,894:INFO:Finalizing model
2024-02-08 03:58:56,821:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 03:58:56,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049613 seconds.
2024-02-08 03:58:56,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 03:58:56,888:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 03:58:56,890:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 03:58:56,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 03:59:19,396:INFO:Uploading results into container
2024-02-08 03:59:19,397:INFO:Uploading model into container now
2024-02-08 03:59:19,397:INFO:_master_model_container: 36
2024-02-08 03:59:19,397:INFO:_display_container: 4
2024-02-08 03:59:19,397:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8BF2B0>
2024-02-08 03:59:19,397:INFO:create_model() successfully completed......................................
2024-02-08 03:59:19,540:INFO:SubProcess create_model() end ==================================
2024-02-08 03:59:19,541:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8BF2B0> result for Accuracy is 0.9404
2024-02-08 03:59:19,541:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000002369A894340>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False) result for Accuracy is 0.9405
2024-02-08 03:59:19,542:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000002369A894340>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False) is best model
2024-02-08 03:59:19,542:INFO:choose_better completed
2024-02-08 03:59:19,554:INFO:_master_model_container: 36
2024-02-08 03:59:19,555:INFO:_display_container: 3
2024-02-08 03:59:19,555:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=<catboost.core.CatBoostClassifier object at 0x000002369A894340>,
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False)
2024-02-08 03:59:19,555:INFO:ensemble_model() successfully completed......................................
2024-02-08 03:59:19,688:INFO:Initializing ensemble_model()
2024-02-08 03:59:19,688:INFO:ensemble_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-08 03:59:19,688:INFO:Checking exceptions
2024-02-08 03:59:19,741:INFO:Importing libraries
2024-02-08 03:59:19,741:INFO:Copying training dataset
2024-02-08 03:59:19,742:INFO:Checking base model
2024-02-08 03:59:19,742:INFO:Base model : Light Gradient Boosting Machine
2024-02-08 03:59:19,750:INFO:Importing untrained ensembler
2024-02-08 03:59:19,750:INFO:Ensemble method set to Bagging
2024-02-08 03:59:19,751:INFO:SubProcess create_model() called ==================================
2024-02-08 03:59:19,752:INFO:Initializing create_model()
2024-02-08 03:59:19,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.3, max_depth=-1,
                                           min_child_samples=21,
                                           min_child_weight=0.001,
                                           min_split_gain=0.4, n_estimators=170,
                                           n_jobs=-1, num_leaves=8,
                                           objective=None, random_state=6300,
                                           reg_alpha=0.7, reg_lambda=0.3,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023698F220E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 03:59:19,753:INFO:Checking exceptions
2024-02-08 03:59:19,753:INFO:Importing libraries
2024-02-08 03:59:19,753:INFO:Copying training dataset
2024-02-08 03:59:19,854:INFO:Defining folds
2024-02-08 03:59:19,854:INFO:Declaring metric variables
2024-02-08 03:59:19,858:INFO:Importing untrained model
2024-02-08 03:59:19,858:INFO:Declaring custom model
2024-02-08 03:59:19,863:INFO:Bagging Classifier Imported successfully
2024-02-08 03:59:19,871:INFO:Starting cross validation
2024-02-08 03:59:19,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:01:12,250:INFO:Calculating mean and std
2024-02-08 04:01:12,252:INFO:Creating metrics dataframe
2024-02-08 04:01:12,265:INFO:Finalizing model
2024-02-08 04:01:17,748:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:17,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071331 seconds.
2024-02-08 04:01:17,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:01:17,842:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:01:17,844:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:01:17,845:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:01:20,151:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:20,152:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:20,152:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:20,247:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:20,247:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:20,247:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:20,247:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:20,262:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011669 seconds.
2024-02-08 04:01:20,262:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:01:20,263:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:20,263:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:20,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499682 -> initscore=-0.001273
2024-02-08 04:01:20,264:INFO:[LightGBM] [Info] Start training from score -0.001273
2024-02-08 04:01:20,965:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:20,965:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:20,965:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:21,094:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:21,095:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:21,095:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:21,095:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:21,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004545 seconds.
2024-02-08 04:01:21,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:21,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:21,117:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:21,117:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:21,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501045 -> initscore=0.004181
2024-02-08 04:01:21,120:INFO:[LightGBM] [Info] Start training from score 0.004181
2024-02-08 04:01:21,871:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:21,871:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:21,871:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:21,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:21,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:21,974:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:21,975:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:21,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003590 seconds.
2024-02-08 04:01:21,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:21,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:21,993:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:21,994:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:21,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502511 -> initscore=0.010044
2024-02-08 04:01:21,995:INFO:[LightGBM] [Info] Start training from score 0.010044
2024-02-08 04:01:22,964:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:22,964:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:22,964:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:23,077:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:23,077:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:23,077:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:23,077:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:23,094:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005243 seconds.
2024-02-08 04:01:23,094:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:23,094:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:23,095:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:23,095:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:23,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499534 -> initscore=-0.001863
2024-02-08 04:01:23,097:INFO:[LightGBM] [Info] Start training from score -0.001863
2024-02-08 04:01:24,121:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:24,121:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:24,121:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:24,261:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:24,261:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:24,262:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:24,262:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:24,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004959 seconds.
2024-02-08 04:01:24,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:24,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:24,283:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:24,283:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:24,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498455 -> initscore=-0.006181
2024-02-08 04:01:24,285:INFO:[LightGBM] [Info] Start training from score -0.006181
2024-02-08 04:01:25,359:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:25,359:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:25,359:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:25,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:25,483:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:25,483:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:25,484:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:25,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014411 seconds.
2024-02-08 04:01:25,503:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:01:25,503:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:25,503:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:25,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498637 -> initscore=-0.005454
2024-02-08 04:01:25,505:INFO:[LightGBM] [Info] Start training from score -0.005454
2024-02-08 04:01:26,385:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:26,385:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:26,385:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:26,532:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:26,534:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:26,534:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:26,534:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:26,554:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.
2024-02-08 04:01:26,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:26,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:26,555:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:26,555:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:26,557:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499875 -> initscore=-0.000500
2024-02-08 04:01:26,557:INFO:[LightGBM] [Info] Start training from score -0.000500
2024-02-08 04:01:27,606:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:27,607:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:27,607:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:27,722:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:27,722:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:27,722:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:27,722:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:27,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005579 seconds.
2024-02-08 04:01:27,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:27,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:27,748:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:27,748:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:27,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498205 -> initscore=-0.007181
2024-02-08 04:01:27,750:INFO:[LightGBM] [Info] Start training from score -0.007181
2024-02-08 04:01:28,783:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:28,783:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:28,783:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:28,929:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:28,930:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:28,930:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:28,930:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:28,953:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018617 seconds.
2024-02-08 04:01:28,953:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:01:28,954:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:28,954:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:28,956:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498057 -> initscore=-0.007772
2024-02-08 04:01:28,956:INFO:[LightGBM] [Info] Start training from score -0.007772
2024-02-08 04:01:29,776:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:29,776:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:29,776:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:29,912:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:01:29,912:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:01:29,912:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:01:29,912:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:01:29,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005730 seconds.
2024-02-08 04:01:29,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:01:29,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:01:29,933:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:01:29,933:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:01:29,936:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500545 -> initscore=0.002181
2024-02-08 04:01:29,936:INFO:[LightGBM] [Info] Start training from score 0.002181
2024-02-08 04:01:30,909:INFO:Uploading results into container
2024-02-08 04:01:30,912:INFO:Uploading model into container now
2024-02-08 04:01:30,913:INFO:_master_model_container: 37
2024-02-08 04:01:30,913:INFO:_display_container: 4
2024-02-08 04:01:30,917:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.3, max_depth=-1,
                                           min_child_samples=21,
                                           min_child_weight=0.001,
                                           min_split_gain=0.4, n_estimators=170,
                                           n_jobs=-1, num_leaves=8,
                                           objective=None, random_state=6300,
                                           reg_alpha=0.7, reg_lambda=0.3,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False)
2024-02-08 04:01:30,917:INFO:create_model() successfully completed......................................
2024-02-08 04:01:31,085:INFO:SubProcess create_model() end ==================================
2024-02-08 04:01:31,085:INFO:choose_better activated
2024-02-08 04:01:31,090:INFO:SubProcess create_model() called ==================================
2024-02-08 04:01:31,091:INFO:Initializing create_model()
2024-02-08 04:01:31,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:01:31,092:INFO:Checking exceptions
2024-02-08 04:01:31,094:INFO:Importing libraries
2024-02-08 04:01:31,094:INFO:Copying training dataset
2024-02-08 04:01:31,213:INFO:Defining folds
2024-02-08 04:01:31,213:INFO:Declaring metric variables
2024-02-08 04:01:31,213:INFO:Importing untrained model
2024-02-08 04:01:31,213:INFO:Declaring custom model
2024-02-08 04:01:31,214:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 04:01:31,215:INFO:Starting cross validation
2024-02-08 04:01:31,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:02:10,472:INFO:Calculating mean and std
2024-02-08 04:02:10,473:INFO:Creating metrics dataframe
2024-02-08 04:02:10,477:INFO:Finalizing model
2024-02-08 04:02:13,629:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:02:13,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054768 seconds.
2024-02-08 04:02:13,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:02:13,703:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:02:13,704:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:02:13,705:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:02:16,221:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:02:16,221:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:02:16,221:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:02:16,328:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2024-02-08 04:02:16,328:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2024-02-08 04:02:16,329:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-08 04:02:16,329:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:02:16,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005255 seconds.
2024-02-08 04:02:16,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:02:16,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:02:16,350:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:02:16,350:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:02:16,352:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:02:17,336:INFO:Uploading results into container
2024-02-08 04:02:17,337:INFO:Uploading model into container now
2024-02-08 04:02:17,338:INFO:_master_model_container: 38
2024-02-08 04:02:17,338:INFO:_display_container: 5
2024-02-08 04:02:17,339:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 04:02:17,340:INFO:create_model() successfully completed......................................
2024-02-08 04:02:17,504:INFO:SubProcess create_model() end ==================================
2024-02-08 04:02:17,505:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=170, n_jobs=-1, num_leaves=8, objective=None,
               random_state=6300, reg_alpha=0.7, reg_lambda=0.3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9387
2024-02-08 04:02:17,507:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.3, max_depth=-1,
                                           min_child_samples=21,
                                           min_child_weight=0.001,
                                           min_split_gain=0.4, n_estimators=170,
                                           n_jobs=-1, num_leaves=8,
                                           objective=None, random_state=6300,
                                           reg_alpha=0.7, reg_lambda=0.3,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False) result for Accuracy is 0.9401
2024-02-08 04:02:17,509:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.3, max_depth=-1,
                                           min_child_samples=21,
                                           min_child_weight=0.001,
                                           min_split_gain=0.4, n_estimators=170,
                                           n_jobs=-1, num_leaves=8,
                                           objective=None, random_state=6300,
                                           reg_alpha=0.7, reg_lambda=0.3,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False) is best model
2024-02-08 04:02:17,509:INFO:choose_better completed
2024-02-08 04:02:17,520:INFO:_master_model_container: 38
2024-02-08 04:02:17,520:INFO:_display_container: 4
2024-02-08 04:02:17,522:INFO:BaggingClassifier(base_estimator='deprecated', bootstrap=True,
                  bootstrap_features=False,
                  estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=6,
                                           boosting_type='gbdt',
                                           class_weight=None,
                                           colsample_bytree=1.0,
                                           feature_fraction=0.6,
                                           importance_type='split',
                                           learning_rate=0.3, max_depth=-1,
                                           min_child_samples=21,
                                           min_child_weight=0.001,
                                           min_split_gain=0.4, n_estimators=170,
                                           n_jobs=-1, num_leaves=8,
                                           objective=None, random_state=6300,
                                           reg_alpha=0.7, reg_lambda=0.3,
                                           subsample=1.0,
                                           subsample_for_bin=200000,
                                           subsample_freq=0),
                  max_features=1.0, max_samples=1.0, n_estimators=10,
                  n_jobs=None, oob_score=False, random_state=6300, verbose=0,
                  warm_start=False)
2024-02-08 04:02:17,522:INFO:ensemble_model() successfully completed......................................
2024-02-08 04:02:17,700:INFO:Initializing blend_models()
2024-02-08 04:02:17,700:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=True, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-08 04:02:17,701:INFO:Checking exceptions
2024-02-08 04:02:17,769:INFO:Importing libraries
2024-02-08 04:02:17,770:INFO:Copying training dataset
2024-02-08 04:02:17,775:INFO:Getting model names
2024-02-08 04:02:17,781:INFO:SubProcess create_model() called ==================================
2024-02-08 04:02:17,784:INFO:Initializing create_model()
2024-02-08 04:02:17,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023698F22110>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6300, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002369A81BD30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:02:17,784:INFO:Checking exceptions
2024-02-08 04:02:17,784:INFO:Importing libraries
2024-02-08 04:02:17,784:INFO:Copying training dataset
2024-02-08 04:02:17,912:INFO:Defining folds
2024-02-08 04:02:17,912:INFO:Declaring metric variables
2024-02-08 04:02:17,916:INFO:Importing untrained model
2024-02-08 04:02:17,916:INFO:Declaring custom model
2024-02-08 04:02:17,922:INFO:Voting Classifier Imported successfully
2024-02-08 04:02:17,931:INFO:Starting cross validation
2024-02-08 04:02:17,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:05:06,997:INFO:Calculating mean and std
2024-02-08 04:05:06,998:INFO:Creating metrics dataframe
2024-02-08 04:05:07,005:INFO:Finalizing model
2024-02-08 04:05:10,641:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:05:10,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078696 seconds.
2024-02-08 04:05:10,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:05:10,739:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:05:10,740:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:05:10,741:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:05:32,683:INFO:Uploading results into container
2024-02-08 04:05:32,684:INFO:Uploading model into container now
2024-02-08 04:05:32,685:INFO:_master_model_container: 39
2024-02-08 04:05:32,685:INFO:_display_container: 4
2024-02-08 04:05:32,691:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002369A8C4FA0>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6300, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-08 04:05:32,691:INFO:create_model() successfully completed......................................
2024-02-08 04:05:32,841:INFO:SubProcess create_model() end ==================================
2024-02-08 04:05:32,841:INFO:choose_better activated
2024-02-08 04:05:32,847:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002369A8C4FA0>),
                             ('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=6300, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for Accuracy is 0.9403
2024-02-08 04:05:32,848:INFO:SubProcess create_model() called ==================================
2024-02-08 04:05:32,848:INFO:Initializing create_model()
2024-02-08 04:05:32,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:05:32,848:INFO:Checking exceptions
2024-02-08 04:05:32,850:INFO:Importing libraries
2024-02-08 04:05:32,850:INFO:Copying training dataset
2024-02-08 04:05:32,963:INFO:Defining folds
2024-02-08 04:05:32,963:INFO:Declaring metric variables
2024-02-08 04:05:32,963:INFO:Importing untrained model
2024-02-08 04:05:32,964:INFO:Declaring custom model
2024-02-08 04:05:32,964:INFO:CatBoost Classifier Imported successfully
2024-02-08 04:05:32,965:INFO:Starting cross validation
2024-02-08 04:05:32,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:08:21,534:INFO:Calculating mean and std
2024-02-08 04:08:21,535:INFO:Creating metrics dataframe
2024-02-08 04:08:21,537:INFO:Finalizing model
2024-02-08 04:08:24,561:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:08:24,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024688 seconds.
2024-02-08 04:08:24,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:08:24,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:08:24,648:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:08:24,649:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:08:24,650:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:08:46,065:INFO:Uploading results into container
2024-02-08 04:08:46,066:INFO:Uploading model into container now
2024-02-08 04:08:46,066:INFO:_master_model_container: 40
2024-02-08 04:08:46,066:INFO:_display_container: 5
2024-02-08 04:08:46,066:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A837B50>
2024-02-08 04:08:46,066:INFO:create_model() successfully completed......................................
2024-02-08 04:08:46,220:INFO:SubProcess create_model() end ==================================
2024-02-08 04:08:46,220:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A837B50> result for Accuracy is 0.9411
2024-02-08 04:08:46,220:INFO:SubProcess create_model() called ==================================
2024-02-08 04:08:46,221:INFO:Initializing create_model()
2024-02-08 04:08:46,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:08:46,221:INFO:Checking exceptions
2024-02-08 04:08:46,223:INFO:Importing libraries
2024-02-08 04:08:46,223:INFO:Copying training dataset
2024-02-08 04:08:46,335:INFO:Defining folds
2024-02-08 04:08:46,335:INFO:Declaring metric variables
2024-02-08 04:08:46,335:INFO:Importing untrained model
2024-02-08 04:08:46,335:INFO:Declaring custom model
2024-02-08 04:08:46,336:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 04:08:46,336:INFO:Starting cross validation
2024-02-08 04:08:46,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:09:26,098:INFO:Calculating mean and std
2024-02-08 04:09:26,098:INFO:Creating metrics dataframe
2024-02-08 04:09:26,103:INFO:Finalizing model
2024-02-08 04:09:29,033:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:09:29,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043452 seconds.
2024-02-08 04:09:29,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:09:29,090:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:09:29,091:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:09:29,092:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:09:31,069:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:09:31,088:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005192 seconds.
2024-02-08 04:09:31,088:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:09:31,088:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:09:31,088:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:09:31,089:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:09:31,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:09:31,798:INFO:Uploading results into container
2024-02-08 04:09:31,799:INFO:Uploading model into container now
2024-02-08 04:09:31,800:INFO:_master_model_container: 41
2024-02-08 04:09:31,800:INFO:_display_container: 5
2024-02-08 04:09:31,801:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 04:09:31,801:INFO:create_model() successfully completed......................................
2024-02-08 04:09:31,962:INFO:SubProcess create_model() end ==================================
2024-02-08 04:09:31,963:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9374
2024-02-08 04:09:31,963:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A837B50> is best model
2024-02-08 04:09:31,963:INFO:choose_better completed
2024-02-08 04:09:31,963:INFO:Original model was better than the blended model, hence it will be returned. NOTE: The display metrics are for the blended model (not the original one).
2024-02-08 04:09:31,976:INFO:_master_model_container: 41
2024-02-08 04:09:31,976:INFO:_display_container: 4
2024-02-08 04:09:31,976:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A837B50>
2024-02-08 04:09:31,976:INFO:blend_models() successfully completed......................................
2024-02-08 04:09:32,175:INFO:Initializing stack_models()
2024-02-08 04:09:32,175:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=True, choose_better=True, optimize=Accuracy, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-08 04:09:32,175:INFO:Checking exceptions
2024-02-08 04:09:32,232:INFO:Defining meta model
2024-02-08 04:09:32,260:INFO:Getting model names
2024-02-08 04:09:32,260:INFO:[('CatBoost Classifier', <catboost.core.CatBoostClassifier object at 0x0000023698F22110>), ('Light Gradient Boosting Machine', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0))]
2024-02-08 04:09:32,267:INFO:SubProcess create_model() called ==================================
2024-02-08 04:09:32,273:INFO:Initializing create_model()
2024-02-08 04:09:32,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x0000023698F22110>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6300,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236E27B2EC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:09:32,273:INFO:Checking exceptions
2024-02-08 04:09:32,273:INFO:Importing libraries
2024-02-08 04:09:32,274:INFO:Copying training dataset
2024-02-08 04:09:32,408:INFO:Defining folds
2024-02-08 04:09:32,408:INFO:Declaring metric variables
2024-02-08 04:09:32,412:INFO:Importing untrained model
2024-02-08 04:09:32,412:INFO:Declaring custom model
2024-02-08 04:09:32,418:INFO:Stacking Classifier Imported successfully
2024-02-08 04:09:32,426:INFO:Starting cross validation
2024-02-08 04:09:32,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:19:22,140:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:22,285:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:22,290:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:25,305:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:37,844:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:40,462:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:47,330:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:19:53,722:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:22:31,158:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:22:33,869:WARNING:C:\ProgramData\miniconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-02-08 04:22:34,190:INFO:Calculating mean and std
2024-02-08 04:22:34,191:INFO:Creating metrics dataframe
2024-02-08 04:22:34,197:INFO:Finalizing model
2024-02-08 04:22:37,618:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:22:37,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051123 seconds.
2024-02-08 04:22:37,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:22:37,685:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:22:37,686:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:22:37,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:24:10,126:INFO:Uploading results into container
2024-02-08 04:24:10,127:INFO:Uploading model into container now
2024-02-08 04:24:10,129:INFO:_master_model_container: 42
2024-02-08 04:24:10,129:INFO:_display_container: 4
2024-02-08 04:24:10,133:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x000002369A894580>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6300,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0)
2024-02-08 04:24:10,133:INFO:create_model() successfully completed......................................
2024-02-08 04:24:10,296:INFO:SubProcess create_model() end ==================================
2024-02-08 04:24:10,297:INFO:choose_better activated
2024-02-08 04:24:10,304:INFO:StackingClassifier(cv=5,
                   estimators=[('CatBoost Classifier',
                                <catboost.core.CatBoostClassifier object at 0x000002369A894580>),
                               ('Light Gradient Boosting Machine',
                                LGBMClassifier(boosting_type='gbdt',
                                               class_weight=None,
                                               colsample_bytree=1.0,
                                               importance_type='split',
                                               learning_rate=0.1, max_depth=-1,
                                               min_child_samples=20,
                                               min_child_weight=0.001,
                                               min_split_gain=0.0,
                                               n_est...
                                               subsample_for_bin=200000,
                                               subsample_freq=0))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6300,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=True, stack_method='auto', verbose=0) result for Accuracy is 0.9061
2024-02-08 04:24:10,304:INFO:SubProcess create_model() called ==================================
2024-02-08 04:24:10,304:INFO:Initializing create_model()
2024-02-08 04:24:10,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023698F22110>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:24:10,305:INFO:Checking exceptions
2024-02-08 04:24:10,307:INFO:Importing libraries
2024-02-08 04:24:10,307:INFO:Copying training dataset
2024-02-08 04:24:10,412:INFO:Defining folds
2024-02-08 04:24:10,412:INFO:Declaring metric variables
2024-02-08 04:24:10,412:INFO:Importing untrained model
2024-02-08 04:24:10,412:INFO:Declaring custom model
2024-02-08 04:24:10,412:INFO:CatBoost Classifier Imported successfully
2024-02-08 04:24:10,413:INFO:Starting cross validation
2024-02-08 04:24:10,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:26:57,415:INFO:Calculating mean and std
2024-02-08 04:26:57,416:INFO:Creating metrics dataframe
2024-02-08 04:26:57,419:INFO:Finalizing model
2024-02-08 04:27:00,976:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:27:01,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079684 seconds.
2024-02-08 04:27:01,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:27:01,077:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:27:01,078:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:27:01,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:27:22,624:INFO:Uploading results into container
2024-02-08 04:27:22,625:INFO:Uploading model into container now
2024-02-08 04:27:22,625:INFO:_master_model_container: 43
2024-02-08 04:27:22,625:INFO:_display_container: 5
2024-02-08 04:27:22,625:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A899720>
2024-02-08 04:27:22,625:INFO:create_model() successfully completed......................................
2024-02-08 04:27:22,762:INFO:SubProcess create_model() end ==================================
2024-02-08 04:27:22,762:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A899720> result for Accuracy is 0.9405
2024-02-08 04:27:22,762:INFO:SubProcess create_model() called ==================================
2024-02-08 04:27:22,763:INFO:Initializing create_model()
2024-02-08 04:27:22,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:27:22,763:INFO:Checking exceptions
2024-02-08 04:27:22,765:INFO:Importing libraries
2024-02-08 04:27:22,765:INFO:Copying training dataset
2024-02-08 04:27:22,880:INFO:Defining folds
2024-02-08 04:27:22,880:INFO:Declaring metric variables
2024-02-08 04:27:22,880:INFO:Importing untrained model
2024-02-08 04:27:22,880:INFO:Declaring custom model
2024-02-08 04:27:22,881:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-08 04:27:22,881:INFO:Starting cross validation
2024-02-08 04:27:22,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-08 04:28:04,586:INFO:Calculating mean and std
2024-02-08 04:28:04,587:INFO:Creating metrics dataframe
2024-02-08 04:28:04,589:INFO:Finalizing model
2024-02-08 04:28:08,131:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:28:08,227:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076413 seconds.
2024-02-08 04:28:08,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:28:08,229:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:28:08,230:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:28:08,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:28:11,046:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:28:11,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003470 seconds.
2024-02-08 04:28:11,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-08 04:28:11,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-08 04:28:11,061:INFO:[LightGBM] [Info] Total Bins 6375
2024-02-08 04:28:11,061:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 25
2024-02-08 04:28:11,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:28:11,538:INFO:Uploading results into container
2024-02-08 04:28:11,539:INFO:Uploading model into container now
2024-02-08 04:28:11,539:INFO:_master_model_container: 44
2024-02-08 04:28:11,540:INFO:_display_container: 5
2024-02-08 04:28:11,540:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-08 04:28:11,540:INFO:create_model() successfully completed......................................
2024-02-08 04:28:11,701:INFO:SubProcess create_model() end ==================================
2024-02-08 04:28:11,701:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9375
2024-02-08 04:28:11,701:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A899720> is best model
2024-02-08 04:28:11,701:INFO:choose_better completed
2024-02-08 04:28:11,702:INFO:Original model was better than the stacked model, hence it will be returned. NOTE: The display metrics are for the stacked model (not the original one).
2024-02-08 04:28:11,714:INFO:_master_model_container: 44
2024-02-08 04:28:11,714:INFO:_display_container: 4
2024-02-08 04:28:11,714:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A899720>
2024-02-08 04:28:11,714:INFO:stack_models() successfully completed......................................
2024-02-08 04:28:11,876:INFO:Initializing automl()
2024-02-08 04:28:11,876:INFO:automl(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, optimize=Accuracy, use_holdout=False, turbo=True, return_train_score=False)
2024-02-08 04:28:11,876:INFO:Model Selection Basis : CV Results on Training set
2024-02-08 04:28:11,876:INFO:Checking model 0
2024-02-08 04:28:11,876:INFO:Checking model 1
2024-02-08 04:28:11,876:INFO:Checking model 2
2024-02-08 04:28:11,877:INFO:Checking model 3
2024-02-08 04:28:11,877:INFO:Checking model 4
2024-02-08 04:28:11,877:INFO:Checking model 5
2024-02-08 04:28:11,877:INFO:Checking model 6
2024-02-08 04:28:11,877:INFO:Checking model 7
2024-02-08 04:28:11,878:INFO:Checking model 8
2024-02-08 04:28:11,878:INFO:Checking model 9
2024-02-08 04:28:11,878:INFO:Checking model 10
2024-02-08 04:28:11,878:INFO:Checking model 11
2024-02-08 04:28:11,878:INFO:Checking model 12
2024-02-08 04:28:11,879:INFO:Checking model 13
2024-02-08 04:28:11,879:INFO:Checking model 14
2024-02-08 04:28:11,879:INFO:Checking model 15
2024-02-08 04:28:11,879:INFO:Checking model 16
2024-02-08 04:28:11,879:INFO:Checking model 17
2024-02-08 04:28:11,879:INFO:Checking model 18
2024-02-08 04:28:11,880:INFO:Checking model 19
2024-02-08 04:28:11,880:INFO:Checking model 20
2024-02-08 04:28:11,880:INFO:Checking model 21
2024-02-08 04:28:11,880:INFO:Checking model 22
2024-02-08 04:28:11,880:INFO:Checking model 23
2024-02-08 04:28:11,881:INFO:Checking model 24
2024-02-08 04:28:11,881:INFO:Checking model 25
2024-02-08 04:28:11,881:INFO:Checking model 26
2024-02-08 04:28:11,881:INFO:Checking model 27
2024-02-08 04:28:11,881:INFO:Checking model 28
2024-02-08 04:28:11,882:INFO:Checking model 29
2024-02-08 04:28:11,882:INFO:Checking model 30
2024-02-08 04:28:11,882:INFO:Checking model 31
2024-02-08 04:28:11,882:INFO:Checking model 32
2024-02-08 04:28:11,882:INFO:Checking model 33
2024-02-08 04:28:11,882:INFO:Checking model 34
2024-02-08 04:28:11,883:INFO:Checking model 35
2024-02-08 04:28:11,883:INFO:Checking model 36
2024-02-08 04:28:11,883:INFO:Checking model 37
2024-02-08 04:28:11,884:INFO:Checking model 38
2024-02-08 04:28:11,884:INFO:Checking model 39
2024-02-08 04:28:11,884:INFO:Checking model 40
2024-02-08 04:28:11,884:INFO:Checking model 41
2024-02-08 04:28:11,885:INFO:Checking model 42
2024-02-08 04:28:11,885:INFO:Checking model 43
2024-02-08 04:28:11,885:INFO:Initializing create_model()
2024-02-08 04:28:11,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A837B50>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:28:11,885:INFO:Checking exceptions
2024-02-08 04:28:11,887:INFO:Importing libraries
2024-02-08 04:28:11,887:INFO:Copying training dataset
2024-02-08 04:28:11,989:INFO:Defining folds
2024-02-08 04:28:11,989:INFO:Declaring metric variables
2024-02-08 04:28:11,989:INFO:Importing untrained model
2024-02-08 04:28:11,989:INFO:Declaring custom model
2024-02-08 04:28:11,990:INFO:CatBoost Classifier Imported successfully
2024-02-08 04:28:12,000:INFO:Cross validation set to False
2024-02-08 04:28:12,000:INFO:Fitting Model
2024-02-08 04:28:15,078:INFO:[LightGBM] [Info] Number of positive: 44007, number of negative: 44007
2024-02-08 04:28:15,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076674 seconds.
2024-02-08 04:28:15,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:28:15,181:INFO:[LightGBM] [Info] Total Bins 31359
2024-02-08 04:28:15,182:INFO:[LightGBM] [Info] Number of data points in the train set: 88014, number of used features: 123
2024-02-08 04:28:15,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:28:37,702:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>
2024-02-08 04:28:37,702:INFO:create_model() successfully completed......................................
2024-02-08 04:28:37,985:INFO:<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>
2024-02-08 04:28:37,985:INFO:automl() successfully completed......................................
2024-02-08 04:28:38,007:INFO:Initializing predict_model()
2024-02-08 04:28:38,007:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002369A8AA290>)
2024-02-08 04:28:38,007:INFO:Checking exceptions
2024-02-08 04:28:38,007:INFO:Preloading libraries
2024-02-08 04:28:38,548:INFO:Initializing finalize_model()
2024-02-08 04:28:38,548:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-08 04:28:38,548:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000002369A8944C0>
2024-02-08 04:28:38,620:INFO:Initializing create_model()
2024-02-08 04:28:38,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 04:28:38,620:INFO:Checking exceptions
2024-02-08 04:28:38,622:INFO:Importing libraries
2024-02-08 04:28:38,622:INFO:Copying training dataset
2024-02-08 04:28:38,630:INFO:Defining folds
2024-02-08 04:28:38,630:INFO:Declaring metric variables
2024-02-08 04:28:38,630:INFO:Importing untrained model
2024-02-08 04:28:38,631:INFO:Declaring custom model
2024-02-08 04:28:38,631:INFO:CatBoost Classifier Imported successfully
2024-02-08 04:28:38,643:INFO:Cross validation set to False
2024-02-08 04:28:38,643:INFO:Fitting Model
2024-02-08 04:28:42,966:INFO:[LightGBM] [Info] Number of positive: 62867, number of negative: 62867
2024-02-08 04:28:43,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088156 seconds.
2024-02-08 04:28:43,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 04:28:43,083:INFO:[LightGBM] [Info] Total Bins 31358
2024-02-08 04:28:43,084:INFO:[LightGBM] [Info] Number of data points in the train set: 125734, number of used features: 123
2024-02-08 04:28:43,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 04:29:10,229:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8970D0>)],
         verbose=False)
2024-02-08 04:29:10,229:INFO:create_model() successfully completed......................................
2024-02-08 04:29:10,355:INFO:_master_model_container: 44
2024-02-08 04:29:10,355:INFO:_display_container: 4
2024-02-08 04:29:10,370:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8970D0>)],
         verbose=False)
2024-02-08 04:29:10,370:INFO:finalize_model() successfully completed......................................
2024-02-08 04:29:10,515:INFO:Initializing predict_model()
2024-02-08 04:29:10,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8970D0>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002369A8A92D0>)
2024-02-08 04:29:10,516:INFO:Checking exceptions
2024-02-08 04:29:10,516:INFO:Preloading libraries
2024-02-08 09:04:22,024:INFO:Initializing finalize_model()
2024-02-08 09:04:22,025:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-08 09:04:22,025:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000002369A8944C0>
2024-02-08 09:04:22,093:INFO:Initializing create_model()
2024-02-08 09:04:22,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-08 09:04:22,093:INFO:Checking exceptions
2024-02-08 09:04:22,095:INFO:Importing libraries
2024-02-08 09:04:22,096:INFO:Copying training dataset
2024-02-08 09:04:22,104:INFO:Defining folds
2024-02-08 09:04:22,104:INFO:Declaring metric variables
2024-02-08 09:04:22,105:INFO:Importing untrained model
2024-02-08 09:04:22,105:INFO:Declaring custom model
2024-02-08 09:04:22,105:INFO:CatBoost Classifier Imported successfully
2024-02-08 09:04:22,115:INFO:Cross validation set to False
2024-02-08 09:04:22,116:INFO:Fitting Model
2024-02-08 09:04:26,680:INFO:[LightGBM] [Info] Number of positive: 62867, number of negative: 62867
2024-02-08 09:04:26,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060136 seconds.
2024-02-08 09:04:26,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-08 09:04:26,772:INFO:[LightGBM] [Info] Total Bins 31358
2024-02-08 09:04:26,773:INFO:[LightGBM] [Info] Number of data points in the train set: 125734, number of used features: 123
2024-02-08 09:04:26,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-08 09:04:47,162:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False)
2024-02-08 09:04:47,162:INFO:create_model() successfully completed......................................
2024-02-08 09:04:47,298:INFO:_master_model_container: 44
2024-02-08 09:04:47,298:INFO:_display_container: 4
2024-02-08 09:04:47,313:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False)
2024-02-08 09:04:47,313:INFO:finalize_model() successfully completed......................................
2024-02-08 09:04:52,888:INFO:Initializing predict_model()
2024-02-08 09:04:52,888:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236829BB0A0>)
2024-02-08 09:04:52,889:INFO:Checking exceptions
2024-02-08 09:04:52,889:INFO:Preloading libraries
2024-02-08 09:05:01,709:INFO:Initializing predict_model()
2024-02-08 09:05:01,709:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002369AA97A30>)
2024-02-08 09:05:01,709:INFO:Checking exceptions
2024-02-08 09:05:01,709:INFO:Preloading libraries
2024-02-08 09:05:01,712:INFO:Set up data.
2024-02-08 09:05:01,801:INFO:Set up index.
2024-02-08 09:07:27,050:INFO:Initializing predict_model()
2024-02-08 09:07:27,050:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236FBA6BBE0>)
2024-02-08 09:07:27,050:INFO:Checking exceptions
2024-02-08 09:07:27,051:INFO:Preloading libraries
2024-02-08 09:07:27,054:INFO:Set up data.
2024-02-08 09:07:27,149:INFO:Set up index.
2024-02-08 09:13:52,493:INFO:Initializing predict_model()
2024-02-08 09:13:52,494:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236FBA6A0E0>)
2024-02-08 09:13:52,494:INFO:Checking exceptions
2024-02-08 09:13:52,494:INFO:Preloading libraries
2024-02-08 09:13:52,496:INFO:Set up data.
2024-02-08 09:13:52,609:INFO:Set up index.
2024-02-08 09:14:23,319:INFO:Initializing predict_model()
2024-02-08 09:14:23,319:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['id', 'last_date_of_month_7',
                                             'last_date_of_month_8', 'arpu_6',
                                             'arpu_7', 'arpu_8', 'onnet_mou_6',
                                             'onnet_mou_7', 'onnet_mou_8',
                                             'offnet_mou_6', 'offnet_mou_7',
                                             'offnet_mou_8', 'roam_ic_mou_6',
                                             'roam_ic_mou_7', 'roam_ic_mou_8',
                                             'roam_og_mou_6', 'roam_og_mou_7...
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=25,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000002369A8988E0>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023704BBFE20>)
2024-02-08 09:14:23,319:INFO:Checking exceptions
2024-02-08 09:14:23,319:INFO:Preloading libraries
2024-02-08 09:14:23,322:INFO:Set up data.
2024-02-08 09:14:23,408:INFO:Set up index.
2024-02-08 09:14:56,108:INFO:Initializing predict_model()
2024-02-08 09:14:56,108:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236E1BC6FE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002369A8944C0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236FBA6B880>)
2024-02-08 09:14:56,109:INFO:Checking exceptions
2024-02-08 09:14:56,109:INFO:Preloading libraries
2024-02-08 09:14:56,112:INFO:Set up data.
2024-02-08 09:14:56,201:INFO:Set up index.
