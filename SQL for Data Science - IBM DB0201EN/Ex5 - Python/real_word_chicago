from urllib.request import urlopen
import json
import pandas as pd

df = pd.read_json('https://data.cityofchicago.org/resource/9xs2-f89t.json')

#Get df metadata
list(df)

#Cut unnecessary columns
df.drop(columns=[ ':@computed_region_rpca_8um6',
 ':@computed_region_vrxf_vc4k',
 ':@computed_region_6mkv_f3dw',
 ':@computed_region_bdys_3d7i',
 ':@computed_region_43wa_7qmu',
 ':@computed_region_awaf_s7ux'], axis=1, inplace=True)
 
#Connect to SQL 
import psycopg2
import IPython
import pandas.io.sql as sqlio
import psycopg2

%load_ext sql
%sql postgresql+psycopg2://postgres:5677@/IBM_SQL

#Check connection with SQL query
%%sql
SELECT * FROM information_schema.tables

#####import lib to create engine
from sqlalchemy import create_engine

#export dataframe to SQL as table
engine = create_engine('postgresql://postgres:5677@/IBM_SQL')


#display max columnis in dataset
pd.set_option('max_columns', None)

#convert link to string
df['link_'] = df['link_'].astype('str') 

#describe dataframe
df.info()

#clean column link_ and sheck values
df['link_'] = df['link_'].str.replace("{'url': ","")
df['link_'] = df['link_'].str.replace("}","")

#clean json dump
for column in df:
    df[column] = df[column].apply(json.dumps)
    
#delete all quotes from dataframe
df = df.replace('"', '', regex=True) 
    
#upload file 
df.to_sql('chicago', engine)